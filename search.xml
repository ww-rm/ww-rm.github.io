<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>序</title>
    <url>//posts/2021/05/21/%E5%BA%8F%E8%A8%80/</url>
    <content><![CDATA[<blockquote>
<p>山不在高，有仙则名。</p>
<p>水不在深，有龙则灵。</p>
<p>斯是陋室，惟吾德馨。</p>
<p>苔痕上阶绿，草色入帘青。</p>
<p>谈笑有鸿儒，往来无白丁。</p>
<p>可以调素琴，阅金经。</p>
<p>无丝竹之乱耳，无案牍之劳形。</p>
<p>南阳诸葛庐，西蜀子云亭。</p>
<p>孔子云：何陋之有？</p>
</blockquote>
]]></content>
      <categories>
        <category>序</category>
      </categories>
      <tags>
        <tag>序</tag>
      </tags>
  </entry>
  <entry>
    <title>扩散模型阅读笔记</title>
    <url>//posts/2022/10/29/diffusion-model/</url>
    <content><![CDATA[<p>本文是对知乎的一篇文章<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81NDgxMTI3MTE=">扩散模型 Diffusion Models - 原理篇<i class="fa fa-external-link-alt"></i></span>的摘要性总结.</p>
<span id="more"></span>

<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p><img data-src="https://s1.ax1x.com/2022/10/29/x5xJiR.jpg" alt="x5xJiR.jpg"></p>
<p>前向过程为一张图片 $x_0$ 在经过 $T$ 轮高斯噪声叠加后会变成一张近似纯高斯噪声图 $x_T$, 而网络则是学习反向过程中的参数, 能够通过 $x_T$ 一步步还原出 $x_0$.</p>
<h2 id="前向扩散"><a href="#前向扩散" class="headerlink" title="前向扩散"></a>前向扩散</h2><p>设共进行 $T$ 轮扩散, 有 $\beta_1 &lt; \beta_2 &lt; \dots &lt; \beta_T (0 &lt; \beta_i &lt; 1)$ 的方差参数.</p>
<p>设 $q(x_t|x_{t-1})$ 服从高斯分布, 且:</p>
<p>$$<br>x_t(z;x_{t-1},t)=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}z \sim N(\sqrt{1-\beta_t}x_{t-1}, \beta_t)<br>$$</p>
<p>设 $\alpha_t=1-\beta_t,\bar{\alpha}_t=\prod_{i=1}^t\alpha_t$, 则有:</p>
<p>$$<br>x_t(\epsilon_t;x_0,t)=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon_t \sim N(\sqrt{\bar{\alpha}_t}x_0, 1-\bar{\alpha}_t)<br>$$</p>
<p>则给定 $x_0,t$, 以及高斯随机量 $\epsilon_t$, 可以直接得到对应的 $x_t$.</p>
<h2 id="逆向扩散"><a href="#逆向扩散" class="headerlink" title="逆向扩散"></a>逆向扩散</h2><p>假设 $p(x_{t-1}|x_t;\theta)$ 也服从高斯分布, 则有:</p>
<p>$$<br>x_{t-1}(z;x_t,t) = \mu_t(x_t, t;\theta)+\sigma_t(x_t, t;\theta)z \sim N(\mu_t(x_t, t;\theta), \sigma^2_t(x_t, t;\theta))<br>$$</p>
<p>$p(x_{t-1}|x_t;\theta)$ 无法用公式表示, 但是 $q(x_{t-1}|x_t,x_0)$ 可以, 有:</p>
<p>$$<br>\mu_t = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_t)<br>$$</p>
<p>$$<br>\sigma_t = \sqrt{\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t}<br>$$</p>
<p>$$<br>x_{t-1}(z;x_t,\epsilon_t,t) = \mu_t+\sigma_tz \sim N(\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_t), \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t)<br>$$</p>
<p>(该公式不含 $x_0$, 但是需要有 $x_0$ 的前提下得到, 由前向的公式替换掉了, $\epsilon_t$ 与前向中的 $\epsilon_t$ 是同一个值)</p>
<p>其中, $\sigma_t$ 可近似认为等于 $\sqrt{\beta_t}$.</p>
<h2 id="损失计算"><a href="#损失计算" class="headerlink" title="损失计算"></a>损失计算</h2><p>目标是能够让 $q$ 和 $p$ 尽可能的接近, 用 $q$ 去近似 $p$.</p>
<p>损失需要算 $q(x_{t-1}|x_t,x_0)$ 和 $p(x_{t-1}|x_t;\theta)$ 之间的 KL 散度(分布相似程度), 一通计算之后得到:</p>
<p>$$<br>Loss = E((\mu_t(x_t, \epsilon_t, t)-\mu_t(x_t,t;\theta))^2)<br>$$</p>
<p>优化后:</p>
<p>$$<br>Loss = E((\epsilon_t-\epsilon_t(x_t,t;\theta))^2)<br>$$</p>
<p>可以看出来实际推理中, 只有均值中的 $\epsilon_t$ 是未知的, 因此需要一个网络去猜测 $\epsilon_t$, 使得 $q(x_{t-1}|x_t,x_0)$ 可以近似替代 $p(x_{t-1}|x_t;\theta)$, 来还原 $t-1$ 步的数据.</p>
<p>优化后是去拟合加入的噪声数据, 也就是一个网络输入了 $t$ 时刻的加噪图, 能估计出添加的噪声变量 $\epsilon_t=\epsilon_t(x_t,t;\theta)$, 进而使用 $q(x_{t-1}|x_t,x_0)$ 得到 $x_{t-1}$.</p>
<h2 id="一些编程时的步骤"><a href="#一些编程时的步骤" class="headerlink" title="一些编程时的步骤"></a>一些编程时的步骤</h2><h3 id="基本参数"><a href="#基本参数" class="headerlink" title="基本参数"></a>基本参数</h3><ul>
<li><p>$T$</p>
<p>扩散步数, 至少 $100$ 以上.</p>
</li>
<li><p>$\beta_1 &lt; \beta_2 &lt; \dots &lt; \beta_T (0 &lt; \beta_i &lt; 1)$</p>
<p>每一轮扩散的方差, 在满足大小关系的情况下, 尽可能的小, 通常在 $10^{-3}$ 的数量级左右. (应该步骤越多, 方差越精细?)</p>
</li>
</ul>
<h3 id="预计算的值"><a href="#预计算的值" class="headerlink" title="预计算的值"></a>预计算的值</h3><ul>
<li>$\alpha_t=1-\beta_t$</li>
<li>$\bar{\alpha}_t=\prod_{i=1}^t\alpha_t$</li>
</ul>
<h3 id="设计一个神经网络"><a href="#设计一个神经网络" class="headerlink" title="设计一个神经网络"></a>设计一个神经网络</h3><p>输入:</p>
<ul>
<li>$x_t$: 训练集样本经过 $t$ 轮正向扩散后的结果.</li>
<li>$t$: 扩散步数</li>
</ul>
<p>输出:</p>
<ul>
<li>$\epsilon_t(\theta)$: 噪声估计值</li>
</ul>
<h3 id="损失计算方法"><a href="#损失计算方法" class="headerlink" title="损失计算方法"></a>损失计算方法</h3><p>产生一个随机噪声 $\epsilon_t$, 通过网络得到估计值 $\epsilon_t(\theta)$, 计算两者之间的均方差 (MSE损失).</p>
<h3 id="训练步骤"><a href="#训练步骤" class="headerlink" title="训练步骤"></a>训练步骤</h3><p>给定训练集 $X$, 去拟合每个样本 $x$ 在每个步骤 $t$ 时刻的噪声估计.</p>
<h3 id="推理步骤"><a href="#推理步骤" class="headerlink" title="推理步骤"></a>推理步骤</h3><p>给定一个真实样本 $x_t$, 指定其 $t$ 值, 根据网络得到噪声估计 $\epsilon_t(\theta)$, 计算出 $\mu_t$ 和 $\sigma_t$, 采样一个随机标准高斯噪声 $z$, 计算 $x_{t-1} = \mu_t+\sigma_tz$</p>
]]></content>
      <categories>
        <category>AI相关</category>
      </categories>
      <tags>
        <tag>图像生成</tag>
        <tag>扩散模型</tag>
        <tag>Diffusion Model</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer 的训练与推理</title>
    <url>//posts/2023/08/29/transformer/</url>
    <content><![CDATA[<p>本文是对 Transformer 训练和预测过程的一些细节理解记录, 基于 <span class="exturl" data-url="aHR0cHM6Ly9qYWxhbW1hci5naXRodWIuaW8vaWxsdXN0cmF0ZWQtdHJhbnNmb3JtZXIv">The Illustrated Transformer<i class="fa fa-external-link-alt"></i></span>, 本文内符号也沿用此文.</p>
<p>主要是对于 Decoder 部分训练和预测时的区别以及并行化原理的总结.</p>
<span id="more"></span>

<h2 id="数据流动回顾"><a href="#数据流动回顾" class="headerlink" title="数据流动回顾"></a>数据流动回顾</h2><p><img data-src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png" alt="framework"></p>
<p>这张图是一个简略的 Transformer 整体框架图.</p>
<p>对于 Encoder 部分, 输入是 <code>(B, T, E)</code> 的形状, 其中 <code>B</code> 是批大小, <code>T</code> 是最大句长, <code>E</code> 是词向量长度; 输出形状和输入相同, 也是 <code>(B, T, E)</code>, 并且这同一份数据对应接下来 Decoder 其中一层注意力的 <code>Key</code> 和 <code>Value</code> 输入.</p>
<p>而对于 Decoder 部分, 同样设输入形状是 <code>(B, T, E)</code>, 那么它的输出形状也是和输入形状一样为 <code>(B, T, E)</code>.</p>
<p>最后的 Liner 和 Softmax 则是将 Decoder 的 <code>(B, T, E)</code> 映射到词典大小的概率矩阵 <code>(B, T, vocab_size)</code>.</p>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>Encoder 部分很简单, 在训练和预测上没有什么理解上的问题, 主要是 Decoder 部分是如何做到并行化的.</p>
<p>前面说到, 对于 Decoder 而言, 输入和输出的形状都是一样的 <code>(B, T, E)</code>, 那么首先要知道的是, 此处的并行化, 是在训练时将不同时间步的输出并行化了.</p>
<p>对于 <code>t</code> 个时间步的输入 $[x_0, x_1, \ldots, x_{t-1}]$, Decoder 的输出是 $[y_1, y_2, \ldots, y_t]$, 而它们的对应关系如下所示:</p>
<p>$$<br>\begin{bmatrix}<br>  x_0 &amp; ~ &amp; ~ &amp; ~ \\<br>  x_0 &amp; x_1 &amp; ~ &amp; ~ \\<br>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>  x_0 &amp; x_1 &amp; \ldots &amp; x_{t-1}<br>\end{bmatrix} \Rightarrow \begin{bmatrix}<br>  y_1 \\<br>  y_2 \\<br>  \vdots \\<br>  y_t<br>\end{bmatrix}<br>$$</p>
<p>而实现这种并行的关键是 Masked-Attension, 这个网上有很多举例, 简单来说就是对于 $y_i$, 通过 Mask 让它只包含了 $[x_0, x_1, \ldots, x_{i-1}]$ 的信息.</p>
<p>最后把这 <code>t</code> 个时刻的不同长度的输入序列 &quot;叠&quot; 在一起, 得到了等长的依次排在一起的不同时刻的输出.</p>
<h2 id="预测过程"><a href="#预测过程" class="headerlink" title="预测过程"></a>预测过程</h2><p>通过前面的训练过程可以知道, 从原理上来说, 虽然 Decoder 的输入和输出形状相同, 但是每个时间步的输入序列只有一个输出符号, 也就是预测出来的下一个输入符号, 因此 Decoder 在预测时, 是串行的循环过程, 直到出现终止符.</p>
<p><img data-src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" alt="decoder"></p>
<p>那么来看这张图, 预测时, Decoder 一开始的输入 <code>(B, T, E)</code> 里面, 只有第一个符号是有效的, 并且是开始符, 随后进行预测, 得到了输出数据 <code>(B, T, E)</code>, 但是只需要取输出的第一个符号, 并且也只有这个符号有效, 它将作为下一个要拼在输入序列后面的第二个符号.</p>
<p>随后重复上述步骤, 对于 <code>t</code> 时刻的操作, 输入的 <code>(B, T, E)</code> 内只有前 <code>t</code> 个符号有效, 而得到输出序列 <code>(B, T, E)</code> 后也只有前 <code>t</code> 个符号有效, 并且第 <code>t</code> 个符号就是下一个要接在输入序列后的预测符号, 而前 <code>t - 1</code> 个符号可以忽略不要, 因为它就是之前已经使用过的已经放在输入序列里的符号 (因为第 <code>i</code> 个输出符号只受前 <code>i - 1</code> 个输入符号的影响, 因此输入序列变长也不影响曾经的输出符号结果, 只有最后的第 <code>t</code> 个输出符号是新内容).</p>
<p>循环整个过程, 直到遇见终止符, 就可以解码出完整的预测结果.</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9qYWxhbW1hci5naXRodWIuaW8vaWxsdXN0cmF0ZWQtdHJhbnNmb3JtZXIv">The Illustrated Transformer<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>AI相关</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>解决学习道路上的 &quot;最后 1 KB&quot;</title>
    <url>//posts/2022/08/14/kxsw/</url>
    <content><![CDATA[<p><code>Github</code> 时断时连? <code>git clone</code> 老是失败? 谷歌学术无法使用? ......</p>
<p>没有关系! 看了本篇以后, 从此不在担忧, 让你在互联网的世界里畅通无阻.</p>
<p>本篇为一篇小白入门, 旨在简单介绍解决上述问题的基本方案, 让你扫清上网时的 &quot;最后 1 KB&quot;.</p>
<span id="more"></span>

<h2 id="工具下载"><a href="#工具下载" class="headerlink" title="工具下载"></a>工具下载</h2><p>这里只说基于 <code>V2Ray</code> 的两个工具, 分别用于 PC 端和安卓端. 先附上两个工具的 Github 官方地址.</p>
<p>PC 端 <code>V2RayN</code>: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzJkdXN0L3YycmF5Ti8=">Github 项目地址<i class="fa fa-external-link-alt"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzJkdXN0L3YycmF5Ti9yZWxlYXNlcy8=">下载页面<i class="fa fa-external-link-alt"></i></span></p>
<p>安卓端 <code>V2RayNG</code>: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzJkdXN0L3YycmF5Tkcv">Github 项目地址<i class="fa fa-external-link-alt"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzJkdXN0L3YycmF5TkcvcmVsZWFzZXMv">下载页面<i class="fa fa-external-link-alt"></i></span></p>
<p>考虑到很多人一开始是没有这些工具的, 而这些工具的下载又可能需要工具本身支持, 所以额外放一个 <code>V2RayN-Core v5.32</code> 的网盘<span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pUG0wUzA5ajZ2cWgv">下载地址<i class="fa fa-external-link-alt"></i></span> (压缩包哈希校验会与官网下载不同, 因为重新打包过再上传的).</p>
<p><img data-src="https://s1.ax1x.com/2022/08/14/vUBwJU.jpg" alt="vUBwJU.jpg"></p>
<h2 id="工具使用"><a href="#工具使用" class="headerlink" title="工具使用"></a>工具使用</h2><p>网上教程很多, 这里直接放一下看起来是官方的<span class="exturl" data-url="aHR0cHM6Ly92MnJheW4ub3JnLw==">教程网站<i class="fa fa-external-link-alt"></i></span>.</p>
<p>在这里只简单科普一下基本概念.</p>
<p>既然由于不可抗力导致直接连接网站的效果很差, 甚至无法连接, 那么我们可以找人帮忙, 找那些访问速度较好的 &quot;中间人&quot; 帮我们访问, 我们再从中间人那里间接获得需要的信息, 这种 &quot;中间人&quot; 就称为 &quot;节点&quot;.</p>
<p>但是我们自己是无法直接和节点进行交互的, 所以需要工具来帮助我们传递需求, 而对于 <code>V2Ray</code> 这一类工具客户端, 其工作方式是在你自己的机器上搭建一个本地的 &quot;代理服务器&quot;, 从而我们可以访问本地的代理服务器, 进而访问到节点, 下面放一个对比.</p>
<p>不使用工具前:</p>
<p><code>用户 --|--&gt; 目标网站</code></p>
<p>使用工具后:</p>
<p><code>用户 --&gt; 本地代理 --&gt; 节点 --&gt; 目标网站</code></p>
<p>所以对使用工具来说, 比较重要的信息是, 代理服务器设置是什么, 以及使用的节点是什么.</p>
<h3 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h3><p>PC 端上, <code>V2RayN</code> 的本地代理默认监听地址是 <code>127.0.0.1</code>, 其中 <code>http</code> 协议的端口是 <code>10809</code>, <code>socks</code> 协议的端口是 <code>10808</code>.</p>
<p>启动 <code>V2RayN</code> 客户端之后, 右键点击通知栏的图标, 在系统代理内有三个选项.</p>
<ul>
<li>清除系统代理: 清除掉在系统设置内的代理设置.</li>
<li>自动配置系统代理: 将系统设置内的代理设置为 <code>V2RayN</code> 的代理服务器.</li>
<li>不改变系统代理: 保持原有系统代理设置不变.</li>
</ul>
<p>这是个让我们快速更改系统代理设置的选项, 除此之外, 我们也可以手动去系统设置里的 <code>网络和 Internet -&gt; 代理 -&gt; 手动设置代理</code> 调整系统要使用的代理服务器.</p>
<p>当系统代理被设置之后, 凡是只能通过系统代理的软件 <code>http</code> 协议流量, 比如 <code>Edge</code> 和 <code>Chrome</code> 浏览器等, 都会经过 <code>V2RayN</code> 来转发给节点, 从而访问到目标网站.</p>
<p>但是某些程序是可以单独设置使用代理服务器的, 比如 <code>Firefox</code> 浏览器, 这种就需要自己去浏览器设置里手动设置代理.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/14/vUyCmd.png" alt="vUyCmd.png"></p>
<p>个人推荐备一个 <code>Firefox</code> 浏览器, 这样子可以单独把代理挂给浏览器而不是影响全局, 既可以访问国外网站也不影响使用 <code>Edge</code> 等浏览器访问国内网站.</p>
<h3 id="使用节点与订阅"><a href="#使用节点与订阅" class="headerlink" title="使用节点与订阅"></a>使用节点与订阅</h3><p>一个节点通常长这样.</p>
<p><code>&lt;协议&gt;://&lt;内容&gt;</code></p>
<p><code>vmess://55yL5ZWl5ZGi77yf5rKh5pyJ6IqC54K55L+h5oGv77yB</code></p>
<p>直接 <code>Ctrl + C</code> 复制内容然后进入客户端 <code>Ctrl + V</code> 就可以导入节点信息了.</p>
<p>这种时候就会有人说了, 一个个节点导入太麻烦, 而且节点说不定什么时候就会失效, 还得重新一个个找. 所以, 订阅地址它出现了.</p>
<p>比如有个白嫖订阅地址 <span class="exturl" data-url="aHR0cHM6Ly9qaWFuZy5uZXRsaWZ5LmNvbS8=">https://jiang.netlify.com/<i class="fa fa-external-link-alt"></i></span>, 你点开了直接看就会发现是一大堆的字符, 其实是一个个的节点信息, 并且每隔一段时间内容还不一样, 也就是节点信息被更新了.</p>
<p>那么, 只要往 <code>V2RayN</code> 客户端内添加这个订阅地址, 以后再使用 &quot;更新订阅&quot; 的功能, 客户端就会自动从这个地址获取节点信息并且更新该订阅下的所有节点为新节点, 为我们懒人带来福音.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>So, 为了解决上网的最后 &quot;1 KB&quot;, 我们需要首先获得工具, 然后获得节点 (或者获得订阅地址), 再然后开启软件设置节点与代理, 之后就可以在学习的道路上畅通无阻了<del>天翼 3G 太快了</del>.</p>
<p>这里贴一个可以白嫖的机场地址 <span class="exturl" data-url="aHR0cHM6Ly9wZXBzaWNvbGEubWUv">https://pepsicola.me<i class="fa fa-external-link-alt"></i></span> , 有免费订阅可以满足日常基本使用需求<del>不知道看到这篇文章的时候是否还进得去</del>.</p>
<p>尝试使用谷歌学术搜索一篇论文, 很 nice, 顷刻之间, 已尽数列出.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/14/vUc2TA.png" alt="vUc2TA.png"></p>
<p>PS: 就这么多了(。_。), 有兴趣的同学还请善用搜索引擎, 发挥互联网自主探索精神.</p>
]]></content>
      <categories>
        <category>实用技能</category>
      </categories>
      <tags>
        <tag>科学上网</tag>
      </tags>
  </entry>
  <entry>
    <title>PCA 算法原理与实现</title>
    <url>//posts/2023/02/18/pca/</url>
    <content><![CDATA[<p>PCA 算法, 也就是主成分分析法 (Principal Component Analysis), 是一种数据降维算法, 能够在尽可能保留数据特征的同时压缩数据, 降低数据复杂度, 便于数据分析的进行.</p>
<p>本文简要介绍 PCA 算法的基本思想与数学推导, 并在文末提供对应的 <code>python</code> 实现.</p>
<span id="more"></span>

<h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>有一组 $p$ 维向量 $X_{n \times p} = \begin{bmatrix}<br>  \boldsymbol{x}_1 \\<br>  \boldsymbol{x}_2 \\<br>  \vdots \\<br>  \boldsymbol{x}_n<br>\end{bmatrix} = \begin{bmatrix}<br>  x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1p} \\<br>  x_{21} &amp; x_{22} &amp; \ldots &amp; x_{2p} \\<br>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>  x_{n1} &amp; x_{n2} &amp; \ldots &amp; x_{np}<br>\end{bmatrix}$, 需要通过一种方法使得它们变成一组 $q~(q &lt; p)$ 维向量 $Y_{n \times q} = \begin{bmatrix}<br>  \boldsymbol{y}_1 \\<br>  \boldsymbol{y}_2 \\<br>  \vdots \\<br>  \boldsymbol{y}_n<br>\end{bmatrix} = \begin{bmatrix}<br>  y_{11} &amp; y_{12} &amp; \ldots &amp; y_{1q} \\<br>  y_{21} &amp; y_{22} &amp; \ldots &amp; y_{2q} \\<br>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>  y_{n1} &amp; y_{n2} &amp; \ldots &amp; y_{nq}<br>\end{bmatrix}$, 在降低维数的同时, 尽可能减少信息损失.</p>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><h3 id="信息重分配"><a href="#信息重分配" class="headerlink" title="信息重分配"></a>信息重分配</h3><p>对于一个向量 $\boldsymbol{x}_i = \begin{pmatrix}x_{i1}, x_{i2}, \ldots, x_{ip}\end{pmatrix}$, $p$ 个值代表了该向量在 $p$ 个方向上的不同特征, 而信息量大小的直接表现就是对数据的区分程度. 如果说在某一维上的值越能对不同的 $\boldsymbol{x}$ 进行区分, 则数据的<strong>离散程度</strong>就越大, 它所包含的信息量就越多, 最终这 $p$ 维共同完成了对 $X$ 所有数据的区分.</p>
<p>对于一组数据 $X$ 来说, 信息总量是确定的, 原始的 $X$ 中信息的分配方式是按某种分布分摊在 $p$ 个维度中.</p>
<p>因此, 在 PCA 方法中, 我们希望:</p>
<ul>
<li>经过变换之后的数据 $Y$, 能够对每一维的信息含量进行调整, 可以将整体数据的信息量先尽可能的分配到第 1 维, 然后分配到第 2 维, 第 3 维, ..., 直到最后一维</li>
<li>在新的数据 $Y$ 中, 每一维之间的<strong>关联性</strong>尽可能小, 最好是不相关, 这样子就能让信息独立的被分配到每一维中, 不会在不同维之间产生维间信息.</li>
</ul>
<p>上述有两个问题需要解决, 同一维之间的离散程度和不同维之间的关联性. 而在数学上, 方差和协方差可以很好的解决这两个问题.</p>
<h3 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h3><p>$X$ 是一个 $n \times p$ 的矩阵, 如果能找到一个 $q \times p$ 的矩阵 $W$ 满足对信息分配的要求, 对 $X$ 进行线性变换, 使得 $Y^T = WX^T$, 就可以得到降维后 $n \times q$ 的数据表示 $Y$.</p>
<p>$$<br>\begin{aligned}<br>  Y^T &amp;= \begin{bmatrix}{\boldsymbol{y}_1}^T &amp; {\boldsymbol{y}_2}^T &amp; \ldots &amp; {\boldsymbol{y}_n}^T\end{bmatrix} \\<br>  ~&amp;= WX^T \\<br>  ~&amp;= \begin{bmatrix}<br>    \boldsymbol{w}_1 \\<br>    \boldsymbol{w}_2 \\<br>    \vdots \\<br>    \boldsymbol{w}_q<br>  \end{bmatrix} \begin{bmatrix}{\boldsymbol{x}_1}^T &amp; {\boldsymbol{x}_2}^T &amp; \ldots &amp; {\boldsymbol{x}_n}^T\end{bmatrix}<br>\end{aligned}<br>$$</p>
<h2 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h2><p>我们的目标是, 寻找一个 $W$ , 使得新数据 $Y^T$ 同一维上的方差最大化, 不同维之间的协方差最小化.</p>
<p>为了方便数据处理, 我们假设 $X$ 已经经过均值和方差的归一化处理, 即 $X = \frac{X - E(X)}{\sqrt{D(X)}}$, 这样子均值为 0, 方便后续计算.</p>
<p>首先是方差与协方差的公式:</p>
<p>$$<br>\begin{aligned}<br>  Cov(X, Y) &amp;= E(XY) - E(X)E(Y) \\<br>  D(X) &amp;= E(X^2) - E^2(X)<br>\end{aligned}<br>$$</p>
<p>因为数据已经经过归一化处理, 所以可以简化成:</p>
<p>$$<br>\begin{aligned}<br>  Cov(X, Y) &amp;= E(XY) = \frac{1}{n}\sum_{i=1}^{n}x_iy_i \\<br>  D(X) &amp;= E(X^2) = \frac{1}{n}\sum_{i=1}^{n}x_i^2<br>\end{aligned}<br>$$</p>
<p>现在, 需要把数据 $Y$ 的方差与协方差进行表示, 定义矩阵 $Y_{Cov}$ 为 $Y$ 的协方差矩阵, 有:</p>
<p>$$<br>\begin{aligned}<br>  Y_{Cov} &amp;= \frac{1}{n}Y^TY \\<br>  ~&amp;= \frac{1}{n} \begin{bmatrix}<br>    y_{11} &amp; y_{21} &amp; \ldots &amp; y_{n1} \\<br>    y_{12} &amp; y_{22} &amp; \ldots &amp; y_{n2} \\<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>    y_{1q} &amp; y_{2q} &amp; \ldots &amp; y_{nq}<br>  \end{bmatrix} \begin{bmatrix}<br>    y_{11} &amp; y_{12} &amp; \ldots &amp; y_{1q} \\<br>    y_{21} &amp; y_{22} &amp; \ldots &amp; y_{2q} \\<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>    y_{n1} &amp; y_{n2} &amp; \ldots &amp; y_{nq}<br>  \end{bmatrix} \\<br>  ~&amp;= \begin{bmatrix}<br>    \frac{1}{n}\sum_{i=1}^{n}y_{i1}^2 &amp; \frac{1}{n}\sum_{i=1}^{n}y_{i1}y_{i2} &amp; \ldots &amp; \frac{1}{n}\sum_{i=1}^{n}y_{i1}y_{iq} \\<br>    \frac{1}{n}\sum_{i=1}^{n}y_{i2}y_{i1} &amp; \frac{1}{n}\sum_{i=1}^{n}y_{i2}^2 &amp; \ldots &amp; \frac{1}{n}\sum_{i=1}^{n}y_{i2}y_{iq} \\<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>    \frac{1}{n}\sum_{i=1}^{n}y_{iq}y_{i1} &amp; \frac{1}{n}\sum_{i=1}^{n}y_{iq}y_{i2} &amp; \ldots &amp; \frac{1}{n}\sum_{i=1}^{n}y_{iq}^2<br>  \end{bmatrix}<br>\end{aligned}<br>$$</p>
<p>可以看到协方差矩阵的主对角线上是 $q$ 个维度上的方差, 而其余位置则是两两之间的协方差, 并且协方差矩阵还是一个实对称矩阵. 所以我们的目标就是让 $Y_{Cov}$ 除了主对角线以外的部分尽量接近 0.</p>
<p>同理可以得到 $X_{Cov} = \frac{1}{n}X^TX$.</p>
<p>下面推导 $Y_{Cov}$ 与原始数据 $X$ 之间的关系.</p>
<p>$$<br>\begin{aligned}<br>  Y_{Cov} &amp;= \frac{1}{n}Y^TY \\<br>    ~&amp;= \frac{1}{n}(WX^T)(WX^T)^T \\<br>    ~&amp;= \frac{1}{n}WX^TXW^T \\<br>    ~&amp;= WX_{Cov}W^T<br>\end{aligned}<br>$$</p>
<p>结合我们的目标可以发现, $Y_{Cov}$ 的最优情况其实就是实对称矩阵 $X_{Cov}$ 的对角化矩阵, 而 $W$ 就是能够满足 $X_{Cov}$ 对角化的矩阵.</p>
<p>关于实对称矩阵的对角化, 线代里面有详细的介绍, 这里简单提一下结论.</p>
<div class="note info"><p>对于一个 $n \times n$ 的实对称矩阵 $D$, 一定可以找到 $n$ 个单位正交特征向量, 组成矩阵 $E = \begin{bmatrix}<br>\boldsymbol{e}_1 \\<br>  \boldsymbol{e}_2 \\<br>  \vdots \\<br>  \boldsymbol{e}_n<br>\end{bmatrix}$, 使得 $\Lambda = EDE^T = \begin{bmatrix}<br>  \lambda_1 &amp; ~ &amp; ~ &amp; ~ \\<br>  ~ &amp; \lambda_2 &amp; ~ &amp; ~ \\<br>  ~ &amp; ~ &amp; \ddots &amp; ~ \\<br>  ~ &amp; ~ &amp; ~ &amp;\lambda_n<br>\end{bmatrix}$, 其中 $\Lambda$ 是对角矩阵, 对角元素是特征向量对应的特征值.</p>
</div>

<p>因此, 对于实对称矩阵 $X_{Cov}$, 总能通过求其特征值与特征向量, 得到一个满足要求的 $W$ 使其对角化, 得到 $Y_{Cov}$.</p>
<p>到这里还没有完全结束, $X_{Cov}$ 是 $p$ 维实对称矩阵, 因此一定存在 $p$ 个特征值与特征向量, 而我们的目标是降维, 因此 $W$ 只需要选择其中的 $q$ 个特征向量组成一个 $q \times p$ 的矩阵即可.</p>
<p>从最后对角化的结果来看, $Y_{Cov}$ 的对角线上, 也就是新数据每一维的方差值, 其实就是 $W$ 按顺序特征向量对应的特征值. 那么为了充分保留原数据里的信息, 需要将特征向量按特征值大小进行降序排列, 然后依次选取前 $q$ 个特征向量去组成最终的 $W$ 矩阵.</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>输入: $X_{n \times p}$, $q~(q \leq p)$</p>
<p>输出: $Y_{n \times q}$</p>
<ol>
<li>对 $X$ 进行均值方差归一化.</li>
<li>求解 $X_{Cov} = \frac{1}{n}X^TX$.</li>
<li>求出 $X_{Cov}$ 的 $p$ 个特征值 $\lambda_1, \lambda_2, \ldots, \lambda_p$, 及其对应的特征向量 $\boldsymbol{w}_1, \boldsymbol{w}_2, \ldots, \boldsymbol{w}_p$.</li>
<li>将 $\boldsymbol{w}_1, \boldsymbol{w}_2, \ldots, \boldsymbol{w}_p$ 按 $\lambda_1, \lambda_2, \ldots, \lambda_p$ 降序排列, 得到 $\boldsymbol{w}&#39;_1, \boldsymbol{w}&#39;_2, \ldots, \boldsymbol{w}&#39;_p$.</li>
<li>选取 $\boldsymbol{w}&#39;_1, \boldsymbol{w}&#39;_2, \ldots, \boldsymbol{w}&#39;_q$, 组成变换矩阵 $W = \begin{bmatrix}<br> \boldsymbol{w}&#39;_1 \\<br> \boldsymbol{w}&#39;_2 \\<br> \vdots \\<br> \boldsymbol{w}&#39;_q<br>\end{bmatrix}$</li>
<li>计算 $Y^T = WX^T$, 得到降维后的新数据 $Y$.</li>
</ol>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pca</span>(<span class="params">X: np.ndarray, n_compnents: <span class="built_in">int</span></span>) -&gt; np.ndarray:</span><br><span class="line">    n, p = X.shape</span><br><span class="line">    q = n_compnents</span><br><span class="line"></span><br><span class="line">    <span class="comment"># normalization</span></span><br><span class="line">    X = (X - np.mean(X, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)) / np.std(X, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># covariance of x</span></span><br><span class="line">    X_cov = (<span class="number">1</span> / n) * X.T @ X</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute eigenwerts and eigenvectors</span></span><br><span class="line">    w, v = np.linalg.eigh(X_cov)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># sort by descending order</span></span><br><span class="line">    w = w[::-<span class="number">1</span>]</span><br><span class="line">    v = v[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># choose top q vectors</span></span><br><span class="line">    W = v[:q]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute Y</span></span><br><span class="line">    Y = (W @ X.T).T</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9vdXJhcmNoaXZlLm90YWdvLmFjLm56L2JpdHN0cmVhbS9oYW5kbGUvMTA1MjMvNzUzNC9PVUNTLTIwMDItMTIucGRm">A tutorial on principal components analysis<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据降维</tag>
      </tags>
  </entry>
  <entry>
    <title>ECC 算法原理简介与实现</title>
    <url>//posts/2022/12/07/simple-ecc/</url>
    <content><![CDATA[<p>本文记于某次密码作业课余, 提供对 ECC 算法的简要介绍与简单实现, 文末附有代码.</p>
<span id="more"></span>

<h2 id="理论介绍"><a href="#理论介绍" class="headerlink" title="理论介绍"></a>理论介绍</h2><h3 id="素域上的离散椭圆曲线"><a href="#素域上的离散椭圆曲线" class="headerlink" title="素域上的离散椭圆曲线"></a>素域上的离散椭圆曲线</h3><p>形如 $y^2 = x^3 + ax + b \bmod p$ 的曲线叫椭圆曲线, 其中需满足 $p$ 是大于 $3$ 的素数, 且 $4a^3 + 27b^2 \ne 0 \bmod p$.</p>
<p>先不看 $\bmod$ 记号, 那么这就是一条普通的连续曲线, 可以按照普通的方程求解, 给定一个 $x$, 就可以求出来对应的 $y$. 容易看出来, 这条曲线是关于 $x$ 轴对称的, 因此它的图像大概长下面这种样子.</p>
<p><img data-src="https://s1.ax1x.com/2022/12/06/zcG6gI.png" alt="zcG6gI.png"></p>
<p>可以有几种不同的形式, 但是基本上差不多.</p>
<p>那么加了 $\bmod$ 记号之后有什么不同呢? 刚刚是根据实数域画出来的连续曲线, 那么加上 $\bmod$ 之后, 曲线还是这条曲线, 但是坐标取值范围变成了整数范围, 且取值在 $[0, p-1]$ 之间.</p>
<p>也就是从这条曲线上挑出了一些离散的整数解, 不仅能够满足这个曲线方程, 同时 $x$ 和 $y$ 的取值范围在 $[0, p-1]$, 也就是对 $p$ 取模, 所有的数据运算都在模 $p$ 下进行, 因此将这种曲线记为 $y^2 = x^3 + ax + b \bmod p$.</p>
<p>所以, ECC 中使用的椭圆曲线并不是一条真正连续的曲线, 而是由很多离散的点组成的.</p>
<h3 id="椭圆曲线上的运算"><a href="#椭圆曲线上的运算" class="headerlink" title="椭圆曲线上的运算"></a>椭圆曲线上的运算</h3><p>既然要使用椭圆曲线进行计算, 那么先得定义在椭圆曲线上的运算.</p>
<p>我们都学过向量的运算, 其中最基本的两种运算是加法和数乘.</p>
<p>如果设 $\vec{a}$, $\vec{b}$ 是两个向量, 那么我们可以计算 $\vec{a}+\vec{b}$ 的值, 这称为<strong>向量加法</strong>.</p>
<p>我还可以计算 $\vec{a}$ 与自己的相加运算, 计算 $k$ 个 $\vec{a}$ 连续相加, 并简记为 $k\vec{a}$, 这称为<strong>向量数乘</strong>.</p>
<p>可以看出, 第二种情况虽然有个&quot;乘&quot;字, 但是仍然属于加法运算的一种, 至此, 向量关于加法的运算已经基本上齐全了, 但是还缺少一些特殊情况定义.</p>
<p>首先是 $0$ 的定义, 此处指的是抽象的 $0$, 不是数字 $0$, 也就是对于向量运算来说, 需要有一个 $0$ 值的概念, 它在加法运算中不会影响运算本身, 通常就将其定义为全零向量 $\vec{0}$, 也可称其为<strong>单位元</strong>.</p>
<p>而在定义完单位元之后, 可以定义向量取负, 依靠于 $\vec{0}$ 来进行的, 如果有 $-\vec{a}$, 则 $\vec{a} + (-\vec{a}) = \vec{0}$, 这样就通过单位元定义了加法的逆运算减法的规则, 因为减去一个原向量等于加上原向量的相反向量, 而相反向量满足上述关于单位元的等式, 因而可以求出相反向量的具体取值. 在这里, 相反向量称之为原向量的<strong>逆元</strong>.</p>
<p>至此, 我们成功在向量中定义了这些基本概念:</p>
<ul>
<li>加法 ($\vec{a} + \vec{b}$)</li>
<li>数乘 ($k\vec{a}$)</li>
<li>单位元 ($\vec{0}$)</li>
<li>逆元 ($-\vec{a}$)</li>
</ul>
<p>那么, 把上述中的&quot;向量&quot;全部换成别的东西, 我们就可以定义出一套新的数据运算, 而对于椭圆曲线, 我们将&quot;向量&quot;换成所有满足椭圆曲线方程的点, 定义了椭圆曲线上的点运算规则.</p>
<p>接下来就是对于点加法具体过程的定义, 用一张图来直观解释椭圆曲线上点是如何进行&quot;相加&quot;的.</p>
<p><img data-src="https://s1.ax1x.com/2022/12/07/zcYiWj.png" alt="zcYiWj.png"></p>
<p>设 $P$, $Q$ 为椭圆曲线上的两点, 则 $P+Q$ 就是 $P$, $Q$ 连线与曲线的交点关于 $x$ 轴的对称点.</p>
<p>当 $P$, $Q$ 重合时, 取切线与曲线的交点的对称点作为加法结果, 也就是 $2P$.</p>
<p>当 $P$, $Q$ 关于 $x$ 轴对称时, 定义相加结果为无穷远点, 视作加法的单位元点, 记为 $O$, 同时易得此时 $P$, $Q$ 互为对方的逆元.</p>
<h3 id="椭圆曲线运算公式"><a href="#椭圆曲线运算公式" class="headerlink" title="椭圆曲线运算公式"></a>椭圆曲线运算公式</h3><p>运算公式按照普通的解析几何去求解即可, 在此直接给出公式, 分为两点不重合和重合的情况.</p>
<p>设曲线方程是 $y^2 = x^3 + ax + b$, $R(x_3, y_3)=P(x_1, y_1) + Q(x_2, y_2)$, 则:</p>
<p>$$<br>\left\{<br>  \begin{align*}<br>    x_3 &amp;= \lambda^2 - x_1 - x_2 \\<br>    y_3 &amp;= \lambda(x_1 - x_3) - y_1<br>  \end{align*}<br>\right.<br>$$</p>
<p>其中, 当 $P(x_1, y_1) \ne Q(x_2, y_2)$, 即两点不重合时,</p>
<p>$$<br>\lambda = \frac{y_2 - y_1}{x_2 - x_1}<br>$$</p>
<p>当 $P(x_1, y_1) = Q(x_2, y_2)$, 即两点重合时,</p>
<p>$$<br>\lambda = \frac{3x_1^2+a}{2y_1}<br>$$</p>
<h3 id="其他概念"><a href="#其他概念" class="headerlink" title="其他概念"></a>其他概念</h3><p>一些代码实现时需要知道的概念, 在此简单记录.</p>
<ul>
<li>循环群: 循环群是一些点的集合, 群内存在一个特殊点 $G$, 在这个群内的任何一个点, 都可以由 $G, 2G, ..., nG$ 表示, 对 $G$ 的 $n$ 次加法运算能够遍历群中的每个点, 群的大小是 $n$.</li>
<li>生成元: 循环群中的 $G$ 称为这个循环群的生成元.</li>
<li>阶: 指循环群或者生成元的阶, 就是生成元所在循环群的大小 $n$.</li>
<li>模逆运算: 指求解方程 $ax \equiv 1 \bmod p$, 即 $a$ 在模 $p$ 运算下的&quot;倒数&quot;.</li>
</ul>
<h2 id="椭圆曲线代码实现"><a href="#椭圆曲线代码实现" class="headerlink" title="椭圆曲线代码实现"></a>椭圆曲线代码实现</h2><h3 id="曲线与点的定义"><a href="#曲线与点的定义" class="headerlink" title="曲线与点的定义"></a>曲线与点的定义</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int64_t</span> x;</span><br><span class="line">    <span class="type">int64_t</span> y;</span><br><span class="line">&#125; EccPoint;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int64_t</span> a;</span><br><span class="line">    <span class="type">int64_t</span> b;</span><br><span class="line">    <span class="type">int64_t</span> p;</span><br><span class="line">&#125; EC; <span class="comment">// y^2 = x^3 + ax + b (mod p)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    EccPoint pt;</span><br><span class="line">    <span class="type">int64_t</span> n;</span><br><span class="line">&#125; GenPoint;</span><br></pre></td></tr></table></figure>

<h3 id="辅助运算"><a href="#辅助运算" class="headerlink" title="辅助运算"></a>辅助运算</h3><p>模 $p$ 运算和模逆运算.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int64_t</span> <span class="title function_">modp</span><span class="params">(<span class="type">int64_t</span> x, <span class="type">int64_t</span> p)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">while</span> (x &lt; <span class="number">0</span>) x += p;</span><br><span class="line">    x %= p;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int64_t</span> <span class="title function_">inverse</span><span class="params">(<span class="type">int64_t</span> x, <span class="type">int64_t</span> p)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int64_t</span> q = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int64_t</span> r = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> r1 = p;</span><br><span class="line">    <span class="type">int64_t</span> r2 = x;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> t1 = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int64_t</span> t2 = <span class="number">1</span>;</span><br><span class="line">    <span class="type">int64_t</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (r2 &gt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        q = r1 / r2, r = r1 % r2;</span><br><span class="line">        r1 = r2, r2 = r;</span><br><span class="line"></span><br><span class="line">        t = t1 - q * t2;</span><br><span class="line">        t1 = t2, t2 = t;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    t1 = modp(t1, p);</span><br><span class="line">    <span class="keyword">return</span> t1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="点加与数乘"><a href="#点加与数乘" class="headerlink" title="点加与数乘"></a>点加与数乘</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">addpt</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EC* ec,</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EccPoint* pt1, <span class="type">const</span> EccPoint* pt2,</span></span><br><span class="line"><span class="params">    EccPoint* new_pt</span></span><br><span class="line"><span class="params">)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (pt1-&gt;x == <span class="number">-1</span> &amp;&amp; pt1-&gt;y == <span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        new_pt-&gt;x = pt2-&gt;x;</span><br><span class="line">        new_pt-&gt;y = pt2-&gt;y;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (pt2-&gt;x == <span class="number">-1</span> &amp;&amp; pt2-&gt;y == <span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        new_pt-&gt;x = pt1-&gt;x;</span><br><span class="line">        new_pt-&gt;y = pt1-&gt;y;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int64_t</span> lambda = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int64_t</span> new_x = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int64_t</span> new_y = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (pt1-&gt;x == pt2-&gt;x)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Unit</span></span><br><span class="line">            <span class="keyword">if</span> (pt1-&gt;y + pt2-&gt;y == ec-&gt;p)</span><br><span class="line">            &#123;</span><br><span class="line">                new_pt-&gt;x = <span class="number">-1</span>;</span><br><span class="line">                new_pt-&gt;y = <span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Same</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (pt1-&gt;y == pt2-&gt;y)</span><br><span class="line">            &#123;</span><br><span class="line">                lambda = (<span class="number">3</span> * pt1-&gt;x * pt1-&gt;x + ec-&gt;a) * inverse(<span class="number">2</span> * pt1-&gt;y, ec-&gt;p);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Different</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int64_t</span> delta_x = <span class="number">0</span>;</span><br><span class="line">            <span class="type">int64_t</span> delta_y = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            delta_x = modp((pt2-&gt;x - pt1-&gt;x), ec-&gt;p);</span><br><span class="line">            delta_y = modp((pt2-&gt;y - pt1-&gt;y), ec-&gt;p);</span><br><span class="line">            lambda = delta_y * inverse(delta_x, ec-&gt;p);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        lambda %= ec-&gt;p;</span><br><span class="line"></span><br><span class="line">        new_x = modp((lambda * lambda - pt1-&gt;x - pt2-&gt;x), ec-&gt;p);</span><br><span class="line">        new_y = modp((lambda * (pt1-&gt;x - new_x) - pt1-&gt;y), ec-&gt;p);</span><br><span class="line"></span><br><span class="line">        new_pt-&gt;x = new_x;</span><br><span class="line">        new_pt-&gt;y = new_y;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">mulpt</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EC* ec,</span></span><br><span class="line"><span class="params">    <span class="type">uint64_t</span> k, <span class="type">const</span> EccPoint* pt,</span></span><br><span class="line"><span class="params">    EccPoint* new_pt</span></span><br><span class="line"><span class="params">)</span></span><br><span class="line">&#123;</span><br><span class="line">    new_pt-&gt;x = <span class="number">-1</span>;</span><br><span class="line">    new_pt-&gt;y = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">64</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        addpt(ec, new_pt, new_pt, new_pt);</span><br><span class="line">        <span class="keyword">if</span> (k &amp; <span class="number">0x8000000000000000</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            addpt(ec, new_pt, pt, new_pt);</span><br><span class="line">        &#125;</span><br><span class="line">        k &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="计算椭圆曲线的所有点及其阶"><a href="#计算椭圆曲线的所有点及其阶" class="headerlink" title="计算椭圆曲线的所有点及其阶"></a>计算椭圆曲线的所有点及其阶</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">uint8_t</span> <span class="title function_">isprime</span><span class="params">(<span class="type">int64_t</span> x)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">2</span>; i &lt; (<span class="type">int64_t</span>)sqrtl((<span class="type">long</span> <span class="type">double</span>)x); i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (x % i == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int64_t</span> <span class="title function_">compute_ptrank</span><span class="params">(<span class="type">const</span> EC* ec, <span class="type">const</span> EccPoint* pt)</span></span><br><span class="line">&#123;</span><br><span class="line">    EccPoint tmp = &#123; pt-&gt;x, pt-&gt;y &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> rank = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        addpt(ec, &amp;tmp, pt, &amp;tmp);</span><br><span class="line">        <span class="keyword">if</span> (tmp.x == pt-&gt;x &amp;&amp; tmp.y == pt-&gt;y)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        rank++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> rank;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_points</span><span class="params">(EC* ec)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;EC: &#123; a = %lld, b = %lld, p = %lld &#125;\n&quot;</span>, ec-&gt;a, ec-&gt;b, ec-&gt;p);</span><br><span class="line">    <span class="keyword">if</span> (modp(<span class="number">4</span> * ec-&gt;a * ec-&gt;a * ec-&gt;a + <span class="number">27</span> * ec-&gt;b * ec-&gt;b, ec-&gt;p) == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Params Invalid!\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int64_t</span> pt_count = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int64_t</span> y_sqr = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int64_t</span> y = <span class="number">0</span>;</span><br><span class="line">        <span class="type">uint8_t</span> find = <span class="number">0</span>;</span><br><span class="line">        EccPoint pt_tmp = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">        <span class="type">int64_t</span> pt_rank = <span class="number">0</span>;</span><br><span class="line">        <span class="type">char</span> prime_rank = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int64_t</span> x = <span class="number">0</span>; x &lt; ec-&gt;p; x++)</span><br><span class="line">        &#123;</span><br><span class="line">            y_sqr = modp((x * x * x + ec-&gt;a * x + ec-&gt;b), ec-&gt;p);</span><br><span class="line">            find = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span> (y_sqr &lt; (ec-&gt;p - <span class="number">1</span>) * (ec-&gt;p - <span class="number">1</span>))</span><br><span class="line">            &#123;</span><br><span class="line">                y = (<span class="type">int64_t</span>)sqrtl((<span class="type">long</span> <span class="type">double</span>)y_sqr);</span><br><span class="line">                <span class="keyword">if</span> (y * y == y_sqr)</span><br><span class="line">                &#123;</span><br><span class="line">                    find = <span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                y_sqr += ec-&gt;p;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (find)</span><br><span class="line">            &#123;</span><br><span class="line">                pt_tmp.x = x;</span><br><span class="line">                pt_tmp.y = y;</span><br><span class="line">                pt_rank = compute_ptrank(ec, &amp;pt_tmp);</span><br><span class="line">                prime_rank = (isprime(pt_rank) ? <span class="string">&#x27;P&#x27;</span> : <span class="string">&#x27;C&#x27;</span>);</span><br><span class="line">                pt_count++;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;(%5lld, %5lld)[%5lld][%c], &quot;</span>, pt_tmp.x, pt_tmp.y, pt_rank, prime_rank);</span><br><span class="line">                <span class="keyword">if</span> (pt_count % <span class="number">4</span> == <span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (y != <span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    pt_tmp.y = ec-&gt;p - y;</span><br><span class="line">                    pt_count++;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;(%5lld, %5lld)[%5lld][%c], &quot;</span>, pt_tmp.x, pt_tmp.y, pt_rank, prime_rank);</span><br><span class="line">                    <span class="keyword">if</span> (pt_count % <span class="number">4</span> == <span class="number">0</span>)</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;(%5d, %5d)[%5d][%c]\n&quot;</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="string">&#x27;C&#x27;</span>);</span><br><span class="line">        pt_count++;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;EccPoints Count: %lld\n&quot;</span>, pt_count);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="使用椭圆曲线进行数据加密"><a href="#使用椭圆曲线进行数据加密" class="headerlink" title="使用椭圆曲线进行数据加密"></a>使用椭圆曲线进行数据加密</h2><p>前面只是实现了关于椭圆曲线的运算, 现在需要使用这个运算来构建一个密码算法, 这其中使用到的问题称为椭圆曲线上的离散对数问题.</p>
<h3 id="ECDLP"><a href="#ECDLP" class="headerlink" title="ECDLP"></a>ECDLP</h3><p>设曲线为 $y^2 = x^3 + ax + b \bmod p$, $p$ 为大于 $3$ 的素数, 且 $4a^3 + 27b^2 \ne 0 \bmod p$.</p>
<p>曲线上的一个循环群记为 $&lt;G, n&gt;$, $G$ 是群的生成元, $n$ 是群的阶, 且 $n$ 为素数.</p>
<p>设 $P$, $Q$ 是群上的两点, 且 $Q = tP$, $t$ 为正整数且 $t \in [1, n-1]$.</p>
<p>则已知 $t$, $P$, 要计算 $Q$ 是简单的, 但是反过来, 已知 $P$, $Q$, 要计算 $t$ 是困难的, 这就是椭圆曲线上的离散对数问题.</p>
<h3 id="公私钥的选取"><a href="#公私钥的选取" class="headerlink" title="公私钥的选取"></a>公私钥的选取</h3><p>根据前面 ECDLP 的定义, 定义用户的私钥为 $d$, 可以为集合 $\{1, 2, ..., n-1\}$ 中的一个随机数, 公钥为 $Q$, 且 $Q = dG$, $G$ 是循环群 $&lt;G, n&gt;$ 的生成元. 其余所有和椭圆曲线有关的参数均是公开已知, 只有 $d$ 的值是秘密保留的, 当 $p$ 足够大时, 求解 $d$ 是困难的.</p>
<h3 id="一个简单的加解密方案"><a href="#一个简单的加解密方案" class="headerlink" title="一个简单的加解密方案"></a>一个简单的加解密方案</h3><p>设 $d$ 为用户私钥, $Q$ 为用户公钥, 明文数据为 $M$, 且 $0 \leq M \leq n-1$.</p>
<p>加密:</p>
<ol>
<li>选择一个随机数 $k$, 且 $k \in \{1, 2, ..., n-1\}$.</li>
<li>计算点 $X_1(x_1, y_1) = kQ$, 如果 $x_1 = 0$, 则转步骤 1.</li>
<li>计算点 $X_2(x_2, y_2) = kG$.</li>
<li>计算密文 $C \equiv Mx_1 \bmod n$.</li>
<li>以 $(X_2, C)$ 作为 $M$ 的最终密文.</li>
</ol>
<p>解密:</p>
<ol>
<li>计算 $X_1(x_1, y_1) = dX_2 = d(kG) = k(dG) = kQ$.</li>
<li>计算明文 $M \equiv Cx_1^{-1} \bmod n$.</li>
</ol>
<h2 id="加解密算法的实现"><a href="#加解密算法的实现" class="headerlink" title="加解密算法的实现"></a>加解密算法的实现</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    EC ec;</span><br><span class="line">    GenPoint genpt;</span><br><span class="line">&#125; ECDLP;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">encrypt_blk</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">const</span> ECDLP* ecdlp,</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EccPoint* pubkey,</span></span><br><span class="line"><span class="params">    <span class="type">int64_t</span> plain,</span></span><br><span class="line"><span class="params">    EccPoint* cipher_pt, <span class="type">int64_t</span>* cipher</span></span><br><span class="line"><span class="params">)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int64_t</span> rndk = <span class="number">0</span>;</span><br><span class="line">    EccPoint x1 = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    &#123;</span><br><span class="line">        rndk = rand() % (ecdlp-&gt;genpt.n - <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">        mulpt(&amp;ecdlp-&gt;ec, rndk, pubkey, &amp;x1);</span><br><span class="line">    &#125; <span class="keyword">while</span> (x1.x == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    mulpt(&amp;ecdlp-&gt;ec, rndk, &amp;ecdlp-&gt;genpt.pt, cipher_pt);</span><br><span class="line">    *cipher = (plain * x1.x) % ecdlp-&gt;genpt.n;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">decrypt_blk</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">const</span> ECDLP* ecdlp,</span></span><br><span class="line"><span class="params">    <span class="type">int64_t</span> prikey,</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EccPoint* cipher_pt, <span class="type">int64_t</span> cipher,</span></span><br><span class="line"><span class="params">    <span class="type">int64_t</span>* plain</span></span><br><span class="line"><span class="params">)</span></span><br><span class="line">&#123;</span><br><span class="line">    EccPoint x1 = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">    mulpt(&amp;ecdlp-&gt;ec, prikey, cipher_pt, &amp;x1);</span><br><span class="line">    *plain = (cipher * inverse(x1.x, ecdlp-&gt;genpt.n)) % ecdlp-&gt;genpt.n;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="包含文件与主程序"><a href="#包含文件与主程序" class="headerlink" title="包含文件与主程序"></a>包含文件与主程序</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    srand((<span class="type">uint32_t</span>)time(<span class="literal">NULL</span>));</span><br><span class="line">    ECDLP ecdlp = &#123; &#123; <span class="number">2</span>, <span class="number">11</span>, <span class="number">49177</span> &#125;, &#123;&#123;<span class="number">1</span>, <span class="number">14445</span>&#125;, <span class="number">49031</span>&#125; &#125;;</span><br><span class="line">    <span class="comment">// print_points(&amp;ecdlp.ec);</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Curve Params: &#123; a = %lld, b = %lld, p = %lld &#125;\n&quot;</span>, ecdlp.ec.a, ecdlp.ec.b, ecdlp.ec.p);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;GenPoint: &#123; pt: (%lld, %lld), n: %lld &#125;\n&quot;</span>, ecdlp.genpt.pt.x, ecdlp.genpt.pt.y, ecdlp.genpt.n);</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> prikey = <span class="number">149</span>;</span><br><span class="line">    EccPoint pubkey = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">    mulpt(&amp;ecdlp.ec, prikey, &amp;ecdlp.genpt.pt, &amp;pubkey);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Prikey: %lld Pubkey: (%lld, %lld)\n&quot;</span>, prikey, pubkey.x, pubkey.y);</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> plain = <span class="number">23456</span>;</span><br><span class="line">    <span class="type">int64_t</span> cipher = <span class="number">-1</span>;</span><br><span class="line">    EccPoint cipher_pt = &#123; <span class="number">0</span> &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Plain: %lld\n&quot;</span>, plain);</span><br><span class="line"></span><br><span class="line">    encrypt_blk(&amp;ecdlp, &amp;pubkey, plain, &amp;cipher_pt, &amp;cipher);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Cipher: (%lld, %lld), %lld\n&quot;</span>, cipher_pt.x, cipher_pt.y, cipher);</span><br><span class="line"></span><br><span class="line">    decrypt_blk(&amp;ecdlp, prikey, &amp;cipher_pt, cipher, &amp;plain);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Plain: %lld\n&quot;</span>, plain);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>密码相关</category>
      </categories>
      <tags>
        <tag>公钥算法</tag>
        <tag>椭圆曲线密码</tag>
      </tags>
  </entry>
  <entry>
    <title>NJ 树算法原理与实现</title>
    <url>//posts/2023/03/08/njtree/</url>
    <content><![CDATA[<p>邻接法 (Neighbor-Joining Method), 是一种利用进化距离数据重建系统进化树的方法, 用这个方法得到的进化树通常称为 NJ 树. 这是一种自底向上的聚类方法, 将每个个体看作一个类别, 然后依次两两聚合, 最终得到一整个聚合后的进化树.</p>
<p>本文简要介绍 NJ 树算法的基本流程与计算方法, 并在文末提供对应的 <code>python</code> 实现.</p>
<span id="more"></span>

<h2 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h2><h3 id="邻居"><a href="#邻居" class="headerlink" title="邻居"></a>邻居</h3><p><img data-src="https://s1.ax1x.com/2023/03/06/ppVbSaR.png" alt="ppVbSaR.png"></p>
<p>首先是关于&quot;邻居&quot;的定义, 在 NJ 树中, 一对&quot;邻居&quot;指的是在一个无根分叉树中仅仅通过一个内部结点连接起来一对分类单元 (OTU).</p>
<p>例如在上图中, $1$ 和 $2$ 可以视为一对邻居, 它们通过内部结点 $A$ 进行连结.</p>
<p>进一步, 可以对分类单元进行组合, 形成新的更大的分类单元与邻居对, 例如, $&lt;1, 2&gt;$ 和 $3$ 可以作为一对邻居, 它们通过内部结点 $B$ 进行连结, $&lt;5, 6&gt;$ 和 $&lt;7, 8&gt;$ 可以作为一对邻居, 它们通过内部结点 $D$ 进行连结.</p>
<h3 id="进化树构建流程"><a href="#进化树构建流程" class="headerlink" title="进化树构建流程"></a>进化树构建流程</h3><p><img data-src="https://s1.ax1x.com/2023/03/06/ppVqOHJ.png" alt="ppVqOHJ.png"></p>
<p>假设初始时没有任何分类单元聚集在一起, 算法起始于一个星状树, 如上图左侧所示. 算法的一步变换则是将左图变成了右图.</p>
<p>在这些分类单元中, 分类单元之间有着不同的距离远近, 右侧的图将 $1$ 和 $2$ 聚合在了一起, 并形成了一个新结点 $Y$, 将 $1$, $2$ 视作一个整体, 则相比于左图, $&lt;1, 2&gt;$ 作为新分类单元整体替换了左图里的分类单元 $1$ 和 $2$, 整个星状树减少了 1 个分类单元, 增加了 1 条内部分支, 每次选择要聚合的邻居时, 都是使得聚合后的新树总枝长最短. 如此循环, 则可以一步一步减少星状树的分类单元, 直至分类单元只剩下 3 个, 内部分支增加至 $N - 3$ 个.</p>
<p><img data-src="https://s1.ax1x.com/2023/03/06/ppVX9mD.png" alt="ppVX9mD.png"></p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p><img data-src="https://s1.ax1x.com/2023/03/06/ppVqOHJ.png" alt="ppVqOHJ.png"></p>
<h3 id="计算总枝长"><a href="#计算总枝长" class="headerlink" title="计算总枝长"></a>计算总枝长</h3><p>还是以这张图为例, 设初始时共有 $N$ 个分类单元, 设 $D_{ij}$ 指分类单元 $i$ 和 $j$ 之间的距离, $L_{ab}$ 指结点 $a$ 和 $b$ 之间的枝长. 整个树的总枝长为:</p>
<p>$$<br>S_O = \sum_{i=1}^{N}L_{iX}=\frac{1}{N-1}\sum_{i&lt;j}^{N}D_{ij}<br>$$</p>
<p>也就是每个结点到 $X$ 的枝长总和, 等价于分类单元两两之间距离求和后除以 $N-1$, 因为每个枝相当于数了 $N-1$ 次.</p>
<details class="note info"><summary><p>为什么是 $N-1$ ?</p>
</summary>
<p>$1$ 到 $X$ 的距离通过 $D_{ij}$ 数了 $N-1$ 次; $2$ 到 $X$ 的距离通过 $D_{12}$ 数了 $1$ 次, 通过 $D_{2j}$ 数了 $N-2$ 次, 以此类推.</p>

</details>

<h3 id="计算新增枝长后的总枝长"><a href="#计算新增枝长后的总枝长" class="headerlink" title="计算新增枝长后的总枝长"></a>计算新增枝长后的总枝长</h3><p>另一方面, 右侧图中 $X$ 和 $Y$ 结点之间的枝长计算方法为:</p>
<p>$$<br>\begin{aligned}<br>  L_{XY} &amp;= \frac{1}{2(N-2)}\left[\sum_{k=3}^{N}{(D_{1k}+D_{2k})} - {(N-2)(L_{1X}+L_{2X})} - {2\sum_{i=3}^{N}{L_{iY}}} \right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[\sum_{k=3}^{N}{(D_{1k}+D_{2k})} - {(N-2)D_{12}} - {\frac{2}{N-3}\sum_{3 \leq i&lt;j}^{N}D_{ij}} \right]<br>\end{aligned}<br>$$</p>
<p>第一项 $\sum_{k=3}^{N}{(D_{1k}+D_{2k})}$ 代表从结点 $1,2$ 到其余所有结点的距离, 包括 $L_{XY}$. 公式的后两项是为了减去多算的那部分距离, $(L_{1X}+L_{2X})$ 是 $1,2$ 到 $X$ 的距离, $\sum_{i=3}^{N}{L_{iY}}$ 是其余点到 $Y$ 的距离.</p>
<details class="note info"><summary><p>前面的那些系数怎么来的 ?</p>
</summary>
<p>在第一项中, $\sum_{k=3}^{N}{(D_{1k}+D_{2k})}$ 将 $1,2$ 到 $X$ 的边各数了 $N-2$ 次, $X$ 到 $Y$ 的边数了 $2(N-2)$ 次, $Y$ 到其余结点各数了 $2$ 次, 因此减去对应的次数后再除以 $2(N-2)$ 就是 $L_{XY}$ 的距离.</p>

</details>

<p>得到 $L_{XY}$ 之后, 可以计算右侧新图的总枝长:</p>
<p>$$<br>\begin{aligned}<br>  S_{12} &amp;= L_{XY} + (L_{1X} + L_{2X}) + \sum_{i=3}^{N}L_{iY} \\<br>  ~ &amp;= \frac{1}{2(N-2)}\sum_{k=3}^{N}(D_{1k} + D_{2k}) + \frac{1}{2}D_{12} + \frac{1}{N-2}\sum_{3 \leq i&lt;j}^{N}D_{ij}<br>\end{aligned}<br>$$</p>
<h3 id="构造新图"><a href="#构造新图" class="headerlink" title="构造新图"></a>构造新图</h3><p>通常来说, 并不会知道右图中 $1,2$ 究竟选择哪一对分类单元作为邻居, 因此需要计算所有的 $S_{ij}$, 并选择最小的那一对作为这一轮的选择.</p>
<p>假设 $1,2$ 就是这一轮选择出来的邻居, 则它们两个和 $X$ 会形成新的分类单元 $&lt;1,2&gt;$, 然后计算新分类单元与其余分类单元的距离:</p>
<p>$$<br>D_{&lt;1,2&gt;j} = \frac{1}{2}(D_{1j} + D_{2j}) \quad (3 \leq j \leq N)<br>$$</p>
<p>得到新距离之后, 还需要计算新分类单元 $&lt;1,2&gt;$ 内部的距离 $L_{1X}, L_{2X}$.</p>
<p>$$<br>\begin{aligned}<br>  L_{1X} &amp;= \frac{1}{2}(D_{12} + D_{1Z} - D_{2Z}) \\<br>  L_{2X} &amp;= \frac{1}{2}(D_{12} + D_{2Z} - D_{1Z})<br>\end{aligned}<br>$$</p>
<p>其中:</p>
<p>$$<br>\begin{aligned}<br>  D_{1Z} &amp;= \frac{1}{N-2}\sum_{i=3}^{N}D_{1i} \\<br>  D_{2Z} &amp;= \frac{1}{N-2}\sum_{i=3}^{N}D_{2i}<br>\end{aligned}<br>$$</p>
<p>在这一组公式里面, $Z$ 代表除去 $1,2$ 的所有结点形成的&quot;假想结点&quot;, 即 $1$ 通过 $Z$ 这个整体与 $2$ 相连. 则 $1,2$ 与 $Z$ 的距离分别为各自到 $Z$ 中其余结点距离的平均值.</p>
<h3 id="循环步骤"><a href="#循环步骤" class="headerlink" title="循环步骤"></a>循环步骤</h3><p>每选择一对合适的邻居, 则图上的分类单元就会减少 1 个, 直到图上的分类单元数量变成 3, 算法结束.</p>
<h2 id="公式化简"><a href="#公式化简" class="headerlink" title="公式化简"></a>公式化简</h2><p>在实际计算之前, 需要对原始公式进行一些化简变形.</p>
<p>首先是对每一轮都需要计算的新图总枝长公式进行变形, 以前文的 $S_{12}$ 为例:</p>
<p>$$<br>\begin{aligned}<br>  S_{12} &amp;= \frac{1}{2(N-2)}\sum_{k=3}^{N}(D_{1k} + D_{2k}) + \frac{1}{2}D_{12} + \frac{1}{N-2}\sum_{3 \leq i&lt;j}^{N}D_{ij} \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[\sum_{k=3}^{N}D_{1k} + \sum_{k=3}^{N}D_{2k} + (N-2)D_{12} + \sum_{3 \leq i&lt;j}^{N}D_{ij} + \sum_{3 \leq i&lt;j}^{N}D_{ij}\right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} - \left(D_{12} + \sum_{k=3}^{N}D_{1k}\right) - \left(D_{21} + \sum_{k=3}^{N}D_{2k}\right) + \left(D_{12} + \sum_{k=3}^{N}D_{1k} + \sum_{3 \leq i&lt;j}^{N}D_{ij}\right) + \left(D_{21} + \sum_{k=3}^{N}D_{2k} + \sum_{3 \leq i&lt;j}^{N}D_{ij}\right)\right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} - \sum_{k \ne 1}^{N}D_{1k} - \sum_{k \ne 2}^{N}D_{2k} + 2\sum_{i&lt;j}^{N}D_{ij}\right] \\<br>  ~ &amp;= \frac{1}{2}\left[D_{12} - \frac{1}{(N-2)}\sum_{k \ne 1}^{N}D_{1k} - \frac{1}{(N-2)}\sum_{k \ne 2}^{N}D_{2k}\right] + \frac{1}{(N-2)}\sum_{i&lt;j}^{N}D_{ij} \\<br>  ~ &amp;= C_1\left[D_{12} - \frac{1}{(N-2)}\sum_{k \ne 1}^{N}D_{1k} - \frac{1}{(N-2)}\sum_{k \ne 2}^{N}D_{2k}\right] + C_2<br>\end{aligned}<br>$$</p>
<p>经过化简之后, 可以看到, 只有方括号里的内容与要计算的邻居对 $1,2$ 有关, 其他量都可以看作这一轮的常量.</p>
<p>因为最终 $S_{ij}$ 是用于比较最小值, 所以只需要保证 $S_{ij}$ 的相对大小不变, 又 $C_1, C_2$ 均大于 $0$, 于是可以在实际计算中忽略掉常数项, 从而简化计算, 从而有:</p>
<p>$$<br>S_{ij} = D_{ij} - D_{iZ} - D_{jZ}<br>$$</p>
<p>其中:</p>
<p>$$<br>D_{iZ} = \frac{1}{(N-2)}\sum_{k \ne i}^{N}D_{ik}<br>$$</p>
<p>仍以前文的图为例, 在选择出最合适的邻居 $1,2$ 后, 会合并成新的分类单元 $&lt;1,2&gt;$, 需要在新图里计算 $&lt;1,2&gt;$ 和其余点的距离值, 以及内部距离 $L_{1X}, L_{2X}$.</p>
<p>新距离值就是 $D_{&lt;i,j&gt;k} = \frac{1}{2}(D_{ik} + D_{jk})$, 这里对 $L_{1X}, L_{2X}$ 进行变形化简.</p>
<p>$$<br>\begin{aligned}<br>  L_{1X} &amp;= \frac{1}{2}(D_{12} + D_{1Z} - D_{2Z}) \\<br>  ~ &amp;= \frac{1}{2}\left(D_{12} + \frac{1}{N-2}\sum_{i=3}^{N}D_{1i} - \frac{1}{N-2}\sum_{i=3}^{N}D_{2i}\right) \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} + \sum_{i=3}^{N}D_{1i} - \sum_{i=3}^{N}D_{2i}\right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} + \left(D_{12} + \sum_{i=3}^{N}D_{1i}\right) - \left(D_{21} + \sum_{i=3}^{N}D_{2i}\right)\right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} + \sum_{k \ne 1}^{N}D_{1k} - \sum_{k \ne 2}^{N}D_{2k}\right] \\<br>  ~ &amp;= \frac{1}{2}\left(D_{12} + \frac{1}{(N-2)}\sum_{k \ne 1}^{N}D_{1k} - \frac{1}{(N-2)}\sum_{k \ne 2}^{N}D_{2k}\right) \\<br>  L_{2X} &amp;= \frac{1}{2}\left(D_{12} + \frac{1}{(N-2)}\sum_{k \ne 2}^{N}D_{2k} - \frac{1}{(N-2)}\sum_{k \ne 1}^{N}D_{1k} \right)<br>\end{aligned}<br>$$</p>
<p>因此有:</p>
<p>$$<br>\begin{aligned}<br>  L_{iX} &amp;= \frac{1}{2}\left(D_{ij} + D_{iZ} - D_{jZ}\right) \\<br>  L_{jX} &amp;= \frac{1}{2}\left(D_{ij} + D_{jZ} - D_{iZ}\right)<br>\end{aligned}<br>$$</p>
<p>变形成这样有个好处, 就是能够复用前面算 $S_{ij}$ 时计算的 $D_{iZ}$ 结果.</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li>依次计算当前轮次的 $M_i$ 值, 得到 $M$ 向量 $(M_1, M_2, \ldots, M_N)$.</li>
<li>计算所有的 $S_{ij} ~ (1 \leq i &lt; j \leq N)$, 选择使 $S_{ij}$ 最小的 $i,j$ 作为这一轮的邻居.</li>
<li>计算新分类单元 $&lt;i,j&gt;$ 对其余点的新距离 $D_{&lt;i,j&gt;k} ~ (1 \leq k \leq N, k \ne i, j)$.</li>
<li>计算内部距离 $L_{iX}$ 和 $L_{jX}$.</li>
<li>更新当前分类单元数 $N = N-1$, 如果 $N &gt; 3$, 则转步骤 1 继续, 否则结束计算.</li>
</ol>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> rich <span class="keyword">import</span> progress</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">neighbor_joining</span>(<span class="params">_otu: <span class="type">List</span>[<span class="built_in">str</span>], _dist: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">float</span>]]</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        _otu: names of otus</span></span><br><span class="line"><span class="string">        _dist: distances dict for otus, (i, j) -&gt; dist, i less than j</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># init</span></span><br><span class="line">    nodes = [&#123;<span class="string">&quot;name&quot;</span>: e, <span class="string">&quot;parent&quot;</span>: <span class="literal">None</span>&#125; <span class="keyword">for</span> e <span class="keyword">in</span> _otu]</span><br><span class="line">    n = <span class="built_in">len</span>(nodes)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># otu_distances: used to record otu distances</span></span><br><span class="line">    otu_distances: np.ndarray = np.array(_dist, dtype=np.float_)</span><br><span class="line">    otu_distances = np.concatenate([otu_distances, np.zeros((n - <span class="number">2</span>, n))], axis=<span class="number">0</span>)</span><br><span class="line">    otu_distances = np.concatenate([otu_distances, np.zeros((<span class="number">2</span> * n - <span class="number">2</span>, n - <span class="number">2</span>))], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># branch_lengths: used to record branch lengths</span></span><br><span class="line">    branch_lengths = np.zeros_like(otu_distances)</span><br><span class="line"></span><br><span class="line">    current_otus = <span class="built_in">list</span>(<span class="built_in">range</span>(n))</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> progress.track(<span class="built_in">range</span>(n - <span class="number">3</span>)):</span><br><span class="line">        n = <span class="built_in">len</span>(current_otus)</span><br><span class="line">        otu_dists = otu_distances[current_otus, ...][..., current_otus]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calc D to Z</span></span><br><span class="line">        otu_dists_to_others: np.ndarray = np.<span class="built_in">sum</span>(otu_dists, axis=<span class="number">0</span>) / (n - <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calc S</span></span><br><span class="line">        graph_branch_length = otu_dists - otu_dists_to_others.reshape(-<span class="number">1</span>, <span class="number">1</span>) - otu_dists_to_others.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># choose min (i, j)</span></span><br><span class="line">        otu1, otu2 = <span class="built_in">min</span>(((i, j) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n)), key=<span class="keyword">lambda</span> x: graph_branch_length[x])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># make new otu and node</span></span><br><span class="line">        n1, n2, n3 = current_otus[otu1], current_otus[otu2], <span class="built_in">len</span>(nodes)</span><br><span class="line">        new_node = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">f&quot;#<span class="subst">&#123;n3&#125;</span>&quot;</span>, <span class="string">&quot;parent&quot;</span>: <span class="literal">None</span>, <span class="string">&quot;children&quot;</span>: (n1, n2)&#125;</span><br><span class="line">        nodes[n1][<span class="string">&quot;parent&quot;</span>] = n3</span><br><span class="line">        nodes[n2][<span class="string">&quot;parent&quot;</span>] = n3</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update otu distances</span></span><br><span class="line">        otu_distances[n3, ...] = (otu_distances[n1, ...] + otu_distances[n2, ...]) / <span class="number">2</span></span><br><span class="line">        otu_distances[..., n3] = (otu_distances[..., n1] + otu_distances[..., n2]) / <span class="number">2</span></span><br><span class="line">        otu_distances[n3, [n1, n2, n3]] = <span class="number">0</span></span><br><span class="line">        otu_distances[[n1, n2, n3], n3] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># update branch lengths</span></span><br><span class="line">        branch_lengths[n1, n3] = branch_lengths[n3, n1] = (</span><br><span class="line">            otu_distances[n1, n2] + otu_dists_to_others[otu1] - otu_dists_to_others[otu2]</span><br><span class="line">            - otu_distances[nodes[n1].get(<span class="string">&quot;children&quot;</span>, (n1, n1))]</span><br><span class="line">        ) / <span class="number">2</span></span><br><span class="line">        branch_lengths[n2, n3] = branch_lengths[n3, n2] = (</span><br><span class="line">            otu_distances[n2, n1] + otu_dists_to_others[otu2] - otu_dists_to_others[otu1]</span><br><span class="line">            - otu_distances[nodes[n2].get(<span class="string">&quot;children&quot;</span>, (n2, n2))]</span><br><span class="line">        ) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># remove n1 &amp; n2</span></span><br><span class="line">        current_otus.remove(n1)</span><br><span class="line">        current_otus.remove(n2)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add n3</span></span><br><span class="line">        nodes.append(new_node)</span><br><span class="line">        current_otus.append(n3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># join rest three otus</span></span><br><span class="line">    n3 = current_otus.pop()</span><br><span class="line">    n2 = current_otus.pop()</span><br><span class="line">    n1 = current_otus.pop()</span><br><span class="line"></span><br><span class="line">    nr = <span class="built_in">len</span>(nodes)</span><br><span class="line">    root_node = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">f&quot;#<span class="subst">&#123;nr&#125;</span>&quot;</span>, <span class="string">&quot;parent&quot;</span>: <span class="literal">None</span>, <span class="string">&quot;children&quot;</span>: (n1, n2, n3)&#125;</span><br><span class="line">    nodes[n1][<span class="string">&quot;parent&quot;</span>] = nr</span><br><span class="line">    nodes[n2][<span class="string">&quot;parent&quot;</span>] = nr</span><br><span class="line">    nodes[n3][<span class="string">&quot;parent&quot;</span>] = nr</span><br><span class="line"></span><br><span class="line">    branch_lengths[n1, nr] = branch_lengths[nr, n1] = (</span><br><span class="line">        otu_distances[n1, n2] + otu_distances[n1, n3] - otu_distances[n2, n3]</span><br><span class="line">        - otu_distances[nodes[n1].get(<span class="string">&quot;children&quot;</span>, (n1, n1))]</span><br><span class="line">    ) / <span class="number">2</span></span><br><span class="line">    branch_lengths[n2, nr] = branch_lengths[nr, n2] = (</span><br><span class="line">        otu_distances[n2, n1] + otu_distances[n2, n3] - otu_distances[n1, n3]</span><br><span class="line">        - otu_distances[nodes[n2].get(<span class="string">&quot;children&quot;</span>, (n2, n2))]</span><br><span class="line">    ) / <span class="number">2</span></span><br><span class="line">    branch_lengths[n3, nr] = branch_lengths[nr, n3] = (</span><br><span class="line">        otu_distances[n3, n1] + otu_distances[n3, n2] - otu_distances[n1, n2]</span><br><span class="line">        - otu_distances[nodes[n3].get(<span class="string">&quot;children&quot;</span>, (n3, n3))]</span><br><span class="line">    ) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    nodes.append(root_node)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nodes, branch_lengths</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_njtree</span>(<span class="params">nodes: <span class="type">List</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]], branch_lengths: np.ndarray</span>):</span><br><span class="line">    lines = []</span><br><span class="line"></span><br><span class="line">    stack = []</span><br><span class="line">    <span class="keyword">for</span> i, node <span class="keyword">in</span> <span class="built_in">enumerate</span>(nodes):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node[<span class="string">&quot;parent&quot;</span>]:</span><br><span class="line">            stack.append((<span class="number">0</span>, <span class="number">0</span>, i, node))</span><br><span class="line">    <span class="keyword">while</span> stack:</span><br><span class="line">        level, count, idx, top = stack.pop()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> level &gt; <span class="number">0</span>:</span><br><span class="line">            level_branchs = []</span><br><span class="line">            pre_level = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> _level, _, _, _ <span class="keyword">in</span> stack[:<span class="built_in">len</span>(stack)-count]:</span><br><span class="line">                <span class="keyword">if</span> _level &gt; pre_level:</span><br><span class="line">                    level_branchs.append(<span class="string">&quot;    &quot;</span> * (_level - pre_level - <span class="number">1</span>) + <span class="string">&quot;│   &quot;</span>)</span><br><span class="line">                    pre_level = _level</span><br><span class="line">            level_branchs.append(<span class="string">&quot;    &quot;</span> * (level - pre_level - <span class="number">1</span>) + (<span class="string">&quot;├──&quot;</span> <span class="keyword">if</span> count &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;└──&quot;</span>))</span><br><span class="line">            edge_length = <span class="string">f&quot;(<span class="subst">&#123;branch_lengths[idx, top[<span class="string">&#x27;parent&#x27;</span>]]:<span class="number">.6</span>f&#125;</span>)&quot;</span></span><br><span class="line">            lines.append(<span class="string">&quot;&quot;</span>.join((*level_branchs, top[<span class="string">&quot;name&quot;</span>], edge_length)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            lines.append(top[<span class="string">&quot;name&quot;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, child <span class="keyword">in</span> <span class="built_in">enumerate</span>(top.get(<span class="string">&quot;children&quot;</span>, [])):</span><br><span class="line">            stack.append((level + <span class="number">1</span>, i, child, nodes[child]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;\n&quot;</span>.join(lines)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    r = neighbor_joining(</span><br><span class="line">        <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">str</span>, <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">9</span>))),</span><br><span class="line">        [[<span class="number">0</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">11</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">13</span>, <span class="number">17</span>],</span><br><span class="line">         [<span class="number">7</span>,  <span class="number">0</span>,  <span class="number">5</span>,  <span class="number">8</span>,  <span class="number">10</span>, <span class="number">13</span>, <span class="number">10</span>, <span class="number">14</span>],</span><br><span class="line">         [<span class="number">8</span>,  <span class="number">5</span>,  <span class="number">0</span>,  <span class="number">5</span>,  <span class="number">7</span>,  <span class="number">10</span>, <span class="number">7</span>,  <span class="number">11</span>],</span><br><span class="line">         [<span class="number">11</span>, <span class="number">8</span>,  <span class="number">5</span>,  <span class="number">0</span>,  <span class="number">8</span>,  <span class="number">11</span>, <span class="number">8</span>,  <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">10</span>, <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">0</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">10</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">13</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">5</span>,  <span class="number">0</span>,  <span class="number">9</span>,  <span class="number">13</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">10</span>, <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">6</span>,  <span class="number">9</span>,  <span class="number">0</span>,  <span class="number">8</span>],</span><br><span class="line">         [<span class="number">17</span>, <span class="number">14</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">10</span>, <span class="number">13</span>, <span class="number">8</span>,  <span class="number">0</span>]]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tree = draw_njtree(r[<span class="number">0</span>], r[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(tree)</span><br></pre></td></tr></table></figure>

<p>输出内容:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#13</span><br><span class="line">├──#12(1.000000)</span><br><span class="line">│   ├──8(6.000000)</span><br><span class="line">│   └──7(2.000000)</span><br><span class="line">├──#11(2.000000)</span><br><span class="line">│   ├──#10(1.000000)</span><br><span class="line">│   │   ├──#8(2.000000)</span><br><span class="line">│   │   │   ├──2(2.000000)</span><br><span class="line">│   │   │   └──1(5.000000)</span><br><span class="line">│   │   └──3(1.000000)</span><br><span class="line">│   └──4(3.000000)</span><br><span class="line">└──#9(2.000000)</span><br><span class="line">    ├──6(4.000000)</span><br><span class="line">    └──5(1.000000)</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9hY2FkZW1pYy5vdXAuY29tL21iZS9hcnRpY2xlLzQvNC80MDYvMTAyOTY2NA==">The Neighbor-joining Method: A New Method for Reconstructing Phylogenetic Trees<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>聚类算法</tag>
        <tag>生信</tag>
        <tag>NJ 树</tag>
      </tags>
  </entry>
  <entry>
    <title>&quot;网安本科速通&quot; 系列后记</title>
    <url>//posts/2022/08/19/wast-afterword/</url>
    <content><![CDATA[<p>终于写完了最后一篇! (撒花~), <a href="/categories/%E7%BD%91%E5%AE%89%E6%9C%AC%E7%A7%91%E9%80%9F%E9%80%9A/">点我查看全系列内容</a>.</p>
<p>虽然这个系列就此完结, 但是只是因为我觉得再写下去已经不算速通的内容了, 我只写了最基本的必需内容.</p>
<p>我相信如果真的好好看完了的话, 应付一下平常的作业应该绰绰有余了. 但是如果真的想要学有所获, 这个系列里的东西真的太浅了, 每一篇都只是入个门而已, 你得花上看这个系列的十倍以上的时间去学习, 去尝试.</p>
<p>这个系列也算是对本科四年一些知识点的总结吧, 都是蜻蜓点水般的带过, 希望日后自己再看到时, 还能够想起来都学了些啥.</p>
<p>就这样了, 网安本科速通, 完成!</p>
<p><img data-src="/images/posts/zzz.gif" alt="zzz.gif"></p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>后记</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 PyTorch 的手写数字分类</title>
    <url>//posts/2022/08/18/wast-dl/</url>
    <content><![CDATA[<p>本篇算是对 <code>pytorch</code> 这一 <code>python</code> 深度学习库神器的入门教程, 以手写数字分类这一经典问题做示例, 来概括一下如何使用 <code>pytorch</code> 来搭建一个自定义的网络结构, 并加以训练.</p>
<span id="more"></span>

<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>所需的第三方库.</p>
<p><code>scikit-learn</code>: 并没有用到里面的算法, 但是小调一下里面现成的指标评价函数, 减少不必要的重复劳动.</p>
<p><code>pytorch</code>: 本篇要使用的核心库, 安装方式需要在<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">官网<i class="fa fa-external-link-alt"></i></span>查询, 且按需安装 <code>cuda</code> 工具.</p>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">example/</span><br><span class="line">    digit_data/</span><br><span class="line">        train/</span><br><span class="line">            0/</span><br><span class="line">                1.jpg</span><br><span class="line">                2.jpg</span><br><span class="line">                ...</span><br><span class="line">            ...</span><br><span class="line">            9/</span><br><span class="line">                ...</span><br><span class="line">                XXX.jpg</span><br><span class="line">        test/</span><br><span class="line">            ...</span><br><span class="line">    main.py</span><br><span class="line">    main.ipynb</span><br></pre></td></tr></table></figure>

<p><img data-src="https://s1.ax1x.com/2022/08/18/vrAZse.png" alt="vrAZse.png"></p>
<h2 id="并不快速的快速上手"><a href="#并不快速的快速上手" class="headerlink" title="并不快速的快速上手"></a>并不快速的快速上手</h2><h3 id="导入所需要的所有库"><a href="#导入所需要的所有库" class="headerlink" title="导入所需要的所有库"></a>导入所需要的所有库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_files</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, f1_score, precision_score, recall_score</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision.io <span class="keyword">import</span> read_image</span><br><span class="line"><span class="keyword">from</span> torchvision.io.image <span class="keyword">import</span> ImageReadMode</span><br><span class="line"></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br></pre></td></tr></table></figure>

<p>除了导入必需的库之外, 还设置了一个全局变量 <code>DEVICE</code>, 后续代码会使用它, 将计算放在 <code>DEVICE</code> 指定的硬件上进行计算, 推荐尽量用 gpu, 速度快很多, 当然对于这个小小的示例程序, cpu 也是能算的.</p>
<h3 id="构建自己的数据集"><a href="#构建自己的数据集" class="headerlink" title="构建自己的数据集"></a>构建自己的数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path</span>):</span><br><span class="line">        data = load_files(path, load_content=<span class="literal">False</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line">        self.inputs = data[<span class="string">&quot;filenames&quot;</span>]</span><br><span class="line">        self.targets = data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.targets)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        input_ = read_image(self.inputs[item], ImageReadMode.GRAY).<span class="built_in">float</span>().to(DEVICE)</span><br><span class="line">        target = torch.tensor([self.targets[item]]).long().to(DEVICE)</span><br><span class="line">        <span class="keyword">return</span> (input_, target)</span><br></pre></td></tr></table></figure>

<p>在 <code>pytorch</code>, 通过继承类 <code>Dataset</code>, 并且重写 <code>__init__</code>, <code>__len__</code> 和 <code>__getitem__</code> 来构建自定义数据集.</p>
<p><code>__init__</code>: 通常在构造函数里定义如何获取原始数据集.</p>
<p><code>__len__</code>: 定义数据集的大小计算方式.</p>
<p><code>__getitem__</code>: 定义如何通过索引来获取一个样本.</p>
<p>这里我们使用之前用过的 <code>load_files</code> 来加载数据集的路径, 并使用 <code>pytorch</code> 提供的图像读取函数 <code>read_image</code> 读取样本.</p>
<h3 id="搭建一个简单的神经网络"><a href="#搭建一个简单的神经网络" class="headerlink" title="搭建一个简单的神经网络"></a>搭建一个简单的神经网络</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyNetwork</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, intput_size=<span class="number">28</span>, input_channels=<span class="number">1</span>, output_size=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.convpooling = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channels, <span class="number">16</span>, <span class="number">5</span>),           <span class="comment"># 28 - 4 = 24</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),                            <span class="comment"># 24 // 2 = 14</span></span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">64</span>, <span class="number">3</span>),                       <span class="comment"># 14 - 2 = 12</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),                            <span class="comment"># 12 // 2 = 6</span></span><br><span class="line">        )</span><br><span class="line">        _size = ((intput_size - <span class="number">4</span>) // <span class="number">2</span> - <span class="number">2</span>) // <span class="number">2</span></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Flatten(<span class="number">1</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*_size*_size, output_size)      <span class="comment"># 64*6*6 -&gt; 10</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = self.convpooling(inputs)</span><br><span class="line">        outputs = self.fc(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>

<p>通过继承 <code>Module</code> 类并重写其中的 <code>__init__</code> 和 <code>forward</code> 来自定义网络结构与前向传播方式.</p>
<p><code>__init__</code>: 在构造函数里给出自定义网络的所有层次结构. 使用 <code>Module</code> 的子类进行定义, 会自动将需要学习的参数注册到整个网络结构上.</p>
<p><code>forward</code>: 定义输入数据如何进行前向传播, 也就是如何使用在构造函数里定义的各个网络层.</p>
<p>这里对于手写数字分类问题, 我们写了一个简单的两层 CNN 网络, 并加上一个全连接层.</p>
<p>网络的输入是 <code>input_size*input_size</code> 大小, 通道数为 <code>input_channels</code> 的图片, 而输出则是 <code>output_size</code> 的一个分类向量, 每个位置代表不同类别的得分.</p>
<p>代码注释里给出了每一层样本大小的变化情况, 每一层之间需要相互对齐才能正确计算.</p>
<h3 id="定义评价指标函数"><a href="#定义评价指标函数" class="headerlink" title="定义评价指标函数"></a>定义评价指标函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">eval_metrics</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    acc = accuracy_score(y_true, y_pred)</span><br><span class="line">    p = precision_score(y_true, y_pred, average=<span class="string">&quot;macro&quot;</span>, zero_division=<span class="number">0</span>)</span><br><span class="line">    r = recall_score(y_true, y_pred, average=<span class="string">&quot;macro&quot;</span>, zero_division=<span class="number">0</span>)</span><br><span class="line">    f1 = f1_score(y_true, y_pred, average=<span class="string">&quot;macro&quot;</span>, zero_division=<span class="number">0</span>)</span><br><span class="line">    report = classification_report(y_true, y_pred, digits=<span class="number">4</span>, zero_division=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (acc, p, r, f1, report)</span><br></pre></td></tr></table></figure>

<p>这里调用了 <code>scikit-learn</code> 的一些常用指标计算函数, 包括准确率, 精度, 召回率, F1 得分, 以及一份汇总结果.</p>
<p>输入数据就是真实标签与预测标签.</p>
<h3 id="定义训练函数"><a href="#定义训练函数" class="headerlink" title="定义训练函数"></a>定义训练函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_data_loader, criterion, optimizer</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    loss_list = []</span><br><span class="line">    pred_list = []</span><br><span class="line">    true_list = []</span><br><span class="line">    <span class="keyword">for</span> inputs, targets <span class="keyword">in</span> train_data_loader:</span><br><span class="line">        targets = targets.flatten()</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        loss_list.append(loss.item())</span><br><span class="line">        pred_list.append(outputs.argmax(dim=-<span class="number">1</span>).cpu().numpy())</span><br><span class="line">        true_list.append(targets.cpu().numpy())</span><br><span class="line"></span><br><span class="line">    y_pred = np.concatenate(pred_list)</span><br><span class="line">    y_true = np.concatenate(true_list)</span><br><span class="line"></span><br><span class="line">    loss = np.mean(loss_list)</span><br><span class="line">    result = eval_metrics(y_true, y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (loss, *result)</span><br></pre></td></tr></table></figure>

<p>训练函数有四个参数.</p>
<p><code>model</code>: 模型, 也就是前面我们自己定义的神经网络实例.</p>
<p><code>train_data_loader</code>: 训练数据集加载器. 是一个 <code>DataLoader</code> 实例, 可以进行迭代从里面按批次大小获得训练数据.</p>
<p><code>criterion</code>: 损失函数, 用来计算每次输出与真实标签之间的损失值, 并进行反向传播计算梯度.</p>
<div class="note info"><p>需要注意的是, 对 <code>targets</code> 使用了一次 <code>flatten</code> 操作.<br>因为使用 <code>DataLoader</code> 对数据集进行加载时, 每次是按照 <code>batch_size</code> 来批量获取的, 因此会自动将单个样本进行拼接变成一个 batch. 所以 <code>targets</code> 是 <code>(batch_size, 1)</code> 的形状.<br>但是我们要使用的损失函数是 <code>CrossEntropy</code> 交叉熵损失函数, 它的输入要求真实标签是一个一维的向量 <code>(batch_size, )</code>, 因此使用 <code>flatten</code> 对 <code>targets</code> 进行展平操作.</p>
</div>

<p><code>optimizer</code>: 优化器, 在使用之前已经将 <code>model</code> 中需要训练的参数注册进去, 每次调用 <code>step</code> 方法可以对 <code>model</code> 注册的参数通过梯度进行更新.</p>
<p>训练的流程共有以下几步.</p>
<ol>
<li>将 <code>model</code> 转为 <code>train</code> 模式.</li>
<li>迭代数据集加载器, 按批次获取每一次要学习的样本.</li>
<li>将样本喂进 <code>model</code> 进行前向传播, 并计算损失.</li>
<li>清空优化器中上一次梯度值.</li>
<li>从损失处开始反向传播, 计算本次参数需进行学习的梯度.</li>
<li>调用优化器的 <code>step</code>, 根据梯度值完成对网络参数的更新.</li>
</ol>
<p>后面还有一些额外的统计操作, 用来记录本次训练过程时的平均损失和准确度等情况.</p>
<h3 id="定义评估函数"><a href="#定义评估函数" class="headerlink" title="定义评估函数"></a>定义评估函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, eval_data_loader, criterion</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    loss_list = []</span><br><span class="line">    pred_list = []</span><br><span class="line">    true_list = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> inputs, targets <span class="keyword">in</span> eval_data_loader:</span><br><span class="line">            targets = targets.flatten()</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">            loss_list.append(loss.item())</span><br><span class="line">            pred_list.append(torch.argmax(outputs, dim=-<span class="number">1</span>).cpu().numpy())</span><br><span class="line">            true_list.append(targets.cpu().numpy())</span><br><span class="line"></span><br><span class="line">    y_pred = np.concatenate(pred_list)</span><br><span class="line">    y_true = np.concatenate(true_list)</span><br><span class="line"></span><br><span class="line">    loss = np.mean(loss_list)</span><br><span class="line">    result = eval_metrics(y_true, y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (loss, *result)</span><br></pre></td></tr></table></figure>

<p>评估函数的过程与训练函数类似, 不同之处在于前者的参数里没有优化器, 因为评估函数用于模型在测试集上进行测试, 不需要反向传播与参数更新的操作.</p>
<p>评估函数的关键是 <code>torch.no_grad</code> 操作, 在此上下文内对 <code>model</code> 的操作不会计算任何梯度值, 只会进行单纯的前向求值计算操作.</p>
<h3 id="定义训练超参数"><a href="#定义训练超参数" class="headerlink" title="定义训练超参数"></a>定义训练超参数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">seed = <span class="number">1</span></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line">batch_size = <span class="number">500</span></span><br><span class="line">epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed(seed)</span><br></pre></td></tr></table></figure>

<p>这里我们设置了学习率和训练轮数, 由于只是示例因此轮数只有 5 来展示效果.</p>
<p>将随机数种子列入了超参数并且固定了 <code>torch</code> 随机数模块的种子, 目的是为了稳定复现结果.</p>
<h3 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_dataset = MyDataset(<span class="string">&quot;./digit_data/train/&quot;</span>)</span><br><span class="line">test_dataset = MyDataset(<span class="string">&quot;./digit_data/test/&quot;</span>)</span><br><span class="line">train_dataloader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataloader = DataLoader(test_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br></pre></td></tr></table></figure>

<p>导入了自己的手写数字数据集并使用 <code>DataLoader</code> 来进行加载, 可以设置是否打乱与批次大小等加载参数.</p>
<h3 id="实例化模型训练需要的对象"><a href="#实例化模型训练需要的对象" class="headerlink" title="实例化模型训练需要的对象"></a>实例化模型训练需要的对象</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MyNetwork().to(DEVICE)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss().to(DEVICE)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<p>模型使用了默认参数, 数据集图片大小为 <code>28*28</code>, 且加上了 <code>to(DEVICE)</code>. 在前面构建数据集部分也使用了 <code>to(DEVICE)</code> 操作, 其目的是为了保证所有要参与计算的 <code>Tensor</code> 都在同一个硬件设备上进行计算.</p>
<p>然后是实例化损失函数与优化器. 在优化器的参数中需要填入 <code>model</code> 所有需要更新的网络参数, 并填入学习率.</p>
<p>优化器选择了 <code>Adam</code>, 一个几乎万用的优化器.</p>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===============================&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-------------------------------&quot;</span>)</span><br><span class="line">    *train_metrics, _ = train(model, train_dataloader, loss_fn, optimizer)</span><br><span class="line">    *evaluate_metrics, _ = evaluate(model, test_dataloader, loss_fn)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Train Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125; F1: &#123;:.4f&#125;(&#123;:.4f&#125;/&#123;:.4f&#125;)&quot;</span>.<span class="built_in">format</span>(*train_metrics))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Eval  Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125; F1: &#123;:.4f&#125;(&#123;:.4f&#125;/&#123;:.4f&#125;)&quot;</span>.<span class="built_in">format</span>(*evaluate_metrics))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;===============================&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>得到如下训练过程输出.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">===============================</span><br><span class="line">Epoch 1</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 11.0961 Acc: 0.4295 F1: 0.4297(0.4272/0.4281)</span><br><span class="line">Eval  Loss: 0.7999 Acc: 0.8052 F1: 0.8232(0.8059/0.8014)</span><br><span class="line">===============================</span><br><span class="line">Epoch 2</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.8910 Acc: 0.8009 F1: 0.8002(0.8000/0.7999)</span><br><span class="line">Eval  Loss: 0.3495 Acc: 0.9106 F1: 0.9111(0.9103/0.9103)</span><br><span class="line">===============================</span><br><span class="line">Epoch 3</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.4862 Acc: 0.8683 F1: 0.8675(0.8675/0.8674)</span><br><span class="line">Eval  Loss: 0.2554 Acc: 0.9324 F1: 0.9324(0.9322/0.9320)</span><br><span class="line">===============================</span><br><span class="line">Epoch 4</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.3536 Acc: 0.9016 F1: 0.9013(0.9008/0.9010)</span><br><span class="line">Eval  Loss: 0.2114 Acc: 0.9396 F1: 0.9393(0.9397/0.9393)</span><br><span class="line">===============================</span><br><span class="line">Epoch 5</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.2802 Acc: 0.9173 F1: 0.9170(0.9170/0.9169)</span><br><span class="line">Eval  Loss: 0.1861 Acc: 0.9470 F1: 0.9474(0.9471/0.9469)</span><br><span class="line">===============================</span><br></pre></td></tr></table></figure>

<p>训练时每训练一轮同时也在测试集上评估一次, 可以看到两个损失值都是成功下降, 且正确率逐步上升. 有时间的话可以多训练几轮, 看看损失值的变化情况.</p>
<h3 id="输出最终的测试结果"><a href="#输出最终的测试结果" class="headerlink" title="输出最终的测试结果"></a>输出最终的测试结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">*_, report = evaluate(model, test_dataloader, loss_fn)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br></pre></td></tr></table></figure>

<p>输出.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0     0.9344    0.9913    0.9620       460</span><br><span class="line">           1     0.9653    0.9737    0.9695       571</span><br><span class="line">           2     0.9176    0.9660    0.9412       530</span><br><span class="line">           3     0.9346    0.9720    0.9529       500</span><br><span class="line">           4     0.9459    0.9440    0.9449       500</span><br><span class="line">           5     0.9566    0.9671    0.9618       456</span><br><span class="line">           6     0.9644    0.9372    0.9506       462</span><br><span class="line">           7     0.9467    0.9023    0.9240       512</span><br><span class="line">           8     0.9585    0.8978    0.9271       489</span><br><span class="line">           9     0.9503    0.9192    0.9345       520</span><br><span class="line"></span><br><span class="line">    accuracy                         0.9470      5000</span><br><span class="line">   macro avg     0.9474    0.9471    0.9469      5000</span><br><span class="line">weighted avg     0.9474    0.9470    0.9468      5000</span><br></pre></td></tr></table></figure>

<p>其实就是再次调用了一下 <code>evaluate</code> 函数, 但是输出了 report 结果.</p>
<p>可以看到正确率尚可, 达到了 0.94 多, 多训练几轮说不定会更高. 贴一下训练了 22 轮的结果.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0     0.9620    0.9913    0.9764       460</span><br><span class="line">           1     0.9758    0.9895    0.9826       571</span><br><span class="line">           2     0.9701    0.9792    0.9746       530</span><br><span class="line">           3     0.9839    0.9760    0.9799       500</span><br><span class="line">           4     0.9739    0.9720    0.9730       500</span><br><span class="line">           5     0.9759    0.9759    0.9759       456</span><br><span class="line">           6     0.9868    0.9697    0.9782       462</span><br><span class="line">           7     0.9631    0.9688    0.9659       512</span><br><span class="line">           8     0.9710    0.9571    0.9640       489</span><br><span class="line">           9     0.9706    0.9519    0.9612       520</span><br><span class="line"></span><br><span class="line">    accuracy                         0.9732      5000</span><br><span class="line">   macro avg     0.9733    0.9731    0.9732      5000</span><br><span class="line">weighted avg     0.9733    0.9732    0.9732      5000</span><br></pre></td></tr></table></figure>

<p><del>提高了足足 <strong>3 个百分点</strong>! 足以让我们发一篇 CVPR 了!</del> 看得出没有太明显的提升, 一是数据集较小, 二是网络结构比较简单, 不过也足以见到神经网络的强大了.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>万变不离其宗, 虽然本篇是一个只是一个非常精简的手写数字分类, 但是麻雀虽小五脏俱全, 再大型再复杂的网络结构, 它的基本流程都离不开那几个步骤, 唯一没提到了可能就是面对长时间训练情况下, 怎么 &quot;断点续训&quot; 记录存档点, 这个靠自己摸索了. <del>都是网安的了, 自学什么的早就会了吧.</del></p>
<p>实际中, 很少真的自己手搓网络了, 就算是学习论文里的模型, 也都是尽可能的直接拉开源代码下来跑. 那么学习本篇的主要目的是知道使用 <code>pytorch</code> 的最基本的几个步骤, 在看开源代码时, 能够快速找到各个部件都在哪, 理解作者的项目组织方式, 并且必要时可以对源代码做出一定的调整.</p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p><code>pytorch</code> 的官方网站: <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">https://pytorch.org/<i class="fa fa-external-link-alt"></i></span>.</p>
<p>这个官方网站挺好的, 不仅文档详细, 同时也提供了很多示例教学, 很适合入门或者详细了解各种接口.</p>
<p>另附上项目中使用的数据集下载地址, <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pVFBrSzA5cGZuaGE=">点击下载<i class="fa fa-external-link-alt"></i></span>.</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>pytorch</tag>
        <tag>手写数字分类</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 与 Github 入门</title>
    <url>//posts/2022/08/15/wast-gitandgithub/</url>
    <content><![CDATA[<p><code>git</code> 你可能用不到但是 <code>github</code> 肯定用得到, 因为面对一大堆代码任务, 谁都想去<del>抄</del>借鉴一下他人优秀的代码.</p>
<p>因此本篇将向萌新们介绍一下版本管理工具 <code>git</code> 与全世界最大的代码托管平台 <code>github</code> 的基本使用方法.</p>
<span id="more"></span>

<h2 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h2><p>先说 <code>github</code>, 简单粗暴的理解就是, <code>github</code> 是一个专属于代码的云盘, 全世界的人都可以在上面存储自己的代码, 并且可以让大家都来查看自己的代码.</p>
<p>平常如果遇到一些不会的代码问题, 多半用搜索引擎搜出来的都是 CSDN 和博客园或者知乎的内容, 偶尔可以见到一些个人博客<del>比如我这个</del>. 个人博客可能质量稍好, 毕竟是自己经营的, 大概率会认真写点东西放上去, 但是前三者就不一定了, 可能同样的内容都被复制的有包浆了. 因此我们如果想要进一步提升自己的 Coding 水平, 就需要看更高质量的内容, 所以我们把目光投向了 <code>github</code>.</p>
<p><code>github</code> 的最大宗旨就是开源, 任何人都可以发布自己的代码并且让他人一起协同合作. 得益于此, <code>github</code> 上面有很多经典的大型开源项目可供学习, 并且小项目的完整度和质量也比一众博客高出不少, 是我们<del>抄</del>借鉴代码的好去处.</p>
<p><code>github</code> 的官网地址是 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLw==">https://github.com/<i class="fa fa-external-link-alt"></i></span>, 由于不可抗力, 访问不太稳定, 但是可以通过科学上网解决, 可以参考我前一篇文章<a href="/posts/2022/08/15/wast-gitandgithub/">解决学习道路上的 &quot;最后 1 KB&quot;</a>快速入门一下. 进去之后就可以像普通的搜索引擎那样使用, 但是是搜索 <code>github</code> 的所有项目仓库 (多用英语搜, 结果会更理想).</p>
<h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><p><code>git</code> 和 <code>github</code> 长得很像但是完全是两回事, 后者是一个存放代码的地方, 但是前者是一个代码版本管理工具.</p>
<p>罗马不是一天建成的, 代码也不是一天肝完的, 前一天写完的代码, 后一天就会出现 bug, 因此对一份代码不间断的进行修修补补是常事. 如果是毕业论文, 倒还是可以给文件名自己加上一个版本号, 比如 &quot;最终版&quot;, &quot;最终版 v2&quot;...... 但是对于代码文件, 这就不太适用了.</p>
<p>一是代码文件将来会修改的次数可能太多, 一份文件动辄十几二十次, 取这么多版本号不太现实, 二是无法很好的对比每一个版本每次的修改变动, 无法让人一目了然每次修改都改了啥.</p>
<p>因此 <code>git</code> 的出现很好解决了上述问题, 下面简要介绍几个常用的 <code>git</code> 命令和基本概念.</p>
<h3 id="安装-Git"><a href="#安装-Git" class="headerlink" title="安装 Git"></a>安装 Git</h3><p>首先当然是安装 <code>git</code>, 官网地址 <span class="exturl" data-url="aHR0cHM6Ly9naXQtc2NtLmNvbS8=">https://git-scm.com/<i class="fa fa-external-link-alt"></i></span>, 点进去直接 &quot;Downloads&quot; 最新版本进行安装, 安装时有一些选项值得注意一下.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/14/vaPitJ.png" alt="vaPitJ.png">]</p>
<p>这两个可以勾上, 这样子右键菜单里会加入这两个快捷项, 方便我们随处快速打开 <code>git</code> 终端.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/14/vaPtnf.png" alt="vaPtnf.png"></p>
<p>然后是这个, 使用 <code>VS Code</code> 作为 <code>git</code> 的默认文本编辑器. 要求我们安装了 <code>VS Code</code>, 然后勾选这个选项. 这个意思是一旦 <code>git</code> 出现需要我们手动敲一点文本内容的时候, 会弹出来 <code>VS Code</code> 界面作为输入界面. 强烈建议换掉, 一是好看二是省事<del>珍爱生命, 远离 Vim</del>.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/14/vaPTjx.png" alt="vaPTjx.png"></p>
<p>然后是这个, 也是建议选下面的, 曾经 <code>git</code> 的主分支默认叫 <code>master</code>, 但是现在大部分新项目都叫 <code>main</code> 了. 不是什么大问题, 但是建议按新的约定来<del>紧随时代潮流</del>.</p>
<p>后面的选项就可以不用太在意了, 直接一路 Next 就行了, 反正之后都还可以自己手动调整设置项.</p>
<h3 id="使用-Git"><a href="#使用-Git" class="headerlink" title="使用 Git"></a>使用 Git</h3><p>这里只介绍待会要用到的命令和一些基本概念, 毕竟是入门<del>主要是太懒不想写</del>, 具体的细节可以自己看官方文档或者使用搜索引擎学习.</p>
<p><code>git init</code>: 初始化一个本地仓库.</p>
<p>想要使用 <code>git</code> 来管理一个项目, 首先需要使用该命令让 <code>git</code> 将一个项目文件夹标记为需要被 <code>git</code> 进行管理的仓库. 运行完成后, 项目文件夹下就会多出来一个 <code>.git</code> 文件夹, 代表这个项目文件夹已经是一个合法的 <code>git</code> 仓库了.</p>
<p><code>git add &lt;文件&gt;</code>: 临时储存文件变动.</p>
<p>当我们的代码文件发生改动时, 使用该命令进行临时存储, 所谓 &quot;临时&quot;, 是指我们还没有完成一次完整的修改, 但是需要临时保存一下已经做过的修改步骤, 让我们在进一步修改时好进行对比.</p>
<p><code>git commit -m &lt;信息&gt;</code>: 提交一次改动.</p>
<p>当我们已经完成了一次修改, 使用了 <code>add</code> 进行了存储, 并且想要把这次修改确定下来, 形成一次记录时, 需要使用该命令. 其中 &quot;信息&quot; 部分是一个很重要的内容, 是对这一次提交的一个简要说明, 日后我们可以很方便的根据当时提交时填的信息来确定提交的内容, 也可以从大量提交中快速检索与某些特定目的相关的提交.</p>
<p><code>git log --graph --oneline --all</code>: 使用图形化方式查看所有分支的提交记录.</p>
<p>使用该命令可以查看所有提交记录以及各提交记录的哈希值, 有助于我们迅速了解整个仓库的提交历史记录.</p>
<p><code>git show &lt;提交 id&gt;</code>: 查看某一次提交的具体内容.</p>
<p>&quot;提交 id&quot; 就是使用 <code>git log</code> 查到的提交记录哈希值, 显示之后会得到文件变动记录以及各文件具体的修改情况.</p>
<h3 id="简单的实践一下"><a href="#简单的实践一下" class="headerlink" title="简单的实践一下"></a>简单的实践一下</h3><p>以我们之前曾经创建过的一个 <code>example</code> 项目举例, 来使用 <code>git</code> 对其进行本地版本管理, 项目文件结构如下所示.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">example/</span><br><span class="line">    env/</span><br><span class="line">    main.py</span><br></pre></td></tr></table></figure>

<p>总共两部分, 一个是 <code>env</code> 文件夹, <code>python</code> 的虚拟环境, 另一个是我们的源文件 <code>main.py</code>, 我们的目标是只提交 <code>main.py</code>, 而忽略虚拟环境 <code>env</code>, 因为环境严格来说并不需要记录到整个项目里, 每次使用时可以重新生成. 完整的命令执行记录如图所示.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/14/vaVnBt.png" alt="vaVnBt.png"></p>
<p>首先进入 <code>example</code> 文件夹, 然后使用 <code>ls</code> 命令查看了一下文件夹内的内容. 之后便是 <code>init -&gt; add -&gt; commit</code> 的一连串操作.</p>
<p>需要注意的地方是, 第一次使用 <code>commit</code> 时, 会给予我们图上的提示信息, 意思是提交时需要指定作者信息. 也就是对于每次提交, <code>git</code> 必须记录是 &quot;谁&quot; 提交了这次修改, 并且是通过 &quot;邮箱&quot; 和 &quot;用户名&quot; 两个信息来确定身份的. 这里我们直接按照提示信息里说的, 设置一下自己的邮箱和用户名, 然后重新使用 <code>commit</code> 命令进行提交即可.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/14/vaVI8e.png" alt="vaVI8e.png"></p>
<p>然后我们使用 <code>log</code> 和 <code>show</code> 两个命令查看一下刚刚的提交记录, 其中 <code>+</code> 表示文件内新增的行, 而 <code>-</code> 表示删去的行, 一般来说如果是对某一行进行了修改则会是 <code>+</code> 和 <code>-</code> 交替出现, 这里只有 <code>+</code> 是因为提交了一份全新的文件.</p>
<h2 id="使用-Git-管理-Github-上的项目"><a href="#使用-Git-管理-Github-上的项目" class="headerlink" title="使用 Git 管理 Github 上的项目"></a>使用 Git 管理 Github 上的项目</h2><h3 id="Git-分支简介"><a href="#Git-分支简介" class="headerlink" title="Git 分支简介"></a>Git 分支简介</h3><p>如果 <code>git</code> 的功能仅限于本地管理, 那也就止步于此了, 其最强大的功能还是与 <code>github</code> 结合, 从而实现本地与远程同步的版本管理.</p>
<p>这里需要先介绍一下 <code>git</code> 进行版本管理的一个重要概念 &quot;分支&quot;.</p>
<p>当我们使用 <code>git init</code> 命令创建本地仓库时, 其实就有了第一个分支, 也是我们的主分支 <code>main</code>, 名字就是在安装 <code>git</code> 时设定的默认名称.</p>
<p>当我们对仓库进行操作并提交记录时, <code>git</code> 需要知道当前仓库正处于哪一个分支上, 并把提交记录在这个分支上, 形成分支上的一个个节点. 从而很多次提交之后, 这个分支会逐渐变长, 并且上面的节点数变多, 每一个节点就是每一次提交记录.</p>
<p>当你某天想让你的代码形成另外一个版本时, 但是并不想影响主分支上的内容时, 就可以从主分支的某个节点开始, 延伸出另一条新分支, 从而让两个分支上的内容同时存在且互不干扰. 可想而知, 当分支数多了之后, 分支图将会是一个树形结构.</p>
<p>本地仓库是如此, 对于远程仓库来说也是类似的. 当我们需要将本地的代码仓库同步放到 <code>Github</code> 上进行管理时, 则需要添加仓库内的 &quot;远程分支&quot; 信息.</p>
<p>远程分支与本地的分支像并列的关系, 它们之间形成关联并进行追踪, 从而你可以指定本地的某个分支与远程的某个分支进行关联并同步. 最终远程仓库的远程分支就像是本地仓库分支的一份 &quot;备份&quot;, 无论是哪一边有改动, 都可以通过 <code>git</code> 指令来进行互相同步.</p>
<p>这里放上一个经典的图形化 <code>git</code> 操作学习网站 <span class="exturl" data-url="aHR0cHM6Ly9sZWFybmdpdGJyYW5jaGluZy5qcy5vcmcv">Leanr Git Branching<i class="fa fa-external-link-alt"></i></span>, 有助于快速理解 <code>git</code> 的分支概念<del>几乎我所有认识的学长都推荐过</del>.</p>
<h3 id="在-Github-上发布第一个项目"><a href="#在-Github-上发布第一个项目" class="headerlink" title="在 Github 上发布第一个项目"></a>在 Github 上发布第一个项目</h3><p>首先, 你得注册一个 <code>Github</code> 账号, 点 <code>Sign up</code> 之后自己琢磨吧.</p>
<p>注册好之后, 你的个人界面网址应该就是 <code>https://github.com/&lt;用户名&gt;/</code>, 并且进去后界面大概长的像下面的样子.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/15/vaLItP.png" alt="vaLItP.png"></p>
<p>但是在创建仓库发布项目之前, 还有一步重要的事情, 往自己的 <code>Github</code> 里添加 <code>ssh</code> 连接公钥, 可能现在你还不清楚是什么但是照着教程做即可, 既可以提高安全性也可以避免一些麻烦. (如果有喜欢尝试的同学可以试一下走 <code>http</code> 协议的方式, <code>Github</code> 已经不推荐并且由于不可抗力网络质量也很差.)</p>
<p>贴上官方的<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmdpdGh1Yi5jb20vY24vYXV0aGVudGljYXRpb24vY29ubmVjdGluZy10by1naXRodWItd2l0aC1zc2g=">教程<i class="fa fa-external-link-alt"></i></span>, 同时下面也会简要描述一下步骤.</p>
<div class="note info"><p>1.生成自己的 ssh 公钥<br>如果曾经已经生成过的同学可以酌情跳过这一步.<br>打开 <code>git bash</code> 或者 <code>cmd</code>, 输入以下指令.<br><code>ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</code><br>其中 <code>-C</code> 后面跟的是注释内容, 一般填一个能够标识身份的邮箱地址. 之后一路回车即可.<br>成功生成之后, 可以使用 <code>ls</code> 和 <code>cat</code> 命令查看生成的文件与公钥内容.<br>所有操作和成功生成后的结果如下图所示.<br><img data-src="https://s1.ax1x.com/2022/08/15/vwila8.png" alt="vwila8.png"><br>2.将公钥添加到 Github<br>回到 <code>github</code> 的个人主页面, 进入 &quot;Settings&quot; 界面, 在左侧选择 &quot;SSH and GPG Keys&quot;, 然后选择 <code>New SSH Key</code>, 并将<strong>公钥文件 <code>id_rsa.pub</code></strong> 的内容复制进去, 注意是<strong>公钥文件 <code>id_rsa.pub</code></strong>.<br><img data-src="https://s1.ax1x.com/2022/08/15/vwi2s1.png" alt="vwi2s1.png"></p>
</div>

<p>继续回到我们的 <code>Github</code> 个人主页面, 点击页面右上角的加号, 选择 &quot;New repository&quot;, 创建我们的第一个项目仓库.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0E9gg.png" alt="v0E9gg.png"></p>
<p>如图所示填好必要的信息, 其中选项 public 即代表这是一个公开仓库, 任何人都可以在 <code>github</code> 上访问并查看里面的文件内容.</p>
<p>创建完成后, 会显示三种后续的操作, 在这里我们选择第二种, &quot;将已有的仓库从命令行推送&quot;.</p>
<p>进入你的本地仓库, 打开 <code>git bash</code> 并依次执行下面三条命令.</p>
<p><code>git remote add origin git@github.com:&lt;用户名&gt;/&lt;仓库名&gt;.git</code>: 将远程主机与仓库地址添加到本地仓库配置中, 主机名 <code>origin</code>, 地址为 <code>ssh</code> 地址 <code>git@github.com:&lt;用户名&gt;/&lt;仓库名&gt;.git</code></p>
<p><code>git branch -M main</code>: 可选步骤, 将当前分支重命名为 <code>main</code>, 此前我们的分支名已经是 <code>main</code> 了.</p>
<p><code>git push -u origin main</code>: 将本地分支 <code>main</code> 推送到远程主机 <code>origin</code>, 并且远程分支名与本地相同也为 <code>main</code>.</p>
<p>执行完成后稍等一会刷新一下页面, 就可以看到 <code>github</code> 上已经有本地仓库的内容了.</p>
<h3 id="在本地管理远程项目"><a href="#在本地管理远程项目" class="headerlink" title="在本地管理远程项目"></a>在本地管理远程项目</h3><p>这部分主要介绍平常敲代码时常用的命令流.</p>
<p><code>git pull</code>: 进行写代码时的第一步, 使用该命令可以将远程仓库里的最新记录同步至本地.</p>
<p><code>git add &lt;文件&gt;</code>: 写代码中途或者写完代码后, 将修改后的文件进行储存.</p>
<p><code>git commit -m &lt;信息&gt;</code>: 将所有通过 <code>add</code> 存储的内容进行提交, 产生一次记录.</p>
<p><code>git push</code>: 将本地所有的提交记录同步推送到远程仓库.</p>
<h2 id="在-VS-Code-中使用-Git"><a href="#在-VS-Code-中使用-Git" class="headerlink" title="在 VS Code 中使用 Git"></a>在 VS Code 中使用 Git</h2><p>前面花了很长的篇幅讲解 <code>git</code> 的各种使用, 并且有着非常多的命令, 很容易让人头晕. 但是好在大部分命令都是重复相似的, 因此, 为了省事, 绝大多数开发工具都支持图形化的 <code>git</code> 命令操作, 从而避免了命令行的痛苦. 但是在使用时仍然需要知道每一个按键选项与命令的基本对应关系, 清楚每一步具体做了什么.</p>
<p><code>VS Code</code> 本身自带对 <code>git</code> 的支持, 且已经能够满足基本使用. 打开我们的 <code>example</code> 项目, 左边切换到 <code>源代码管理</code> 的面板.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0naB4.png" alt="v0naB4.png"></p>
<p>在这里可以看到本地仓库的所有更改, 我们可以手动切换一下视图模式, 以树形式查看, 方便与资源管理器的视图对应.</p>
<p>可以看到存在两部分变动, 且标记为 <code>U</code>, 意为 &quot;未跟踪&quot;, 也就是它是一份新文件, 如果是曾经有过记录则是 <code>M</code>. 点击左侧的文件名, 还可以在右方的窗口里预览文件的每一行更改情况.</p>
<p>我们选择 <code>main.py</code> 一行右侧的 <code>+</code> 号, &quot;暂存更改&quot;, 其行为等价于 <code>add</code> 操作.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0uFrF.png" alt="v0uFrF.png"></p>
<p>操作之后 <code>main.py</code> 被放入 &quot;暂存的更改&quot; 中, 此时可以在上方的输入框中键入信息, 然后点提交, 该步骤等价于 <code>git commit</code> 操作.</p>
<p>如果没有暂存的更改, 则所有的更改都将会被提交. 如果提交信息为空, 则会弹出界面让你输入信息.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0KiWt.png" alt="v0KiWt.png"></p>
<p>提交完成后, <code>VS Code</code> 左下角将会如图所示, 有一个双箭头圆圈且有数字标记, 意为本地比远程多一次提交记录, 点击圆圈, <code>VS Code</code> 会将本地仓库与远程仓库进行自动同步, 其操作等价于先进行 <code>pull</code> 再进行 <code>push</code>.</p>
<p>一般来说, 推荐使用命令行创建仓库以及关联远程仓库等初始化操作, 之后再使用图形化界面进行每天的提交和同步操作. 此外, 如果觉得 <code>VS Code</code> 原生支持不够, 还有丰富的插件可以选择, 比如 <code>GitLens</code> 诸如此类.</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>尽可能的把平常高频使用的内容都写上去了, 虽然感觉写的很长但是仍然很难把每一件事都写的很清楚, 只能是把表面写一写, 内部的细节原理不是这个入门篇能一次性搞定, 还得靠自己平日善用搜索引擎和官方文档.</p>
<p>这里贴一下 <code>git</code> 与 <code>github</code> 的文档地址, <span class="exturl" data-url="aHR0cHM6Ly9naXQtc2NtLmNvbS9kb2Nz">https://git-scm.com/docs<i class="fa fa-external-link-alt"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmdpdGh1Yi5jb20vY24=">https://docs.github.com/cn<i class="fa fa-external-link-alt"></i></span>, 熟能生巧~</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>经典问题之文本分类</title>
    <url>//posts/2022/08/17/wast-ml/</url>
    <content><![CDATA[<p>成为一个熟练的调包侠是速通的关键要素之一, 在无数的课程大作业和小任务中, 使用机器学习来解决一些问题算是经典中的经典<del>典中典</del>, 比如通过文本分类来实现垃圾邮件过滤. 因此本篇将基于 <code>python</code> 中最常用的机器学习库 <code>scikit-learn</code>, 用朴素贝叶斯模型来完成一次文本分类任务.</p>
<span id="more"></span>

<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>需要的第三方库.</p>
<p><code>jieba</code>: 一个中文分词库, 可以将一个句子分成一个个的单词.</p>
<p><code>scikit-learn</code>: <code>python</code> 中最常用的机器学习库, 内置多种模型与算法, 开箱即用.</p>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">example/</span><br><span class="line">    data/</span><br><span class="line">        财经/</span><br><span class="line">            1.txt</span><br><span class="line">            2.txt</span><br><span class="line">            ...</span><br><span class="line">            200.txt</span><br><span class="line">        房产/</span><br><span class="line">            1.txt</span><br><span class="line">            ...</span><br><span class="line">            200.txt</span><br><span class="line">        XXX/</span><br><span class="line">            XXX.txt</span><br><span class="line">        ...</span><br><span class="line">    main.py</span><br><span class="line">    main.ipynb</span><br></pre></td></tr></table></figure>

<p><img data-src="https://s1.ax1x.com/2022/08/17/vBh4sA.png" alt="vBh4sA.png"></p>
<h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><h3 id="导入所有需要用到的库"><a href="#导入所有需要用到的库" class="headerlink" title="导入所有需要用到的库"></a>导入所有需要用到的库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_files</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br></pre></td></tr></table></figure>

<h3 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">raw_data = load_files(<span class="string">&quot;./data/&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>, shuffle=<span class="literal">True</span>, decode_error=<span class="string">&quot;ignore&quot;</span>, random_state=<span class="number">1</span>)</span><br><span class="line">data_x = raw_data[<span class="string">&quot;data&quot;</span>]</span><br><span class="line">data_y = raw_data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">index2label = raw_data[<span class="string">&quot;target_names&quot;</span>]</span><br><span class="line">label2index = &#123;l: i <span class="keyword">for</span> i, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(index2label)&#125;</span><br><span class="line"><span class="comment"># print(len(data_x), data_x[1])</span></span><br><span class="line"><span class="comment"># print(len(data_y), data_y[1])</span></span><br><span class="line"><span class="comment"># print(index2label)</span></span><br><span class="line"><span class="comment"># print(label2index)</span></span><br><span class="line"><span class="comment">## ========== Output ==========</span></span><br><span class="line"><span class="comment">## 1400 她们深陷美妆圈分享好货停不下来...更多的是时间与心思。</span></span><br><span class="line"><span class="comment">## 1400 3</span></span><br><span class="line"><span class="comment">## [&#x27;家居&#x27;, &#x27;房产&#x27;, &#x27;教育&#x27;, &#x27;时尚&#x27;, &#x27;时政&#x27;, &#x27;科技&#x27;, &#x27;财经&#x27;]</span></span><br><span class="line"><span class="comment">## &#123;&#x27;家居&#x27;: 0, &#x27;房产&#x27;: 1, &#x27;教育&#x27;: 2, &#x27;时尚&#x27;: 3, &#x27;时政&#x27;: 4, &#x27;科技&#x27;: 5, &#x27;财经&#x27;: 6&#125;</span></span><br><span class="line"><span class="comment">## ============================</span></span><br></pre></td></tr></table></figure>

<p>数据的读取直接使用现成的库函数 <code>load_files</code>, 需要满足一定的目录结构才能直接使用, 即数据集文件夹下面是类别文件夹, 类别文件夹下面是每一份数据文件.</p>
<p>读取之后返回的对象包含所有的原始数据与自动生成的标签, 从 <code>index2label</code> 和 <code>label2index</code> 可以看到数字标签与类别文字的对应关系.</p>
<p>如果是其他形式的数据集, 需要自己写加载函数. 加载后的获取的内容与上面的应当类似, 有数字标签及其与文字类别的对应关系, 以及样本与标签相互对应的两个有序列表.</p>
<h3 id="划分训练集与测试集"><a href="#划分训练集与测试集" class="headerlink" title="划分训练集与测试集"></a>划分训练集与测试集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_x, test_x, train_y, test_y = train_test_split(</span><br><span class="line">    data_x, data_y, train_size=<span class="number">0.7</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>, stratify=data_y, random_state=<span class="number">1</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># print(f&quot;train_x: &#123;len(train_x)&#125;&quot;)</span></span><br><span class="line"><span class="comment"># print(f&quot;test_x: &#123;len(test_x)&#125;&quot;)</span></span><br><span class="line"><span class="comment">## ========== Output ==========</span></span><br><span class="line"><span class="comment">## train_x: 979</span></span><br><span class="line"><span class="comment">## test_x: 421</span></span><br><span class="line"><span class="comment">## ============================</span></span><br></pre></td></tr></table></figure>

<p>继续调包来划分数据集, 并且填入参数, 按 7:3 划分训练集与测试集.</p>
<p>其中 <code>stratify</code> 参数含义为按比例划分, 即训练集与测试集的各类别之间的比例与提供的 <code>data_y</code> 比例一致, 即划分前的总比例.</p>
<h3 id="对数据集进行特征提取"><a href="#对数据集进行特征提取" class="headerlink" title="对数据集进行特征提取"></a>对数据集进行特征提取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv = CountVectorizer(tokenizer=jieba.lcut)</span><br><span class="line">train_x = cv.fit_transform(train_x)</span><br><span class="line">test_x = cv.transform(test_x)</span><br></pre></td></tr></table></figure>

<p>因为我们最终是使用朴素贝叶斯模型进行文本分类, 因此需要得到一些离散特征.</p>
<p>这部分使用了 <code>CountVectorizer</code> 来进行特征提取, 它可以使用 <code>tokenizer</code> 对数据集进行分词并统计, 在内部构建一个词典, 将每个单词映射到一个序号, 进而把每个样本变成一个向量.</p>
<p><code>CountVectorizer.fit</code>: 接受数据集进行拟合, 更新内部的词典.<br><code>CountVectorizer.transform</code>: 接受数据集, 按照内部的词典将每个样本转换成向量形式.</p>
<p>在这里我们使用 <code>fit_transform</code> 来处理训练集, 这是两步合并操作, 意思是使用训练集来构建词典并将训练集向量化.</p>
<p>但是只使用 <code>transform</code> 来处理测试集, 也就是使用训练集上的词典来向量化测试集. 这个比较好理解, 因为对于模型来说, 通过训练集训练, 理论上来说是不知道测试集的内容的, 因此不需要让词典更新测试集的词汇.</p>
<h3 id="构建模型并拟合"><a href="#构建模型并拟合" class="headerlink" title="构建模型并拟合"></a>构建模型并拟合</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MultinomialNB()</span><br><span class="line">model.fit(train_x, train_y)</span><br></pre></td></tr></table></figure>

<p>我们选择 <code>MultinomialNB</code> 模型, 因为它是 <code>sklearn</code> 中适合处理离散特征的贝叶斯模型, 有很多可调节的参数, 这里从简, 直接全部默认参数.</p>
<p>把训练集喂进模型的 <code>fit</code> 函数, 然后等待一会训练过程.</p>
<h3 id="在测试集上测试准确性"><a href="#在测试集上测试准确性" class="headerlink" title="在测试集上测试准确性"></a>在测试集上测试准确性</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y, target_names=index2label))</span><br></pre></td></tr></table></figure>

<p>将测试集的样本喂进训练之后的模型 <code>predict</code> 函数中得到 <code>pred_y</code>. 我们直接调包来计算各项指标 (当然包里还有其他分别计算各项指标的函数), 得到如下输出.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">          家居       0.88      0.97      0.92        60</span><br><span class="line">          房产       1.00      0.80      0.89        60</span><br><span class="line">          教育       0.82      1.00      0.90        60</span><br><span class="line">          时尚       1.00      0.98      0.99        60</span><br><span class="line">          时政       0.91      0.85      0.88        60</span><br><span class="line">          科技       1.00      0.97      0.98        61</span><br><span class="line">          财经       0.98      0.98      0.98        60</span><br><span class="line"></span><br><span class="line">    accuracy                           0.94       421</span><br><span class="line">   macro avg       0.94      0.94      0.94       421</span><br><span class="line">weighted avg       0.94      0.94      0.94       421</span><br></pre></td></tr></table></figure>

<p>可以看到效果不错, 稍低一点的是 &quot;房产&quot; 与 &quot;时政&quot;, 召回率较低, 猜测可能被误分类到 &quot;家居&quot; 和 &quot;教育&quot; 里面去了.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实做一个调包侠还是挺简单的, 不到 50 行代码就实现了一个看起来似乎挺麻烦的事, 但是能够正确调包的前提是知道各个模型的基本原理, 能够构建合适的特征并选择合适的模型, 同时也需要对常用的机器学习库的 api 有一定了解和使用经验, 不然连调包侠也当不了 X﹏X.</p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p><code>scikit-learn</code> 官方文档: <span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9pbmRleC5odG1s">https://scikit-learn.org/stable/index.html<i class="fa fa-external-link-alt"></i></span> (其实这文档很少看, 不如搜索引擎现搜).</p>
<p>另外贴一下文章里面用的数据集网盘地址, <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pVHZLejA5cGNxOGI=">点击下载<i class="fa fa-external-link-alt"></i></span>.</p>
<p>没啥其他相关资源了, 课上好好学<del>课下慢慢搜</del>就完事了.</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>scikit-learn</tag>
        <tag>文本分类</tag>
      </tags>
  </entry>
  <entry>
    <title>再遇文本分类</title>
    <url>//posts/2022/08/19/wast-nlp/</url>
    <content><![CDATA[<p>这是<a href="/categories/%E7%BD%91%E5%AE%89%E6%9C%AC%E7%A7%91%E9%80%9F%E9%80%9A/">网安本科速通</a>系列的最后一篇了, 主题还是 <code>pytorch</code>, 但是问题换成了 <code>NLP</code>, 并且还是以经典的文本分类作为示例, 数据集使用与前面<a href="/posts/2022/08/17/wast-ml/">经典问题之文本分类</a>相同的一份小数据集, 方便进行比较.</p>
<p>阅读本篇前需要先看前两篇, <a href="/posts/2022/08/17/wast-ml/">经典问题之文本分类</a>与<a href="/posts/2022/08/18/wast-dl/">基于 PyTorch 的手写数字分类</a>. 本篇的项目代码和数据集是以前两篇作为基础的, 并且也会精简正文内容.</p>
<span id="more"></span>

<h2 id="环境准备与项目结构"><a href="#环境准备与项目结构" class="headerlink" title="环境准备与项目结构"></a>环境准备与项目结构</h2><p>环境使用 <code>pytorch</code> 环境.</p>
<p>项目结构与文本分类项目结构一致, 并且使用相同的数据集.</p>
<h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><h3 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_files</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, f1_score, precision_score, recall_score</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line"></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br></pre></td></tr></table></figure>

<p>前两个项目的结合, 都是些常规库.</p>
<h3 id="构建数据集"><a href="#构建数据集" class="headerlink" title="构建数据集"></a>构建数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vocabulary</span>:</span><br><span class="line">    PAD = <span class="string">&quot;&lt;PAD&gt;&quot;</span></span><br><span class="line">    UNK = <span class="string">&quot;&lt;UNK&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.token2id = &#123;self.PAD: <span class="number">0</span>, self.UNK: <span class="number">1</span>&#125;</span><br><span class="line">        self.id2token = [self.PAD, self.UNK]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.token2id)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_token</span>(<span class="params">self, token</span>):</span><br><span class="line">        <span class="keyword">if</span> token <span class="keyword">not</span> <span class="keyword">in</span> self.token2id:</span><br><span class="line">            self.token2id[token] = <span class="built_in">len</span>(self.token2id)</span><br><span class="line">            self.id2token.append(token)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, text</span>):</span><br><span class="line">        <span class="keyword">return</span> [self.token2id.get(x, self.token2id[self.UNK]) <span class="keyword">for</span> x <span class="keyword">in</span> text]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, ids</span>):</span><br><span class="line">        <span class="keyword">return</span> [self.id2token[x] <span class="keyword">for</span> x <span class="keyword">in</span> ids]</span><br></pre></td></tr></table></figure>

<p>先写一个词表类, 这个词表可以按需求添加生词, 并且将分词后的文本进行词与序号之间的编解码操作, 核心目的是提供文本向量化的能力.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_raw_data</span>(<span class="params">path</span>):</span><br><span class="line">    raw_data = load_files(path, encoding=<span class="string">&quot;utf8&quot;</span>, shuffle=<span class="literal">True</span>, decode_error=<span class="string">&quot;ignore&quot;</span>, random_state=<span class="number">1</span>)</span><br><span class="line">    data_x = raw_data[<span class="string">&quot;data&quot;</span>]</span><br><span class="line">    data_y = raw_data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">    index2label = raw_data[<span class="string">&quot;target_names&quot;</span>]</span><br><span class="line">    label2index = &#123;l: i <span class="keyword">for</span> i, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(index2label)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (data_x, data_y), (index2label, label2index)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">data_x, data_y</span>):</span><br><span class="line">    data_x = [jieba.lcut(s) <span class="keyword">for</span> s <span class="keyword">in</span> data_x]</span><br><span class="line">    train_x, test_x, train_y, test_y = train_test_split(</span><br><span class="line">        data_x, data_y, train_size=<span class="number">0.7</span>,</span><br><span class="line">        shuffle=<span class="literal">True</span>, stratify=data_y, random_state=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    vocab = Vocabulary()</span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> train_x:</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> text:</span><br><span class="line">            vocab.add_token(word)</span><br><span class="line"></span><br><span class="line">    train_x = [vocab.encode(x) <span class="keyword">for</span> x <span class="keyword">in</span> train_x]</span><br><span class="line">    test_x = [vocab.encode(x) <span class="keyword">for</span> x <span class="keyword">in</span> test_x]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (train_x, test_x, train_y, test_y), vocab</span><br></pre></td></tr></table></figure>

<p>然后封装一下之前文本分类项目里的数据集加载操作, 手动使用 <code>jieba.lcut</code> 进行分词并构建词表, 最后返回划分好的训练集与测试集.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        self.inputs = x</span><br><span class="line">        self.targets = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.inputs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        input_ = torch.tensor(self.inputs[item]).long().to(DEVICE)</span><br><span class="line">        target = torch.tensor([self.targets[item]]).long().to(DEVICE)</span><br><span class="line">        <span class="keyword">return</span> (input_, target)</span><br></pre></td></tr></table></figure>

<p>自定义数据集类, 与数字分类项目里的定义方式类似, 但是输入参数换成直接获取前面预处理好的数据集.</p>
<h3 id="定义神经网络结构"><a href="#定义神经网络结构" class="headerlink" title="定义神经网络结构"></a>定义神经网络结构</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyNetwork</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, output_size=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        _embedding_size = <span class="number">128</span></span><br><span class="line">        _hidden_size = <span class="number">128</span></span><br><span class="line">        _filter_sizes = (<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, _embedding_size)</span><br><span class="line">        self.dropout = nn.Dropout()</span><br><span class="line">        self.convs = nn.ModuleList([nn.Conv1d(_embedding_size, _hidden_size, k) <span class="keyword">for</span> k <span class="keyword">in</span> _filter_sizes])</span><br><span class="line">        self.fc = nn.Linear(_hidden_size * <span class="built_in">len</span>(_filter_sizes), output_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_convpool</span>(<span class="params">self, x</span>):</span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="keyword">for</span> conv <span class="keyword">in</span> self.convs:</span><br><span class="line">            output = torch.relu(conv(x))                                <span class="comment"># (128, L) -&gt; (128, L-k+1)</span></span><br><span class="line">            output = torch.max_pool1d(output, output.size(<span class="number">2</span>)).squeeze() <span class="comment"># (128, L-k+1) -&gt; (128,)</span></span><br><span class="line">            outputs.append(output)</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, -<span class="number">1</span>)                                   <span class="comment"># (128,) -&gt; (384,)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = self.embedding(inputs)                                <span class="comment"># (L,) -&gt; (L, 128)</span></span><br><span class="line">        outputs = self.dropout(outputs)                                 <span class="comment"># </span></span><br><span class="line">        outputs = outputs.transpose(<span class="number">1</span>, <span class="number">2</span>)                               <span class="comment"># (L, 128) -&gt; (128, L)</span></span><br><span class="line">        outputs = self._convpool(outputs)                               <span class="comment"># (128, L) -&gt; (384,)</span></span><br><span class="line">        outputs = self.fc(outputs)                                      <span class="comment"># (384,) -&gt; (7,)</span></span><br><span class="line">        outputs = torch.log_softmax(outputs, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>

<p>继续使用与数字分类中相同的卷积结构, 也就是 <code>TextCNN</code>, 卷积核选择经典的三个值. 各个步骤的维度变化在注释里有标注.</p>
<h3 id="定义指标评价函数"><a href="#定义指标评价函数" class="headerlink" title="定义指标评价函数"></a>定义指标评价函数</h3><p>见<a href="/posts/2022/08/18/wast-dl/#%E5%AE%9A%E4%B9%89%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E5%87%BD%E6%95%B0">定义评价指标函数</a>.</p>
<h3 id="训练与评估函数"><a href="#训练与评估函数" class="headerlink" title="训练与评估函数"></a>训练与评估函数</h3><p>见<a href="/posts/2022/08/18/wast-dl/#%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0">定义训练函数</a>与<a href="/posts/2022/08/18/wast-dl/#%E5%AE%9A%E4%B9%89%E8%AF%84%E4%BC%B0%E5%87%BD%E6%95%B0">定义评估函数</a></p>
<h3 id="校对函数-collate-fn"><a href="#校对函数-collate-fn" class="headerlink" title="校对函数 (collate_fn)"></a>校对函数 (collate_fn)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">data: <span class="built_in">list</span></span>):</span><br><span class="line">    inputs, targets = <span class="built_in">map</span>(<span class="built_in">list</span>, <span class="built_in">zip</span>(*data))</span><br><span class="line">    inputs = pad_sequence(inputs, batch_first=<span class="literal">True</span>)</span><br><span class="line">    targets = torch.stack(targets)</span><br><span class="line">    <span class="keyword">return</span> inputs, targets</span><br></pre></td></tr></table></figure>

<p>这个东西可能第一次见, 并且用了一些很奇怪的操作, 比如那个 <code>map</code>, 但是首先要明白这个函数用于干什么.</p>
<p>回忆我们在数字分类项目里使用 <code>DataLoader</code> 时, 它可以给我们提供一个 loader 来迭代我们自定义的 <code>Dataset</code>. <code>Dataset</code> 每次取出来的东西是一个二元组, 里面包含样本与标签两部分, 而 <code>Dataloader</code> 又能够按 <code>batch_size</code> 的大小批量获取这些二元组, 形成一个 <code>list</code>. 这个长度为 <code>batch_size</code>, 内容为二元组的 <code>list</code> 就是 <code>collate_fn</code> 的输入参数.</p>
<p>再看 <code>map</code> 那一行操作, 涉及了几个 <code>python</code> 函数用法, 这里直接说结论, 它将 <code>data</code> 里的样本与标签拆分成了两个单独的 <code>list</code>.</p>
<p>然后再说 <code>pad_sequence</code> 操作, 对于神经网络来说, 所有的计算过程都是矩阵计算, 但是对于文本任务, 每个样本句子长度几乎都不是相同的, 因此需要进行对齐操作, 对短句进行填充. 需要注意的是, 默认参数里的填充值是 <code>0</code>, 这与我们前面词表里的定义是一致的, 如果不一致则需要手动填一下.</p>
<p>最后是参数的返回值, 直接对应了我们从 loader 里迭代数据时获取的变量形式, 此处就是和之前一样, 分别返回样本列表与标签列表.</p>
<h3 id="定义训练超参数"><a href="#定义训练超参数" class="headerlink" title="定义训练超参数"></a>定义训练超参数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">seed = <span class="number">1</span></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">epochs = <span class="number">25</span></span><br><span class="line"></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed(seed)</span><br></pre></td></tr></table></figure>

<p>与前面的项目类似, 但是 <code>batch_size</code> 设的稍小一些, 因为对于文本处理, 按批次训练时, 进行了填充操作, 越大的 <code>batch_size</code> 能够得到越快的训练速度, 但是在一个 <code>batch</code> 内会引入更多不必要的 <code>0</code> 填充值, 可以酌情尝试调整.</p>
<h3 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(data_x, data_y), (index2label, label2index) = load_raw_data(<span class="string">&quot;./data/&quot;</span>)</span><br><span class="line">(train_x, test_x, train_y, test_y), vocab = preprocess(data_x, data_y)</span><br><span class="line"></span><br><span class="line">train_dataset = MyDataset(train_x, train_y)</span><br><span class="line">test_dataset = MyDataset(test_x, test_y)</span><br><span class="line">train_dataloader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size, collate_fn=collate_fn)</span><br><span class="line">test_dataloader = DataLoader(test_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size, collate_fn=collate_fn)</span><br></pre></td></tr></table></figure>

<p>最大的不同就是添加了 <code>collate_fn</code> 参数, 其余的都是之前涉及过的操作.</p>
<h3 id="实例化模型训练需要的对象"><a href="#实例化模型训练需要的对象" class="headerlink" title="实例化模型训练需要的对象"></a>实例化模型训练需要的对象</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MyNetwork(<span class="built_in">len</span>(vocab)).to(DEVICE)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss().to(DEVICE)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<p>与之前的定义也是几乎一致的, 唯一的不同就是 <code>MyNetwork</code> 多了一个 <code>vocab_size</code> 的参数需要传进去, 其他参数都用的默认值.</p>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>代码见<a href="/posts/2022/08/18/wast-dl/#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">训练模型</a>, 这里只贴一下后 5 轮的训练结果.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">===============================</span><br><span class="line">Epoch 21</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0071 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1102 Acc: 0.9667 F1: 0.9669(0.9669/0.9667)</span><br><span class="line">===============================</span><br><span class="line">Epoch 22</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0055 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1099 Acc: 0.9644 F1: 0.9645(0.9645/0.9643)</span><br><span class="line">===============================</span><br><span class="line">Epoch 23</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0056 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1062 Acc: 0.9644 F1: 0.9645(0.9645/0.9643)</span><br><span class="line">===============================</span><br><span class="line">Epoch 24</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0048 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1019 Acc: 0.9667 F1: 0.9669(0.9669/0.9667)</span><br><span class="line">===============================</span><br><span class="line">Epoch 25</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0042 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1051 Acc: 0.9644 F1: 0.9645(0.9645/0.9643)</span><br><span class="line">===============================</span><br></pre></td></tr></table></figure>

<p>可以看到在训练集上已经完全拟合了, 并且测试集上 F1 得分也高达 0.9645.</p>
<h3 id="输出最终的测试结果"><a href="#输出最终的测试结果" class="headerlink" title="输出最终的测试结果"></a>输出最终的测试结果</h3><p>代码见<a href="/posts/2022/08/18/wast-dl/#%E8%BE%93%E5%87%BA%E6%9C%80%E7%BB%88%E7%9A%84%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C">输出最终的测试结果</a>, 这里只贴一下输出结果.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0     0.9524    1.0000    0.9756        60</span><br><span class="line">           1     0.9667    0.9667    0.9667        60</span><br><span class="line">           2     1.0000    1.0000    1.0000        60</span><br><span class="line">           3     0.9649    0.9167    0.9402        60</span><br><span class="line">           4     0.9833    0.9833    0.9833        60</span><br><span class="line">           5     0.9333    0.9180    0.9256        61</span><br><span class="line">           6     0.9508    0.9667    0.9587        60</span><br><span class="line"></span><br><span class="line">    accuracy                         0.9644       421</span><br><span class="line">   macro avg     0.9645    0.9645    0.9643       421</span><br><span class="line">weighted avg     0.9644    0.9644    0.9642       421</span><br></pre></td></tr></table></figure>

<p>可以和之前使用朴素贝叶斯的文本分类做个比较, 可以看到还是有明显提升的, <code>2</code> 号类别甚至已经完全正确了. 当然这个对比不是很科学, 毕竟这是一个很小的数据集, 而且两者都还有大量的可调整空间. 朴素贝叶斯里有很多超参数, 而且样本的特征提取也有待进一步升级; <code>TextCNN</code> 网络里也有很多超参数可调, 比如词向量的长度等等.</p>
<p>不过神经网络的强处正是在于能够自动提取深层次特征, 避免了人工构造特征的麻烦, 也就是非常擅长 &quot;找规律&quot;, 只要数据集充足, 选择合适的网络结构, 然后经过一番超参数调整之后, 效果都不会很差. <del>就是玄学炼丹.</del></p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p>各个模块的使用方法可以去看 <code>pytorch</code> 的<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">官方网站<i class="fa fa-external-link-alt"></i></span>, 项目中使用的数据集在前面的文章里也有, 这里再贴一下, <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pVHZLejA5cGNxOGI=">点击下载<i class="fa fa-external-link-alt"></i></span>.</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>pytorch</tag>
        <tag>文本分类</tag>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title>打造一个舒适的 Python 编程环境</title>
    <url>//posts/2022/08/13/wast-pythonandvsc/</url>
    <content><![CDATA[<p>网安专业几乎 99% 的作业都可以用 <code>python</code> 来解决, 除了大一大二一些特别的专业课, 需要折腾一下 <code>c</code> 语言, 之后其余的所有网安专业必修与选修的大作业, 都多多少少和 &quot;大数据&quot;, &quot;人工智能&quot; 挂钩, 里面涉及了很多数据处理与分析, 这类任务用 <code>python</code> 写将会非常方便, 因为已经有了许多的第三方包让我们直接使用.</p>
<p>因此本篇主要基于个人经验介绍一下比较舒适的 <code>python</code> 编程环境设置, 让大家能够把精力放在<del>抄</del>写代码上, 而不是被环境弄的头疼.</p>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>从本篇开始, 基本上算是完全的个人经验分享. 由于我自己是网安专业而非信安, 因此可能分享的内容对网安同学适用性更好, 不过信安同学可以酌情参考. 如果还没分专业, 也可以参考一下将来可能需要点一些啥技能来速通网安各个课程作业.</p>
<p>如果对 <code>VS Code</code> 没有了解, 可以看前一篇<a href="/posts/2022/08/11/wast-vscandvs/">给新生的编程工具推荐与基本使用方法</a>, 这里面讲了 <code>VS Code</code> 的基本使用方法. 而本篇将会基于 <code>VS Code</code>, 打造一个相对舒适的 <code>python</code> 编程环境.</p>
<h2 id="安装-Python"><a href="#安装-Python" class="headerlink" title="安装 Python"></a>安装 Python</h2><p>第一步肯定是安装 <code>python</code>, 官网就是 <span class="exturl" data-url="aHR0cHM6Ly93d3cucHl0aG9uLm9yZy8=">https://www.python.org/<i class="fa fa-external-link-alt"></i></span>.</p>
<p>可以选择下最新版, 不过不是那么的推荐, 而是适当旧一点, 比如现在最新的版本是 <code>3.10.6</code>, 那么可以下 <code>3.8.10</code> (<code>3.8.x</code> 发布的最后一个有安装包的版本). 这样子兼容度大一点. (曾经遇见过要装的某个包还没发布适配新版本 <code>python</code> 的版本, 害得我又重装降级了 <code>python</code>).</p>
<p>这里直接提供 <a href="https://www.python.org/downloads/release/python-3810/"><code>Python 3.8.10</code></a> 的官方下载页面, 点进去之后选 &quot;Windows installer (64-bit)&quot; 这个版本就好了.</p>
<p>下载好之后双击进入安装界面. 下面两项都勾上, 并且选择 &quot;Customize installation&quot;.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vtamNQ.png" alt="vtamNQ.png"></p>
<p>这一面也是直接全勾.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vtaN4J.png" alt="vtaN4J.png"></p>
<p>再次 Next 之后, 这个界面里, 勾选 &quot;Install for all users&quot;, 并且可以在下方调整 <code>python</code> 的安装路径. 推荐装到 D 盘或者其他方便找到的地方, 比如 <code>D:\Program Files\Python38</code>.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vtd9VU.png" alt="vtd9VU.png"></p>
<p>重启一下电脑, 快捷键 <code>Win + R</code>, 输入 <code>cmd</code> 打开命令提示符, 敲一下 <code>python --version</code>, 如下图所示则安装成功.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vtdqeK.png" alt="vtdqeK.png"></p>
<h2 id="Python-虚拟环境"><a href="#Python-虚拟环境" class="headerlink" title="Python 虚拟环境"></a>Python 虚拟环境</h2><h3 id="虚拟环境简介"><a href="#虚拟环境简介" class="headerlink" title="虚拟环境简介"></a>虚拟环境简介</h3><p>关于虚拟环境的详细介绍很多, 必应一搜就有很多<span class="exturl" data-url="aHR0cHM6Ly9jbi5iaW5nLmNvbS9zZWFyY2g/cT1weXRob24lRTclOUElODQlRTglOTklOUElRTYlOEIlOUYlRTclOEUlQUYlRTUlQTIlODMlRTYlOTglQUYlRTQlQkIlODAlRTQlQjklODg=">结果<i class="fa fa-external-link-alt"></i></span>, 有时间可以慢慢理解.</p>
<p>当你写代码时, 不可能完全都靠自己从零开始, 这样子很低效<del>并且很蠢</del>, 所以对于 <code>python</code> 而言, 写代码之前确定并安装合适的第三方包就是基本操作.</p>
<p>然而, 第三方包在发布的时候, 可能会存在许多不同的版本, 不同项目之间所需要的包版本也不尽相同, 会造成巨大的兼容问题 (比如万恶的 <code>tensorflow 1.x</code> 和 <code>tensorflow 2.x</code>). 这种时候就需要使用虚拟环境.</p>
<p>虚拟环境可以简单认为是 &quot;<code>python</code> 和对应的包的副本&quot;, 最基本的要素是环境内的 <code>python</code> 版本和包的版本. 每一个环境之间的 <code>python</code> 和包版本都是相互独立的. 这样子在运行项目时, 我们可以选择特定的某一个环境, 从而使用某个特定的 <code>python</code> 版本与包版本.</p>
<h3 id="虚拟环境管理"><a href="#虚拟环境管理" class="headerlink" title="虚拟环境管理"></a>虚拟环境管理</h3><p>网上很多推荐使用 <span class="exturl" data-url="aHR0cHM6Ly93d3cuYW5hY29uZGEuY29tLw==">Anaconda<i class="fa fa-external-link-alt"></i></span> 来进行包和环境的管理, 我觉得可以但没必要, 一是臃肿二是让新手有点摸不着头脑. 不过等熟练之后用倒是个不错的选择.</p>
<p>这里只介绍一下 <code>python</code> 自带的 <code>venv</code> 模块使用以及第三方包 <code>virtualenvwrapper-win</code> 的使用.</p>
<h4 id="在环境中安装第三方包"><a href="#在环境中安装第三方包" class="headerlink" title="在环境中安装第三方包"></a>在环境中安装第三方包</h4><p>一般来说, 安装完 <code>python</code> 之后, 就会有一个 &quot;本地环境&quot;, 而将除本地环境之外的其他环境通常 &quot;虚拟环境&quot;.</p>
<p>在运行 <code>python</code> 程序时, 是按照所指定的 <code>python</code> 解释器来决定使用的环境的.</p>
<p>我们在命令行里可以直接使用 <code>python</code> 指令, 实际上是因为我们在安装时勾选了 &quot;Add Python 3.8 to PATH&quot;, 在环境变量 <code>PATH</code> 中添加了本地环境中 <code>python</code> 解释器的路径, 所以在使用 <code>python</code> 指令时, 实际上就是使用了本地环境.</p>
<p>通常主要使用内置的 <code>pip</code> 模块进行第三方包的管理, 并且有以下几个常用命令.</p>
<ul>
<li><p><code>&lt;解释器&gt; -m pip list &lt;包名&gt;</code>: 列出当前环境所有安装的包.</p>
</li>
<li><p><code>&lt;解释器&gt; -m pip install &lt;包名&gt;</code>: 安装包.</p>
</li>
<li><p><code>&lt;解释器&gt; -m pip install &lt;包名&gt;</code>: 卸载包.</p>
</li>
</ul>
<p><code>&lt;解释器&gt;</code> 就是你要进行包管理的环境的解释器 <code>python.exe</code> 路径, 对于本地环境来说就是直接使用的 <code>python</code> 命令.</p>
<p><code>-m pip</code> 表示调用了指定解释器中的 <code>pip</code> 模块进行包的管理.</p>
<p><code>&lt;包名&gt;</code> 则是你需要的包的 &quot;安装名称&quot;, 一般来说它和 <code>import</code> 语句的名字是一致的, 但是也有可能不一样, 推荐去官方的包发布网站 <span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy8=">https://pypi.org/<i class="fa fa-external-link-alt"></i></span> 上进行搜索.</p>
<p>除此之外, <code>pip</code> 也支持使用 <code>whl</code> 文件或者源码安装, 具体的可以自行进一步学习.</p>
<h4 id="创建并使用虚拟环境"><a href="#创建并使用虚拟环境" class="headerlink" title="创建并使用虚拟环境"></a>创建并使用虚拟环境</h4><p>最简单的创建方法是使用自带的 <code>venv</code> 模块, 命令如下.</p>
<p><code>python -m venv &lt;路径&gt;</code></p>
<p>比如使用 <code>python -m venv env</code> 则会在当前目录下生成一个 <code>env</code> 文件夹, 这里面就包含了名为 <code>env</code> 的虚拟环境的解释器以及第三方库.</p>
<p>另外比较重要的文件是 <code>activate</code> 与 <code>deactivate</code>, 用于激活和退出虚拟环境.</p>
<p>具体的使用在后面的部分<a href="#%E5%9C%A8-VS-Code-%E4%B8%AD%E4%BD%BF%E7%94%A8-Python">在 VS Code 中使用 Python</a> 中再进行说明.</p>
<p>另一种方案是使用第三方库 <code>virtualenvwrapper-win</code> 来辅助我们管理虚拟环境.</p>
<p>使用 <code>python -m pip install virtualenvwrapper-win</code> 进行安装. 安装完后, 即可以在命令行中使用以下几个常用命令对机器上的虚拟环境进行集中管理.</p>
<ul>
<li><code>mkvirtualenv &lt;虚拟环境名称&gt;</code>: 创建虚拟环境.</li>
<li><code>workon &lt;虚拟环境名称&gt;</code>: 激活对应的虚拟环境.</li>
<li><code>rmvirtualenv &lt;虚拟环境名称&gt;</code>: 删除虚拟环境.</li>
</ul>
<p>前面的 <code>venv</code> 模块常常用于某个项目内的临时环境, 而 <code>virtualenvwrapper-win</code> 这个第三方工具主要用于你希望自己的电脑上常驻某些不同类别的环境, 并对它们方便的进行集中管理.</p>
<p>默认该模块创建的环境都将位于 <code>%USERPROFILE%\envs</code> 文件夹下,可以通过环境变量 <code>WORKON_HOME</code> 来自定义你希望的存储位置.</p>
<h3 id="常用的第三方包"><a href="#常用的第三方包" class="headerlink" title="常用的第三方包"></a>常用的第三方包</h3><p>对于速通网安, 有一些常用的第三方库总结, 在这里把我自己常用的包情况列举一下.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 用于格式化和检测代码规范的工具</span><br><span class="line">autopep8</span><br><span class="line">pylint</span><br><span class="line"></span><br><span class="line"># 与爬虫有关的库</span><br><span class="line">lxml</span><br><span class="line">beautifulsoup4</span><br><span class="line">requests</span><br><span class="line"></span><br><span class="line"># 与数据处理有关的库</span><br><span class="line">numpy</span><br><span class="line">pandas</span><br><span class="line">matplotlib</span><br><span class="line"></span><br><span class="line"># 机器学习以及深度学习相关的库</span><br><span class="line">opencv-python</span><br><span class="line">scikit-learn</span><br><span class="line"># torch</span><br><span class="line"># torchaudio</span><br><span class="line"># torchvision</span><br><span class="line"></span><br><span class="line"># 在 VS Code 内使用 jupyter notebook 有关的库</span><br><span class="line">ipykernel</span><br><span class="line">jupyter</span><br></pre></td></tr></table></figure>

<p>其中 <code>torch</code> 的安装需要前往官网 <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">https://pytorch.org/<i class="fa fa-external-link-alt"></i></span> 按说明进行安装.</p>
<h2 id="在-VS-Code-中使用-Python"><a href="#在-VS-Code-中使用-Python" class="headerlink" title="在 VS Code 中使用 Python"></a>在 VS Code 中使用 Python</h2><p>这一节将会实践一下前面所有的内容, 在 <code>VS Code</code> 中使用 <code>python</code> 完成一次向量乘法计算.</p>
<p>打开之前曾经创建的 <code>example</code> 文件夹, 并且新建一个终端.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vNUegI.png" alt="vNUegI.png"></p>
<p>我们使用以下命令为这个项目建立一个单独的虚拟环境, 取名为 <code>env</code>.</p>
<p><code>python -m venv env</code></p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vNami4.png" alt="vNami4.png"></p>
<p>命令执行完成后, 左边的资源管理器面板上多出来一个 <code>env</code> 文件夹, 这就是我们刚刚创建好的虚拟环境. 我们使用 <code>.\env\Scripts\activate</code> 在终端中激活这个虚拟环境, 激活完成后可以看到终端的提示信息前面多了一个 <code>(env)</code> 标记, 表示当前终端处于 <code>env</code> 的虚拟环境之下.</p>
<p>如果出现不能执行的情况, 可以参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGF4aW9uZzEzMTQvcC8xNjI2NTU0OS5odG1s">这篇博客<i class="fa fa-external-link-alt"></i></span>解决权限问题. 或者在 <code>VS Code</code> 的设置里把默认的终端类型调成 <code>cmd</code> 而不是 <code>powershell</code>, 我推荐改成 <code>cmd</code> 一劳永逸. <del><code>powershell</code> 屁事多</del>.</p>
<p>解决完问题之后就如下图所示了.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vNdYn0.png" alt="vNdYn0.png"></p>
<p>此时在终端里直接执行 <code>python</code> 有关的命令, 都会映射到虚拟环境里的命令.</p>
<p>然后我们继续, 使用 <code>pip</code> 向虚拟环境里添加一个第三方库 <code>numpy</code>.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vNwSvn.png" alt="vNwSvn.png"></p>
<p>顺利安装完成之后, 可以看到左边的 <code>env</code> 文件夹里 <code>site-packages</code> 下多出来一个 <code>numpy</code> 的文件夹, 这就是我们刚刚安装好的第三方库了. 同时终端里给了我们一个 <code>WARNING</code>, 提示我们可以对 <code>pip</code> 模块进行升级. 虽然影响不是很大, 不过推荐复制它提供的指令升一下级, 这样 <code>pip</code> 在查找和安装包时能够使用最新的功能, 减小安装失败的风险<del>主要是有彩色进度条</del>.</p>
<p>然后清空之前 <code>main.py</code> 里面的代码, 并且敲入以下新的内容.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vNDSvd.png" alt="vNDSvd.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    vector1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">    vector2 = np.array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(np.dot(vector1, vector2))</span><br><span class="line">    <span class="built_in">print</span>(np.multiply(vector1, vector2))</span><br></pre></td></tr></table></figure>

<p>会发现 <code>import</code> 语句的 <code>numpy</code> 有黄色波浪线, 同时下面的 &quot;问题&quot; 面板有写出来原因, 意思是没有 <code>numpy</code> 这个库.</p>
<p>这是因为虽然我们刚刚在终端里是已经成功激活了虚拟环境, 但是对于 <code>VS Code</code> 来说, 它并不关心终端里是什么情况, 而是对于这个项目来说, 它需要使用什么环境来处理项目内容, 所以我们还需要在下方的状态栏里切换 <code>VS Code</code> 对于当前项目使用的 <code>python</code> 环境.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vN0OpQ.png" alt="vN0OpQ.png"></p>
<p>点击下方状态栏的环境选择, 并且切换到刚刚创建的 <code>env</code> 环境, 此时下方的环境已经换成了 <code>&#39;env&#39;:venv</code>, 并且刚刚的黄色波浪线与问题也消失了.</p>
<p>此时我们可以选择在激活了虚拟环境的终端里运行这份代码, 或者使用快捷键 <code>Ctrl + F5</code> 让 <code>VS Code</code> 帮我们运行. 这里展示一下在终端里直接运行的结果, 可以看到成功输出, 一个是向量内积结果, 一个是向量按位乘法结果.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vNDsPO.png" alt="vNDsPO.png"></p>
<h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>到这里就结束了, 说实话只讲了 <code>VS Code</code> 中使用 <code>python</code> 的最基本技巧, 这些操作之后写代码的时候多操作几次应该就烂熟于心了.</p>
<p>但是对于进校没多久的萌新们来说, 估计看的还是很晕的, 因为有很多新名词, 特别是 &quot;环境变量&quot; 这种, 可能是完全第一次听说, 而且也容易出问题. 所以还是建议多动手尝试尝试, 并且善用搜索引擎, 多翻几篇博客, 总会能够找到适合你问题的解决方案.</p>
<p>就这样了, 下回单独写写怎么合理的科学上网, 为使用 <code>Github</code> <del>抄代码</del>打下坚实基础.</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>新手入门</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>VS Code</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 Requests 的爬虫入门</title>
    <url>//posts/2022/08/16/wast-spider/</url>
    <content><![CDATA[<p>本篇是基于 <code>python</code> 语言及其第三方库 <code>requests</code> 的爬虫入门, 实现一个最简单的爬虫, 从网页上自动化获取我们能想要的信息.</p>
<span id="more"></span>

<p>教程要开始加速了! 从本篇开始, 默认你已经有了一些编程基础, 并且对 <code>python</code> 已经有过不少的使用经验, 将以速通为根本目的, 进行示范性操作, 而不会过深的涉及代码原理. <del>努力成为一个调包侠吧!</del></p>
<h2 id="工具与环境准备"><a href="#工具与环境准备" class="headerlink" title="工具与环境准备"></a>工具与环境准备</h2><p>浏览器: <code>Edge</code>, <code>Chrome</code>, <code>Firefox</code> 均可, 推荐使用 <code>Firefox</code>, 抓包更方便.</p>
<p><code>python</code> 的第三方库: <code>beautifulsoup4</code>, <code>lxml</code>, <code>requests</code>.</p>
<h2 id="爬虫基本原理"><a href="#爬虫基本原理" class="headerlink" title="爬虫基本原理"></a>爬虫基本原理</h2><p>爬虫的本质是在模仿用户操作浏览器的过程.</p>
<p>我们平常看到的网页内容, 都是通过操作浏览器, 浏览器再向服务器请求内容从而呈现给用户, 省去复杂的网络通信过程之后, 可以简要概括成下面的流程图.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0cQQx.png" alt="v0cQQx.png"></p>
<p>我们的目标就是使用代码来完成其中的发出请求和接收响应的过程.</p>
<h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><p>下面以百度热搜的游戏榜为例, 梳理一下每一步, 最后写一个爬虫出来.</p>
<h3 id="分析网站"><a href="#分析网站" class="headerlink" title="分析网站"></a>分析网站</h3><p>这是第一步也是最重要的一步, 通常使用浏览器的开发人员工具, 对你想要抓取的页面进行网络请求分析, 观察请求是如何发起, 想要的内容响应返回后出现在什么地方.</p>
<p>目标网页网址为 <code>https://top.baidu.com/board?tab=game</code>, 浏览器查看一下长这样.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0hSFU.png" alt="v0hSFU.png"></p>
<p>我们的目标是获得整个榜按顺序所有游戏的<strong>名字</strong>, <strong>热搜指数</strong>, <strong>类型</strong>以及<strong>详情页链接</strong>.</p>
<p>打开我们的 <code>Firefox</code> 浏览器 (其他浏览器也是类似的), 首先快捷键 <code>F12</code> 或者更多工具里打开 &quot;开发者工具&quot;, 并切换到 &quot;网络&quot; 选项卡.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0hhc9.png" alt="v0hhc9.png"></p>
<p>此时我们的页面停留在目标页面, 并且没有任何的记录信息, 因此我们选择 &quot;重新载入&quot; 或者刷新一次页面, 让浏览器重新发起一次请求.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v04mBq.png" alt="v04mBq.png"></p>
<p>查看网络请求的第一项, 也就是向目标网址发起的请求, 并选择右侧的响应选项卡, 可以看到我们要的内容已经预览出来了.</p>
<p>所以我们确定爬取内容的方案, 就是直接请求目标网址, 然后获得文本内容响应即可.</p>
<h3 id="请求网页"><a href="#请求网页" class="headerlink" title="请求网页"></a>请求网页</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">res = requests.get(<span class="string">&quot;https://top.baidu.com/board?tab=game&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(res.status_code)</span><br><span class="line"></span><br><span class="line">Path(<span class="string">&quot;a.html&quot;</span>).write_text(res.text, encoding=<span class="string">&quot;utf8&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>代码如上所示, 我们在这里解释一下关键代码 <code>requests.get</code>.</p>
<p>在之前的网络请求面板中, 除了看到了响应, 我们还能够看到左侧的信息栏里, 有 &quot;状态&quot; 与 &quot;方法&quot; 两个取值, 分别为 <code>200</code> 和 <code>GET</code>.</p>
<p>方法: 当浏览器向服务器发出请求时, 请求是有不同类型的, 其基本的区分标志就是该请求的方法 (Method), 常见的有 <code>GET</code> 与 <code>POST</code>, 此处则为 <code>GET</code> 请求方法.</p>
<p>状态: 当服务器送回响应时, 除了相应的内容, 还会有一个基本要素 &quot;响应状态码&quot; (Status Code), 用来标识此次请求操作的结果 (而非请求需要的内容), 可以通过状态码来判断返回内容的类别. 通常为 <code>2XX</code>, <code>4XX</code> 等三位数字, 此处的 <code>200</code> 则是表示请求成功, 并正确的返回了响应内容.</p>
<p>所以代码里的 <code>requests.get</code> 就是对参数里的 url 使用 <code>GET</code> 方法发起了请求, 并将响应存储到了 <code>res</code> 变量中, 随后将响应的状态码打印出来.</p>
<p>将响应的文本内容保存至本地文件 <code>a.html</code> 中, 等待后续进一步分析.</p>
<h3 id="分析网页结构与内容"><a href="#分析网页结构与内容" class="headerlink" title="分析网页结构与内容"></a>分析网页结构与内容</h3><p>与网站的交互就到此暂告一段落了, 接下来是对网页内容的分析, 从中提取出我们想要的内容.</p>
<p>在 <code>VS Code</code> 中打开刚刚保存的 <code>a.html</code>, 并且使用自带格式化程序整理一下, 再使用 <code>Ctrl + F</code> 搜索内容中的关键词进行快速定位.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0oHrd.png" alt="v0oHrd.png"></p>
<p>定位完成后, 我们分析数据附近的结构.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/16/v0TFZn.png" alt="v0TFZn.png"></p>
<p>贴一个缩小后的图, 由 <code>html</code> 的树形结构可以知道, 红框里的每一个 <code>&lt;div&gt;</code> 块内就是榜上排名的其中一项游戏数据, 而它们的嵌套结构也很容易分析, 所有红框所示的数据都位于 <code>&lt;main&gt;</code> 的第二个 <code>&lt;div&gt;</code> 的第一个 <code>&lt;div&gt;</code> 的第二个 <code>&lt;div&gt;</code> 内, 不过这个嵌套有点稍长, 我们尝试看看最近的一个 <code>div</code> 是否有独特性.</p>
<p>使用 <code>Ctrl + F</code> 搜索最里层的 <code>&lt;div&gt;</code> 块的属性 <code>style</code> 的内容 <code>margin-bottom:20px</code>, 惊喜的发现只查找到了一个, 所以我们待会可以直接定位到这一层, 然后依次获取它下面的子级 <code>&lt;div&gt;</code> 内容, 也就是我们要的数据.</p>
<p>我们继续分析红框所示的 <code>&lt;div&gt;</code> 块内容, 它的内容由 3 部分组成, 分别是 <code>&lt;a&gt;</code>, <code>&lt;div&gt;</code> 和 <code>&lt;div&gt;</code>, 而我们需要的内容就位于后两个 <code>&lt;div&gt;</code> 中.</p>
<p>按同样的方式可以继续分析最终的文本数据位于何处, 此处不再赘述.</p>
<h3 id="从网页内容提取数据"><a href="#从网页内容提取数据" class="headerlink" title="从网页内容提取数据"></a>从网页内容提取数据</h3><p>面对这种有良好嵌套结构层次的网页, 我们使用 <code>beautifulsoup4</code> 对其进行内容解析, 下面直接贴代码.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">soup = BeautifulSoup(res.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">items_div = soup.find(<span class="string">&quot;div&quot;</span>, &#123;<span class="string">&quot;style&quot;</span>: <span class="string">&quot;margin-bottom:20px&quot;</span>&#125;).find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">for</span> div <span class="keyword">in</span> items_div:</span><br><span class="line">    index = div.find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">0</span>].find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].get_text(strip=<span class="literal">True</span>)</span><br><span class="line">    name = div.find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].find(<span class="string">&quot;a&quot;</span>, recursive=<span class="literal">False</span>).find(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>).get_text(strip=<span class="literal">True</span>)</span><br><span class="line">    link = div.find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].find(<span class="string">&quot;a&quot;</span>, recursive=<span class="literal">False</span>).attrs[<span class="string">&quot;href&quot;</span>]</span><br><span class="line">    type_ = div.find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">0</span>].get_text(strip=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>\t<span class="subst">&#123;index&#125;</span>\t<span class="subst">&#123;type_&#125;</span>\t<span class="subst">&#123;link&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>代码中变量 <code>items_div</code> 其中一个 <code>div</code> 的 <code>html</code> 内容也附上.</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;category-wrap_iQLoo square_1ULM9&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;img-wrapper_29V76&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">href</span>=<span class="string">&quot;https://www.baidu.com/s?wd=%E5%8E%9F%E7%A5%9E+%E6%B8%B8%E6%88%8F<span class="symbol">&amp;amp;</span>sa=fyb_game_all<span class="symbol">&amp;amp;</span>rsv_dl=fyb_game_all&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;index_1Ew5p c-index-bg1&quot;</span>&gt;</span> 1 <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span></span></span><br><span class="line"><span class="tag">            <span class="attr">src</span>=<span class="string">&quot;https://fyb-1.cdn.bcebos.com/fyb-1/20220811/4d0a80d59a3675130cf61eff31e3ae41?x-bce-process=image/resize,m_fill,w_214,h_214&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">alt</span>=<span class="string">&quot;&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;border_3WfEn&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;trend_2RttY&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;img-wrap_JPOmE trend-icon_1Z3Cd&quot;</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span></span></span><br><span class="line"><span class="tag">                <span class="attr">src</span>=<span class="string">&quot;//fyb-pc-static.cdn.bcebos.com/static/asset/icon-same_886375f242bd1538af21a9721f16b170.png&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;hot-index_1Bl1a&quot;</span>&gt;</span> 228934 <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;text_1lUwZ&quot;</span>&gt;</span> 热搜指数 <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">&quot;line_3-bzA&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">src</span>=<span class="string">&quot;//fyb-pc-static.cdn.bcebos.com/static/asset/line-bg@2x_95cb5a089159c6d5a959a596d460d60a.png&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content_1YWBm&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.baidu.com/s?wd=%E5%8E%9F%E7%A5%9E+%E6%B8%B8%E6%88%8F<span class="symbol">&amp;amp;</span>sa=fyb_game_all<span class="symbol">&amp;amp;</span>rsv_dl=fyb_game_all&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">class</span>=<span class="string">&quot;title_dIF3B &quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;c-single-text-ellipsis&quot;</span>&gt;</span> 原神 <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--s-frag--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;intro_1l0wp&quot;</span>&gt;</span> 类型：单机游戏 <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;c-single-text-ellipsis desc_3CTjT&quot;</span>&gt;</span></span><br><span class="line">            陌生的天空下，少年少女立于尘沙。你们是一对旅行中的双子，从世界之外漂流而来。你的血亲被陌生的神灵带走，而你也被神封印，陷入沉眠。再度醒来，天地间风景已变……《原神》是由米哈游自研的一款全新开放世界冒险RPG。你将在游戏中探索一个被称作「提瓦特」的幻想世界。在这广阔的世界中，你可以踏遍七国，邂逅性格各异、能力独特的同伴，与他们一同对抗强敌，踏上寻回血亲之路；也可以不带目的地漫游，沉浸在充满生机的世界</span><br><span class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.baidu.com/s?wd=%E5%8E%9F%E7%A5%9E+%E6%B8%B8%E6%88%8F<span class="symbol">&amp;amp;</span>sa=fyb_game_all<span class="symbol">&amp;amp;</span>rsv_dl=fyb_game_all&quot;</span></span></span><br><span class="line"><span class="tag">                <span class="attr">class</span>=<span class="string">&quot;look-more_3oNWC&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span> 查看更多<span class="symbol">&amp;gt;</span> <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--/s-frag--&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>代码稍显冗长, 首先是获得 <code>soup</code>, 也就是解析好的文档内容, 然后是反复的调用核心函数 <code>find</code> 和 <code>find_all</code>.</p>
<p><code>bs4</code> 的理念是, 整个文档 <code>soup</code> 会被视作一个文档树, 且其中的子节点也是相同的小文档树, 形成一个递归结构. 而使用这两个函数则可以很方便的在树中进行遍历与查找.</p>
<p>两个函数参数相同, 详情可以查阅使用文档, 唯一不同的地方是 <code>find</code> 只获取找到的第一个节点而 <code>find_all</code> 则会获取所有节点返回一个列表. 我们给所有的调用都加上了 <code>recursive=False</code>, 这样可以确保让我们一层一层依次往下而不是递归获取内部所有节点, 每一层节点的序号和文档内部的实际情况相对应, 可以自行对比看看每一行是怎么来的.</p>
<p><code>get_text</code> 用来获取当前节点内部所有的文本内容, 加上参数后可以去除首尾的空白.</p>
<h3 id="接下来干什么"><a href="#接下来干什么" class="headerlink" title="接下来干什么"></a>接下来干什么</h3><p>获得数据之后, 我们可以选择保存到文件进行存储.</p>
<p>但是我们获取的东西非常有限, 仅仅只是一个排行榜, 不过在这些数据里, 有一项是详情链接, 后续可以进一步对详情链接的页面进行分析, 从而实现对详情页面内容的抓取, 让爬虫爬的更远一点.</p>
<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p>这次文章内容很简短, 仅仅是实践了一下最基本过程, 并且随着网站数据更新, 页面结构随时会发生变化, 因此还需多多练习.</p>
<p>有很多与爬虫相关的内容, 可以搜索相关的关键词进行进一步学习, 一并贴在下面了.</p>
<p><code>http 协议</code>: 进一步了解请求中的方法和响应中的状态码的含义, 掌握更多浏览器与服务器交互的细节过程.</p>
<p><code>html 文档结构</code>: 了解网页的树形结构, 学习 <code>html</code> 语法.</p>
<p><code>正则表达式</code>: 除了使用 <code>beautifulsoup4</code> 这样的工具结构化处理网页, 也可以按规则直接搜索你想要的所有结果.</p>
<p>一些库的官方文档地址.</p>
<p><code>requests</code>: <span class="exturl" data-url="aHR0cHM6Ly9yZXF1ZXN0cy5yZWFkdGhlZG9jcy5pby8=">https://requests.readthedocs.io/<i class="fa fa-external-link-alt"></i></span></p>
<p><code>beautifulsoup4</code>: <span class="exturl" data-url="aHR0cHM6Ly93d3cuY3J1bW15LmNvbS9zb2Z0d2FyZS9CZWF1dGlmdWxTb3VwL2JzNC9kb2Mv">https://www.crummy.com/software/BeautifulSoup/bs4/doc/<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>requests</tag>
      </tags>
  </entry>
  <entry>
    <title>给新生的编程工具推荐与基本使用方法</title>
    <url>//posts/2022/08/11/wast-vscandvs/</url>
    <content><![CDATA[<p>此帖面向大一新生刚入门的编程小白, 作为编程工具的常规推荐, 大佬请直接无视orz.</p>
<p>主要讲解一下 <code>Visual Studio Code</code> 和 <code>Visual Studio</code> 的基本使用.</p>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为一个合格的网络空间安全专业本科生, 平常课程作业中最常使用的编程语言应该就是 <code>c</code> 和 <code>python</code>. (信息安全专业也可以参考)</p>
<p><code>c</code> 应该会伴随你四年的本科生涯, 并且将会是大部分人接触的第一门语言, 大一也会有一门课叫 &quot;C语言程序设计&quot;, 这个课包括理论课与实验课两个课头, 相信大家还是会学有所获的.</p>
<p>而 <code>python</code>, 就我这一届来看, 并没有开设和 <code>python</code> 相关的语言课程, 但是, 从速通网安的角度来说, <code>python</code> 是非常推荐学一下的, 毕竟有很多现成的库, 网上的相关资源也非常丰富, 同时很适合做各种课程大作业. <del>人生苦短, 我学python</del>.</p>
<p>所以就我四年的本科使用经验来说, <code>Visual Studio Code</code> 和 <code>Visual Studio</code> 用来写上述两种语言的体验还是非常舒适的, 所以在此进行推荐和软件的使用方法入门.</p>
<h2 id="Visual-Studio-Code"><a href="#Visual-Studio-Code" class="headerlink" title="Visual Studio Code"></a>Visual Studio Code</h2><p>首先是 <code>VS Code</code>. 从本质上来说, <code>VS Code</code> 是一个多功能的文本编辑器, 不管你是否需要写代码, 我都建议你在电脑上装一个, 可以极大的提高你的文本处理效率. <del>珍爱生命, 远离记事本</del>.</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>官网地址是 <span class="exturl" data-url="aHR0cHM6Ly9jb2RlLnZpc3VhbHN0dWRpby5jb20v">https://code.visualstudio.com/<i class="fa fa-external-link-alt"></i></span>. 进去之后的界面现在长这样.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/11/vGcccj.jpg" alt="vGcccj.jpg"></p>
<p>可以直接点 Download 下载然后快速安装, 不过我不是那么的推荐, 因为直接点下载的是 User 版本, 可能会有奇怪的权限问题. 推荐下能够获取系统权限的版本比较好, 并且可以安装在系统目录.</p>
<p>所以按下图直接点到其他版本的选择页面, 选 64 bit System 版本下载.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/11/vGgPvd.png" alt="vGgPvd.png"></p>
<p><img data-src="https://s1.ax1x.com/2022/08/11/vGgNPU.png" alt="vGgNPU.png"></p>
<p>下载完之后点击安装, 接下来提一下几个比较有用的安装选项, 可以极大的提高你的使用体验.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/11/vGRJ9U.png" alt="vGRJ9U.png"></p>
<p>这个界面上的选项建议全勾上, 第 2 个和第 3 个选项可以在你的右键菜单里添加 &quot;通过 Code 打开&quot; 的选项, 这样子你可以很方便的直接使用右键点击文件或者文件夹或者文件夹的空白处, 然后把他们在 <code>VS Code</code> 中打开进行操作.</p>
<p>第 5 个选项平常不会怎么用到, 但是保持默认选项勾上就可以了, 它可以让你在命令行中用 <code>Code</code> 进行操作</p>
<p>一路下一步, 然后就安装完成, 之后可以选择重启一下电脑让一些配置立即生效, 不过不重启也没关系, 没啥影响.</p>
<h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><p>首先说说平常写代码时候, 一般来说都是至少以一个文件夹作为最小单位来操作 (除非真的是非常临时的一份小脚本, 否则都推荐弄个文件夹舒服, 里面不仅放代码同时也放代码要引用和生成的其他文件).</p>
<p>这个文件夹就是你的项目文件夹, 一个 Project, 之后会在这个基础上开展你后续的 Coding 工作.</p>
<p>所以基本上你要写点啥课程大作业代码的时候, 第一步就是找个地方新建一个文件夹, 然后用 Code 打开. 这里用一个叫 &quot;example&quot; 的文件夹作为示例, 讲解一下 <code>VS Code</code> 的基本使用方法.</p>
<h4 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h4><p>不管你是用通过右键打开的项目文件夹还是从 &quot;文件&quot; 菜单栏打开的, 之后的界面都应该和下面的图长得差不多, 一片空白.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJ85wR.png" alt="vJ85wR.png"></p>
<p>然后我们选到左边的长得像方块的图标, 也就是扩展, 开始按照工作需求自定义我们的 <code>VS Code</code>.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJGk6g.png" alt="vJGk6g.png"></p>
<p>可以看到这里已经有一个扩展了, 这也是我们下载 <code>VS Code</code> 几乎必装的一个扩展, 中文汉化扩展, 如果没有预装, 则直接搜索对应的扩展名字装上就可以了. <del>英语大佬请无视中文扩展</del>.</p>
<p>装完会提示重新启动 <code>VS Code</code> 加载, 之后的界面就会像我图里那样全中文了.</p>
<p>然后是编程语言扩展, 这也是最基本的东西, 需要用 <code>VS Code</code> 写什么语言的代码就装什么语言的扩展, 一般直接装 Microsoft 官方的或者 Star 最多的就行.</p>
<p>由于 <code>VS Code</code> 之后基本上用来写 <code>python</code>, 因此这里把 <code>python</code> 扩展先装上, 日后有需求可以自行举一反三.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJGj3T.png" alt="vJGj3T.png"></p>
<p>安装完成之后可能会弹出来一些 Get Start 页面, 不用管, 不过有时间的话可以稍微翻一翻, 也是一些新手教程.</p>
<h4 id="第一份代码"><a href="#第一份代码" class="headerlink" title="第一份代码"></a>第一份代码</h4><p><img data-src="https://s1.ax1x.com/2022/08/12/vJJhI1.png" alt="vJJhI1.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sub</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a - b</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mul</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a * b</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">div</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a / b</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    num1 = add(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    num2 = mul(num1, <span class="number">7</span>)</span><br><span class="line">    num3 = sub(num2, num1)</span><br><span class="line">    num4 = div(num3, num1)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Result: <span class="subst">&#123;num4&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>新建一份文件, 然后随便敲一点东西之后, 得到了现在的 <code>main.py</code> 文件. 下面说说对这份文件最简单的运行和调试.</p>
<h5 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h5><p>有很多方法可以运行, 这里只说两种最简单的, 一是靠鼠标或者快捷键, 二是在命令行里敲命令.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJYkZj.png" alt="vJYkZj.png"></p>
<p>图内可以看到菜单栏有个运行选项, 点开就是两个, 一个叫 &quot;启动调试&quot; (<code>F5</code>), 另一个是 &quot;以非调试模式运行&quot; (<code>Ctrl + F5</code>).</p>
<p>前者是调试, 后者是单纯的运行, 对于我们来说, 只需要点击后者, 或者直接快捷键 <code>Ctrl + F5</code>, 就可以看到运行效果了.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJY3w9.png" alt="vJY3w9.png"></p>
<p>自动弹出了一个终端, 并且成功的打印出了我们的结果. 到这里第一种方法就结束了, 更多细致的功能日后再慢慢探索吧.</p>
<p>然后是第二种方式, 自己在命令行里敲命令, 那么首先需要知道怎么把终端调用出来.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJYBeH.png" alt="vJYBeH.png"></p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJYyFI.png" alt="vJYyFI.png"></p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJY4mQ.png" alt="vJY4mQ.png"></p>
<p>如上图新建一个终端, 然后敲入指令 <code>python main.py</code>, 同样输出了我们的运行结果. 可以看到, 新建的终端会自动打开到我们的项目文件夹目录, 所以可以直接访问到里面的内容, 而我们的所有命令, 也都是基于项目文件夹作为根目录来运行的. (这一点很重要, 如果命令行的工作目录和项目文件夹不一致, 可以自己手动 <code>cd</code> 切换一下, 可以免去写代码时带来的一些路径问题)</p>
<h5 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h5><p>这里简单的调试一下这份文件, 打一下断点, 查看一下运行中变量.</p>
<p>所谓断点, 就是你在调试的时候需要让程序停在哪个点, 从而在某个点可以查看程序的运行情况, 快速定位问题来源.</p>
<p>打上断点的方式也很简单, 比如在第 15 行停下, 那么只需要在行号左边点一下就可以了, 这样子当程序运行到第 15 行的时候, 会停下, 且第 15 行<strong>不会执行</strong>, 是即将要执行的语句.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJtKht.png" alt="vJtKht.png"></p>
<p>然后, 从运行菜单里选择 &quot;进行调试&quot; 或者快捷键 <code>F5</code>, 会弹出提示让你选择要使用的调试配置 (因为我们没有给这个项目设定自己的调试配置, 所以需要选择一种系统提供的默认调试配置), 这里直接选第一个就行了.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJtyB4.png" alt="vJtyB4.png"></p>
<p>不出意外的话, 程序会稳稳的停在第 15 行, 并且左边跳转到了调试面板, 显示了各种调试信息.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJtouD.png" alt="vJtouD.png"></p>
<ul>
<li>变量: 显示了各种局部或者全局的变量值.</li>
<li>监视: 可以手动输入一些变量或者表达式来进行单独观察.</li>
<li>调用堆栈: 显示了函数之间的嵌套调用关系.</li>
<li>断点: 显示当前所有的断点信息, 有三种固有断点, 和程序的报错有关.</li>
</ul>
<p>这里可以看到, 左边变量里, 显示了一个局部变量 <code>num1</code> 等于 5, 这和我们的预期是一致的, 并且第 15 行尚未执行, 所以还没有 <code>num2</code> 这个变量.</p>
<p>然后是调试过程中可以使用的基本操作, 可以看到上方多出来一个条, 有各种调试按钮.</p>
<div class="note info"><p>程序执行过程中, 可能会遇到函数调用, 如果我们需要进入这个函数进行调试, 查看这个函数的内部情况, 则需要使用 &quot;单步调试&quot;, 即一步一步执行, 进入函数内部.</p>
<p>而当你在当前函数内部查看完情况之后, 可能函数还剩很多没执行完, 这个之后需要使用 &quot;单步跳出&quot;, 直接快进到把当前函数执行完成.</p>
<p>有的时候你完全不想进入某个函数, 想直接执行一整行, 这种时候可以使用 &quot;单步跳过&quot;.</p>
<p>最后, 如果你这一片代码已经调试完成, 需要直接快进到下一个断点, 使用 &quot;继续&quot; 则会将程序继续执行, 直到再次遇见断点则停下, 或者直接执行到程序结束.</p>
</div>

<p>这些调试按钮配合左侧面板的调试信息, 可以很清晰的知道程序的执行步骤以及每一步的变化情况, 是解决代码 bug 的利器, 闲暇时间可以多尝试几次, 熟悉调试过程和操作.</p>
<h2 id="Visual-Studio"><a href="#Visual-Studio" class="headerlink" title="Visual Studio"></a>Visual Studio</h2><p>第二个推荐的编程工具是 <code>VS</code>, 相比于 <code>VS Code</code>, <code>VS</code> 更加臃肿但是功能更加强大, 如果用习惯了, 在 Windows 平台上写 <code>c</code> 语言之类的课程作业,  将会是无比舒适.</p>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p><code>VS</code> 的安装分成两步, 首先是安装它专属的 Installer, 然后再决定安装具体的 <code>VS</code> 内容.</p>
<p>官方网站是 <span class="exturl" data-url="aHR0cHM6Ly92aXN1YWxzdHVkaW8ubWljcm9zb2Z0LmNvbS8=">https://visualstudio.microsoft.com/<i class="fa fa-external-link-alt"></i></span>, 目前是 2022 的最新版本, 下的时候选择 Community 版本下载, 这个版本是<strong>面向个人免费使用</strong>的, 只需要注册微软的账户就可以授权给个人了.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJ5QCq.png" alt="vJ5QCq.png"></p>
<p>这个东西下完之后是 VS 的 Installer, 直接无脑装好然后运行, 会进入如下的选择界面. (找不到就去开始菜单里翻, 它是不会有桌面快捷方式的)</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJI6S0.png" alt="vJI6S0.png"></p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJIfw4.png" alt="vJIfw4.png"></p>
<p>默认会直接进到第二张图, 如果不是的话按第一张图自己选安装.</p>
<p>对于我们日常写写作业来说, 我们只需要能够写 <code>c</code> 语言就够了, 所以只需勾选下面其中的一个就完全足够使用了, 那就是 &quot;使用 C++ 的桌面开发&quot;. 虽然写的是 <code>c++</code>, 但是其实写 <code>c</code> 也是用这个写的, 只要你创建源文件的时候, 后缀名自己改成 <code>.c</code> 而不是 <code>.cpp</code>, 这样子编译的时候就会换成 <code>c</code> 的编译方式.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJIqOO.png" alt="vJIqOO.png"></p>
<p>这一坨子东西装下来还是要一点空间和时间的, 推荐电脑有空闲时间的时候慢慢挂机安装, 安装完之后重启一下电脑, 让一些系统项生效.</p>
<h3 id="基本使用-1"><a href="#基本使用-1" class="headerlink" title="基本使用"></a>基本使用</h3><p>打开装好的 <code>VS</code>, 我们开始用 <code>c</code> 写一个 Hello World 程序<del>程序员绕不过去的新手代码</del>.</p>
<p>首先会跳出来这个界面, 我们直接选择创建新项目.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJOeqP.png" alt="vJOeqP.png"></p>
<p>然后是选择项目模板, 模板类型有很多, 但是我们选择最简单的 &quot;空项目&quot;, 这样子可以后续自己手动创建文件, 了解一下具体的项目结构.</p>
<p>然后是设置名称. 这里有两个内容可以自定义, 一个是项目名称, 一个是解决方案名称.</p>
<p>在 <code>VS</code> 里面创建项目时, 顶层结构不是 &quot;项目&quot; 而是 &quot;解决方案&quot;, 这是与 <code>VS Code</code> 不同的一点. 一个 &quot;解决方案&quot; 是一个更大的容器, 里面可以包含很多的 &quot;项目&quot;, 然后每一个 &quot;项目&quot; 是一个个单独的内容, 用不同的文件夹分门别类的区分开来.</p>
<p>这样子的好处就是, 适应性范围更广, 能够很方便的做多个项目之间的互相调用, 比如你可以一个项目用来写测试, 另一个项目是你实际上要写的代码库.</p>
<p>这里我们把 &quot;解决方案&quot; 的名称设为 &quot;example&quot;, 把项目名称设置为 &quot;c_project&quot;. 这样子实际的物理结构就会是一个 <code>example</code> 的总文件夹下面还有一个 <code>c_project</code> 的项目文件夹.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJXf00.png" alt="vJXf00.png"></p>
<p>创建好之后大概长下图所示, 解决方案资源管理器位置可以自己调, 我调左边去了, 视图菜单里也可以手动显示出来.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJXztO.png" alt="vJXztO.png"></p>
<h4 id="认识解决方案资源管理器"><a href="#认识解决方案资源管理器" class="headerlink" title="认识解决方案资源管理器"></a>认识解决方案资源管理器</h4><p><code>VS</code> 里面的解决方案资源管理器是一个集合了非常多功能的管理器, 需要熟悉一下它提供给我们的基本功能.</p>
<p>管理器的顶层是解决方案, 也就是刚刚我们命名的 <code>example</code> 文件夹, 然后列出来了里面包含的所有项目, 目前只有一个项目, 就是一起创建的 <code>c_project</code>.</p>
<p>目前看到的这个视图是 &quot;解决方案视图&quot;, 是解决方案内的<strong>逻辑结构</strong>而不是在磁盘上的<strong>物理结构</strong>.</p>
<p>那么我们首先尝试创建一份 <code>main.c</code>, 并写几句代码.</p>
<p>右键 &quot;源文件&quot;, 选择 &quot;添加&quot;, 然后选择 &quot;新建项&quot;, 选择源文件, 同时把文件名设为 <code>main.c</code>. 然后键入经典的 Hello world 程序代码.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJjO2Q.png" alt="vJjO2Q.png"></p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJviPU.png" alt="vJviPU.png"></p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJvKIK.png" alt="vJvKIK.png"></p>
<p>可以看到左侧已经成功的在源文件项下面多出来了一份 <code>main.c</code>. 但是刚刚说了目前的界面是解决方案的 &quot;逻辑结构&quot;, 所以我们需要切换一下视图, 看看刚刚创建的文件究竟在哪.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJv6Ln.png" alt="vJv6Ln.png"></p>
<p>管理器的上方有一个切换视图按钮, 点击之后可以选择是 &quot;解决方案&quot; 还是 &quot;文件夹视图&quot;, 我们直接换到文件夹视图.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJv4WF.png" alt="vJv4WF.png"></p>
<p>这个时候就非常清晰了, 顶层文件夹 <code>example</code>, 次级项目文件夹 <code>c_project</code>, 然后在项目文件夹内有一份 <code>main.c</code>.</p>
<p>切回解决方案视图, 现在再看 &quot;源文件&quot; 这一项, 它其实只是人为设置的一个分类结构, 在 <code>VS</code> 里叫 &quot;筛选器&quot;, 可以在不影响物理结构文件实际路径的同时给开发人员一个合适的文件分类方法, 可以右键新建里添加新的自定义筛选器.</p>
<h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h4><p>既然是写 <code>c</code> 语言, 运行前必不可少的步骤就是编译, 那么首先我们要知道, <code>VS</code> 是如何知道哪些文件是需要被纳入编译范围的.</p>
<p>一个最简单的设置方法就是将文件或者文件夹设置是否包含在项目中. 解决方案视图只会显示在项目中的内容. 即使文件实际上在项目文件夹内, 如果不在项目中, 那它也不会纳入 <code>VS</code> 项目的各种判断逻辑中, 比如不会参与编译.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJxqXj.png" alt="vJxqXj.png"></p>
<p>这种方式可以很轻松的把文件排除项目. 那么对于添加到项目里, 比如需要添加现有的文件与源代码, 我们需要首先把对应的文件在物理上移到我们的项目文件夹内合适的地方, 然后使用管理器切换到 &quot;所有文件&quot; 视图.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/12/vJzQjH.png" alt="vJzQjH.png"></p>
<p>如果刚刚把 <code>main.c</code> 排除了, 那么就会像图上那样有个红色符号, 表示这个文件没有纳入项目逻辑考虑范围. 我们可以用右键把它重新包含到项目内, 这样子红色符号就消失了, 解决方案视图里也能重新看到这个文件了.</p>
<p>当确定了那些文件被包含到项目中后, 就可以开始编译了.</p>
<p>有两种方式会进行编译, 一种是直接运行或者调试程序, 如果项目没有被编译, 则会先进行编译, 再运行程序. 另一种就是只编译不运行, 分步骤进行.</p>
<p>我这里还是推荐分步骤进行, 先编译看看是否存在什么警告或者错误, 再进行运行或者调试.</p>
<p>编译的时候有一些基本选项可以调整.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vtQxRU.png" alt="vtQxRU.png"></p>
<p><code>x86</code> 和 <code>x64</code> 好理解, 指的是编译出来的二进制文件是 32 位程序还是 64 位程序, 一般来说调成 <code>x64</code> 会让程序能更充分利用现在的 64 位处理器性能.</p>
<p>而 <code>Release</code> 与 <code>Debug</code>, 翻译一般叫 &quot;发布&quot; 与 &quot;调试&quot;. 调试版本是适合于调试代码的版本, <code>VS</code> 在编译时会加入很多调试信息进入最终的二进制文件, 能够在调试时充分的获得程序运行的每一步信息. 而 &quot;发布&quot; 则是适合最终运行的优化版本, <code>VS</code> 会在编译时尽可能的减少代码冗余, 对代码结构进行优化, 提高最终程序的运行效率.</p>
<p>所以写代码的时候用 <code>Debug</code> 版本, 而交程序的时候用 <code>Release</code> 版本. (这两个版本的运行效率差异非常大, 如果你觉得代码太慢, 不妨试一下 <code>Release</code> 来尝试提高效率. <del>说不定有奇效</del>)</p>
<p>然后进入编译的正题. 选择菜单栏里的 &quot;生成&quot;, 在这里可以对解决方案和每个项目进行生成操作. 此处 &quot;生成&quot; 不一定指编译, 而是去生成每个项目的目标文件, 对于 <code>c</code> 语言来说就是编译链接操作. </p>
<p>选择生成整个解决方案, 则 <code>VS</code> 会按照项目间的依赖关系依次生成方案内所有的项目. 选择生成某一个项目, 那就是生成单独的一个项目. 每次可以选择 &quot;重新生成&quot; 或者 &quot;生成&quot;, 前者会先进行一步 &quot;清理&quot; 操作, 把上一次生成时产生的所有文件先清除再进行生成.</p>
<p>一般来说, 直接使用快捷键 <code>Ctrl + B</code> 即可, 会生成当前正在操作的项目.</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vtlezD.png" alt="vtlezD.png"></p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vtlnQe.png" alt="vtlnQe.png"></p>
<p>运行一下生成, 可以看到下方的输出里显示生成成功, 并且也输出了生成的二进制文件的路径.</p>
<h4 id="运行与调试"><a href="#运行与调试" class="headerlink" title="运行与调试"></a>运行与调试</h4><p>这里就简单说说, 不赘述了, 因为同为微软家的产品, 基本概念和快捷键都是一样的, 具体的操作和前面 <code>VS Code</code> 中说的大同小异, 几乎是一致的. 这里就放一下成功运行截图了.</p>
<p>按下快捷键 <code>Ctrl + F5</code>, <code>VS</code> 就会自动弹出来一个运行黑框了, &quot;Hello world!&quot;</p>
<p><img data-src="https://s1.ax1x.com/2022/08/13/vtlJW8.png" alt="vtlJW8.png"></p>
<h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>这一篇就打算写这么多了, 第一次写这种新手教程额, 尽可能的按照一个没有接触过编程但是来到了网安学院的大一新生视角来写, 希望能够有所帮助, 快速入门吧. <del>上啊, 卷死他们!</del></p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>新手入门</category>
      </categories>
      <tags>
        <tag>VS Code</tag>
        <tag>Visual Studio Code</tag>
        <tag>Visual Studio</tag>
        <tag>VS</tag>
      </tags>
  </entry>
  <entry>
    <title>碧蓝航线立绘提取与批量还原</title>
    <url>//posts/2023/04/11/blhx-painting/</url>
    <content><![CDATA[<p>因为网上没看到太好的核心步骤介绍和脚本, 所以自己造了一下轮子, 方便自己记录学习过程.</p>
<p>本文介绍碧蓝航线立绘提取和还原基本思路, 文末附有完整的批量还原 <code>python</code> 脚本.</p>
<span id="more"></span>

<h2 id="资源提取"><a href="#资源提取" class="headerlink" title="资源提取"></a>资源提取</h2><p>提取的方法网上很多, 不再赘述, 用 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlcmZhcmUvQXNzZXRTdHVkaW8vcmVsZWFzZXM=">AssetStudio<i class="fa fa-external-link-alt"></i></span> 导出安装包和热更新里的 <code>painting</code> 内容, 得到 里面的 <code>Mesh</code> 和 <code>Texture2D</code> 资源即可进行下一步还原.</p>
<h2 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h2><p><code>Texture2D</code> 下面的内容是所有打包后的立绘纹理图片, 目测都是 <code>名字</code> + <code>.png</code> 的文件名.</p>
<p><code>Mesh</code> 下面是 3D 模型贴图格式, 大部分都是 <code>名字</code> + <code>-mesh.obj</code> 的文件名, 小部分要特殊处理, 名字和前面纹理图名字一一对应.</p>
<ul>
<li><code>g</code> 开头的行是标识行, 可以忽略;</li>
<li><code>v</code> 开头的是模型顶点坐标, 对应还原后的图的坐标;</li>
<li><code>vt</code> 是纹理图的顶点坐标, 对应打包后图片的坐标;</li>
<li><code>f</code> 是 <code>v</code> 和 <code>vt</code> 的对应关系, 每一行代表一个三角面, 用三组点来记录, 分别是 <code>v/vt/vn</code> 的序号, 从 1 开始.</li>
</ul>
<p>更为详细的内容可以自行谷歌 <code>Mesh</code> 的文件格式.</p>
<h2 id="还原思路"><a href="#还原思路" class="headerlink" title="还原思路"></a>还原思路</h2><h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h3><p><code>Mesh</code> 中每一个 <code>f</code> 行代表一个小三角形, 实测相邻的两行就是一整个矩形, 因此只需要读取 <code>Mesh</code> 文件记录之后, 两行两行去处理 <code>f</code> 记录, 就可以像拼图一样从纹理图把原图拼出来.</p>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li>模型坐标的 <code>x</code> 取值需要取绝对值进行镜像 (原因不知).</li>
<li>原始坐标系的原点都在图片的左下角, 需要调整成左上角 (翻转 <code>y</code> 轴).</li>
<li>需要将坐标系里的点转换到图片里的像素行列值 (比较玄学, 坐标里的点对应图片像素一个 <code>2x2</code> 像素的中心点)</li>
<li>打包的纹理图图块和原图图块可能存在某一些块大小不一致, 实测都是纹理图可能比原图多 1 行/列透明像素, 因此拼的时候需要对比大小, 剔除多余的透明行/列<del>想想也知道怎么可能拆分成这么多块后还刚好能重新拼成一个大块</del>. 而且由于绘图误差, 全透明点的 RGB 不一定是全 0, 并且 alpha 通道也可能有一些值, 所以凡是透明度小于某个阈值就可以认为是透明的了.</li>
<li>瓜游的 0.125 个程序员导致很多立绘就是原图, 然后对应的 <code>Mesh</code> 文件没有; 也可能热更新很多次, 同一个纹理图有很多个 <code>Mesh</code> 文件, 需要都尝试一下.</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>安装一下必要的库, 运行的时候需要设定资源文件夹和导出文件夹.</p>
<p>当遇到无法通过 <code>Mesh</code> 文件来还原的纹理图时, 会弹窗显示图片的缩略图, 可以手动选择是直接复制原图过去还是放弃这张图, 比如下面:</p>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLHg1I.png" alt="ppLHg1I.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> tkinter <span class="keyword">as</span> tk</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageTk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_mesh_obj</span>(<span class="params">path</span>):</span><br><span class="line">    vertex = []  <span class="comment"># x, y, x</span></span><br><span class="line">    vertex_texture = []  <span class="comment"># u, v</span></span><br><span class="line">    vector_normal = []  <span class="comment"># x, y, z # 2D 没有法向量</span></span><br><span class="line">    face = []  <span class="comment"># v/vt/vn</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            type_, *values = line.strip().split(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> type_ == <span class="string">&quot;v&quot;</span>:</span><br><span class="line">                vertex.append(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, values[:<span class="number">2</span>])))</span><br><span class="line">            <span class="keyword">elif</span> type_ == <span class="string">&quot;vt&quot;</span>:</span><br><span class="line">                vertex_texture.append(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, values)))</span><br><span class="line">            <span class="keyword">elif</span> type_ == <span class="string">&quot;f&quot;</span>:</span><br><span class="line">                face.append([<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, value.split(<span class="string">&quot;/&quot;</span>))) <span class="keyword">for</span> value <span class="keyword">in</span> values])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">return</span> vertex, vertex_texture, face</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">restore_painting</span>(<span class="params">texture: np.ndarray, v, vt, f</span>) -&gt; np.ndarray:</span><br><span class="line">    v = np.array(v)[:, <span class="number">0</span>:<span class="number">2</span>]  <span class="comment"># 去除 z 轴</span></span><br><span class="line">    vt = np.array(vt)</span><br><span class="line">    f = np.array(f)[:, :, <span class="number">0</span>:<span class="number">2</span>]  <span class="comment"># 去除法向量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理 v</span></span><br><span class="line">    v = np.<span class="built_in">abs</span>(v)  <span class="comment"># 水平镜像, 原因不明</span></span><br><span class="line">    v[:, <span class="number">1</span>] = np.<span class="built_in">max</span>(v[:, <span class="number">1</span>]) - v[:, <span class="number">1</span>]  <span class="comment"># 翻转 y 轴, x 对应列数, y 对应行数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理 vt</span></span><br><span class="line">    vt = vt * np.array(texture.shape[<span class="number">1</span>::-<span class="number">1</span>]).reshape(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 转换到像素</span></span><br><span class="line">    vt[:, <span class="number">1</span>] = texture.shape[<span class="number">0</span>] - vt[:, <span class="number">1</span>]  <span class="comment"># 翻转 y 轴</span></span><br><span class="line">    vt = np.<span class="built_in">round</span>(vt, <span class="number">0</span>).astype(<span class="built_in">int</span>)  <span class="comment"># 转换整数坐标</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 新建空图</span></span><br><span class="line">    width, height = np.<span class="built_in">max</span>(v, axis=<span class="number">0</span>) + <span class="number">2</span>  <span class="comment"># 上下左右各扩展 1 个位置</span></span><br><span class="line">    png = np.zeros((height, width, <span class="number">4</span>), dtype=texture.dtype)</span><br><span class="line">    <span class="comment"># print(png.shape)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(f), <span class="number">2</span>):</span><br><span class="line">        v_rect_pts: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]] = []</span><br><span class="line">        vt_rect_pts: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]] = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v_idx, vt_idx <span class="keyword">in</span> f[i]:</span><br><span class="line">            v_rect_pts.append(v[v_idx - <span class="number">1</span>])  <span class="comment"># 下标需要序号 -1</span></span><br><span class="line">            vt_rect_pts.append(vt[vt_idx - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v_idx, vt_idx <span class="keyword">in</span> f[i + <span class="number">1</span>]:</span><br><span class="line">            v_rect_pts.append(v[v_idx - <span class="number">1</span>])</span><br><span class="line">            vt_rect_pts.append(vt[vt_idx - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 排序得到左上和右下坐标</span></span><br><span class="line">        leftup_v, *_, rightdown_v = <span class="built_in">sorted</span>(v_rect_pts, key=<span class="built_in">list</span>)</span><br><span class="line">        leftup_vt, *_, rightdown_vt = <span class="built_in">sorted</span>(vt_rect_pts, key=<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转换像素行列坐标, 左闭右开</span></span><br><span class="line">        leftup_v = (leftup_v + <span class="number">1</span>) - <span class="number">1</span>  <span class="comment"># +1 是为了把图往两个正方向移动一格, 修正坐标</span></span><br><span class="line">        rightdown_v = (rightdown_v + <span class="number">1</span>) + <span class="number">1</span></span><br><span class="line">        leftup_vt = leftup_vt - <span class="number">1</span></span><br><span class="line">        rightdown_vt = rightdown_vt + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 判断区域是否大小相等</span></span><br><span class="line">        size1 = rightdown_v - leftup_v</span><br><span class="line">        size2 = rightdown_vt - leftup_vt</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">all</span>(size1 == size2):</span><br><span class="line">            <span class="comment"># 处理不相等情况, 目前只发现纹理区域会可能多一行/列, 想办法去掉空白</span></span><br><span class="line">            <span class="comment"># 空白的条件是某一行/列透明度均小于一个阈值</span></span><br><span class="line">            texture_region = texture[leftup_vt[<span class="number">1</span>]:rightdown_vt[<span class="number">1</span>], leftup_vt[<span class="number">0</span>]:rightdown_vt[<span class="number">0</span>]]</span><br><span class="line">            alpha_value = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">            row_delta = size2[<span class="number">1</span>] - size1[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> row_delta == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> np.<span class="built_in">all</span>(texture_region[-<span class="number">1</span>, :, -<span class="number">1</span>] &lt; alpha_value):</span><br><span class="line">                    rightdown_vt[<span class="number">1</span>] -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> np.<span class="built_in">all</span>(texture_region[<span class="number">0</span>, :, -<span class="number">1</span>] &lt; alpha_value):</span><br><span class="line">                    leftup_vt[<span class="number">1</span>] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">&quot;Empty row not found!&quot;</span>)</span><br><span class="line">            <span class="keyword">elif</span> row_delta &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;<span class="subst">&#123;row_delta&#125;</span> extra rows found.&quot;</span>)</span><br><span class="line"></span><br><span class="line">            col_delta = size2[<span class="number">0</span>] - size1[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> col_delta == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> np.<span class="built_in">all</span>(texture_region[:, -<span class="number">1</span>, -<span class="number">1</span>] &lt; alpha_value):</span><br><span class="line">                    rightdown_vt[<span class="number">0</span>] -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> np.<span class="built_in">all</span>(texture_region[:, <span class="number">0</span>, -<span class="number">1</span>] &lt; alpha_value):</span><br><span class="line">                    leftup_vt[<span class="number">0</span>] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">&quot;Empty col not found!&quot;</span>)</span><br><span class="line">            <span class="keyword">elif</span> col_delta &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;<span class="subst">&#123;col_delta&#125;</span> extra cols found.&quot;</span>)</span><br><span class="line"></span><br><span class="line">        png[leftup_v[<span class="number">1</span>]:rightdown_v[<span class="number">1</span>], leftup_v[<span class="number">0</span>]:rightdown_v[<span class="number">0</span>]] = texture[leftup_vt[<span class="number">1</span>]:rightdown_vt[<span class="number">1</span>], leftup_vt[<span class="number">0</span>]:rightdown_vt[<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> png</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">choose_image</span>(<span class="params">image_path</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_confirm</span>():</span><br><span class="line">        root.result = <span class="literal">True</span></span><br><span class="line">        root.destroy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_cancel</span>():</span><br><span class="line">        root.result = <span class="literal">False</span></span><br><span class="line">        root.destroy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化 tkinter 窗口</span></span><br><span class="line">    root = tk.Tk()</span><br><span class="line">    root.title(<span class="string">&quot;选择保留&quot;</span>)</span><br><span class="line">    root.result = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载图片并调整大小</span></span><br><span class="line">    image = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line">    max_size = (<span class="number">300</span>, <span class="number">300</span>)</span><br><span class="line">    image.thumbnail(max_size)</span><br><span class="line">    photo = ImageTk.PhotoImage(image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建图片标签并放置在窗口上</span></span><br><span class="line">    label = tk.Label(root, image=photo)</span><br><span class="line">    label.pack(padx=<span class="number">5</span>, pady=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建确认和取消按钮并放置在窗口上</span></span><br><span class="line">    confirm_button = tk.Button(root, text=<span class="string">&quot;复制&quot;</span>, command=on_confirm)</span><br><span class="line">    confirm_button.pack(side=tk.LEFT, padx=(<span class="number">20</span>, <span class="number">10</span>), pady=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    cancel_button = tk.Button(root, text=<span class="string">&quot;放弃&quot;</span>, command=on_cancel)</span><br><span class="line">    cancel_button.pack(side=tk.RIGHT, padx=(<span class="number">10</span>, <span class="number">20</span>), pady=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 运行窗口并等待用户操作</span></span><br><span class="line">    root.mainloop()</span><br><span class="line">    <span class="keyword">return</span> root.result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PNG_DIR = Path(<span class="string">&quot;./Texture2D&quot;</span>)</span><br><span class="line">OBJ_DIR = Path(<span class="string">&quot;./Mesh&quot;</span>)</span><br><span class="line"></span><br><span class="line">EXPORT_DIR = Path(<span class="string">&quot;./paintings&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> png <span class="keyword">in</span> PNG_DIR.iterdir():</span><br><span class="line">        char_name = png.stem</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(char_name)</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        painting_path = EXPORT_DIR.joinpath(png.name)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> mesh <span class="keyword">in</span> OBJ_DIR.glob(<span class="string">f&quot;<span class="subst">&#123;char_name&#125;</span>-mesh*.obj&quot;</span>):</span><br><span class="line">            v, vt, f = read_mesh_obj(mesh)</span><br><span class="line">            texture: np.ndarray = cv2.imread(png.as_posix(), cv2.IMREAD_UNCHANGED)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                painting = restore_painting(texture, v, vt, f)</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                traceback.print_exc()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Restore Error: <span class="subst">&#123;char_name&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span>  <span class="comment"># 还原失败继续试下一个可能的 mesh 文件</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 还原成功跳出循环</span></span><br><span class="line">            cv2.imwrite(painting_path.as_posix(), painting)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;No valid mesh file found for <span class="subst">&#123;png&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> choose_image(png):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Copy: <span class="subst">&#123;png&#125;</span>&quot;</span>)</span><br><span class="line">                shutil.copy(png, painting_path)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Discard: <span class="subst">&#123;png&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total: <span class="subst">&#123;count&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">input</span>(<span class="string">&quot;Press &lt;Enter&gt; to exit...&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="还原效果"><a href="#还原效果" class="headerlink" title="还原效果"></a>还原效果</h2><p>放一些还原前和还原后的图作对比<del>夹带私货</del>.</p>
<details class="note danger"><summary><p>guanghui_h.png</p>
</summary>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLI7y8.png" alt="ppLI7y8.png"><br><img data-src="https://s1.ax1x.com/2023/04/11/ppLIDRx.png" alt="ppLIDRx.png"><br>🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹</p>
<div style="text-align:center;">🌹<span class="black-curtain">为光辉老婆献上 99 朵玫瑰!</span>🌹</div>
</details>

<details class="note info"><summary><p>guanghui.png</p>
</summary>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLITQf.png" alt="ppLITQf.png"><br><img data-src="https://s1.ax1x.com/2023/04/11/ppLIBJ1.png" alt="ppLIBJ1.png"></p>

</details>

<details class="note info"><summary><p>guanghui_2.png</p>
</summary>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLIoSP.png" alt="ppLIoSP.png"><br><img data-src="https://s1.ax1x.com/2023/04/11/ppLI0iR.png" alt="ppLI0iR.png"></p>

</details>

<details class="note info"><summary><p>guanghui_3.png</p>
</summary>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLI5Wt.png" alt="ppLI5Wt.png"><br><img data-src="https://s1.ax1x.com/2023/04/11/ppLIdo9.png" alt="ppLIdo9.png"></p>

</details>

<details class="note info"><summary><p>guanghui_4.png</p>
</summary>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLIhFA.png" alt="ppLIhFA.png"><br><img data-src="https://s1.ax1x.com/2023/04/11/ppLIadJ.png" alt="ppLIadJ.png"></p>

</details>

<details class="note info"><summary><p>guanghui_5.png</p>
</summary>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLIHOS.png" alt="ppLIHOS.png"><br><img data-src="https://s1.ax1x.com/2023/04/11/ppLIrz6.png" alt="ppLIrz6.png"></p>

</details>

<details class="note info"><summary><p>guanghui_idol.png</p>
</summary>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLHstH.png" alt="ppLHstH.png"><br><img data-src="https://s1.ax1x.com/2023/04/11/ppLI6sO.png" alt="ppLI6sO.png"></p>

</details>

<details class="note info"><summary><p>guanghui_idol_n.png</p>
</summary>
<p><img data-src="https://s1.ax1x.com/2023/04/11/ppLIqeg.png" alt="ppLIqeg.png"><br><img data-src="https://s1.ax1x.com/2023/04/11/ppLIyQK.png" alt="ppLIyQK.png"></p>

</details>
]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>碧蓝航线</tag>
        <tag>立绘还原</tag>
      </tags>
  </entry>
  <entry>
    <title>IDM 破解版</title>
    <url>//posts/2023/05/17/idm-cracked/</url>
    <content><![CDATA[<p>IDM 破解版, 下载地址: <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pZkNUaDB3Zjdxa2I=">IDM-v6.41.11-Repack.zip<i class="fa fa-external-link-alt"></i></span>.</p>
<p>校验码:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MD5: EC358D55F0B1657A3095568747CC5B27</span><br><span class="line">SHA1: 8F544AA6CA37BA181A6D942441CC65C0B448FE42</span><br><span class="line">SHA2-256: 8A6DE19A91AE4644762D89C507946AB8E7D096B39D14A32B42C2FAACF9C442DD</span><br><span class="line">SHA3-256: 0679F2F0EB14C58149380429E1229AED27012A5ABC46347AE4742E3975C59079</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>下载工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 10 激活工具</title>
    <url>//posts/2023/02/27/win10activation/</url>
    <content><![CDATA[<p>Windows 10 激活工具存档, 下载地址: <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pZFJabjBvbTJqdWQ=">W10_Digital_Activation_Program_v1.4.6_Chs.zip<i class="fa fa-external-link-alt"></i></span>.</p>
<p>校验码:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MD5: A7A44635E59CC9C403EBA7873D1B6D0E</span><br><span class="line">SHA1: 13275066B9D3FBFF8F99AA7CDF89D5AC2E94F571</span><br><span class="line">SHA2-256: E44F2F49A0805F3B0B7CB4720B48CFCAEDB3755189ED12CC49F406B425A40296</span><br><span class="line">SHA3-256: 078D7D813914831F4D19757FE98E89F49177C8EC9DEBA4A7FDEEE1083233D890</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>激活工具</tag>
      </tags>
  </entry>
</search>
