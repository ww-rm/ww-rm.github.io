<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>序</title>
    <url>//posts/2021/05/21/prologue/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>孔子云：何陋之有？</p>

</blockquote>
]]></content>
      <categories>
        <category>序</category>
      </categories>
      <tags>
        <tag>序</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 Spine 的碧蓝航线桌宠</title>
    <url>//posts/2023/08/30/desktopsprite/</url>
    <content><![CDATA[<p>本文是对个人项目 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL0Rlc2t0b3BTcHJpdGU=">DesktopSprite<i class="fa fa-external-link-alt"></i></span> 的介绍, 一个使用 <code>C++</code> 实现的原生桌宠程序, 基于 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0Vzb3RlcmljU29mdHdhcmUvc3BpbmUtcnVudGltZXMvcmVsZWFzZXMvdGFnLzMuNi41Mw==">spine-runtimes v3.6.53<i class="fa fa-external-link-alt"></i></span> 运行库, 可以支持碧蓝航线导出的小人动画资源.</p>
<span id="more"></span>

<h2 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h2><p>项目地址: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL0Rlc2t0b3BTcHJpdGU=">https://github.com/ww-rm/DesktopSprite<i class="fa fa-external-link-alt"></i></span></p>
<p>这是一个适用于 <code>Windows</code> 系统下的桌面精灵, 目前已在 <code>Win10</code>, <code>Win11</code> 下基本测试通过.</p>
<ul>
<li>轻量的性能监视器: 可以显示电脑占用和网速监视浮窗</li>
</ul>
<p><img data-src="/static/image/desktopsprite/perfmonitor.gif" alt="性能浮窗动图"></p>
<ul>
<li>可自定义桌宠: 支持基于 <code>spine v3.6.53</code> 导出的碧蓝航线全角色小人动画</li>
</ul>
<p><img data-src="/static/image/desktopsprite/guanghui_2.gif" alt="guanghui_2 动图"><br><img data-src="/static/image/desktopsprite/biaoqiang_h.gif" alt="biaoqiang_h 动图"><br><img data-src="/static/image/desktopsprite/lafei_h.gif" alt="lafei_h 动图"><br><img data-src="/static/image/desktopsprite/z23_h.gif" alt="z23_h 动图"></p>
<h2 id="安装与使用"><a href="#安装与使用" class="headerlink" title="安装与使用"></a>安装与使用</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>前往 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL0Rlc2t0b3BTcHJpdGUvcmVsZWFzZXM=">Release<i class="fa fa-external-link-alt"></i></span> 下载 <code>Latest</code> 版本的 <code>zip</code> 压缩包, 解压后双击运行里面的 <code>DesktopSprite.msi</code> 安装文件进行安装, 可以自定义安装位置.</p>
<p>安装完成后, 开始菜单和桌面都会出现程序启动图标. 双击运行, 通知栏会有程序图标, 首次运行桌面默认会显示自带的碧蓝小人角色, 且有一个性能浮窗.</p>
<h3 id="更换角色"><a href="#更换角色" class="headerlink" title="更换角色"></a>更换角色</h3><p>右键通知区域程序图标, 可以进入设置界面, 设置对应的 <code>atlas</code> 和 <code>skel/json</code> 文件, 然后应用/确定设置即可完成更换.</p>
<p>需要注意 <code>*.atlas</code>, <code>*.png</code>, <code>*.skel/*.json</code> 三份文件需要互相匹配, 且 <code>*.atlas</code> 和 <code>*.png</code> 文件名必须相同 (选择 <code>atlas</code> 的时候会自动填入 <code>png</code> 文件).</p>
<p><img data-src="/static/image/desktopsprite/atlasconfig.png" alt="atlasconfig"></p>
<h3 id="详细使用说明"><a href="#详细使用说明" class="headerlink" title="详细使用说明"></a>详细使用说明</h3><h4 id="设置面板"><a href="#设置面板" class="headerlink" title="设置面板"></a>设置面板</h4><p><img data-src="/static/image/desktopsprite/config.png" alt="config.png"></p>
<h5 id="系统设置"><a href="#系统设置" class="headerlink" title="系统设置"></a>系统设置</h5><ul>
<li>开机启动: 程序是否开机启动</li>
<li>整点报时: 一个小功能, 可以在整点时间弹出通知提醒</li>
<li>提示声音: 整点报时是否有声音</li>
<li>气泡图标路径: 整点报时气泡通知使用的图标</li>
</ul>
<h5 id="显示设置"><a href="#显示设置" class="headerlink" title="显示设置"></a>显示设置</h5><p>这部分的设置是针对性能浮窗的.</p>
<ul>
<li>显示浮窗: 是在桌面显示浮窗还是隐藏到通知区域图标使用鼠标悬停显示</li>
<li>显示占用: 是否在浮窗上显示处理器和内存占用百分比</li>
<li>显示网速: 是否在浮窗上显示上传和下载速度</li>
<li>深色主题: 设置浮窗主题颜色</li>
<li>透明度: 设置浮窗透明度百分比, 0 为完全透明, 100 为完全不透明</li>
</ul>
<h5 id="精灵设置"><a href="#精灵设置" class="headerlink" title="精灵设置"></a>精灵设置</h5><p>这部分的设置是针对桌宠的</p>
<ul>
<li>atlas, png, skel 路径: 选择要使用的 SD 小人模型, 三个文件要互相匹配</li>
<li>显示精灵: 是否在桌面上显示桌宠, 不显示的情况下不会有桌宠的资源占用</li>
<li>鼠标穿透: 是否让桌宠鼠标穿透, 穿透情况下桌宠无视鼠标和键盘输入</li>
<li>最大帧率: 设置桌宠的渲染帧率, 对电脑性能有较高影响</li>
<li>透明度: 设置桌宠透明度, 配合鼠标穿透可以设置挂件效果</li>
<li>缩放: 设置桌宠的大小</li>
</ul>
<h5 id="Spine-设置"><a href="#Spine-设置" class="headerlink" title="Spine 设置"></a>Spine 设置</h5><p>该部分设置桌宠动画小人不同事件和动画的映射关系, 可选内容由加载的 spine 模型决定.</p>
<ul>
<li>待机: 无操作的普通情况</li>
<li>拖动: 鼠标拖动桌宠时触发</li>
<li>任务中: 没想好</li>
<li>睡觉: 电脑无输入闲置一段时间后触发</li>
<li>闲置: 电脑低负载时随机触发</li>
<li>触摸: 单击桌宠触发</li>
<li>摸头: 鼠标中键下滚</li>
<li>任务完成: 任务结束后, 和任务中是连着的</li>
<li>跳舞: 鼠标中键上滚</li>
<li>过载: 电脑高负载时随机触发</li>
</ul>
<h5 id="按钮"><a href="#按钮" class="headerlink" title="按钮"></a>按钮</h5><ul>
<li>打开数据文件夹: 打开程序数据文件所在的文件夹</li>
</ul>
<h4 id="快捷操作"><a href="#快捷操作" class="headerlink" title="快捷操作"></a>快捷操作</h4><ul>
<li>右键菜单: 有两个, 一个是浮窗/通知区域图标的, 另一个是桌宠的, 大部分选项都是设置面板里有的, 是快捷操作</li>
<li>精灵复位: 用来预防一些未知的特殊情况, 如一些不可知的显示器分辨率问题导致的精灵错位消失, 点击之后精灵会回到原点, 屏幕的正下方</li>
<li>双击桌宠: 让角色转向</li>
</ul>
<h4 id="通知区域图标"><a href="#通知区域图标" class="headerlink" title="通知区域图标"></a>通知区域图标</h4><ul>
<li>右键单击: 显示右键菜单</li>
<li>左键双击: 显示桌宠</li>
</ul>
<h2 id="一些开发细节"><a href="#一些开发细节" class="headerlink" title="一些开发细节"></a>一些开发细节</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul>
<li><code>Win10+</code></li>
<li><code>Visual Studio 2022</code></li>
<li><code>C++14</code></li>
<li><a href="https://github.com/EsotericSoftware/spine-runtimes/tree/3.6"><code>spine-runtime</code></a></li>
<li><a href="https://github.com/open-source-parsers/jsoncpp"><code>jsoncpp</code></a></li>
</ul>
<p>其中 <code>spine-runtime</code> 和 <code>jsoncpp</code> 均是以源码方式引入并编译的, 内部有一些相应的适配性修改.</p>
<p><code>spine-runtime</code> 版本固定了是 <code>v3.6.53</code>, 所以几乎只支持碧蓝航线导出的小人资源.</p>
<h3 id="动画渲染"><a href="#动画渲染" class="headerlink" title="动画渲染"></a>动画渲染</h3><p>桌宠使用 2D 图形库绘制, 具体实现原理参考 <span class="exturl" data-url="aHR0cDovL3poLmVzb3Rlcmljc29mdHdhcmUuY29tL3NwaW5lLWM=">spine-c 运行时文档<i class="fa fa-external-link-alt"></i></span>, 标准实现需要使用纹理映射等计算机图形学操作<del>但是我不会</del>, 所以纹理映射是通过 2D 库的纹理笔刷来实现的.</p>
<p>创建纹理笔刷之后, 在绘制顶点三角形时, 需要自己手动计算纹理到模型的仿射矩阵, 然后设置笔刷的变换矩阵, 就能完成纹理映射. 关键函数是这个 <code>GetAffineMatrix</code>:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">GetAffineMatrix</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">float</span> x1, <span class="type">float</span> y1, <span class="type">float</span> x2, <span class="type">float</span> y2, <span class="type">float</span> x3, <span class="type">float</span> y3, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">float</span> u1, <span class="type">float</span> v1, <span class="type">float</span> u2, <span class="type">float</span> v2, <span class="type">float</span> u3, <span class="type">float</span> v3, </span></span></span><br><span class="line"><span class="params"><span class="function">    Matrix* m</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>;</span><br></pre></td></tr></table></figure>

<p>能够计算两个平面三角形 <code>UV</code> 到 <code>XY</code> 的仿射矩阵. 与渲染有关的详细实现见 <a href="https://github.com/ww-rm/DesktopSprite/blob/main/DesktopSprite/src/ds/spinechar.cpp"><code>spinechar.cpp</code></a>.</p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><h3 id="关于配置文件"><a href="#关于配置文件" class="headerlink" title="关于配置文件"></a>关于配置文件</h3><p>⚠️不建议直接操作配置文件! ⚠️</p>
<p>⚠️不建议直接操作配置文件! ⚠️</p>
<p>⚠️不建议直接操作配置文件! ⚠️</p>
<p>点击 &quot;打开数据文件夹&quot; 后, 可以看到数据文件夹里有一份 <code>config.json</code>, 里面以 <code>json</code> 格式存储了所有的设置面板可见的配置信息.</p>
<h3 id="使用上的问题"><a href="#使用上的问题" class="headerlink" title="使用上的问题"></a>使用上的问题</h3><ul>
<li>不建议帧率调太高, 会使电脑耗电显著增加, 或者风扇抽风</li>
<li>如果不慎出了一些和配置有关的问题, 比如设置了错误的内容导致程序崩了/打不开, 直接打开数据文件夹, 关闭程序并删除 <code>config.json</code> 后重启程序, 即可让程序使用默认配置运行</li>
</ul>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p>此处附一下自己导出的角色小人资源, 不一定包含最新角色, <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL0F6dXJMYW5lU0Q=">AzurLaneSD<i class="fa fa-external-link-alt"></i></span>.</p>
<p>如果无法下载则可以试一下下面的链接:</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMXRTYUJ6WlRXQ3l2Y3JnYkdoX21ncmc/cHdkPWJsaHg=">单角色下载<i class="fa fa-external-link-alt"></i></span>, 提取码: <code>blhx</code>.</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMXFwWm5KUkI0UGFDOUViM3RrWmRBQ3c/cHdkPWJsaHg=">全角色下载<i class="fa fa-external-link-alt"></i></span>, 提取码: <code>blhx</code>.</li>
</ul>
<p>如果 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL0Rlc2t0b3BTcHJpdGUvcmVsZWFzZXM=">Release<i class="fa fa-external-link-alt"></i></span> 界面进不去 (可能需要魔法才能访问), 这里贴一下程序的网盘链接.</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMXZERnIwS1lSa25EakdESDFIYUVYNmc/cHdkPWJsaHg=">安装包 - 百度网盘<i class="fa fa-external-link-alt"></i></span>, 提取码: <code>blhx</code>.</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMVR4c3ZIYmsyVFZqbHZ2OUx2LUM3eWc/cHdkPWJsaHg=">免安装 - 百度网盘<i class="fa fa-external-link-alt"></i></span>, 提取码: <code>blhx</code>.</li>
<li><span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9peUtXZTE3NGNycmU=">安装包 - 蓝奏云<i class="fa fa-external-link-alt"></i></span>.</li>
<li><span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pRlVNTDE3NGNybGk=">免安装 - 蓝奏云<i class="fa fa-external-link-alt"></i></span>.</li>
</ul>
]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>桌宠</tag>
        <tag>碧蓝航线</tag>
        <tag>Spine</tag>
      </tags>
  </entry>
  <entry>
    <title>对话情绪检测</title>
    <url>//posts/2021/09/11/emodetection/</url>
    <content><![CDATA[<p>本篇是大三时自然语言处理课程的大作业, 题目选了 &quot;对话情绪检测&quot; (Emotion Detection in Conversations), 目标是对对话中的每个句子进行情绪的分类，以此来识别说话者当时的情绪.</p>
<p>本文整理一下自己的课程报告内容, 并将代码整理至 Github 上, 文末附有项目地址.</p>
<span id="more"></span>

<h2 id="软硬件环境"><a href="#软硬件环境" class="headerlink" title="软硬件环境"></a>软硬件环境</h2><p>软件: <code>python 3.7</code>, <code>pytorch 1.6.0</code>, <code>pytorch-nlp</code></p>
<p>硬件: <code>GeForce RTX 2080 Ti</code></p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>使用的数据集为 <span class="exturl" data-url="aHR0cDovL3lhbnJhbi5saS9kYWlseWRpYWxvZw==">DailyDialog<i class="fa fa-external-link-alt"></i></span> 对话数据集, 在这里我们只用到对话文本数据和情绪标签文件.</p>
<p>对话数据为多行文本, 每一行是一段对话, 每一句话用 <code>__eou__</code> 作为结束符. 每一段对话只有两个说话人, 且交替出现.</p>
<p>在标签文件中, 每一行与对话数据一一对应, 但是每句话换成标签值, 取值范围 0-6, 共7种不同的情绪类别.</p>
<h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><p>模型设计主要参考论文: <span class="exturl" data-url="aHR0cHM6Ly9kb2kub3JnLzEwLjE2MDkvYWFhaS52MzNpMDEuMzMwMTY4MTg=">DialogueRNN: An Attentive RNN for Emotion Detection in Conversations<i class="fa fa-external-link-alt"></i></span>.</p>
<p>整个网络大致分为特征提取和情绪分类两部分.</p>
<h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>首先是文本的嵌入表示, 使用 <code>GloVe</code> 预训练词向量来转换原始文本, 词向量维度大小为 300.</p>
<p>在使用预训练词向量之后, 对于每段对话中的每个发言, 采用 <code>BiLSTM</code> 进行语义提取, 取正向和反向的最后时刻输出拼接在一起, 最终将每句话转换为等长向量.</p>
<h3 id="情绪检测"><a href="#情绪检测" class="headerlink" title="情绪检测"></a>情绪检测</h3><p>这一部分存在 4 个状态变量:</p>
<ul>
<li>全局上下文信息: 用于记录当前对话的进行位置以及对话的整个历史信息.</li>
<li>两个说话人状态: 用于记录每个说话人在最新发言之前的状态.</li>
<li>情绪状态: 用于记录最近一次发言的情绪状态, 用于输出每句话的情绪向量表达.</li>
</ul>
<p>整个结构可以用下图表示:</p>
<p><img data-src="/static/image/emodetection/detection_model.jpg" alt="detection_model"></p>
<p>其中 $U_t$ 就是每一句话, $t$ 代表时刻.</p>
<p>注意力结构使用了简单的乘性注意力, 具体可以看代码, 就是求点积然后 softmax.</p>
<p>最后将每个句子对应的 $E_t$ 放进线性层进行分类.</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>最终的训练参数如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Namespace(</span><br><span class="line">   batch_size=<span class="number">16</span>, </span><br><span class="line">   embedding_size=<span class="number">300</span>, </span><br><span class="line">   lstm_size=<span class="number">256</span>, </span><br><span class="line">   hidden_size=<span class="number">256</span>, </span><br><span class="line">   learning_rate=<span class="number">0.001</span>, </span><br><span class="line">   epochs=<span class="number">50</span>, </span><br><span class="line">   seed=<span class="number">1</span>, </span><br><span class="line">   istrain=<span class="literal">True</span>, </span><br><span class="line">   dev_data_path=<span class="string">&#x27;./data/Emotion Detection in Conversations/validation/dialogues_validation.txt&#x27;</span>, </span><br><span class="line">   dev_label_path=<span class="string">&#x27;./data/Emotion Detection in Conversations/validation/dialogues_emotion_validation.txt&#x27;</span>, </span><br><span class="line">   model_save_path=<span class="string">&#x27;attn.pt&#x27;</span>, </span><br><span class="line">   test_data_path=<span class="string">&#x27;./data/Emotion Detection in Conversations/test/dialogues_test.txt&#x27;</span>, </span><br><span class="line">   test_label_path=<span class="string">&#x27;./data/Emotion Detection in Conversations/test/dialogues_emotion_test.txt&#x27;</span>, </span><br><span class="line">   train_data_path=<span class="string">&#x27;./data/Emotion Detection in Conversations/train/dialogues_train.txt&#x27;</span>, </span><br><span class="line">   train_label_path=<span class="string">&#x27;./data/Emotion Detection in Conversations/train/dialogues_emotion_train.txt&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>在测试集上的结果如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0       0.91      0.91      0.91      6321</span><br><span class="line">           1       0.43      0.25      0.31       118</span><br><span class="line">           2       0.46      0.23      0.31        47</span><br><span class="line">           3       0.71      0.29      0.42        17</span><br><span class="line">           4       0.60      0.62      0.61      1019</span><br><span class="line">           5       0.28      0.27      0.28       102</span><br><span class="line">           6       0.48      0.43      0.45       116</span><br><span class="line"></span><br><span class="line">    accuracy                           0.84      7740</span><br><span class="line">   macro avg       0.55      0.43      0.47      7740</span><br><span class="line">weighted avg       0.84      0.84      0.84      7740</span><br></pre></td></tr></table></figure>

<p>咋说呢, 调过很多参数了, 但是效果都不是很好, 个人感觉是数据集太小了, 样本数不够, 或者是炼丹手法不行, 有哪里不对, 看人家论文里也不是特别高就是了. <del>教辅说可能就是这个任务不适合深度学习, 但是我觉得数据量管够啥都能深度学习.</del></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>作为一个结课作业项目, 没有太多创新之处, 只是复现了一下论文里的模型结构, 然后在不同的数据集上做了实验, 效果说不上多好.</p>
<p>主要收获就是增强动手能力吧, 毕竟是纯手搓的网络代码, 让自己能更加熟悉一些基础网络结构和 <code>pytorch</code> 框架的使用方法.</p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p>项目地址: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL0Vtb3Rpb24tRGV0ZWN0aW9uLWluLUNvbnZlcnNhdGlvbnM=">Emotion Detection in Conversations<i class="fa fa-external-link-alt"></i></span></p>
<p>参考论文: <span class="exturl" data-url="aHR0cHM6Ly9kb2kub3JnLzEwLjE2MDkvYWFhaS52MzNpMDEuMzMwMTY4MTg=">DialogueRNN: An Attentive RNN for Emotion Detection in Conversations<i class="fa fa-external-link-alt"></i></span></p>
<p>数据集地址: <span class="exturl" data-url="aHR0cDovL3lhbnJhbi5saS9kYWlseWRpYWxvZw==">DailyDialog<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>情绪检测</tag>
        <tag>nlp</tag>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>国密算法的纯 Python 实现</title>
    <url>//posts/2023/12/14/gmalg/</url>
    <content><![CDATA[<p>近期花了点时间学习国密算法, 并且按国标文档用纯 Python 实现了一个小的国密算法库, 这里贴一下项目的简介和用法.</p>
<p>Github 地址: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL2dtYWxn">https://github.com/ww-rm/gmalg<i class="fa fa-external-link-alt"></i></span></p>
<span id="more"></span>

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight bat"><table><tr><td class="code"><pre><span class="line">pip install gmalg</span><br></pre></td></tr></table></figure>

<h2 id="实现的核心算法"><a href="#实现的核心算法" class="headerlink" title="实现的核心算法"></a>实现的核心算法</h2><ul>
<li>祖冲之序列密码算法</li>
<li>SM2 椭圆曲线公钥密码算法<ul>
<li>签名验签</li>
<li>密钥交换</li>
<li>加密解密</li>
</ul>
</li>
<li>SM3 密码杂凑算法</li>
<li>SM4 分组密码算法</li>
<li>SM9 标识密码算法<ul>
<li>签名验签</li>
<li>密钥交换</li>
<li>密钥封装</li>
<li>加密解密</li>
</ul>
</li>
</ul>
<h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><h3 id="ZUC-生成伪随机密钥流"><a href="#ZUC-生成伪随机密钥流" class="headerlink" title="ZUC 生成伪随机密钥流"></a>ZUC 生成伪随机密钥流</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">zuc = gmalg.ZUC(<span class="built_in">bytes</span>.fromhex(<span class="string">&quot;3d4c4be96a82fdaeb58f641db17b455b&quot;</span>),</span><br><span class="line">                <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;84319aa8de6915ca1f6bda6bfbd8c766&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(zuc.generate().<span class="built_in">hex</span>())</span><br><span class="line"><span class="built_in">print</span>(zuc.generate().<span class="built_in">hex</span>())</span><br></pre></td></tr></table></figure>

<h3 id="SM3-计算哈希值"><a href="#SM3-计算哈希值" class="headerlink" title="SM3 计算哈希值"></a>SM3 计算哈希值</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">sm3 = gmalg.SM3()</span><br><span class="line"><span class="built_in">print</span>(sm3.value().<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line">sm3.update(<span class="string">b&quot;I&#x27;m SM3 algorithm.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(sm3.value().<span class="built_in">hex</span>())</span><br></pre></td></tr></table></figure>

<h3 id="SM4-加密-解密"><a href="#SM4-加密-解密" class="headerlink" title="SM4 加密/解密"></a>SM4 加密/解密</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">sm4 = gmalg.SM4(<span class="built_in">bytes</span>.fromhex(<span class="string">&quot;0123456789ABCDEFFEDCBA9876543210&quot;</span>))</span><br><span class="line">cipher = sm4.encrypt(<span class="string">b&quot;0102030405060708&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cipher.<span class="built_in">hex</span>())</span><br><span class="line"><span class="built_in">print</span>(sm4.decrypt(cipher))</span><br></pre></td></tr></table></figure>

<h3 id="SM2-签名-验签"><a href="#SM2-签名-验签" class="headerlink" title="SM2 签名/验签"></a>SM2 签名/验签</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">sm2 = gmalg.SM2(</span><br><span class="line">    <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;3945208F 7B2144B1 3F36E38A C6D39F95 88939369 2860B51A 42FB81EF 4DF7C5B8&quot;</span>),</span><br><span class="line">    <span class="string">b&quot;1234567812345678&quot;</span>,</span><br><span class="line">    <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;04 09F9DF31 1E5421A1 50DD7D16 1E4BC5C6 72179FAD 1833FC07 6BB08FF3 56F35020&quot;</span></span><br><span class="line">                  <span class="string">&quot;CCEA490C E26775A5 2DC6EA71 8CC1AA60 0AED05FB F35E084A 6632F607 2DA9AD13&quot;</span>),</span><br><span class="line">)</span><br><span class="line">msg = <span class="string">b&quot;I&#x27;m SM2 sign/verify algorithm.&quot;</span></span><br><span class="line">r, s = sm2.sign(msg)</span><br><span class="line"><span class="built_in">print</span>(r.<span class="built_in">hex</span>())</span><br><span class="line"><span class="built_in">print</span>(s.<span class="built_in">hex</span>())</span><br><span class="line"><span class="built_in">print</span>(sm2.verify(msg, r, s))</span><br></pre></td></tr></table></figure>

<h3 id="SM2-加密-解密"><a href="#SM2-加密-解密" class="headerlink" title="SM2 加密/解密"></a>SM2 加密/解密</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">sm2 = gmalg.SM2(</span><br><span class="line">    <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;3945208F 7B2144B1 3F36E38A C6D39F95 88939369 2860B51A 42FB81EF 4DF7C5B8&quot;</span>),</span><br><span class="line">    P=<span class="built_in">bytes</span>.fromhex(<span class="string">&quot;04 09F9DF31 1E5421A1 50DD7D16 1E4BC5C6 72179FAD 1833FC07 6BB08FF3 56F35020&quot;</span></span><br><span class="line">                    <span class="string">&quot;CCEA490C E26775A5 2DC6EA71 8CC1AA60 0AED05FB F35E084A 6632F607 2DA9AD13&quot;</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cipher = sm2.encrypt(<span class="string">b&quot;I&#x27;m SM2 encrypt/decrypt algorithm.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cipher.<span class="built_in">hex</span>())</span><br><span class="line"><span class="built_in">print</span>(sm2.decrypt(cipher))</span><br></pre></td></tr></table></figure>

<h3 id="SM2-密钥交换"><a href="#SM2-密钥交换" class="headerlink" title="SM2 密钥交换"></a>SM2 密钥交换</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">PA = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;04 160E1289 7DF4EDB6 1DD812FE B96748FB D3CCF4FF E26AA6F6 DB9540AF 49C94232&quot;</span></span><br><span class="line">                   <span class="string">&quot;4A7DAD08 BB9A4595 31694BEB 20AA489D 6649975E 1BFCF8C4 741B78B4 B223007F&quot;</span>)</span><br><span class="line">sm2A = gmalg.SM2(</span><br><span class="line">    <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;81EB26E9 41BB5AF1 6DF11649 5F906952 72AE2CD6 3D6C4AE1 678418BE 48230029&quot;</span>),</span><br><span class="line">    <span class="string">b&quot;abcdefghijklmnopqrstuvwxyz&quot;</span>, PA</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">PB = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;04 6AE848C5 7C53C7B1 B5FA99EB 2286AF07 8BA64C64 591B8B56 6F7357D5 76F16DFB&quot;</span></span><br><span class="line">                   <span class="string">&quot;EE489D77 1621A27B 36C5C799 2062E9CD 09A92643 86F3FBEA 54DFF693 05621C4D&quot;</span>)</span><br><span class="line">sm2B = gmalg.SM2(</span><br><span class="line">    <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;78512991 7D45A9EA 5437A593 56B82338 EAADDA6C EB199088 F14AE10D EFA229B5&quot;</span>),</span><br><span class="line">    <span class="string">b&quot;1234567812345678&quot;</span>, PB</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">RA, tA = sm2A.begin_key_exchange()</span><br><span class="line">RB, tB = sm2B.begin_key_exchange()</span><br><span class="line"></span><br><span class="line">KB = sm2B.end_key_exchange(<span class="number">16</span>, tB, RA, <span class="string">b&quot;abcdefghijklmnopqrstuvwxyz&quot;</span>, PA, gmalg.KEYXCHG_MODE.RESPONDER)</span><br><span class="line">KA = sm2A.end_key_exchange(<span class="number">16</span>, tA, RB, <span class="string">b&quot;1234567812345678&quot;</span>, PB, gmalg.KEYXCHG_MODE.INITIATOR)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(KA == KB)</span><br><span class="line"><span class="built_in">print</span>(KA.<span class="built_in">hex</span>())</span><br></pre></td></tr></table></figure>

<h3 id="SM9-签名-验签"><a href="#SM9-签名-验签" class="headerlink" title="SM9 签名/验签"></a>SM9 签名/验签</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">hid_s = <span class="string">b&quot;\x01&quot;</span></span><br><span class="line">msk_s = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;0130E7 8459D785 45CB54C5 87E02CF4 80CE0B66 340F319F 348A1D5B 1F2DC5F4&quot;</span>)</span><br><span class="line">mpk_s = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;04&quot;</span></span><br><span class="line">                      <span class="string">&quot;9F64080B 3084F733 E48AFF4B 41B56501 1CE0711C 5E392CFB 0AB1B679 1B94C408&quot;</span></span><br><span class="line">                      <span class="string">&quot;29DBA116 152D1F78 6CE843ED 24A3B573 414D2177 386A92DD 8F14D656 96EA5E32&quot;</span></span><br><span class="line">                      <span class="string">&quot;69850938 ABEA0112 B57329F4 47E3A0CB AD3E2FDB 1A77F335 E89E1408 D0EF1C25&quot;</span></span><br><span class="line">                      <span class="string">&quot;41E00A53 DDA532DA 1A7CE027 B7A46F74 1006E85F 5CDFF073 0E75C05F B4E3216D&quot;</span>)</span><br><span class="line">kgc = gmalg.SM9KGC(hid_s=hid_s, msk_s=msk_s, mpk_s=mpk_s)</span><br><span class="line"></span><br><span class="line">uid = <span class="string">b&quot;Alice&quot;</span></span><br><span class="line">sk_s = kgc.generate_sk_sign(uid)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sk_s.<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line">sm9 = gmalg.SM9(hid_s=hid_s, mpk_s=mpk_s, sk_s=sk_s, uid=uid)</span><br><span class="line"></span><br><span class="line">message = <span class="string">b&quot;Chinese IBS standard&quot;</span></span><br><span class="line">h, S = sm9.sign(message)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(h.<span class="built_in">hex</span>())</span><br><span class="line"><span class="built_in">print</span>(S.<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sm9.verify(message, h, S))</span><br></pre></td></tr></table></figure>

<h3 id="SM9-密钥交换"><a href="#SM9-密钥交换" class="headerlink" title="SM9 密钥交换"></a>SM9 密钥交换</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">hid_e = <span class="string">b&quot;\x02&quot;</span></span><br><span class="line">msk_e = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;02E65B 0762D042 F51F0D23 542B13ED 8CFA2E9A 0E720636 1E013A28 3905E31F&quot;</span>)</span><br><span class="line">mpk_e = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;04&quot;</span></span><br><span class="line">                      <span class="string">&quot;91745426 68E8F14A B273C094 5C3690C6 6E5DD096 78B86F73 4C435056 7ED06283&quot;</span></span><br><span class="line">                      <span class="string">&quot;54E598C6 BF749A3D ACC9FFFE DD9DB686 6C50457C FC7AA2A4 AD65C316 8FF74210&quot;</span>)</span><br><span class="line">kgc = gmalg.SM9KGC(hid_e=hid_e, msk_e=msk_e, mpk_e=mpk_e)</span><br><span class="line"></span><br><span class="line">uid_A = <span class="string">b&quot;Alice&quot;</span></span><br><span class="line">sk_e_A = kgc.generate_sk_encrypt(uid_A)</span><br><span class="line"><span class="built_in">print</span>(sk_e_A.<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line">uid_B = <span class="string">b&quot;Bob&quot;</span></span><br><span class="line">sk_e_B = kgc.generate_sk_encrypt(uid_B)</span><br><span class="line"><span class="built_in">print</span>(sk_e_B.<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line">sm9_A = gmalg.SM9(hid_e=hid_e, mpk_e=mpk_e, sk_e=sk_e_A, uid=uid_A)</span><br><span class="line">sm9_B = gmalg.SM9(hid_e=hid_e, mpk_e=mpk_e, sk_e=sk_e_B, uid=uid_B)</span><br><span class="line"></span><br><span class="line">rA, RA = sm9_A.begin_key_exchange(uid_B)</span><br><span class="line">rB, RB = sm9_B.begin_key_exchange(uid_A)</span><br><span class="line"></span><br><span class="line">KB = sm9_B.end_key_exchange(<span class="number">16</span>, rB, RB, uid_A, RA, gmalg.KEYXCHG_MODE.RESPONDER)</span><br><span class="line">KA = sm9_A.end_key_exchange(<span class="number">16</span>, rA, RA, uid_B, RB, gmalg.KEYXCHG_MODE.INITIATOR)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(KA == KB)</span><br><span class="line"><span class="built_in">print</span>(KA.<span class="built_in">hex</span>())</span><br></pre></td></tr></table></figure>

<h3 id="SM9-密钥封装"><a href="#SM9-密钥封装" class="headerlink" title="SM9 密钥封装"></a>SM9 密钥封装</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">hid_e = <span class="string">b&quot;\x03&quot;</span></span><br><span class="line">msk_e = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;01EDEE 3778F441 F8DEA3D9 FA0ACC4E 07EE36C9 3F9A0861 8AF4AD85 CEDE1C22&quot;</span>)</span><br><span class="line">mpk_e = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;04&quot;</span></span><br><span class="line">                      <span class="string">&quot;787ED7B8 A51F3AB8 4E0A6600 3F32DA5C 720B17EC A7137D39 ABC66E3C 80A892FF&quot;</span></span><br><span class="line">                      <span class="string">&quot;769DE617 91E5ADC4 B9FF85A3 1354900B 20287127 9A8C49DC 3F220F64 4C57A7B1&quot;</span>)</span><br><span class="line">kgc = gmalg.SM9KGC(hid_e=hid_e, msk_e=msk_e, mpk_e=mpk_e)</span><br><span class="line"></span><br><span class="line">uid = <span class="string">b&quot;Bob&quot;</span></span><br><span class="line"></span><br><span class="line">sk_e = kgc.generate_sk_encrypt(uid)</span><br><span class="line"><span class="built_in">print</span>(sk_e.<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line">sm9 = gmalg.SM9(hid_e=hid_e, mpk_e=mpk_e, sk_e=sk_e, uid=uid)</span><br><span class="line"></span><br><span class="line">K, C = sm9.encapsulate(<span class="number">32</span>, uid)  <span class="comment"># encapsulate key to self</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(K.<span class="built_in">hex</span>())</span><br><span class="line"><span class="built_in">print</span>(C.<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sm9.decapsulate(C, <span class="number">32</span>) == K)</span><br></pre></td></tr></table></figure>

<h3 id="SM9-加密-解密"><a href="#SM9-加密-解密" class="headerlink" title="SM9 加密/解密"></a>SM9 加密/解密</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmalg</span><br><span class="line"></span><br><span class="line">hid_e = <span class="string">b&quot;\x03&quot;</span></span><br><span class="line">msk_e = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;01EDEE 3778F441 F8DEA3D9 FA0ACC4E 07EE36C9 3F9A0861 8AF4AD85 CEDE1C22&quot;</span>)</span><br><span class="line">mpk_e = <span class="built_in">bytes</span>.fromhex(<span class="string">&quot;04&quot;</span></span><br><span class="line">                      <span class="string">&quot;787ED7B8 A51F3AB8 4E0A6600 3F32DA5C 720B17EC A7137D39 ABC66E3C 80A892FF&quot;</span></span><br><span class="line">                      <span class="string">&quot;769DE617 91E5ADC4 B9FF85A3 1354900B 20287127 9A8C49DC 3F220F64 4C57A7B1&quot;</span>)</span><br><span class="line">kgc = gmalg.SM9KGC(hid_e=hid_e, msk_e=msk_e, mpk_e=mpk_e)</span><br><span class="line"></span><br><span class="line">uid = <span class="string">b&quot;Bob&quot;</span></span><br><span class="line"></span><br><span class="line">sk_e = kgc.generate_sk_encrypt(uid)</span><br><span class="line"><span class="built_in">print</span>(sk_e.<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line">sm9 = gmalg.SM9(hid_e=hid_e, mpk_e=mpk_e, sk_e=sk_e, uid=uid)</span><br><span class="line"></span><br><span class="line">plain = <span class="string">b&quot;Chinese IBE standard&quot;</span></span><br><span class="line">cipher = sm9.encrypt(plain, uid)  <span class="comment"># encrypt data to self</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(cipher.<span class="built_in">hex</span>())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sm9.decrypt(cipher))</span><br></pre></td></tr></table></figure>

<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>其实大部分算法以前都接触过, 实现起来也比较简单, 但是 SM9 真的是第一次看, 里面的数学原理啥的一窍不通, 因此耗费了大量时间, 中途有很多地方都是卡在数学公式上, 对文档的描述理解有误, 导致调试了半天也不对, 之后总结一下在实现 SM9 中涉及的一些关键概念和坑点.</p>
]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>国密</tag>
        <tag>SM2</tag>
        <tag>SM3</tag>
        <tag>SM4</tag>
        <tag>SM9</tag>
        <tag>ZUC</tag>
        <tag>gmalg</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 C# 写一个哈希计算小工具</title>
    <url>//posts/2022/04/17/hashtool/</url>
    <content><![CDATA[<p>之前电脑上有一个用来计算文件哈希值的迷你小工具, 带界面能直接拖文件计算, 挺方便的. 正好最近闲着了, 于是想着自己仿造一个差不多的小工具, 顺便再补充一些缺少的哈希算法进去, 同时也能入门一下 <code>C#</code> 这门语言.</p>
<p>文末附有 Github 项目地址.</p>
<span id="more"></span>

<h2 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h2><p>环境选了 <code>.NET Framework 4.6</code> 及以上, 估计绝大部分 Windows 系统都已经自带了, 能直接运行软件.</p>
<h2 id="软件功能"><a href="#软件功能" class="headerlink" title="软件功能"></a>软件功能</h2><p>界面大概长这样:</p>
<p><img data-src="/static/image/hashtool/hashtool.png" alt="hashtool.png"></p>
<p>支持下列算法:</p>
<ul>
<li>MD5</li>
<li>SHA1</li>
<li>SHA2-256</li>
<li>SHA2-512</li>
<li>SHA3-256</li>
<li>SHA3-512</li>
<li>SM3</li>
<li>CRC32</li>
</ul>
<p>支持以下功能:</p>
<ul>
<li>拖动或者使用打开按钮对多个文件进行指定的哈希值计算</li>
<li>实时显示当前文件计算进度与总任务计算进度</li>
<li>可以指定计算文件哈希时是否对每个算法使用单独的线程进行加速</li>
</ul>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><h3 id="窗口界面"><a href="#窗口界面" class="headerlink" title="窗口界面"></a>窗口界面</h3><p>这是我第一次用 <code>C#</code> 写窗口程序, 学习了一下决定用 <code>WinForms</code> 这个框架, 因为作为入门程序来说, 它足够简单, 容易上手.</p>
<p>VS 新建一个 WinForms 项目, 项目结构不复杂, 有一个主程序文件和基本的窗口文件, 我们的主要任务就是补充窗口文件的代码.</p>
<p>思路也很简单, VS 提供了简单的窗口设计界面, 能够用键鼠直接设计窗口元素和窗口显示的内容, 然后我们自己写对应的事件响应函数, 并把对应的函数和响应事件在设计窗口里绑定即可.</p>
<p>这里将主窗口 <code>MainWnd</code> 的代码分作了两份:</p>
<ul>
<li><code>MainWnd.cs</code>: 实现事件响应函数.</li>
<li><code>MainWnd.Func.cs</code>: 实现主窗口真正要用到的计算功能函数.</li>
</ul>
<p>两份文件用 <code>partial</code> 类将功能组合到一起.</p>
<p>最后额外补充了一个 <code>About</code> 窗口, 在 VS 菜单里添加窗口就能直接生成需要的模板文件.</p>
<h3 id="多线程与进度条"><a href="#多线程与进度条" class="headerlink" title="多线程与进度条"></a>多线程与进度条</h3><p>作为一个窗口程序, 为了避免窗口响应卡死, 所有耗时的计算过程都必须用多线程的方式放到后台执行. 再就是程序支持用多线程并行多个算法之间的计算, 因此多线程的使用和同步问题是第一个麻烦之处.</p>
<p>第二个有点麻烦的地方就是显示进度条, 由于可以一次性计算多个文件, 所以分了当前文件进度和总进度, 在多线程时也是需要考虑同步问题的.</p>
<p>首先多线程用的 <code>System.Threading.Tasks.Task</code> 类, 这是自带封装好的多线程 API, 如果勾选了多线程选项, 那么就将每个算法的计算都分配一个 <code>Task</code>, 最后将结果汇总到一起.</p>
<p>有关的几个方法实现如下:</p>
<ul>
<li><code>TaskCompHash</code>: 对指定文件计算指定哈希算法的结果, 并累加计算进度值.</li>
<li><code>ComputeWithOneTask</code> 和 <code>ComputeWithMultiTask</code>: 每个文件的不同哈希算法计算任务. 两个方法都会创建子任务, 区别是前者每次只对 1 个算法创建 1 个任务计算, 后者根据算法数量创建多个同时计算. 然后轮询任务是否计算完成, 并更新进度条.</li>
<li><code>TaskCompute</code>: 对每个文件计算每一种哈希算法的值.</li>
<li><code>BeginCompute</code>: 创建后台计算任务, 创建完后立即返回, 不会使窗口假死.</li>
</ul>
<p>调用关系为:</p>
<p><code>BeginCompute</code> -&gt; <code>TaskCompute</code> -&gt; <code>ComputeWithOneTask | ComputeWithMultiTask</code> -&gt; <code>TaskCompHash</code></p>
<p>其中 <code>Task</code> 开头的是要被 <code>Task</code> 类创建以多线程方式在后台执行的方法. 如此一来便完成了对每个文件的每种哈希值的计算过程.</p>
<p>而进度条的实现, 则是靠 <code>pbValueSingle</code> 和 <code>pbValueTotal</code> 两个成员来记录. 每次使用哈希算法计算时, 累加计算量相对于文件大小的百分比值, 这样对于一个文件的一种算法就有一个完整的单位 1, 所以总计算量就是文件数乘以算法数.</p>
<h3 id="哈希算法实现"><a href="#哈希算法实现" class="headerlink" title="哈希算法实现"></a>哈希算法实现</h3><p><code>C#</code> 的系统库里已经提供了大部分常见的哈希算法, 都在 <code>System.Security.Cryptography</code> 命名空间中, 我们需要额外实现一下SM3 和 SHA3 等算法.</p>
<p>具体的算法原理另写一篇记录, 这里主要看看实现思路.</p>
<p>查阅一下 API 文档, 可以看到 <code>System.Security.Cryptography</code> 提供了一个哈希算法的基类 <code>HashAlgorithm</code> 给我们用来继承, 并且需要重写下列方法:</p>
<ul>
<li><code>Initialize</code>: 初始化方法, 也就是计算一个哈希的初始准备工作, 例如一些缓冲区的初始值可以在这里设置.</li>
<li><code>HashCore</code>: 核心计算过程, 有三个参数, 接收任意长度的字节数组输入, 并完成这一部分内容的计算. 这个方法可以完成对大文件的分块哈希值计算.</li>
<li><code>HashFinal</code>: 结束计算方法, 比如一些尾部填充操作可以在这里进行.</li>
</ul>
<p>继承并重写后, 我们的哈希算法就有统一的基类和接口, 这也方便我们后续的方法调用.</p>
<h3 id="编译与发布"><a href="#编译与发布" class="headerlink" title="编译与发布"></a>编译与发布</h3><p>编译的方式和普通项目一样, 在菜单的 &quot;生成&quot; 项里进行生成即可.</p>
<p>值得关注的是生成时的配置, 右键查看项目属性, 里面可以设置目标框架, 如果考虑兼容性, 选低一点比较好, 这里我选了 4.6 的版本.</p>
<p>再就是生成里可以设置目标平台, 尽量选成 <code>x64</code>, 速度上有一些小的优化.</p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p>Github 项目地址: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL0hhc2h0b29s">https://github.com/ww-rm/Hashtool<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>hashtool</tag>
        <tag>C#</tag>
        <tag>winforms</tag>
      </tags>
  </entry>
  <entry>
    <title>NCM 文件批量转换 (保留专辑和封面信息)</title>
    <url>//posts/2023/11/04/ncmdump/</url>
    <content><![CDATA[<p>这段时间打算用网易云音乐囤点资源, 但是下载之后才发现内容已经全部加密, 变成了 <code>ncm</code> 后缀的文件. 搜索一番, 找到了一些现成的转换工具和源码. 但是功能都十分有限, 而且转换出来之后的文件都没有专辑和封面信息<del>强迫症大怒</del>. 看了看有关的分析和源码之后, 决定自己重新整理一下转换功能, 并且把专辑和封面信息也加进去, 做个完善的命令行工具自用, 顺便打包成 Python 库, 上传到 PyPI 上.</p>
<p>本文包括以下内容, 首先整理一下网上已有的 <code>ncm</code> 格式转换代码, 然后增加补充专辑和封面信息的功能, 并实现批量转换和界面友好, 最后打包成二进制文件和 Python 库, 并上传到 PyPI 上.</p>
<p>文末附有项目的 Github 地址, 以及使用 PyInstaller 打包的二进制文件下载地址和 PyPI 项目地址.</p>
<span id="more"></span>

<h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><p>安装:</p>
<p><code>pip install ncmdump-py</code></p>
<p>命令行使用:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m ncmdump [-h] [--in-folder IN_FOLDER] [--out-folder OUT_FOLDER] [--dump-metadata] [--dump-cover] [files ...]</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">usage: ncmdump [-h] [--in-folder IN_FOLDER] [--out-folder OUT_FOLDER] [--dump-metadata] [--dump-cover] [files ...]</span><br><span class="line"></span><br><span class="line">Dump ncm files with progress bar and logging info, only process files with suffix &#x27;.ncm&#x27;</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  files                 Files to dump, can follow multiple files.</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  --in-folder IN_FOLDER</span><br><span class="line">                        Input folder of files to dump.</span><br><span class="line">  --out-folder OUT_FOLDER</span><br><span class="line">                        Output folder of files dumped.</span><br><span class="line">  --dump-metadata       Whether dump metadata.</span><br><span class="line">  --dump-cover          Whether dump album cover.</span><br></pre></td></tr></table></figure>

<p>导入代码使用:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> ncmdump <span class="keyword">import</span> NeteaseCloudMusicFile</span><br><span class="line"></span><br><span class="line">ncmfile = NeteaseCloudMusicFile(<span class="string">&quot;filename.ncm&quot;</span>)</span><br><span class="line">ncmfile.decrypt()</span><br><span class="line"></span><br><span class="line">ncmfile.dump_music(<span class="string">&quot;filename.mp3&quot;</span>)  <span class="comment"># auto detect correct suffix</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Maybe you need metadata or cover image</span></span><br><span class="line"><span class="comment"># ncmfile.dump_metadata(&quot;filename.json&quot;)  </span></span><br><span class="line"><span class="comment"># ncmfile.dump_cover(&quot;filename.jpeg&quot;)</span></span><br></pre></td></tr></table></figure>

<h2 id="NCM-格式分析"><a href="#NCM-格式分析" class="headerlink" title="NCM 格式分析"></a>NCM 格式分析</h2><p>Github 上搜 <code>ncmdump</code>, 有很多现成的项目, 通过源码和自己尝试后总结一下 <code>ncm</code> 格式如下表:</p>
<table>
<thead>
<tr>
<th align="center">字段</th>
<th align="center">长度</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>MAGIC_HEADER</code></td>
<td align="center">8 字节</td>
<td align="center">ncm 文件的文件头标识, 内容为 <code>b&quot;CTENFDAM&quot;</code></td>
</tr>
<tr>
<td align="center"><code>gap1</code></td>
<td align="center">2 字节</td>
<td align="center">不确定, 据观察所有的文件都相同, 为 <code>b&quot;\x01\x61&quot;</code>, 猜测也是文件头一部分</td>
</tr>
<tr>
<td align="center"><code>rc4_key_enc_size</code></td>
<td align="center">4 字节</td>
<td align="center"><code>int</code> 整数</td>
</tr>
<tr>
<td align="center"><code>rc4_key_enc</code></td>
<td align="center"><code>rc4_key_enc_size</code></td>
<td align="center">加密后的 RC4 算法密钥</td>
</tr>
<tr>
<td align="center"><code>metadata_enc_size</code></td>
<td align="center">4 字节</td>
<td align="center"><code>int</code> 整数</td>
</tr>
<tr>
<td align="center"><code>metadata_enc</code></td>
<td align="center"><code>metadata_enc_size</code></td>
<td align="center">加密后的 <code>metadata</code>, 包含音乐的专辑和封面信息</td>
</tr>
<tr>
<td align="center"><code>crc32</code></td>
<td align="center">4 字节</td>
<td align="center">不确定, 据网上流传为 CRC32 校验码, 但是没找到是算哪个值的</td>
</tr>
<tr>
<td align="center"><code>gap2</code></td>
<td align="center">5 字节</td>
<td align="center">不确定, 据观察都为 <code>b&quot;\x01&quot;</code> 开头, <code>b&quot;\x00&quot;</code> 结尾</td>
</tr>
<tr>
<td align="center"><code>cover_data_size</code></td>
<td align="center">4 字节</td>
<td align="center"><code>int</code> 整数</td>
</tr>
<tr>
<td align="center"><code>cover_data</code></td>
<td align="center"><code>cover_data_size</code></td>
<td align="center">专辑封面图片二进制数据</td>
</tr>
<tr>
<td align="center"><code>music_data_enc</code></td>
<td align="center">任意长度</td>
<td align="center">加密后的音乐二进制数据, 处于 <code>ncm</code> 文件的最末尾</td>
</tr>
</tbody></table>
<p>格式很清晰, 虽然有一些未知项, 但是不影响核心内容. 其中 <code>rc4_key_enc</code>, <code>metadata_enc</code>, <code>music_data_enc</code> 是加密过的, 只要全部解密就能还原出原本完整的音乐文件.</p>
<h2 id="NCM-文件解密"><a href="#NCM-文件解密" class="headerlink" title="NCM 文件解密"></a>NCM 文件解密</h2><p>这部分内容也是总结已有的源码.</p>
<p><code>ncm</code> 文件中使用了两种密码算法:</p>
<ul>
<li>一种是经过魔改的 <code>RC4</code> 算法, 后文称它为 <code>NCMRC4</code></li>
<li>另一种是标准的 <code>AES</code> 算法, 分组长度 <code>128</code> 比特, 工作模式 <code>ECB</code>, 填充算法为 <code>PKCS7</code>, 后文称它为 <code>NCMAES</code></li>
</ul>
<p><code>ncm</code> 文件的加密方式如下:</p>
<ul>
<li><code>music_data_enc = NCMRC4.encrypt(music_data, rc4_key)</code></li>
<li><code>metadata_enc = NCMAES.encrypt(metadata_enc, AES_KEY_METADATA)</code></li>
<li><code>rc4_key_enc = NCMAES.encrypt(rc4_key, AES_KEY_RC4_KEY)</code></li>
</ul>
<p>较大的 <code>music_data</code> 用魔改后的流密码加密, 节省时间; 较短的 <code>metadata</code> 和 <code>rc4_key</code> 用对称密码加密, 提高安全性.</p>
<p>这里 <code>AES_KEY_RC4_KEY</code> 和 <code>AES_KEY_METADATA</code> 是两个关键的对称密码密钥, 前人已经通过逆向等手段挖出来了, 这里就不放出来了, 可以去看看别人的分析或者看本文的源码, 里面都有.</p>
<p>除了使用加密手段, 还有一些简单的混淆操作, 以及去除解密后内容多余的头部字段等, 这里也不详细写了, 源码里面写的很清楚, 可以直接看源码.</p>
<h2 id="添加专辑和封面信息"><a href="#添加专辑和封面信息" class="headerlink" title="添加专辑和封面信息"></a>添加专辑和封面信息</h2><p>来到本文的重点部分, 前面对 <code>ncm</code> 格式和加密方式的分析都是已有的, 我们主要想扩展功能, 自动添加专辑和封面信息到解密后的文件里, 这里主要用到 <code>mutagen</code> 这个库, 支持向 <code>mp3</code> 和 <code>flac</code> 文件内加入专辑等信息.</p>
<p>解密后的 <code>metadata</code> 是一份 <code>json</code> 数据, 格式如下:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;format&quot;</span><span class="punctuation">:</span> <span class="string">&quot;flac&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;musicId&quot;</span><span class="punctuation">:</span> <span class="number">431259256</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;musicName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;カタオモイ&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">[</span><span class="string">&quot;Aimer&quot;</span><span class="punctuation">,</span> <span class="number">16152</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;album&quot;</span><span class="punctuation">:</span> <span class="string">&quot;daydream&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;albumId&quot;</span><span class="punctuation">:</span> <span class="number">34826361</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;albumPicDocId&quot;</span><span class="punctuation">:</span> <span class="number">109951165052089697</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;albumPic&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://p1.music.126.net/2QRYxUqXfW0zQpm2_DVYRA==/109951165052089697.jpg&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;mvId&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;flag&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;bitrate&quot;</span><span class="punctuation">:</span> <span class="number">876923</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;duration&quot;</span><span class="punctuation">:</span> <span class="number">207866</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;alias&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;transNames&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;单相思&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<details class="note info"><summary><p>v1.1.0 中的改动</p>
</summary>
<p><code>metadata</code> 可能存在多种类型, 上面是最简单的 <code>music</code> 类型, 新增了 <code>dj</code> 类型, 格式如下:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;programId&quot;</span><span class="punctuation">:</span> <span class="number">2506516081</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;programName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;03 踏遍万水千山&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;mainMusic&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;musicId&quot;</span><span class="punctuation">:</span> <span class="number">1957438579</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;musicName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;03 踏遍万水千山&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;album&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[DJ节目]北方文艺出版社的DJ节目 第8期&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;albumId&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;albumPicDocId&quot;</span><span class="punctuation">:</span> <span class="number">109951167551086981</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;albumPic&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://p1.music.126.net/M48NPuT591tIqqUdQyKZlg==/109951167551086981.jpg&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;mvId&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;flag&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;bitrate&quot;</span><span class="punctuation">:</span> <span class="number">320000</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;duration&quot;</span><span class="punctuation">:</span> <span class="number">1222948</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;alias&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;transNames&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;djId&quot;</span><span class="punctuation">:</span> <span class="number">7891086863</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;djName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;北方文艺出版社&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;djAvatarUrl&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://p1.music.126.net/DQr2q_S23tYY8vU_C-kAYw==/109951167535553901.jpg&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;createTime&quot;</span><span class="punctuation">:</span> <span class="number">1655691020376</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;brand&quot;</span><span class="punctuation">:</span> <span class="string">&quot;林徽因传：倾我所能去坚强&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;serial&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;programDesc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;这是一本有温度、有态度的传记，记录了真正意义上的民国女神——林徽因，从容坚强、传奇丰沛的一生。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;programFeeType&quot;</span><span class="punctuation">:</span> <span class="number">15</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;programBuyed&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioId&quot;</span><span class="punctuation">:</span> <span class="number">977264730</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;林徽因传：倾我所能去坚强&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioCategory&quot;</span><span class="punctuation">:</span> <span class="string">&quot;文学出版&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioCategoryId&quot;</span><span class="punctuation">:</span> <span class="number">3148096</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioDesc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;这是一本有温度、有态度的传记，记录了真正意义上的民国女神——林徽因，从容坚强、传奇丰沛的一生。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioFeeType&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioFeeScope&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioBuyed&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioPrice&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;radioPurchaseCount&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
</details>

<p>我们需要把 <code>musicName</code>, <code>artist</code>, <code>album</code> 这三个字段的内容保留, 同时把 <code>ncm</code> 中附带的封面图片也保留.</p>
<p>我们导入一下要用到的库:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> mutagen <span class="keyword">import</span> flac, id3, mp3</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br></pre></td></tr></table></figure>

<p>对于 <code>mp3</code>, 如下操作:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_addinfo_mp3</span>(<span class="params">self, path: <span class="type">Union</span>[<span class="built_in">str</span>, PathLike]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Add info for mp3 format.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    audio = mp3.MP3(path)</span><br><span class="line"></span><br><span class="line">    audio[<span class="string">&quot;TIT2&quot;</span>] = id3.TIT2(text=self.name, encoding=id3.Encoding.UTF8)  <span class="comment"># title</span></span><br><span class="line">    audio[<span class="string">&quot;TALB&quot;</span>] = id3.TALB(text=self.album, encoding=id3.Encoding.UTF8)  <span class="comment"># album</span></span><br><span class="line">    audio[<span class="string">&quot;TPE1&quot;</span>] = id3.TPE1(text=<span class="string">&quot;/&quot;</span>.join(self.artists), encoding=id3.Encoding.UTF8)  <span class="comment"># artists</span></span><br><span class="line">    audio[<span class="string">&quot;TPE2&quot;</span>] = id3.TPE2(text=<span class="string">&quot;/&quot;</span>.join(self.artists), encoding=id3.Encoding.UTF8)  <span class="comment"># album artists</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self._cover_data_size &gt; <span class="number">0</span>:</span><br><span class="line">        audio[<span class="string">&quot;APIC&quot;</span>] = id3.APIC(<span class="built_in">type</span>=id3.PictureType.COVER_FRONT, mime=self.cover_mime, data=self._cover_data)  <span class="comment"># cover</span></span><br><span class="line"></span><br><span class="line">    audio.save()</span><br></pre></td></tr></table></figure>

<p>这里 <code>cover_mime</code> 就是图像的内容类型, 例如 <code>image/jpeg</code> 这种, 可以通过 <code>mimetypes</code> 库获取.</p>
<p>而对于 <code>flac</code>, 如下操作:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_addinfo_flac</span>(<span class="params">self, path: <span class="type">Union</span>[<span class="built_in">str</span>, PathLike]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Add info for flac format.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    audio = flac.FLAC(path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add music info</span></span><br><span class="line">    audio[<span class="string">&quot;title&quot;</span>] = self.name</span><br><span class="line">    audio[<span class="string">&quot;artist&quot;</span>] = self.artists</span><br><span class="line">    audio[<span class="string">&quot;album&quot;</span>] = self.album</span><br><span class="line">    audio[<span class="string">&quot;albumartist&quot;</span>] = <span class="string">&quot;/&quot;</span>.join(self.artists)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add cover</span></span><br><span class="line">    <span class="keyword">if</span> self._cover_data_size &gt; <span class="number">0</span>:</span><br><span class="line">        cover = flac.Picture()</span><br><span class="line">        cover.<span class="built_in">type</span> = id3.PictureType.COVER_FRONT</span><br><span class="line">        cover.data = self._cover_data</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> BytesIO(self._cover_data) <span class="keyword">as</span> data:</span><br><span class="line">            <span class="keyword">with</span> Image.<span class="built_in">open</span>(data) <span class="keyword">as</span> f:</span><br><span class="line">                cover.mime = self.cover_mime</span><br><span class="line">                cover.width = f.width</span><br><span class="line">                cover.height = f.height</span><br><span class="line">                cover.depth = <span class="built_in">len</span>(f.getbands()) * <span class="number">8</span></span><br><span class="line"></span><br><span class="line">        audio.add_picture(cover)</span><br><span class="line"></span><br><span class="line">    audio.save()</span><br></pre></td></tr></table></figure>

<p>添加专辑封面图片的时候稍微复杂一点, 需要使用 <code>Pillow</code> 库读取一下图像的基本信息, 然后填进去.</p>
<p>值得注意的是, <code>ncm</code> 文件里可能没有存放专辑封面图片, 这种时候可以借助 <code>metadata</code> 里的 <code>albumPic</code> 字段, 它代表专辑封面图片的一个 url, 我们可以用 <code>urllib</code> 尝试联网获取内容, 代码片段如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># if no cover data, try get cover data by url in metadata</span></span><br><span class="line"><span class="keyword">if</span> self._cover_data_size &lt;= <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> request.urlopen(self._metadata.get(<span class="string">&quot;albumPic&quot;</span>, <span class="string">&quot;&quot;</span>)) <span class="keyword">as</span> res:</span><br><span class="line">            <span class="keyword">if</span> res.status &lt; <span class="number">400</span>:</span><br><span class="line">                self._cover_data = res.read()</span><br><span class="line">                self._cover_data_size = <span class="built_in">len</span>(self._cover_data)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>值得注意的是, 代码里需要判断, 如果最终就是没有办法获得图片数据, 那么就放弃添加图片信息, 避免报错.</p>
<h2 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h2><p>到这里, 我们的包目录结构长这样:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ncmdump</span><br><span class="line">  ├── core.py</span><br><span class="line">  ├── crypto.py</span><br><span class="line">  ├── __init__.py</span><br><span class="line">  └── __main__.py</span><br></pre></td></tr></table></figure>

<p>共有四份文件, 为了能够在命令行里运行这个包, 我们需要在 <code>__main__.py</code> 里添加一些内容.</p>
<p>这里我们使用 <code>ArgumentParser</code> 解析命令行输入, <code>rich</code> 库显示进度条和日志输出, 完整代码如下.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> rich.progress <span class="keyword">import</span> Progress, SpinnerColumn, TimeElapsedColumn</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ncmdump <span class="keyword">import</span> NeteaseCloudMusicFile</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    parser = ArgumentParser(<span class="string">&quot;ncmdump&quot;</span>, description=<span class="string">&quot;Dump ncm files with progress bar and logging info, only process files with suffix &#x27;.ncm&#x27;&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;files&quot;</span>, nargs=<span class="string">&quot;*&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Files to dump, can follow multiple files.&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--in-folder&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Input folder of files to dump.&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--out-folder&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Output folder of files dumped.&quot;</span>, default=<span class="string">&quot;.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--dump-metadata&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Whether dump metadata.&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--dump-cover&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Whether dump album cover.&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    out_folder = Path(args.out_folder)</span><br><span class="line">    out_folder.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    dump_metadata = args.dump_metadata</span><br><span class="line">    dump_cover = args.dump_cover</span><br><span class="line"></span><br><span class="line">    files = args.files</span><br><span class="line">    <span class="keyword">if</span> args.in_folder:</span><br><span class="line">        files.extend(Path(args.in_folder).iterdir())</span><br><span class="line">    files = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> p: p.suffix == <span class="string">&quot;.ncm&quot;</span>, <span class="built_in">map</span>(Path, files)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> files:</span><br><span class="line">        parser.print_help()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> Progress(SpinnerColumn(), *Progress.get_default_columns(), TimeElapsedColumn()) <span class="keyword">as</span> progress:</span><br><span class="line">            task = progress.add_task(<span class="string">&quot;[#d75f00]Dumping files&quot;</span>, total=<span class="built_in">len</span>(files))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> ncm_path <span class="keyword">in</span> files:</span><br><span class="line">                output_path = out_folder.joinpath(ncm_path.stem)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    ncmfile = NeteaseCloudMusicFile(ncm_path).decrypt()</span><br><span class="line">                    music_path = ncmfile.dump_music(output_path)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> dump_metadata:</span><br><span class="line">                        ncmfile.dump_metadata(output_path)</span><br><span class="line">                    <span class="keyword">if</span> dump_cover:</span><br><span class="line">                        ncmfile.dump_cover(output_path)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    progress.log(<span class="string">f&quot;[red]ERROR[/red]: <span class="subst">&#123;ncm_path&#125;</span> -&gt; <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> ncmfile.metadata:</span><br><span class="line">                        progress.log(<span class="string">f&quot;[yellow]WARNING[/yellow]: <span class="subst">&#123;ncm_path&#125;</span> -&gt; <span class="subst">&#123;music_path&#125;</span>, no metadata found&quot;</span>)</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> ncmfile.cover_data:</span><br><span class="line">                        progress.log(<span class="string">f&quot;[yellow]WARNING[/yellow]: <span class="subst">&#123;ncm_path&#125;</span> -&gt; <span class="subst">&#123;music_path&#125;</span>, no cover data found&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">finally</span>:</span><br><span class="line">                    progress.advance(task)</span><br></pre></td></tr></table></figure>

<p>该命令行可以接收若干数量的 <code>.ncm</code> 文件作为输入, 可以用 <code>--in-folder</code> 指定一整个文件夹, 会和输入的单个文件合并一起处理, 比如有下面几种使用示例.</p>
<figure class="highlight bat"><table><tr><td class="code"><pre><span class="line"><span class="comment">REM 指定某些文件</span></span><br><span class="line">python -m ncmdump file1.ncm file2.ncm</span><br></pre></td></tr></table></figure>

<figure class="highlight bat"><table><tr><td class="code"><pre><span class="line"><span class="comment">REM 指定一整个文件夹, 同时指定输出目录</span></span><br><span class="line">python -m ncmdump --<span class="keyword">in</span>-folder ncmfiles --out-folder musicfolder</span><br></pre></td></tr></table></figure>

<figure class="highlight bat"><table><tr><td class="code"><pre><span class="line"><span class="comment">REM 同时指定</span></span><br><span class="line">python -m ncmdump file1.ncm file2.ncm --<span class="keyword">in</span>-folder ncmfiles --out-folder musicfolder</span><br></pre></td></tr></table></figure>

<p>输出文件的文件名和原本的 <code>.ncm</code> 文件名相同, 但是后缀会自动替换成对应格式的后缀 (<code>.mp3</code> 或者 <code>.flac</code>).</p>
<h2 id="打包到-PyPI"><a href="#打包到-PyPI" class="headerlink" title="打包到 PyPI"></a>打包到 PyPI</h2><p>最后就是打包上传<del>造福大众的时间</del>, 这也是我第一次在 PyPI 上上传自己的包, 之后会单独写一篇文章说说中途遇到的一些问题.</p>
<p>上传完成之后, 就可以通过命令 <code>pip install ncmdump-py</code> 安装使用了~</p>
<p>PS: 虽然库名字叫 <code>ncmdump-py</code>, 但是导入的时候还是 <code>import ncmdump</code>, 因为 <code>ncmdump</code> 这个项目名字在 PyPI 上已经被前人注册了, 只好加点东西区分一下.</p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p>Github 地址: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL25jbWR1bXAtcHk=">https://github.com/ww-rm/ncmdump-py/<i class="fa fa-external-link-alt"></i></span></p>
<p>PyPI 项目页: <span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy9wcm9qZWN0L25jbWR1bXAtcHkv">https://pypi.org/project/ncmdump-py/<i class="fa fa-external-link-alt"></i></span></p>
<p>PyInstaller 打包的命令行工具: <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pdEdRcjFlemE1YWI=">ncmdump v1.1.0.zip<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>ncm</tag>
        <tag>格式转换</tag>
        <tag>ncmdump</tag>
        <tag>python 库</tag>
        <tag>PyPI</tag>
        <tag>网易云音乐</tag>
      </tags>
  </entry>
  <entry>
    <title>安卓 APK 重打包</title>
    <url>//posts/2024/07/09/apkrepack/</url>
    <content><![CDATA[<p>为了用 Simpleperf 在非 root 机上进行性能分析, 需要在 apk 的清单文件中设置 <code>android:debuggable=&quot;true&quot;</code> 的标记, 因此研究了一下怎么对 apk 进行重打包, 对修改后的包进行性能分析.</p>
<p>本文参考<span class="exturl" data-url="aHR0cHM6Ly9jcmlmYW4uZ2l0aHViLmlvL2FuZHJvaWRfcmVfcmVwYWNrX2Fway93ZWJzaXRlL3JlcGFja19wcm9jZXNzLw==">重新打包apk流程<i class="fa fa-external-link-alt"></i></span>.</p>
<span id="more"></span>

<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>重打包大概分成几个步骤:</p>
<ol>
<li>解包</li>
<li>修改包体</li>
<li>重打包</li>
<li>对齐</li>
<li>重签名</li>
</ol>
<p>顺序很重要, 签名的步骤一定是最后完成.</p>
<p>其中解包和重打包用 <span class="exturl" data-url="aHR0cHM6Ly9hcGt0b29sLm9yZy8=">apktool<i class="fa fa-external-link-alt"></i></span> 解决.</p>
<p>修改包体可以自己按需手动或者脚本修改.</p>
<p>对齐和重签名分别用 Android Sdk 的 build-tools 里的 <code>zipalign.exe</code> 和 <code>apksigner.jar</code> 完成.</p>
<p>上述提到的工具都可以通过 <code>--help</code> 查看用法, 比较简单.</p>
<p>值得一提的是重签名的时候需要用 java 自带的工具 <code>keytool</code> 生成一份自签名的证书文件, 可以用类似下面的命令生成:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">keytool -genkeypair -v -keystore repacker.keystore -keyalg RSA -keysize 4096 -validity 10000</span><br></pre></td></tr></table></figure>

<p>要填很多信息, 可以随便填, 比如都填 <code>repacker</code>, 最后输入 <code>y</code> 确认, 但是开头的口令可以怎么简单怎么来, 比如 <code>123456</code>.</p>
<h2 id="一键脚本"><a href="#一键脚本" class="headerlink" title="一键脚本"></a>一键脚本</h2><p>写了个一键重打包脚本, 并且可以选择增加调试标志.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> subprocess <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span>, <span class="type">Union</span></span><br><span class="line"><span class="keyword">from</span> xml.dom <span class="keyword">import</span> minidom</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DEFAULT_ANDROID_SDK_DIR = Path(os.getenv(<span class="string">&quot;LOCALAPPDATA&quot;</span>), <span class="string">&quot;Android&quot;</span>, <span class="string">&quot;Sdk&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_bin_path</span>(<span class="params">filename: <span class="built_in">str</span>, *extra_search_dirs: <span class="built_in">list</span>[os.PathLike]</span>) -&gt; <span class="type">Optional</span>[Path]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Try to find bin file in system path and return full file path.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    search_dirs = os.get_exec_path()</span><br><span class="line">    search_dirs.extend(extra_search_dirs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">map</span>(Path, search_dirs):</span><br><span class="line">        exec_path = p.joinpath(filename)</span><br><span class="line">        <span class="keyword">if</span> exec_path.is_file():</span><br><span class="line">            <span class="keyword">return</span> exec_path.resolve()</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AndroidSdkBuildTool</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tool_dir</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self._<span class="built_in">dir</span> = Path(tool_dir).resolve()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">version</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._<span class="built_in">dir</span>.name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">apksigner</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._<span class="built_in">dir</span>.joinpath(<span class="string">&quot;lib&quot;</span>, <span class="string">&quot;apksigner.jar&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">zipalign</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._<span class="built_in">dir</span>.joinpath(<span class="string">&quot;zipalign.exe&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AndroidSdk</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sdk_dir: os.PathLike</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self._<span class="built_in">dir</span> = Path(sdk_dir).resolve()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_build_tools</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> [AndroidSdkBuildTool(p) <span class="keyword">for</span> p <span class="keyword">in</span> self._<span class="built_in">dir</span>.joinpath(<span class="string">&quot;build-tools&quot;</span>).iterdir()]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AndroidManifest</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path: os.PathLike</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self._tree = minidom.parse(<span class="built_in">str</span>(path))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">enable_debuggable</span>(<span class="params">self, flag: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">        application_node = self._tree.getElementsByTagName(<span class="string">&quot;application&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">        application_node.setAttribute(<span class="string">&quot;android:debuggable&quot;</span>, (<span class="string">&quot;true&quot;</span> <span class="keyword">if</span> flag <span class="keyword">else</span> <span class="string">&quot;false&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, path: os.PathLike</span>):</span><br><span class="line">        path = Path(path)</span><br><span class="line">        path.write_bytes(self._tree.toxml(encoding=<span class="string">&quot;utf-8&quot;</span>, standalone=<span class="literal">False</span>))</span><br><span class="line">        <span class="keyword">return</span> path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">APKRepacker</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        *extra_bin_dirs,</span></span><br><span class="line"><span class="params">        android_sdk_dir: <span class="type">Optional</span>[Path] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        ks_file: <span class="type">Optional</span>[os.PathLike] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        ks_pwd: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> android_sdk_dir <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            android_sdk_dir = DEFAULT_ANDROID_SDK_DIR</span><br><span class="line">        self._java_path = find_bin_path(<span class="string">&quot;java.exe&quot;</span>, *extra_bin_dirs)</span><br><span class="line">        self._apktool_path = find_bin_path(<span class="string">&quot;apktool.jar&quot;</span>, *extra_bin_dirs)</span><br><span class="line">        self._android_sdk = AndroidSdk(android_sdk_dir)</span><br><span class="line">        self._android_build_tool = self._android_sdk.get_build_tools()[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        self._ks_file = <span class="literal">None</span> <span class="keyword">if</span> ks_file <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> Path(ks_file)</span><br><span class="line">        self._ks_pwd = ks_pwd</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_exec</span>(<span class="params">self, bin_path: os.PathLike, *args</span>):</span><br><span class="line">        args = [<span class="built_in">str</span>(Path(bin_path).resolve()), *<span class="built_in">map</span>(<span class="built_in">str</span>, args)]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Exec: <span class="subst">&#123;args&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> sp.run(args)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_exec_jar</span>(<span class="params">self, jar_path: os.PathLike, *args</span>):</span><br><span class="line">        <span class="keyword">return</span> self._<span class="built_in">exec</span>(self._java_path, <span class="string">&quot;-jar&quot;</span>, jar_path, args)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_executables</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;java: <span class="subst">&#123;self._java_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;apktool: <span class="subst">&#123;self._apktool_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;zipalign: <span class="subst">&#123;self._android_build_tool.zipalign&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;apksigner: <span class="subst">&#123;self._android_build_tool.apksigner&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">unpack</span>(<span class="params">self, apk_path: os.PathLike, output_dir: os.PathLike</span>):</span><br><span class="line">        self._exec_jar(self._apktool_path, <span class="string">&quot;-f&quot;</span>, <span class="string">&quot;d&quot;</span>, <span class="built_in">str</span>(apk_path), <span class="string">&quot;-o&quot;</span>, <span class="built_in">str</span>(output_dir))</span><br><span class="line">        <span class="keyword">return</span> Path(output_dir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pack</span>(<span class="params">self, apk_dir: os.PathLike, output_path: os.PathLike</span>):</span><br><span class="line">        self._exec_jar(self._apktool_path, <span class="string">&quot;-f&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="built_in">str</span>(apk_dir), <span class="string">&quot;-o&quot;</span>, <span class="built_in">str</span>(output_path))</span><br><span class="line">        <span class="keyword">return</span> Path(output_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">align</span>(<span class="params">self, apk_path: os.PathLike, output_path: os.PathLike</span>):</span><br><span class="line">        <span class="comment"># MUST use absolute path</span></span><br><span class="line">        apk_path = Path(apk_path).resolve()</span><br><span class="line">        output_path = Path(output_path).resolve()</span><br><span class="line">        self._<span class="built_in">exec</span>(self._android_build_tool.zipalign, <span class="string">&quot;-f&quot;</span>, <span class="string">&quot;-p&quot;</span>, <span class="string">&quot;4&quot;</span>, <span class="built_in">str</span>(apk_path), <span class="built_in">str</span>(output_path))</span><br><span class="line">        <span class="keyword">return</span> Path(output_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sign</span>(<span class="params">self, apk_path: os.PathLike, output_path: os.PathLike</span>):</span><br><span class="line">        <span class="keyword">if</span> self._ks_file <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> self._ks_pwd <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;apksigner needs ks file and ks password&quot;</span>)</span><br><span class="line"></span><br><span class="line">        p = sp.Popen(</span><br><span class="line">            [<span class="built_in">str</span>(self._java_path), <span class="string">&quot;-jar&quot;</span>,</span><br><span class="line">             <span class="built_in">str</span>(self._android_build_tool.apksigner), <span class="string">&quot;sign&quot;</span>,</span><br><span class="line">             <span class="string">&quot;--ks&quot;</span>, <span class="built_in">str</span>(self._ks_file), <span class="string">&quot;--out&quot;</span>, <span class="built_in">str</span>(output_path), <span class="built_in">str</span>(apk_path)],</span><br><span class="line">            stdin=sp.PIPE</span><br><span class="line">        )</span><br><span class="line">        sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="built_in">print</span>(self._ks_pwd, file=p.stdin, end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> Path(output_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_debuggable_flag</span>(<span class="params">self, apk_dir: os.PathLike</span>):</span><br><span class="line">        manifest_path = Path(apk_dir).joinpath(<span class="string">&quot;AndroidManifest.xml&quot;</span>)</span><br><span class="line">        manifest = AndroidManifest(manifest_path)</span><br><span class="line">        manifest.enable_debuggable(<span class="literal">True</span>)</span><br><span class="line">        manifest.save(manifest_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;-p&quot;</span>, <span class="string">&quot;--apk&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;要修改的 APK 文件路径&quot;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;-o&quot;</span>, <span class="string">&quot;--output&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;重新打包后 APK 的输出路径&quot;</span>, required=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--sdk-dir&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;Android Sdk 目录&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--extra-search-dir&quot;</span>, nargs=<span class="string">&quot;+&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;可执行文件或者 jar 包的额外搜索路径&quot;</span>, default=())</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--ks-file&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;keytool 生成的自签名证书文件&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--ks-pwd&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;ks 文件的口令&quot;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--enable-debuggable&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;在 AndroidManifest.xml 增加可调试标记&quot;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    tmp = Path(<span class="string">&quot;./tmp&quot;</span>).resolve()</span><br><span class="line">    tmp.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    repacker = APKRepacker(</span><br><span class="line">        *args.extra_search_dir,</span><br><span class="line">        android_sdk_dir=args.sdk_dir,</span><br><span class="line">        ks_file=args.ks_file,</span><br><span class="line">        ks_pwd=args.ks_pwd</span><br><span class="line">    )</span><br><span class="line">    repacker.print_executables()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apk paths and dirs</span></span><br><span class="line">    apk_path = Path(args.apk)</span><br><span class="line">    apk_name = apk_path.stem</span><br><span class="line">    apk_dir = tmp.joinpath(apk_name)</span><br><span class="line">    apk_repack_path = tmp.joinpath(<span class="string">f&quot;<span class="subst">&#123;apk_name&#125;</span>_repack.apk&quot;</span>)</span><br><span class="line">    apk_align_path = tmp.joinpath(<span class="string">f&quot;<span class="subst">&#123;apk_name&#125;</span>_align.apk&quot;</span>)</span><br><span class="line">    apk_output_path = Path(args.output)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># unpack apk to dir</span></span><br><span class="line">    repacker.unpack(apk_path, apk_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># do some modifications</span></span><br><span class="line">    <span class="keyword">if</span> args.enable_debuggable:</span><br><span class="line">        repacker.add_debuggable_flag(apk_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pack and resign</span></span><br><span class="line">    repacker.pack(apk_dir, apk_repack_path)</span><br><span class="line">    repacker.align(apk_repack_path, apk_align_path)</span><br><span class="line">    repacker.sign(apk_align_path, apk_output_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>会自动搜索本机上存在的可执行文件, 也可以提供额外的文件搜索路径.</p>
]]></content>
      <categories>
        <category>代码块</category>
      </categories>
      <tags>
        <tag>安卓</tag>
        <tag>APK</tag>
        <tag>重打包</tag>
      </tags>
  </entry>
  <entry>
    <title>碧蓝航线立绘提取与批量还原</title>
    <url>//posts/2023/04/11/blhx-painting/</url>
    <content><![CDATA[<p>因为网上没看到太好的核心步骤介绍和脚本, 所以自己造了一下轮子, 方便自己记录学习过程.</p>
<p>本文介绍碧蓝航线立绘提取和还原基本思路, 文末附有完整的批量还原 <code>python</code> 脚本.</p>
<span id="more"></span>

<h2 id="资源提取"><a href="#资源提取" class="headerlink" title="资源提取"></a>资源提取</h2><p>提取的方法网上很多, 不再赘述, 用 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlcmZhcmUvQXNzZXRTdHVkaW8vcmVsZWFzZXM=">AssetStudio<i class="fa fa-external-link-alt"></i></span> 导出安装包和热更新里的 <code>painting</code> 内容, 得到 里面的 <code>Mesh</code> 和 <code>Texture2D</code> 资源即可进行下一步还原.</p>
<h2 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h2><p><code>Texture2D</code> 下面的内容是所有打包后的立绘纹理图片, 目测都是 <code>名字</code> + <code>.png</code> 的文件名.</p>
<p><code>Mesh</code> 下面是 3D 模型贴图格式, 大部分都是 <code>名字</code> + <code>-mesh.obj</code> 的文件名, 小部分要特殊处理, 名字和前面纹理图名字一一对应.</p>
<ul>
<li><code>g</code> 开头的行是标识行, 可以忽略;</li>
<li><code>v</code> 开头的是模型顶点坐标, 对应还原后的图的坐标;</li>
<li><code>vt</code> 是纹理图的顶点坐标, 对应打包后图片的坐标;</li>
<li><code>f</code> 是 <code>v</code> 和 <code>vt</code> 的对应关系, 每一行代表一个三角面, 用三组点来记录, 分别是 <code>v/vt/vn</code> 的序号, 从 1 开始.</li>
</ul>
<p>更为详细的内容可以自行谷歌 <code>Mesh</code> 的文件格式.</p>
<h2 id="还原思路"><a href="#还原思路" class="headerlink" title="还原思路"></a>还原思路</h2><h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h3><p><code>Mesh</code> 中每一个 <code>f</code> 行代表一个小三角形, 实测相邻的两行就是一整个矩形, 因此只需要读取 <code>Mesh</code> 文件记录之后, 两行两行去处理 <code>f</code> 记录, 就可以像拼图一样从纹理图把原图拼出来.</p>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li>模型坐标的 <code>x</code> 取值需要取绝对值进行镜像 (原因不知).</li>
<li>原始坐标系的原点都在图片的左下角, 需要调整成左上角 (翻转 <code>y</code> 轴).</li>
<li>需要将坐标系里的点转换到图片里的像素行列值 (比较玄学, 坐标里的点对应图片像素一个 <code>2x2</code> 像素的中心点)</li>
<li>打包的纹理图图块和原图图块可能存在某一些块大小不一致, 实测都是纹理图可能比原图多 1 行/列透明像素, 因此拼的时候需要对比大小, 剔除多余的透明行/列<del>想想也知道怎么可能拆分成这么多块后还刚好能重新拼成一个大块</del>. 而且由于绘图误差, 全透明点的 RGB 不一定是全 0, 并且 alpha 通道也可能有一些值, 所以凡是透明度小于某个阈值就可以认为是透明的了.</li>
<li>瓜游的 0.125 个程序员导致很多立绘就是原图, 然后对应的 <code>Mesh</code> 文件没有; 也可能热更新很多次, 同一个纹理图有很多个 <code>Mesh</code> 文件, 需要都尝试一下.</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>安装一下必要的库, 运行的时候需要设定资源文件夹和导出文件夹.</p>
<p>当遇到无法通过 <code>Mesh</code> 文件来还原的纹理图时, 会弹窗显示图片的缩略图, 可以手动选择是直接复制原图过去还是放弃这张图, 比如下面:</p>
<p><img data-src="/static/image/blhx-painting/ppLHg1I.png" alt="ppLHg1I.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> tkinter <span class="keyword">as</span> tk</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageTk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_mesh_obj</span>(<span class="params">path</span>):</span><br><span class="line">    vertex = []  <span class="comment"># x, y, x</span></span><br><span class="line">    vertex_texture = []  <span class="comment"># u, v</span></span><br><span class="line">    vector_normal = []  <span class="comment"># x, y, z # 2D 没有法向量</span></span><br><span class="line">    face = []  <span class="comment"># v/vt/vn</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            type_, *values = line.strip().split(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> type_ == <span class="string">&quot;v&quot;</span>:</span><br><span class="line">                vertex.append(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, values[:<span class="number">2</span>])))</span><br><span class="line">            <span class="keyword">elif</span> type_ == <span class="string">&quot;vt&quot;</span>:</span><br><span class="line">                vertex_texture.append(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, values)))</span><br><span class="line">            <span class="keyword">elif</span> type_ == <span class="string">&quot;f&quot;</span>:</span><br><span class="line">                face.append([<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, value.split(<span class="string">&quot;/&quot;</span>))) <span class="keyword">for</span> value <span class="keyword">in</span> values])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">return</span> vertex, vertex_texture, face</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">restore_painting</span>(<span class="params">texture: np.ndarray, v, vt, f</span>) -&gt; np.ndarray:</span><br><span class="line">    v = np.array(v)[:, <span class="number">0</span>:<span class="number">2</span>]  <span class="comment"># 去除 z 轴</span></span><br><span class="line">    vt = np.array(vt)</span><br><span class="line">    f = np.array(f)[:, :, <span class="number">0</span>:<span class="number">2</span>]  <span class="comment"># 去除法向量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理 v</span></span><br><span class="line">    v = np.<span class="built_in">abs</span>(v)  <span class="comment"># 水平镜像, 原因不明</span></span><br><span class="line">    v[:, <span class="number">1</span>] = np.<span class="built_in">max</span>(v[:, <span class="number">1</span>]) - v[:, <span class="number">1</span>]  <span class="comment"># 翻转 y 轴, x 对应列数, y 对应行数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理 vt</span></span><br><span class="line">    vt = vt * np.array(texture.shape[<span class="number">1</span>::-<span class="number">1</span>]).reshape(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 转换到像素</span></span><br><span class="line">    vt[:, <span class="number">1</span>] = texture.shape[<span class="number">0</span>] - vt[:, <span class="number">1</span>]  <span class="comment"># 翻转 y 轴</span></span><br><span class="line">    vt = np.<span class="built_in">round</span>(vt, <span class="number">0</span>).astype(<span class="built_in">int</span>)  <span class="comment"># 转换整数坐标</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 新建空图</span></span><br><span class="line">    width, height = np.<span class="built_in">max</span>(v, axis=<span class="number">0</span>) + <span class="number">2</span>  <span class="comment"># 上下左右各扩展 1 个位置</span></span><br><span class="line">    png = np.zeros((height, width, <span class="number">4</span>), dtype=texture.dtype)</span><br><span class="line">    <span class="comment"># print(png.shape)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(f), <span class="number">2</span>):</span><br><span class="line">        v_rect_pts: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]] = []</span><br><span class="line">        vt_rect_pts: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]] = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v_idx, vt_idx <span class="keyword">in</span> f[i]:</span><br><span class="line">            v_rect_pts.append(v[v_idx - <span class="number">1</span>])  <span class="comment"># 下标需要序号 -1</span></span><br><span class="line">            vt_rect_pts.append(vt[vt_idx - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v_idx, vt_idx <span class="keyword">in</span> f[i + <span class="number">1</span>]:</span><br><span class="line">            v_rect_pts.append(v[v_idx - <span class="number">1</span>])</span><br><span class="line">            vt_rect_pts.append(vt[vt_idx - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 排序得到左上和右下坐标</span></span><br><span class="line">        leftup_v, *_, rightdown_v = <span class="built_in">sorted</span>(v_rect_pts, key=<span class="built_in">list</span>)</span><br><span class="line">        leftup_vt, *_, rightdown_vt = <span class="built_in">sorted</span>(vt_rect_pts, key=<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转换像素行列坐标, 左闭右开</span></span><br><span class="line">        leftup_v = (leftup_v + <span class="number">1</span>) - <span class="number">1</span>  <span class="comment"># +1 是为了把图往两个正方向移动一格, 修正坐标</span></span><br><span class="line">        rightdown_v = (rightdown_v + <span class="number">1</span>) + <span class="number">1</span></span><br><span class="line">        leftup_vt = leftup_vt - <span class="number">1</span></span><br><span class="line">        rightdown_vt = rightdown_vt + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 判断区域是否大小相等</span></span><br><span class="line">        size1 = rightdown_v - leftup_v</span><br><span class="line">        size2 = rightdown_vt - leftup_vt</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">all</span>(size1 == size2):</span><br><span class="line">            <span class="comment"># 处理不相等情况, 目前只发现纹理区域会可能多一行/列, 想办法去掉空白</span></span><br><span class="line">            <span class="comment"># 空白的条件是某一行/列透明度均小于一个阈值</span></span><br><span class="line">            texture_region = texture[leftup_vt[<span class="number">1</span>]:rightdown_vt[<span class="number">1</span>], leftup_vt[<span class="number">0</span>]:rightdown_vt[<span class="number">0</span>]]</span><br><span class="line">            alpha_value = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">            row_delta = size2[<span class="number">1</span>] - size1[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> row_delta == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> np.<span class="built_in">all</span>(texture_region[-<span class="number">1</span>, :, -<span class="number">1</span>] &lt; alpha_value):</span><br><span class="line">                    rightdown_vt[<span class="number">1</span>] -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> np.<span class="built_in">all</span>(texture_region[<span class="number">0</span>, :, -<span class="number">1</span>] &lt; alpha_value):</span><br><span class="line">                    leftup_vt[<span class="number">1</span>] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">&quot;Empty row not found!&quot;</span>)</span><br><span class="line">            <span class="keyword">elif</span> row_delta &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;<span class="subst">&#123;row_delta&#125;</span> extra rows found.&quot;</span>)</span><br><span class="line"></span><br><span class="line">            col_delta = size2[<span class="number">0</span>] - size1[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> col_delta == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> np.<span class="built_in">all</span>(texture_region[:, -<span class="number">1</span>, -<span class="number">1</span>] &lt; alpha_value):</span><br><span class="line">                    rightdown_vt[<span class="number">0</span>] -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> np.<span class="built_in">all</span>(texture_region[:, <span class="number">0</span>, -<span class="number">1</span>] &lt; alpha_value):</span><br><span class="line">                    leftup_vt[<span class="number">0</span>] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">&quot;Empty col not found!&quot;</span>)</span><br><span class="line">            <span class="keyword">elif</span> col_delta &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;<span class="subst">&#123;col_delta&#125;</span> extra cols found.&quot;</span>)</span><br><span class="line"></span><br><span class="line">        png[leftup_v[<span class="number">1</span>]:rightdown_v[<span class="number">1</span>], leftup_v[<span class="number">0</span>]:rightdown_v[<span class="number">0</span>]] = texture[leftup_vt[<span class="number">1</span>]:rightdown_vt[<span class="number">1</span>], leftup_vt[<span class="number">0</span>]:rightdown_vt[<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> png</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">choose_image</span>(<span class="params">image_path</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_confirm</span>():</span><br><span class="line">        root.result = <span class="literal">True</span></span><br><span class="line">        root.destroy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_cancel</span>():</span><br><span class="line">        root.result = <span class="literal">False</span></span><br><span class="line">        root.destroy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化 tkinter 窗口</span></span><br><span class="line">    root = tk.Tk()</span><br><span class="line">    root.title(<span class="string">&quot;选择保留&quot;</span>)</span><br><span class="line">    root.result = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载图片并调整大小</span></span><br><span class="line">    image = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line">    max_size = (<span class="number">300</span>, <span class="number">300</span>)</span><br><span class="line">    image.thumbnail(max_size)</span><br><span class="line">    photo = ImageTk.PhotoImage(image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建图片标签并放置在窗口上</span></span><br><span class="line">    label = tk.Label(root, image=photo)</span><br><span class="line">    label.pack(padx=<span class="number">5</span>, pady=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建确认和取消按钮并放置在窗口上</span></span><br><span class="line">    confirm_button = tk.Button(root, text=<span class="string">&quot;复制&quot;</span>, command=on_confirm)</span><br><span class="line">    confirm_button.pack(side=tk.LEFT, padx=(<span class="number">20</span>, <span class="number">10</span>), pady=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    cancel_button = tk.Button(root, text=<span class="string">&quot;放弃&quot;</span>, command=on_cancel)</span><br><span class="line">    cancel_button.pack(side=tk.RIGHT, padx=(<span class="number">10</span>, <span class="number">20</span>), pady=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 运行窗口并等待用户操作</span></span><br><span class="line">    root.mainloop()</span><br><span class="line">    <span class="keyword">return</span> root.result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PNG_DIR = Path(<span class="string">&quot;./Texture2D&quot;</span>)</span><br><span class="line">OBJ_DIR = Path(<span class="string">&quot;./Mesh&quot;</span>)</span><br><span class="line"></span><br><span class="line">EXPORT_DIR = Path(<span class="string">&quot;./paintings&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> png <span class="keyword">in</span> PNG_DIR.iterdir():</span><br><span class="line">        char_name = png.stem</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(char_name)</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        painting_path = EXPORT_DIR.joinpath(png.name)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> mesh <span class="keyword">in</span> OBJ_DIR.glob(<span class="string">f&quot;<span class="subst">&#123;char_name&#125;</span>-mesh*.obj&quot;</span>):</span><br><span class="line">            v, vt, f = read_mesh_obj(mesh)</span><br><span class="line">            texture: np.ndarray = cv2.imread(png.as_posix(), cv2.IMREAD_UNCHANGED)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                painting = restore_painting(texture, v, vt, f)</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                traceback.print_exc()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Restore Error: <span class="subst">&#123;char_name&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span>  <span class="comment"># 还原失败继续试下一个可能的 mesh 文件</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 还原成功跳出循环</span></span><br><span class="line">            cv2.imwrite(painting_path.as_posix(), painting)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;No valid mesh file found for <span class="subst">&#123;png&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> choose_image(png):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Copy: <span class="subst">&#123;png&#125;</span>&quot;</span>)</span><br><span class="line">                shutil.copy(png, painting_path)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Discard: <span class="subst">&#123;png&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total: <span class="subst">&#123;count&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">input</span>(<span class="string">&quot;Press &lt;Enter&gt; to exit...&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="还原效果"><a href="#还原效果" class="headerlink" title="还原效果"></a>还原效果</h2><p>放一些还原前和还原后的图作对比<del>夹带私货</del>.</p>
<details class="note danger"><summary><p>guanghui_h.png</p>
</summary>
<p><img data-src="/static/image/blhx-painting/ppLI7y8.png" alt="ppLI7y8.png"><br><img data-src="/static/image/blhx-painting/ppLIDRx.png" alt="ppLIDRx.png"><br>🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹</p>
<div style="text-align:center;">🌹<span class="black-curtain">为光辉老婆献上 99 朵玫瑰!</span>🌹</div>
</details>

<details class="note info"><summary><p>guanghui.png</p>
</summary>
<p><img data-src="/static/image/blhx-painting/ppLITQf.png" alt="ppLITQf.png"><br><img data-src="/static/image/blhx-painting/ppLIBJ1.png" alt="ppLIBJ1.png"></p>

</details>

<details class="note info"><summary><p>guanghui_2.png</p>
</summary>
<p><img data-src="/static/image/blhx-painting/ppLIoSP.png" alt="ppLIoSP.png"><br><img data-src="/static/image/blhx-painting/ppLI0iR.png" alt="ppLI0iR.png"></p>

</details>

<details class="note info"><summary><p>guanghui_3.png</p>
</summary>
<p><img data-src="/static/image/blhx-painting/ppLI5Wt.png" alt="ppLI5Wt.png"><br><img data-src="/static/image/blhx-painting/ppLIdo9.png" alt="ppLIdo9.png"></p>

</details>

<details class="note info"><summary><p>guanghui_4.png</p>
</summary>
<p><img data-src="/static/image/blhx-painting/ppLIhFA.png" alt="ppLIhFA.png"><br><img data-src="/static/image/blhx-painting/ppLIadJ.png" alt="ppLIadJ.png"></p>

</details>

<details class="note info"><summary><p>guanghui_5.png</p>
</summary>
<p><img data-src="/static/image/blhx-painting/ppLIHOS.png" alt="ppLIHOS.png"><br><img data-src="/static/image/blhx-painting/ppLIrz6.png" alt="ppLIrz6.png"></p>

</details>

<details class="note info"><summary><p>guanghui_idol.png</p>
</summary>
<p><img data-src="/static/image/blhx-painting/ppLHstH.png" alt="ppLHstH.png"><br><img data-src="/static/image/blhx-painting/ppLI6sO.png" alt="ppLI6sO.png"></p>

</details>

<details class="note info"><summary><p>guanghui_idol_n.png</p>
</summary>
<p><img data-src="/static/image/blhx-painting/ppLIqeg.png" alt="ppLIqeg.png"><br><img data-src="/static/image/blhx-painting/ppLIyQK.png" alt="ppLIyQK.png"></p>

</details>
]]></content>
      <categories>
        <category>代码块</category>
      </categories>
      <tags>
        <tag>碧蓝航线</tag>
        <tag>工具</tag>
        <tag>立绘还原</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 NumPy 的手写数字识别 (卷积神经网络) (一)</title>
    <url>//posts/2023/10/13/cnn-numpy-1/</url>
    <content><![CDATA[<p>&quot;基于 numpy 的手写数字识别&quot;, 这一经典问题除了用作深度学习入门内容, 还被广泛作为各大课程的课程作业, 因此在各大搜索引擎上搜索率也是相当之高<del>(代码复用率也是相当之高)</del>. 网上确实有挺多现成的可使用代码, 但是大部分都是造的全连接网络, 并且很多时候内部原理不是特别清晰. 因此决定自己也来造一次轮子, 使用 <code>numpy</code> 实现一个简单的卷积神经网络进行手写数字识别, 正好也能借此机会梳理一下神经网络的基本原理.</p>
<p>全文包含完整的卷积网络实现, 以及矩阵梯度和卷积矩阵化的推导过程, 由于全文过长, 因此分成了三部分, 内容上是完全连着的.</p>
<p>本文为第一篇, 简单介绍了神经网络的基本学习原理和一些无参数网络层的实现.</p>
<span id="more"></span>

<p>本系列文章传送门:</p>
<ul>
<li><a href="/posts/2023/10/13/cnn-numpy-1/">基于 NumPy 的手写数字识别 (卷积神经网络) (一)</a></li>
<li><a href="/posts/2023/10/14/cnn-numpy-2/">基于 NumPy 的手写数字识别 (卷积神经网络) (二)</a></li>
<li><a href="/posts/2023/10/15/cnn-numpy-3/">基于 NumPy 的手写数字识别 (卷积神经网络) (三)</a></li>
</ul>
<h2 id="必要的理论知识"><a href="#必要的理论知识" class="headerlink" title="必要的理论知识"></a>必要的理论知识</h2><p>本节是对神经网络所需的数学知识进行简单介绍, 只涉及基本的高数知识. <del>全文可能有一些不严谨的数学式子, 会意即可.</del></p>
<h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p>神经网络的本质是一个多元复合函数, 因此在给定输入的情况下计算网络的输出, 就是网络的前向传播过程.</p>
<p><img data-src="/static/image/cnn-numpy-1/forward.jpg" alt="forward.jpg"></p>
<p>如果有上图所示的一个简单网络, 其中:</p>
<p>$$<br>\begin{aligned}<br>  y_1 &amp;= y_1(x_1, x_2) \\<br>  y_2 &amp;= y_2(x_2, x_3) \\<br>  z &amp;= z(y_1, y_2) = z(y_1(x_1, x_2), y_2(x_2, x_3))<br>\end{aligned}<br>$$</p>
<p>则称 $y_1$ 是关于 $x_1, x_2$ 的函数, $y_2$ 是关于 $x_2, x_3$ 的函数, $z$ 是关于 $x_1, x_2, x_3$ 的函数, 且由 $y_1, y_2$ 复合而成.</p>
<p>则通过 $x_1, x_2, x_3$ 按照图中复合函数一步一步计算 $z$ 的过程就是网络的前向传播过程.</p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>从上面的图我们可以知道 $z$ 有三个输入参数, 假设 $z$ 就是网络最终的损失函数, 我们的目标就是不断调整这些参数, 使得损失减小, 也就是 $z$ 减小.</p>
<p>那么, 回忆高数最基本的知识, 如果一个函数存在最 (极) 小值, 那么该点的导数等于 0. 所以纯理论计算最暴力的方式就是对 $z$ 关于所有参数求导, 然后看所有参数极值点的组合, 最后得到 $z$ 的最小值.</p>
<p>但是上述方法不能充分利用计算机的优势, 就是数值计算, 并且很多时候函数十分复杂无法推导, 而且我们也不需要精确求出最小值, 只要接近某个极小值就行了, 因此有了梯度下降法.</p>
<p>所谓梯度, 简单理解就是函数的导数, 只不过是对每个参数都求偏导数, 所有参数的偏导数组合在一起就叫梯度. 而梯度所指向的参数变化方向永远使得整个函数值变大, 因此如果朝着梯度的反方向更新参数, 就会使得函数值减小.</p>
<p>例如我们知道了 $z$ 关于三个参数的梯度是 $(\frac{\partial{z}}{\partial{x_1}}, \frac{\partial{z}}{\partial{x_2}}, \frac{\partial{z}}{\partial{x_3}})$, 那么 $z(x_1 - \eta\frac{\partial{z}}{\partial{x_1}}, x_2 - \eta\frac{\partial{z}}{\partial{x_2}}, x_3 - \eta\frac{\partial{z}}{\partial{x_3}})$ 小于 $z(x_1, x_2, x_3)$, 其中 $\eta$ 可以视作&quot;学习率&quot;, 取一个相对较小的值.</p>
<h3 id="链式法则与反向传播"><a href="#链式法则与反向传播" class="headerlink" title="链式法则与反向传播"></a>链式法则与反向传播</h3><p>知道了梯度下降的基本原理之后, 我们下一步目标就是高效的求解梯度.</p>
<p>先说链式法则, 这个内容也是高数的基本知识, 在此回顾一下.</p>
<p>例如要求 $z$ 的所有偏导数, 则:</p>
<p>$$<br>\begin{aligned}<br>  \frac{\partial{z}}{\partial{x_1}} &amp;= \frac{\partial{z}}{\partial{y_1}}\frac{\partial{y_1}}{\partial{x_1}} \\<br>  \frac{\partial{z}}{\partial{x_2}} &amp;= \frac{\partial{z}}{\partial{y_1}}\frac{\partial{y_1}}{\partial{x_2}} + \frac{\partial{z}}{\partial{y_2}}\frac{\partial{y_2}}{\partial{x_2}} \\<br>  \frac{\partial{z}}{\partial{x_3}} &amp;= \frac{\partial{z}}{\partial{y_2}}\frac{\partial{y_2}}{\partial{x_3}}<br>\end{aligned}<br>$$</p>
<p>和上面的函数复合关系对应一下, 很容易就能看出链式求导逻辑, 然后可以按下图标记偏导数.</p>
<p><img data-src="/static/image/cnn-numpy-1/backward.jpg" alt="backward.jpg"></p>
<p>可以看出来整个网络图形成了一个树形结构, 也可称之为计算图, 其中树的根部是损失值, 而函数所有的输入参数是树的叶节点.</p>
<p>显然, 从算法角度考虑, 如果要复用中间结果, 减少计算量, 最佳方式就是总树的根部开始遍历每一个叶节点, 中途不断按照链式法则进行累加和累乘, 得到根节点关于每一个叶节点的偏导值.</p>
<p>由于这种梯度计算方式和前向计算 $z$ 的过程刚好相反, 因此得名反向传播算法. 只要在前向计算时构造好计算图, 则计算梯度时只需要反方向从计算图根部遍历叶节点即可算出所有参数的梯度值.</p>
<h2 id="导入使用的库"><a href="#导入使用的库" class="headerlink" title="导入使用的库"></a>导入使用的库</h2><p>下面的内容将使用 <code>numpy</code> 库手搓一个简单的卷积神经网络, 并进行训练和评估. 全篇代码需要导入的库如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br></pre></td></tr></table></figure>

<p><code>matplotlib.pyplot</code> 用来绘制损失曲线, <code>numpy</code> 提供神经网络所需要的矩阵计算, <code>PIL</code> 用来读取数据集, <code>sklearn.metrics</code> 里有一些评价分类任务的指标函数, 借用一下.</p>
<p>本文使用的 <code>python</code> 版本为 <code>3.9.13</code>, 各依赖库的版本如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">numpy==1.24.3</span><br><span class="line">Pillow==10.0.0</span><br><span class="line">scikit-learn==1.2.2</span><br><span class="line">matplotlib==3.7.2</span><br></pre></td></tr></table></figure>

<h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><p>数据集使用一个较小的手写数字分类图片数据集, 之前文章里也一直用这个举例, 这里再贴一下蓝奏云下载地址, <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pVFBrSzA5cGZuaGE=">手写数字分类.zip<i class="fa fa-external-link-alt"></i></span>, 里面包含 10000 张训练数据和 5000 张测试数据.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_dataset</span>(<span class="params">folder, shuffle: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        inputs: (B, C, H, W)</span></span><br><span class="line"><span class="string">        targets: (B, )</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    inputs = []</span><br><span class="line">    targets = []</span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> img_path <span class="keyword">in</span> Path(folder, <span class="built_in">str</span>(num)).iterdir():</span><br><span class="line">            inputs.append(np.asarray(PIL.Image.<span class="built_in">open</span>(img_path)))</span><br><span class="line">            targets.append(num)</span><br><span class="line"></span><br><span class="line">    inputs = np.stack(inputs, <span class="number">0</span>, dtype=np.float32) / <span class="number">255</span></span><br><span class="line">    targets = np.stack(targets, <span class="number">0</span>, dtype=np.int32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(inputs.shape) == <span class="number">3</span>:</span><br><span class="line">        inputs = inputs[:, <span class="literal">None</span>, :, :]  <span class="comment"># (B, C, H, W)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        rnd_index = np.arange(inputs.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            np.random.shuffle(rnd_index)</span><br><span class="line">        inputs = inputs[rnd_index]</span><br><span class="line">        targets = targets[rnd_index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inputs, targets</span><br></pre></td></tr></table></figure>

<p>这里要注意的地方是, 为了之后网络能稳定训练, 不会出现梯度爆炸等奇怪的问题, 像素值被转换到 0-1 的范围.</p>
<h2 id="无参数网络层的实现"><a href="#无参数网络层的实现" class="headerlink" title="无参数网络层的实现"></a>无参数网络层的实现</h2><p>首先来实现网络中简单内容, 一些只有单纯函数计算的层.</p>
<p>对于网络中的层, 我们需要实现前向和反向两个功能即可, 因此先声明基类 <code>NetworkLayer</code>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NetworkLayer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, x: np.ndarray, last_x_grad: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>

<p>只有两个方法, <code>forward</code> 和 <code>bacckward</code>, 分别代表前向和反向计算, 而这两个方法的输入输出有以下关系.</p>
<ul>
<li><code>forward</code> 的输入 <code>x</code> 形状等于反向的输出形状, 返回值为函数计算值.</li>
<li><code>backward</code> 的输入 <code>last_x_grad</code> 形状等于前向的输出形状, 返回值为上一层输入的梯度.</li>
</ul>
<div class="note info"><p>其实更完备的反向传播做法并不是直接返回 $x$ 的梯度, 因为计算图中可能存在需要梯度累加的情况, 构建完整的图然后遍历才是正确的做法.</p>
<p>但是由于本文要实现的卷积神经网络, 整个计算图只有一条路径, 并且以 $x$ 为主线路, 所以关于 $x$ 的梯度可以直接被返回依次向前传递, 同时在每次求解各个参数的梯度时, 也不必进行累加, 直接清空重新赋值即可, 这一点在后续的代码实现中可以看到.</p></div>

<h3 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h3><p>在卷积神经网络中, 我们需要用到最大池化层, 这里我们简单起见, 只实现核大小等于两个方向上步长且能整除图片宽高的情况. 以图片大小 $6 \times 4$, 核大小为 $3 \times 2$ 举例, 池化过程如下图所示.</p>
<p><img data-src="/static/image/cnn-numpy-1/pooling.jpg" alt="pooling.jpg"></p>
<p>对于前向传播, 虚线是使用循环遍历的方式求解, 而实线则是通过数组变形使用矩阵方式求解.</p>
<p>我们本篇代码实现里, 对于所有计算均采用矩阵化形式实现, 每一小节都有详细的讲解. 因此只看实线部分即可.</p>
<p>重点关注反向传播, 对于池化操作而言, 池化后的值被原封不动的传递到下一层, 相当于是 $y = x$ 函数, 因此这些值在这一层的梯度为 1. 而没有被传递的值, 相当于是常数函数 $y = 0$, 因此梯度值为 0.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MaxPoolingLayer</span>(<span class="title class_ inherited__">NetworkLayer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;步长与核大小相同的最大池化层&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k1: <span class="built_in">int</span>, k2: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.k1 = k1</span><br><span class="line">        self.k2 = k2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, C, H, W)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x: (B, C, H / k1, W / k2)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        _, c, h, w = x.shape</span><br><span class="line">        k1 = self.k1</span><br><span class="line">        k2 = self.k2</span><br><span class="line">        o1 = h // k1</span><br><span class="line">        o2 = w // k2</span><br><span class="line"></span><br><span class="line">        x = x.reshape(-<span class="number">1</span>, o1, k1, o2, k2).transpose(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>).reshape(-<span class="number">1</span>, k1 * k2)</span><br><span class="line">        ridx = np.arange(x.shape[<span class="number">0</span>])</span><br><span class="line">        cidx = np.argmax(x, axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = x[ridx, cidx].reshape(-<span class="number">1</span>, c, o1, o2)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, x: np.ndarray, last_x_grad: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, C, H, W)</span></span><br><span class="line"><span class="string">            last_x_grad: (B, C, H / k1, W / k2)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x_grad: (B, C, H, W)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        _, c, h, w = x.shape</span><br><span class="line">        k1 = self.k1</span><br><span class="line">        k2 = self.k2</span><br><span class="line">        o1 = h // k1</span><br><span class="line">        o2 = w // k2</span><br><span class="line"></span><br><span class="line">        x = x.reshape(-<span class="number">1</span>, o1, k1, o2, k2).transpose(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>).reshape(-<span class="number">1</span>, k1 * k2)</span><br><span class="line">        ridx = np.arange(x.shape[<span class="number">0</span>])</span><br><span class="line">        cidx = np.argmax(x, axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x_grad: np.ndarray = np.zeros_like(x).reshape(-<span class="number">1</span>, k1 * k2)</span><br><span class="line">        x_grad[ridx, cidx] = last_x_grad.reshape(-<span class="number">1</span>)</span><br><span class="line">        x_grad = x_grad.reshape((-<span class="number">1</span>, o1, o2, k1, k2)).transpose((<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>)).reshape((-<span class="number">1</span>, c, h, w))</span><br><span class="line">        <span class="keyword">return</span> x_grad</span><br></pre></td></tr></table></figure>

<p>注意这里的输入输出都是包含样本数和通道数的, 但是没关系, 我们当作有 $B \times C$ 张二维图片即可, <code>numpy</code> 会自动把我们的步骤按单张图片进行批量操作.</p>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>ReLU 是本文卷积神经网络中将要使用的激活函数, 它的表达式为:</p>
<p>$$<br>ReLU(x) = \left\{<br>  \begin{aligned}<br>    x \quad x &gt; 0 \\<br>    0 \quad x \leq 0<br>  \end{aligned}<br>  \right.<br>$$</p>
<p>然后对应的导数表达式为:</p>
<p>$$<br>ReLU&#39;(x) = \left\{<br>  \begin{aligned}<br>    1 \quad x &gt; 0 \\<br>    0 \quad x \leq 0<br>  \end{aligned}<br>  \right.<br>$$</p>
<p>可以看到, 无论是函数还是导函数, 就是一个分段函数, 因此实现起来也是比较容易的.</p>
<p>对于前向过程, 将小于等于 0 的部分置零, 对于反向部分, 将输入中小于等于 0 部分的梯度置零, 其余梯度按原值传递即可.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReLULayer</span>(<span class="title class_ inherited__">NetworkLayer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;ReLU&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> x * (x &gt; <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, x: np.ndarray, last_x_grad: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> last_x_grad * (x &gt; <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Flatten"><a href="#Flatten" class="headerlink" title="Flatten"></a>Flatten</h3><p>在我们网络的末尾, 全连接层的之前, 需要一个 Flatten 层, 它能够将二维的样本展平成一维, 从而送进全连接层进行最后的分类.</p>
<p>这里的前向和反向就十分简单了, 这是一个等值函数, 只需要对输入输出进行维度变换就能完成正确的计算过程.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FlattenLayer</span>(<span class="title class_ inherited__">NetworkLayer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Flatten&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start: <span class="built_in">int</span> = <span class="number">1</span>, end: <span class="built_in">int</span> = -<span class="number">1</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.start = start</span><br><span class="line">        self.end = end</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;&quot;&quot;</span></span><br><span class="line">        shape = x.shape</span><br><span class="line">        shapen_len = <span class="built_in">len</span>(shape)</span><br><span class="line">        start = (self.start + shapen_len) % shapen_len</span><br><span class="line">        end = (self.end + shapen_len) % shapen_len</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x.reshape(shape[:start] + (-<span class="number">1</span>, ) + shape[end + <span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, x: np.ndarray, last_x_grad: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> last_x_grad.reshape(x.shape)</span><br></pre></td></tr></table></figure>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>受限于篇幅问题, 本文到此就暂告一段落了. 在本篇中, 我们完成了对数据集的加载和简单的预处理, 同时回顾了神经网络的基本原理并实现了简单的无参数网络层, 包括一些变换和激活函数等等.</p>
<p>下一篇中, 我们将实现卷积神经网络中用到的两个有参数网络层, 线性层和卷积层, 并且完成对它们前向和反向过程的推导, 以及网络的最后一层, 损失函数的推导和实现.</p>
<p>本系列文章传送门:</p>
<ul>
<li><a href="/posts/2023/10/13/cnn-numpy-1/">基于 NumPy 的手写数字识别 (卷积神经网络) (一)</a></li>
<li><a href="/posts/2023/10/14/cnn-numpy-2/">基于 NumPy 的手写数字识别 (卷积神经网络) (二)</a></li>
<li><a href="/posts/2023/10/15/cnn-numpy-3/">基于 NumPy 的手写数字识别 (卷积神经网络) (三)</a></li>
</ul>
]]></content>
      <categories>
        <category>代码块</category>
      </categories>
      <tags>
        <tag>numpy</tag>
        <tag>手写数字识别</tag>
        <tag>卷积神经网络</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 NumPy 的手写数字识别 (卷积神经网络) (二)</title>
    <url>//posts/2023/10/14/cnn-numpy-2/</url>
    <content><![CDATA[<blockquote>
<p>&quot;基于 numpy 的手写数字识别&quot;, 这一经典问题除了用作深度学习入门内容, 还被广泛作为各大课程的课程作业, 因此在各大搜索引擎上搜索率也是相当之高<del>(代码复用率也是相当之高)</del>. 网上确实有挺多现成的可使用代码, 但是大部分都是造的全连接网络, 并且很多时候内部原理不是特别清晰. 因此决定自己也来造一次轮子, 使用 <code>numpy</code> 实现一个简单的卷积神经网络进行手写数字识别, 正好也能借此机会梳理一下神经网络的基本原理.</p>
<p>全文包含完整的卷积网络实现, 以及矩阵梯度和卷积矩阵化的推导过程, 由于全文过长, 因此分成了三部分, 内容上是完全连着的.</p>
</blockquote>
<p>本文为第二篇, 介绍含参数网络层和损失函数的实现, 以及反向传播时的梯度推导.</p>
<span id="more"></span>

<p>本系列文章传送门:</p>
<ul>
<li><a href="/posts/2023/10/13/cnn-numpy-1/">基于 NumPy 的手写数字识别 (卷积神经网络) (一)</a></li>
<li><a href="/posts/2023/10/14/cnn-numpy-2/">基于 NumPy 的手写数字识别 (卷积神经网络) (二)</a></li>
<li><a href="/posts/2023/10/15/cnn-numpy-3/">基于 NumPy 的手写数字识别 (卷积神经网络) (三)</a></li>
</ul>
<h2 id="含参数网络层"><a href="#含参数网络层" class="headerlink" title="含参数网络层"></a>含参数网络层</h2><p>上一篇中我们结束了无参数网络层的内容, 我们来到网络的重点部分, 含参数层. 这一类层依然需要实现 <code>forward</code> 和 <code>backward</code> 方法, 但是在 <code>backward</code> 方法中需要计算自己拥有的参数的梯度值并存起来, 同时需要新增 <code>update</code> 方法, 用于按照梯度值更新自己的参数.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ParamLayer</span>(<span class="title class_ inherited__">NetworkLayer</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, lr: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>

<p>继承一下 <code>NetworkLayer</code> 类, 并且增加一个 <code>update</code> 方法, 该方法接收学习率 <code>lr</code> 作为参数.</p>
<h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><p>首先是线性层, 也是含学习参数中最简单的层, 先上图.</p>
<p><img data-src="/static/image/cnn-numpy-2/linear.jpg" alt="linear.jpg"></p>
<p>方便起见, 这里我们的输入都是行向量的形式, 因此第一维是样本数, 第二维是特征数.</p>
<p>一般的, 设 $\mathbf{X}$ 为一个 $n \times d_1$ 的矩阵, 权重 $\mathbf{W}$ 为一个 $d_1 \times d_2$ 的矩阵, $\mathbf{b}$ 为长度 $d_2$ 的偏置向量, 则 $\mathbf{Y}, \mathbf{Z}$ 均为 $n \times d_2$. 线性层的可学习参数就是 $\mathbf{W}$ 和 $\mathbf{b}$.</p>
<p>图上高亮部分表示对最终输出 $z_{11}$ 的计算过程, 而对 $z_{ik}$ 的计算过程用公式表示如下:</p>
<p>$$<br>z_{ik} = \sum_{j=1}^{d_1}{x_{ij}w_{jk}} + b_k<br>$$</p>
<p>写成矩阵形式就是:</p>
<p>$$<br>\mathbf{Z} = \mathbf{X}\mathbf{W} + \mathbf{b}<br>$$</p>
<p>其中 $\mathbf{b}$ 需要重复每一行扩展成矩阵.</p>
<p>前向计算就到此结束了, 下面我们看看反向中梯度是如何计算的.</p>
<p>首先是 $\mathbf{b}$ 的, 这一层中, 对于 $b_k$ 而言, 因为是加上常数, 所以都是 1, 因此只需要直接等于上一层传进来的梯度即可. 再由链式法则里的加法法则可知, 同一个 $b_k$ 每个样本中都参与了运算, 因此需要把后一层传过来的梯度进行累加.</p>
<p>设最终损失为 $L$, 则:</p>
<p>$$<br>\begin{aligned}<br>  \frac{\partial{L}}{\partial{b_k}} &amp;= \sum_{i=1}^{n}{\frac{\partial{L}}{\partial{z_{ik}}}\frac{\partial{z_{ik}}}{\partial{b_k}}} \\<br>  ~ &amp;= \sum_{i=1}^{n}{\frac{\partial{L}}{\partial{z_{ik}}}} \cdot 1<br>\end{aligned}<br>$$</p>
<p>所以 $\mathbf{b}$ 的梯度就是把后一层传进来关于 $z$ 的梯度按行累加即可.</p>
<p>下面来看关于 $\mathbf{W}$ 的梯度. 在 $z_{ik}$ 的表达式中, $b_k$ 作为常数存在, 因此可以忽略, 所以梯度只与 $x_{ij}$ 有关, 所以我们第一步是找出来含有 $w_{jk}$ 的结果有哪些.</p>
<p>注意到 $w_{jk}$ 是不包含下标 $i$ 的, 因此在 $z_{1k}, z_{2k}, \ldots, z_{nk}$ 中都是有 $w_{jk}$ 的. 所以:</p>
<p>$$<br>\begin{aligned}<br>  \frac{\partial{L}}{\partial{w_{jk}}} &amp;= \sum_{i=1}^{n}{\frac{\partial{L}}{\partial{z_{ik}}}\frac{\partial{z_{ik}}}{\partial{w_{jk}}}} \\<br>  ~ &amp;= \sum_{i=1}^{n}{\frac{\partial{L}}{\partial{z_{ik}}}x_{ij}}<br>\end{aligned}<br>$$</p>
<p>换成矩阵形式则是:</p>
<p>$$<br>\frac{\partial{L}}{\partial{\mathbf{W}}} = \mathbf{X}^\top\frac{\partial{L}}{\partial{\mathbf{Z}}}<br>$$</p>
<p>其中 $\frac{\partial{L}}{\partial{\mathbf{Z}}}$ 是最终损失 $L$ 对 $z_{ik}$ 的梯度矩阵, 形状与 $\mathbf{Z}$ 相同.</p>
<p>最后我们来看关于 $\mathbf{X}$ 的梯度, 有了求 $\mathbf{W}$ 梯度的经验, 我们很容易写出下列推导:</p>
<p>$$<br>\begin{aligned}<br>  \frac{\partial{L}}{\partial{x_{ij}}} &amp;= \sum_{k=1}^{d_2}{\frac{\partial{L}}{\partial{z_{ik}}}\frac{\partial{z_{ik}}}{\partial{x_{ij}}}} \\<br>  ~ &amp;= \sum_{k=1}^{d_2}{\frac{\partial{L}}{\partial{z_{ik}}}w_{jk}}<br>\end{aligned}<br>$$</p>
<p>同样可以换成矩阵形式:</p>
<p>$$<br>\frac{\partial{L}}{\partial{\mathbf{X}}} = \frac{\partial{L}}{\partial{\mathbf{Z}}}\mathbf{W}^\top<br>$$</p>
<p>到这里我们已经完成对线性层的前向和反向过程推导, 矩阵形式的公式总结就是:</p>
<p>前向:</p>
<p>$$<br>\mathbf{Z} = \mathbf{X}\mathbf{W} + \mathbf{b}<br>$$</p>
<p>反向:</p>
<p>$$<br>\begin{aligned}<br>    \frac{\partial{L}}{\partial{b_k}} &amp;= \sum_{i=1}^{n}{\frac{\partial{L}}{\partial{z_{ik}}}} \\<br>    \frac{\partial{L}}{\partial{\mathbf{W}}} &amp;= \mathbf{X}^\top\frac{\partial{L}}{\partial{\mathbf{Z}}} \\<br>    \frac{\partial{L}}{\partial{\mathbf{X}}} &amp;= \frac{\partial{L}}{\partial{\mathbf{Z}}}\mathbf{W}^\top<br>\end{aligned}<br>$$</p>
<p>这个结论很重要, 在卷积层中还会用到.</p>
<p>然后我们可以按照公式完成线性层的代码.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LinearLayer</span>(<span class="title class_ inherited__">ParamLayer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;线性层&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d1: <span class="built_in">int</span>, d2: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.w = np.random.random((d1, d2)) * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">        self.b = np.random.random((<span class="number">1</span>, d2)) * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.w_grad = np.zeros_like(self.w)</span><br><span class="line">        self.b_grad = np.zeros_like(self.b)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, d1)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x: (B, d2)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x @ self.w + self.b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, x: np.ndarray, last_x_grad: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, d1)</span></span><br><span class="line"><span class="string">            last_grad: (B, d2)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x_grad: (B, d1)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        self.b_grad = last_x_grad.<span class="built_in">sum</span>(<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        self.w_grad = x.T @ last_x_grad</span><br><span class="line"></span><br><span class="line">        x_grad = last_x_grad @ self.w.T</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x_grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, lr: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.w -= lr * self.w_grad</span><br><span class="line">        self.b -= lr * self.b_grad</span><br></pre></td></tr></table></figure>

<p><code>update</code> 方法就是按学习率 <code>lr</code> 给每个参数减去相应的梯度就行了.</p>
<p>一个值得注意的地方是 <code>__init__</code> 中, 对 <code>w</code> 和 <code>b</code> 的初始化是使用了 -1 到 1 之间的均匀分布, 这有助于训练的稳定性, 防止出现梯度爆炸.</p>
<h3 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h3><p>这里我们只实现步长为 1 的无填充卷积操作.</p>
<h4 id="卷积及其参数维度"><a href="#卷积及其参数维度" class="headerlink" title="卷积及其参数维度"></a>卷积及其参数维度</h4><p>卷积层是整个网络的核心层, 网络也因此得名卷积神经网络, 用下图来简单回顾一下网络里的卷积操作.</p>
<p><img data-src="/static/image/cnn-numpy-2/conv.jpg" alt="conv.jpg"></p>
<p>卷积核 $\mathbf{K}$ 在输入 $\mathbf{X}$ 上逐步移动, 将每个位置上的值相乘并求和, 得到卷积后的结果 $\mathbf{Y}$, 然后对于每一次卷积都加上一个偏置常数 $b$, 得到网络中对于单张图片单通道的完整卷积过程.</p>
<p>如果是多通道的情况, 设输入 $\mathbf{X}$ 的通道数是 $c_1$, 输出通道数是 $c_2$.</p>
<p>输入 $\mathbf{X}$ 的形状变为 $n \times c_1 \times h_\mathbf{X} \times w_\mathbf{X}$, 其中 $n$ 是样本数, $h_\mathbf{X}, w_\mathbf{X}$ 分别是图片的高宽.</p>
<p>那么对于 $\mathbf{K}$ 而言, 输入通道数从 $1$ 变成 $c_1$, 所以每一次卷积都需要 $c_1$ 个单层的 $\mathbf{K}$. 进一步, 输出通道数从 $1$ 变成 $c_2$, 因此总共需要 $c_2 \times c_1$ 个单层卷积核. 所以最终卷积核 $\mathbf{K}$ 的形状为 $c_2 \times c_1 \times h_\mathbf{K} \times w_\mathbf{K}$, 其中 $h_\mathbf{K}, w_\mathbf{K}$ 分别表示卷积核的高宽.</p>
<p>对于 $b$ 而言, 只和输出通道数有关, 因此变成了一个长度为 $c_2$ 向量 $\mathbf{b}$, 在其他维度上重复数值即可.</p>
<p>在卷积层中, $\mathbf{K}$ 和 $\mathbf{b}$ 就是需要被学习的参数.</p>
<h4 id="卷积矩阵化"><a href="#卷积矩阵化" class="headerlink" title="卷积矩阵化"></a>卷积矩阵化</h4><p>基本的卷积操作需要多重循环, 无法充分利用 GPU 等硬件设备的加速效果, 因此需要将常规的卷积操作转化成矩阵形式, 从而批量运算.</p>
<p>有两种数据重组方式可以达到同样的效果, 分别是对输入 $\mathbf{X}$ 和卷积核 $\mathbf{K}$ 进行数据重组. 首先介绍第一种方式, 对 $\mathbf{X}$ 进行数据重组, 而 $\mathbf{K}$ 只需要保持数据不变, 维度变换即可.</p>
<p><img data-src="/static/image/cnn-numpy-2/unfold_x.jpg" alt="unfold_x.jpg"></p>
<p>上图展示的是对于一个样本下矩阵化运算, 如果是 $n$ 个样本, $\mathbf{X&#39;}$ 和 $\mathbf{Y&#39;}$ 在行上变成 $n$ 倍即可.</p>
<p>这里, $h_{\mathbf{Y}} = h_{\mathbf{X}} - h_{\mathbf{K}} + 1$, $w_{\mathbf{Y}} = w_{\mathbf{X}} - w_{\mathbf{K}} + 1$, 是卷积后的图像高宽.</p>
<p>在这种情况下, 变形后的 $\mathbf{K}&#39;$ 和原始的 $\mathbf{K}$ 数据相同, 前向公式为:</p>
<p>$$<br>\mathbf{Y}&#39; = \mathbf{X}&#39;\mathbf{K}&#39;^\top<br>$$</p>
<p>第二种方式则是只对输入数据 $\mathbf{X}$ 进行变形, 对卷积核 $\mathbf{K}$ 进行数据重组.</p>
<p><img data-src="/static/image/cnn-numpy-2/unfold_k.jpg" alt="unfold_k.jpg"></p>
<p>图太大画不下, 所以中间部分用省略号省去, 只保留了一些关键内容和维度信息.</p>
<p>同样的, 这里也是展示了对于一个样本的矩阵化运算.</p>
<p>图片被完全展平, 而卷积核被重组成中间包含一些 0 值的矩阵. 在这种情况下, $\mathbf{X}&#39;&#39;$ 和原本的 $\mathbf{X}$ 内容完全相同. 前向公式为:</p>
<p>$$<br>\mathbf{Y}&#39;&#39; = \mathbf{X}&#39;&#39;\mathbf{K}&#39;&#39;^\top<br>$$</p>
<h4 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h4><p>卷积层的梯度计算都是基于矩阵化之后的卷积操作. 首先是偏置向量 $\mathbf{b}$ 的梯度计算, 前向中有两种方式能算出 $\mathbf{Y}$, 但是通过数据变形后, 与 $\mathbf{b}$ 的相加方式相同, 结合前面线性层的结论, $\mathbf{b}$ 的梯度就是将除了 $c_2$ 的其他维度求和即可.</p>
<p>现在我们来看最关键的 $\mathbf{K}$ 和 $\mathbf{X}$ 的梯度怎么求, 首先回忆线性层得到的结论.</p>
<div class="note info"><p>设最终的损失为 $L$, 当前向传播为:</p>
<p>$$<br>\mathbf{Y} = \mathbf{X}\mathbf{W}<br>$$</p>
<p>时, 则反向传播 $\mathbf{X}$ 和 $\mathbf{W}$ 的梯度为:</p>
<p>$$<br>\begin{aligned}<br>    \frac{\partial{L}}{\partial{\mathbf{W}}} &amp;= \mathbf{X}^\top\frac{\partial{L}}{\partial{\mathbf{Y}}} \\<br>    \frac{\partial{L}}{\partial{\mathbf{X}}} &amp;= \frac{\partial{L}}{\partial{\mathbf{Y}}}\mathbf{W}^\top<br>\end{aligned}<br>$$</p>
<p>其中 $\frac{\partial{L}}{\partial{\mathbf{Y}}}$ 是损失 $L$ 对输出 $\mathbf{Y}$ 的损失矩阵, 形状与 $\mathbf{Y}$ 相同.</p></div>

<p>这是一个通用结论, 可以用于任意的两个矩阵相乘. 结合我们前面得到了两种不同的前向计算方式:</p>
<p>$$<br>\begin{aligned}<br>  \mathbf{Y}&#39; &amp;= \mathbf{X}&#39;\mathbf{K}&#39;^\top \\<br>  \mathbf{Y}&#39;&#39; &amp;= \mathbf{X}&#39;&#39;\mathbf{K}&#39;&#39;^\top<br>\end{aligned}<br>$$</p>
<p>在这两个不同的计算中, $\mathbf{K}&#39;$ 与原始的 $\mathbf{K}$ 相同, $\mathbf{X}&#39;&#39;$ 与原始的 $\mathbf{X}$ 数据相同, 只是进行了数据变形. 因此只要分别求出 $\mathbf{K}&#39;$ 和 $\mathbf{X}&#39;&#39;$ 的梯度, 再通过变形就能得到原始 $\mathbf{K}$ 和 $\mathbf{X}$ 的梯度. 结合结论, 有:</p>
<p>$$<br>\begin{aligned}<br>    \frac{\partial{L}}{\partial{\mathbf{K}&#39;}} &amp;= \mathbf{X}&#39;^\top\frac{\partial{L}}{\partial{\mathbf{Y}&#39;}} \\<br>    \frac{\partial{L}}{\partial{\mathbf{X}&#39;&#39;}} &amp;= \frac{\partial{L}}{\partial{\mathbf{Y}&#39;&#39;}}\mathbf{K}&#39;&#39;^\top<br>\end{aligned}<br>$$</p>
<p>其中, $\frac{\partial{L}}{\partial{\mathbf{Y}&#39;}}$ 和 $\frac{\partial{L}}{\partial{\mathbf{Y}&#39;&#39;}}$ 都可以通过对后一层传进来的 $\frac{\partial{L}}{\partial{\mathbf{Y}}}$ 进行数据变形得到.</p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>到这里我们已经完成了卷积层的前向和反向推导, 按照前面的内容便可完成代码.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvolutionLayer</span>(<span class="title class_ inherited__">ParamLayer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;步长为 1 的卷积层&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1: <span class="built_in">int</span>, c2: <span class="built_in">int</span>, k1: <span class="built_in">int</span>, k2: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            c1: 输入通道数</span></span><br><span class="line"><span class="string">            c2: 输出通道数</span></span><br><span class="line"><span class="string">            k1: 卷积核高</span></span><br><span class="line"><span class="string">            k2: 卷积核宽</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        self.k = np.random.random((c2, c1, k1, k2)) * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">        self.b = np.random.random((<span class="number">1</span>, c2, <span class="number">1</span>, <span class="number">1</span>)) * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">        self.k_grad = np.zeros_like(self.k)</span><br><span class="line">        self.b_grad = np.zeros_like(self.b)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_unfold_k</span>(<span class="params">self, h: <span class="built_in">int</span>, w: <span class="built_in">int</span>, c1: <span class="built_in">int</span>, c2: <span class="built_in">int</span>, k1: <span class="built_in">int</span>, k2: <span class="built_in">int</span>, o1: <span class="built_in">int</span>, o2: <span class="built_in">int</span></span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;展开卷积核 k, 能够与展平的多通道图像直接相乘</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            k: (c2 * o1 * o2, c1 * H * W)</span></span><br><span class="line"><span class="string">                有 c2 个 (o1 * o2, c1 * H * W) 的展平卷积核, 每一个核大小是 c1 * H * W, 将在一张 c1 通道的一维图片上进行 o1 * o2 次卷积</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        ridx = np.arange(o1 * o2).reshape(-<span class="number">1</span>, <span class="number">1</span>).repeat(k1 * k2, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        cidx1 = np.arange(o2).reshape(<span class="number">1</span>, -<span class="number">1</span>).repeat(k1 * k2, <span class="number">1</span>).repeat(o1, <span class="number">0</span>).reshape(o1 * o2, k1 * k2)</span><br><span class="line">        cidx2 = np.arange(k2).reshape(<span class="number">1</span>, -<span class="number">1</span>).repeat(o1 * o2 * k1, <span class="number">0</span>).reshape(o1 * o2, k1 * k2)</span><br><span class="line">        cidx3 = np.arange(<span class="number">0</span>, k1 * w, w).reshape(<span class="number">1</span>, -<span class="number">1</span>).repeat(k2, <span class="number">1</span>).repeat(o1 * o2, <span class="number">0</span>)</span><br><span class="line">        cidx4 = np.arange(<span class="number">0</span>, o1 * w, w).reshape(-<span class="number">1</span>, <span class="number">1</span>).repeat(o2, <span class="number">0</span>).repeat(k1 * k2, <span class="number">1</span>)</span><br><span class="line">        cidx = cidx1 + cidx2 + cidx3 + cidx4</span><br><span class="line"></span><br><span class="line">        k = np.zeros((c2, c1, o1 * o2, h * w))</span><br><span class="line">        k[:, :, ridx, cidx] = self.k.reshape(c2, c1, <span class="number">1</span>, k1 * k2).repeat(o1 * o2, <span class="number">2</span>)</span><br><span class="line">        k = k.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).reshape(c2 * o1 * o2, c1 * h * w)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> k</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_unfold_x</span>(<span class="params">self, x: np.ndarray, c1: <span class="built_in">int</span>, k1: <span class="built_in">int</span>, k2: <span class="built_in">int</span>, o1: <span class="built_in">int</span>, o2: <span class="built_in">int</span></span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;展开输入 x, 能够与展平的卷积核直接相乘</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, c1, H, W)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x: (B, o1 * o2, c1 * k1 * k2)</span></span><br><span class="line"><span class="string">                每张图片将与 c1 通道的一维卷积核进行 o1 * o2 次卷积</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        ridx_r = np.arange(k1).reshape(<span class="number">1</span>, k1).repeat(k2, <span class="number">1</span>).repeat(o1 * o2, <span class="number">0</span>)</span><br><span class="line">        ridx_c = np.arange(o1).reshape(o1, <span class="number">1</span>).repeat(o2, <span class="number">0</span>).repeat(k1 * k2, <span class="number">1</span>)</span><br><span class="line">        ridx = ridx_r + ridx_c</span><br><span class="line"></span><br><span class="line">        cidx_r = np.arange(k2).reshape(<span class="number">1</span>, k2).repeat(k1, <span class="number">0</span>).reshape(<span class="number">1</span>, -<span class="number">1</span>).repeat(o1 * o2, <span class="number">0</span>)</span><br><span class="line">        cidx_c = np.arange(o2).reshape(<span class="number">1</span>, o2).repeat(o1, <span class="number">0</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>).repeat(k1 * k2, <span class="number">1</span>)</span><br><span class="line">        cidx = cidx_r + cidx_c</span><br><span class="line"></span><br><span class="line">        x = x[:, :, ridx, cidx].transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).reshape(-<span class="number">1</span>, o1 * o2, c1 * k1 * k2)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, c1, H, W)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x: (B, c2, o1, o2)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        _, _, h, w = x.shape</span><br><span class="line">        c2, c1, k1, k2 = self.k.shape</span><br><span class="line">        o1 = h - k1 + <span class="number">1</span></span><br><span class="line">        o2 = w - k2 + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 展开卷积核</span></span><br><span class="line">        output = x.reshape(-<span class="number">1</span>, c1 * h * w) @ self._unfold_k(h, w, c1, c2, k1, k2, o1, o2).T</span><br><span class="line">        output = output.reshape(-<span class="number">1</span>, c2, o1, o2) + self.b</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">        <span class="comment"># # 展开输入 (B, o1 * o2, c1 * k1 * k2) @ (c1 * k1 * k2, c2) = (B, o1 * o2, c2)</span></span><br><span class="line">        <span class="comment"># output = self._unfold_x(x, c1, k1, k2, o1, o2) @ self.k.reshape(c2, c1 * k1 * k2).T</span></span><br><span class="line">        <span class="comment"># output = output.transpose(0, 2, 1).reshape(-1, c2, o1, o2) + self.b</span></span><br><span class="line">        <span class="comment"># return output</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, x: np.ndarray, last_x_grad: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, c1, H, W)</span></span><br><span class="line"><span class="string">            last_x_grad: (B, c2, o1, o2)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x_grad: (B, c1, H, W)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        _, _, h, w = x.shape</span><br><span class="line">        c2, c1, k1, k2 = self.k.shape</span><br><span class="line">        o1 = h - k1 + <span class="number">1</span></span><br><span class="line">        o2 = w - k2 + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        unfold_x = self._unfold_x(x, c1, k1, k2, o1, o2)</span><br><span class="line">        unfold_k = self._unfold_k(h, w, c1, c2, k1, k2, o1, o2)</span><br><span class="line"></span><br><span class="line">        self.b_grad = last_x_grad.<span class="built_in">sum</span>((<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">        self.k_grad = unfold_x.reshape(-<span class="number">1</span>, c1 * k1 * k2).T @ last_x_grad.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(-<span class="number">1</span>, c2)</span><br><span class="line">        self.k_grad = self.k_grad.transpose().reshape(c2, c1, k1, k2)</span><br><span class="line"></span><br><span class="line">        x_grad = last_x_grad.reshape(-<span class="number">1</span>, c2 * o1 * o2) @ unfold_k</span><br><span class="line">        x_grad = x_grad.reshape(-<span class="number">1</span>, c1, h, w)</span><br><span class="line">        <span class="keyword">return</span> x_grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, lr: <span class="built_in">float</span></span>):</span><br><span class="line">        self.k -= lr * self.k_grad</span><br><span class="line">        self.b -= lr * self.b_grad</span><br></pre></td></tr></table></figure>

<p>这里的 <code>_unfold_k</code> 和 <code>_unfold_x</code> 就是对卷积核 $\mathbf{K}$ 和输入 $\mathbf{X}$ 进行数据重组的方法, 可以用于不同的前向和反向梯度计算. 前向中实现两种矩阵化方法的一种就行, 而反向中则需要同时使用两个方法来计算参数梯度.</p>
<h2 id="损失函数层"><a href="#损失函数层" class="headerlink" title="损失函数层"></a>损失函数层</h2><p>最后是网络的损失函数, 从 <code>Linear</code> 层往后, 将网络的输出与真实标签进行损失计算.</p>
<p>这里我们实现分类任务最常用的损失函数, 交叉熵损失函数, 它的前向和反向所需要的参数与前面的网络层有一些小的区别, 均需要输入真实标签值.</p>
<h3 id="CrossEntropy"><a href="#CrossEntropy" class="headerlink" title="CrossEntropy"></a>CrossEntropy</h3><p>首先上交叉熵损失的公式. 损失计算从线性层的输出开始, 设函数输入为 $\mathbf{X}$, 形状为 $n \times C$, 真实标签 $\mathbf{y}$ 为长度是 $n$ , 取值范围 $[1, C]$ 的向量, 则损失 $L$:</p>
<p>$$<br>\begin{aligned}<br>  L &amp;= \frac{1}{n} \sum_{i=1}^{n} {\left( -\log\left( \frac{\exp\left( {x_{i y_i}} \right)}{\sum_{j=1}^{C}{\exp\left(x_{ij}\right)}} \right) \right)} \\<br>  ~ &amp;= \frac{1}{n} \sum_{i=1}^{n} {\left( -\log\left( \frac{\exp\left({x_{i y_i} - \max_{j=1}^{C}{x_{ij}}}\right)}{\sum_{j=1}^{C}{\exp\left(x_{ij} - \max_{j=1}^{C}{x_{ij}} \right)}} \right) \right)} \\<br>  ~ &amp;= \frac{1}{n} \sum_{i=1}^{n} {\left( \log\left( \sum_{j=1}^{C}{\exp\left(x_{ij} - \max_{j=1}^{C}{x_{ij}} \right)} \right) - \left({x_{i y_i} - \max_{j=1}^{C}{x_{ij}}}\right) \right)} \\<br>  ~ &amp;= \frac{1}{n} \sum_{i=1}^{n} {\left( \log\left( \sum_{j=1}^{C}{\exp\left(x_{ij}&#39; \right)} \right) - x_{i y_i}&#39; \right)}<br>\end{aligned}<br>$$</p>
<p>详细的原理就不说了, 网上都有, 这里说一下为什么要给每个 $x$ 减去 $\max_{j=1}^{C}{x_{ij}}$, 因为中间用到了指数函数, 所以为了防止数据溢出, 将数据都变换到小于等于 0 的区间, 这样指数函数的值域就在 $(0, 1]$, 容易看出来这种变换是等价不影响计算结果的.</p>
<p>前向计算就这样了, 然后看反向梯度计算. 注意到最外层是将每个样本的 &quot;小损失 $L_i$&quot; 进行了求和平均, 所以我们先看求和符号内每一个样本的值如何求梯度.</p>
<p>掏出高中求导知识, 很容易得到:</p>
<p>$$<br>\frac{\partial{L_i}}{\partial{x_{ij}}} = \left\{<br>  \begin{aligned}<br>    &amp; \frac{\exp{(x_{ij}&#39;)}}{\sum_{j=1}^{C}{\exp\left(x_{ij}&#39; \right)}}     &amp; , ~ &amp; j \neq y_i \\<br>    &amp; \frac{\exp{(x_{ij}&#39;)}}{\sum_{j=1}^{C}{\exp\left(x_{ij}&#39; \right)}} - 1 &amp; , ~ &amp; j = y_i<br>  \end{aligned}<br>\right.<br>$$</p>
<p>这里为了防止数据溢出, 同样使用 $x&#39;_{ij}$ 而不是原始输入值.</p>
<p>最后, 由于求和平均的关系, 整个梯度也需要乘上一个系数, 因此有最终的梯度计算公式:</p>
<p>$$<br>\begin{aligned}<br>  \frac{\partial{L}}{\partial{x_{ij}}} &amp;= \frac{\partial{L}}{\partial{L_i}}\frac{\partial{L_i}}{\partial{x_{ij}}} \\<br>  ~ &amp;= \frac{1}{n}\frac{\partial{L_i}}{\partial{x_{ij}}} \\<br>  ~ &amp;= \left\{<br>  \begin{aligned}<br>    &amp; \frac{1}{n}\left( \frac{\exp{(x_{ij}&#39;)}}{n\sum_{j=1}^{C}{\exp\left(x_{ij}&#39; \right)}} \right) &amp; , ~ &amp; j \neq y_i \\<br>    &amp; \frac{1}{n}\left( \frac{\exp{(x_{ij}&#39;)}}{n\sum_{j=1}^{C}{\exp\left(x_{ij}&#39; \right)}} - 1 \right) &amp; , ~ &amp; j = y_i<br>  \end{aligned}<br>\right.<br>\end{aligned}<br>$$</p>
<p>至此, 损失函数的前向和反向都已经推导完成, 然后完成代码实现.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CrossEntropyLoss</span>(<span class="title class_ inherited__">NetworkLayer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray, y: np.ndarray</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, C)</span></span><br><span class="line"><span class="string">            y: (B, )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            loss: float number</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = x - x.<span class="built_in">max</span>(-<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        loss = np.log(np.exp(x).<span class="built_in">sum</span>(-<span class="number">1</span>)) - x[np.arange(x.shape[<span class="number">0</span>]), y]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">float</span>(loss.mean())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, x: np.ndarray, y: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, C)</span></span><br><span class="line"><span class="string">            y: (B, )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x_grad: (B, C)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        exp_x = np.exp(x - x.<span class="built_in">max</span>(-<span class="number">1</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line">        x_grad = exp_x / exp_x.<span class="built_in">sum</span>(-<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        x_grad[np.arange(x.shape[<span class="number">0</span>]), y] -= <span class="number">1</span></span><br><span class="line">        x_grad /= x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x_grad</span><br></pre></td></tr></table></figure>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本篇到此结束, 我们终于完成了网络需要的所有基础结构. 而下一篇, 也是最后一篇, 我们将把这些零件拼接起来, 组合出最终的卷积神经网络, 并完成对网络的训练和评估.</p>
<p>本系列文章传送门:</p>
<ul>
<li><a href="/posts/2023/10/13/cnn-numpy-1/">基于 NumPy 的手写数字识别 (卷积神经网络) (一)</a></li>
<li><a href="/posts/2023/10/14/cnn-numpy-2/">基于 NumPy 的手写数字识别 (卷积神经网络) (二)</a></li>
<li><a href="/posts/2023/10/15/cnn-numpy-3/">基于 NumPy 的手写数字识别 (卷积神经网络) (三)</a></li>
</ul>
]]></content>
      <categories>
        <category>代码块</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>矩阵求导</tag>
        <tag>卷积矩阵化</tag>
        <tag>交叉熵损失函数</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 NumPy 的手写数字识别 (卷积神经网络) (三)</title>
    <url>//posts/2023/10/15/cnn-numpy-3/</url>
    <content><![CDATA[<blockquote>
<p>&quot;基于 numpy 的手写数字识别&quot;, 这一经典问题除了用作深度学习入门内容, 还被广泛作为各大课程的课程作业, 因此在各大搜索引擎上搜索率也是相当之高<del>(代码复用率也是相当之高)</del>. 网上确实有挺多现成的可使用代码, 但是大部分都是造的全连接网络, 并且很多时候内部原理不是特别清晰. 因此决定自己也来造一次轮子, 使用 <code>numpy</code> 实现一个简单的卷积神经网络进行手写数字识别, 正好也能借此机会梳理一下神经网络的基本原理.</p>
<p>全文包含完整的卷积网络实现, 以及矩阵梯度和卷积矩阵化的推导过程, 由于全文过长, 因此分成了三部分, 内容上是完全连着的.</p>
</blockquote>
<p>本文为第三篇, 也是最后一篇, 结合前两篇的内容搭建完整的卷积神经网络并完成训练和评估.</p>
<span id="more"></span>

<p>本系列文章传送门:</p>
<ul>
<li><a href="/posts/2023/10/13/cnn-numpy-1/">基于 NumPy 的手写数字识别 (卷积神经网络) (一)</a></li>
<li><a href="/posts/2023/10/14/cnn-numpy-2/">基于 NumPy 的手写数字识别 (卷积神经网络) (二)</a></li>
<li><a href="/posts/2023/10/15/cnn-numpy-3/">基于 NumPy 的手写数字识别 (卷积神经网络) (三)</a></li>
</ul>
<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>因为只是一个简单的示例, 所以弄一个小一点的网络, 大概长这样.</p>
<p><img data-src="/static/image/cnn-numpy-3/cnn.jpg" alt="cnn.jpg"></p>
<p>然后就是按照这个结构用代码把前面实现的层串起来.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvolutionNeuralNetwork</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Conv -&gt; Pool -&gt; ReLU -&gt; Conv -&gt; Pool -&gt; ReLU -&gt; Flatten -&gt; Linear -&gt; CrossEntropy</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.layers = [</span><br><span class="line">            ConvolutionLayer(<span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>),  <span class="comment"># 24 * 24</span></span><br><span class="line">            MaxPoolingLayer(<span class="number">2</span>, <span class="number">2</span>),  <span class="comment"># 12 * 12</span></span><br><span class="line">            ReLULayer(),</span><br><span class="line">            ConvolutionLayer(<span class="number">4</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">3</span>),  <span class="comment"># 10 * 10</span></span><br><span class="line">            MaxPoolingLayer(<span class="number">2</span>, <span class="number">2</span>),  <span class="comment"># 5 * 5</span></span><br><span class="line">            ReLULayer(),</span><br><span class="line">            FlattenLayer(),</span><br><span class="line">            LinearLayer(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">        ]</span><br><span class="line">        self.loss_func = CrossEntropyLoss()</span><br><span class="line">        self.layer_inputs = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray, keepgrad: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, C_ch, H, W), images</span></span><br><span class="line"><span class="string">            keepgrad: whether keep temp layer inputs</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x: (B, C_cls), logits</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            <span class="keyword">if</span> keepgrad:</span><br><span class="line">                self.layer_inputs.append(x)</span><br><span class="line">            x = layer.forward(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, last_x_grad: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            last_x_grad: (B, C_cls), computed by loss function</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            last_x_grad: (B, C_ch, H, W)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x, layer <span class="keyword">in</span> <span class="built_in">zip</span>(self.layer_inputs[::-<span class="number">1</span>], self.layers[::-<span class="number">1</span>]):</span><br><span class="line">            last_x_grad = layer.backward(x, last_x_grad)</span><br><span class="line">        <span class="keyword">return</span> last_x_grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, lr: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, ParamLayer):</span><br><span class="line">                layer.update(lr)</span><br></pre></td></tr></table></figure>

<p>这里网络同样需要实现 <code>forward</code> 和 <code>backward</code> 方法, 但是增加了 <code>layer_inputs</code> 成员, 用于保存网络的计算图中间节点, 在反向传播时能直接读取数据计算.</p>
<p>至于网络每层的参数填多大, 得视数据量和网络深度决定<del>玄学问题</del>, 这里就填了几个比较小的值, 方便下一步训练.</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>然后实现网络的训练代码.</p>
<p>训练分几个固定步骤:</p>
<ol>
<li>前向传播</li>
<li>计算损失</li>
<li>反向传播</li>
<li>更新参数</li>
<li>清空本次计算的中间值和梯度</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvolutionNeuralNetwork</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Conv -&gt; Pool -&gt; ReLU -&gt; Conv -&gt; Pool -&gt; ReLU -&gt; Flatten -&gt; Linear -&gt; CrossEntropy</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>: ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray, keepgrad: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; np.ndarray: ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, last_x_grad: np.ndarray</span>) -&gt; np.ndarray: ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, lr: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>: ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, train_x: np.ndarray, train_y: np.ndarray, batch_size: <span class="built_in">int</span>, epochs: <span class="built_in">int</span>, lr: <span class="built_in">float</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            loss: mean loss for train_x</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        losses = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, train_x.shape[<span class="number">0</span>], batch_size):</span><br><span class="line">            inputs, targets = train_x[i:i+batch_size], train_y[i:i+batch_size]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># forward</span></span><br><span class="line">            logits = self.forward(inputs, <span class="literal">True</span>)</span><br><span class="line">            loss = self.loss_func.forward(logits, targets)</span><br><span class="line">            losses.append(loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># backward</span></span><br><span class="line">            last_x_grad = self.loss_func.backward(logits, targets)</span><br><span class="line">            self.backward(last_x_grad)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># update</span></span><br><span class="line">            self.update(lr)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># clear temp values</span></span><br><span class="line">            self.layer_inputs.clear()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(losses) / <span class="built_in">len</span>(losses)</span><br></pre></td></tr></table></figure>

<h3 id="测试和预测"><a href="#测试和预测" class="headerlink" title="测试和预测"></a>测试和预测</h3><p>测试和训练步骤是类似的, 但是不需要计算损失和梯度, 同时也不需要保留中间计算结果.</p>
<p>而预测则是在 <code>forward</code> 的基础上, 将输出结果使用 <code>Softmax</code> 函数转换成概率值, 公式如下:</p>
<p>$$<br>\begin{aligned}<br>  Softmax(x_{ij}) &amp;= \frac{\exp\left( {x_{ij}} \right)}{\sum_{j=1}^{C}{\exp\left(x_{ij}\right)}} \\<br>  ~ &amp;= \frac{\exp\left( {x_{ij} - \max_{j=1}^{C}{x_{ij}}} \right)}{\sum_{j=1}^{C}{\exp\left(x_{ij} - \max_{j=1}^{C}{x_{ij}}\right)}} \\<br>  ~ &amp;= \frac{\exp\left( {x_{ij}&#39;} \right)}{\sum_{j=1}^{C}{\exp\left(x_{ij}&#39;\right)}}<br>\end{aligned}<br>$$</p>
<p>其实就是在计算交叉熵损失中间 $\log$ 括号内的内容, 并且同样可以减去最大值来防止数据溢出.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvolutionNeuralNetwork</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Conv -&gt; Pool -&gt; ReLU -&gt; Conv -&gt; Pool -&gt; ReLU -&gt; Flatten -&gt; Linear -&gt; CrossEntropy</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>: ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: np.ndarray, keepgrad: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; np.ndarray: ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, last_x_grad: np.ndarray</span>) -&gt; np.ndarray: ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, lr: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>: ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, train_x: np.ndarray, train_y: np.ndarray, batch_size: <span class="built_in">int</span>, epochs: <span class="built_in">int</span>, lr: <span class="built_in">float</span></span>) -&gt; <span class="built_in">float</span>: ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self, test_x: np.ndarray, test_y: np.ndarray, batch_size: <span class="built_in">int</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            loss: mean loss for test_x</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        losses = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, test_x.shape[<span class="number">0</span>], batch_size):</span><br><span class="line">            inputs, targets = test_x[i:i+batch_size], test_y[i:i+batch_size]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># forward</span></span><br><span class="line">            logits = self.forward(inputs)</span><br><span class="line">            loss = self.loss_func.forward(logits, targets)</span><br><span class="line">            losses.append(loss)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(losses) / <span class="built_in">len</span>(losses)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, x: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, C_ch, H, W), images</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x: (B, C_cls), probs by softmax</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        x = self.forward(x)</span><br><span class="line">        exp_x = np.exp(x - x.<span class="built_in">max</span>(-<span class="number">1</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line">        outputs = exp_x / exp_x.<span class="built_in">sum</span>(-<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>

<h2 id="训练并评估网络"><a href="#训练并评估网络" class="headerlink" title="训练并评估网络"></a>训练并评估网络</h2><p>完成网络搭建后, 接下来就是进行训练和评估. 先贴上完整的代码.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    np.random.seed(<span class="number">1234</span>)</span><br><span class="line"></span><br><span class="line">    train_x, train_y = load_dataset(<span class="string">&quot;./cv-data/train&quot;</span>, <span class="literal">True</span>)</span><br><span class="line">    test_x, test_y = load_dataset(<span class="string">&quot;./cv-data/test&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(train_x.shape, train_y.shape)</span><br><span class="line">    <span class="built_in">print</span>(test_x.shape, test_y.shape)</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">100</span></span><br><span class="line">    epochs = <span class="number">200</span></span><br><span class="line">    lr = <span class="number">0.1</span></span><br><span class="line">    cnn = ConvolutionNeuralNetwork()</span><br><span class="line"></span><br><span class="line">    train_losses = []</span><br><span class="line">    test_losses = []</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=============== Begin Train ===============&quot;</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        train_loss = cnn.train(train_x, train_y, batch_size, epochs, lr)</span><br><span class="line">        test_loss = cnn.test(test_x, test_y, batch_size)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;i + <span class="number">1</span>:3d&#125;</span> Train Loss: <span class="subst">&#123;train_loss:<span class="number">.4</span>f&#125;</span> Test Loss: <span class="subst">&#123;test_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        train_losses.append(train_loss)</span><br><span class="line">        test_losses.append(test_loss)</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;=============== End Train: <span class="subst">&#123;time_elapsed / <span class="number">60</span>:<span class="number">.2</span>f&#125;</span> min ===============&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_losses = np.array(train_losses)</span><br><span class="line">    test_losses = np.array(test_losses)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制损失变化曲线, 忽略第一轮损失</span></span><br><span class="line">    plt.plot(np.arange(train_losses.shape[<span class="number">0</span>]-<span class="number">1</span>), train_losses[<span class="number">1</span>:], label=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">    plt.plot(np.arange(test_losses.shape[<span class="number">0</span>]-<span class="number">1</span>), test_losses[<span class="number">1</span>:], label=<span class="string">&quot;test&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.savefig(<span class="string">&quot;loss.png&quot;</span>)</span><br><span class="line"></span><br><span class="line">    y_true = train_y</span><br><span class="line">    y_pred = cnn.predict(train_x).argmax(-<span class="number">1</span>)</span><br><span class="line">    report = classification_report(y_true, y_pred, digits=<span class="number">4</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=============== Classification Report: Train ===============&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(report)</span><br><span class="line"></span><br><span class="line">    y_true = test_y</span><br><span class="line">    y_pred = cnn.predict(test_x).argmax(-<span class="number">1</span>)</span><br><span class="line">    report = classification_report(y_true, y_pred, digits=<span class="number">4</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=============== Classification Report: Test ===============&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(report)</span><br></pre></td></tr></table></figure>

<p>这里为了稳定结果, 固定了一下随机种子为 <code>1234</code>.</p>
<p>有三个训练的超参数:</p>
<ul>
<li><code>batch_size</code>: 每一轮 mini-batch 的大小.</li>
<li><code>epochs</code>: 共训练多少轮.</li>
<li><code>lr</code>: 网络学习率.</li>
</ul>
<p>具体填多少得反复尝试<del>也是炼丹的精髓</del>, 这里学习率是尝试后收敛比较快而且比较稳定的一个值.</p>
<p>中途把每一轮的损失记录一下, 并且用 <code>matplotlib.pyplot</code> 画个简单的曲线图, 对比一下训练集和测试集损失随轮数的变化关系.</p>
<p>最后借用一下 <code>classification_report</code> 来看看网络在训练集和测试集上的分类性能报告.</p>
<p>200 轮的训练大概跑了 20 分钟左右, 挺久的.</p>
<p>损失曲线图:</p>
<p><img data-src="/static/image/cnn-numpy-3/loss.png" alt="loss.jpg"></p>
<p>分类性能报告:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">=============== Classification Report: Train ===============</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0     0.9970    0.9900    0.9935       999</span><br><span class="line">           1     0.9955    0.9928    0.9941      1106</span><br><span class="line">           2     0.9871    0.9765    0.9818      1020</span><br><span class="line">           3     0.9814    0.9786    0.9800      1027</span><br><span class="line">           4     0.9958    0.9712    0.9834       973</span><br><span class="line">           5     0.9821    0.9854    0.9838       891</span><br><span class="line">           6     0.9959    0.9939    0.9949       977</span><br><span class="line">           7     0.9750    0.9887    0.9818      1063</span><br><span class="line">           8     0.9567    0.9888    0.9725       984</span><br><span class="line">           9     0.9781    0.9771    0.9776       960</span><br><span class="line"></span><br><span class="line">    accuracy                         0.9844     10000</span><br><span class="line">   macro avg     0.9845    0.9843    0.9843     10000</span><br><span class="line">weighted avg     0.9845    0.9844    0.9844     10000</span><br><span class="line"></span><br><span class="line">=============== Classification Report: Test ===============</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0     0.9517    0.9848    0.9679       460</span><br><span class="line">           1     0.9723    0.9825    0.9774       571</span><br><span class="line">           2     0.9618    0.9491    0.9554       530</span><br><span class="line">           3     0.9298    0.9540    0.9418       500</span><br><span class="line">           4     0.9630    0.9360    0.9493       500</span><br><span class="line">           5     0.9538    0.9518    0.9528       456</span><br><span class="line">           6     0.9581    0.9416    0.9498       462</span><br><span class="line">           7     0.9384    0.9219    0.9300       512</span><br><span class="line">           8     0.9039    0.9427    0.9229       489</span><br><span class="line">           9     0.9324    0.9019    0.9169       520</span><br><span class="line"></span><br><span class="line">    accuracy                         0.9466      5000</span><br><span class="line">   macro avg     0.9465    0.9466    0.9464      5000</span><br><span class="line">weighted avg     0.9468    0.9466    0.9466      5000</span><br></pre></td></tr></table></figure>

<p>效果还不错, 损失曲线也很经典, 大约从 15 轮开始收敛, 120 轮左右测试集损失就差不多到底了. 中途试过一些别的随机种子, 收敛速度有差异, 但是最终的损失值都差不多.</p>
<p>分类性能的话, 训练集的 F1 值和测试集差了 4% 左右, 看着也还不错, 正常表现.</p>
<h2 id="进一步探索"><a href="#进一步探索" class="headerlink" title="进一步探索"></a>进一步探索</h2><p>到这里我们就已经彻底完成了基于纯 NumPy 手工搭建的卷积神经网络了, 从这个过程中我们可以了解到很多底层原理以及一些细节问题, 比如参数的初始化和训练超参数的调节. 大部分时间我们都是使用深度学习框架来完成这些事情, 我们只需要专注于搭积木即可. 这里联系一下我常用的 PyTorch 库, 里面内置了很多不同的模块, 分别对应整个网络搭建和训练过程中的基本环节.</p>
<ul>
<li><code>torch.utils.data</code>: 数据处理模块, 控制数据的读取和迭代方式.</li>
<li><code>torch.nn</code>: 常用的网络模块, 例如 <code>Linear</code> 和 <code>Conv2d</code>.</li>
<li><code>torch.nn.functional</code>: <code>torch.nn</code> 中模块的函数形式, 需要手动传入计算的参数.</li>
<li><code>torch.nn.init</code>: 不同的网络参数初始化方法.</li>
<li><code>torch.optim</code>: 优化器模块, 包含不同的学习率调整算法, 控制网络的优化过程.</li>
</ul>
<p>这是一些常用的, 还有很多, 可以去看看 <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9pbmRleC5odG1s">PyTorch 文档<i class="fa fa-external-link-alt"></i></span>并加以实践.</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>这份文档写了很久, 起因是觉得要是下次再碰到相关的问题, 自己有轮子和内容就不用上网找了<del>属实是闲着没事</del>. 前后花了一两周的时间, 因为要从头跑一份代码, 然后又是调公式又是画图, 不过算是彻底复习了一遍神经网络, 把很多深度学习框架的使用原理都串起来了, 还是挺好的.</p>
<p>这个系列就此圆满结束<del>作业报告从此一劳永逸</del>.</p>
]]></content>
      <categories>
        <category>代码块</category>
      </categories>
      <tags>
        <tag>手写数字识别</tag>
        <tag>卷积神经网络</tag>
        <tag>深度学习</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始的 DDPM 动漫头像生成</title>
    <url>//posts/2024/02/16/ddpm/</url>
    <content><![CDATA[<p>Stable Diffusion 已经火了很久了, 在此之前也是在自己电脑上部署过 Github 上那个 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0FVVE9NQVRJQzExMTEvc3RhYmxlLWRpZmZ1c2lvbi13ZWJ1aQ==">stable-diffusion-webui<i class="fa fa-external-link-alt"></i></span>. 作为一个折腾分子, 本着更深入了解一下概率扩散模型的想法, 决定在参考其他教程的基础上从零开始炼制一个基于 DDPM 的动漫头像生成模型.</p>
<span id="more"></span>

<h2 id="基础设施"><a href="#基础设施" class="headerlink" title="基础设施"></a>基础设施</h2><p>没钱没精力折腾服务器, 用的自己的笔记本.</p>
<ul>
<li>Win11</li>
<li>CPU <code>i7-13700H</code></li>
<li>内存 16 GB</li>
<li>显卡 <code>NVIDIA GeForce RTX 4060 Laptop GPU</code>, 8 GB 显存.</li>
<li>显卡驱动版本 <code>551.23</code></li>
<li>CUDA 版本 <code>12.4</code></li>
<li>python <code>3.9.13</code></li>
<li>torch <code>2.0.1+cu118</code></li>
</ul>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>有两个数据集, 都是从 <span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS8=">Kaggle<i class="fa fa-external-link-alt"></i></span> 上下的.</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9kYXRhc2V0cy9zb3VtaWtyYWtzaGl0L2FuaW1lLWZhY2Vz">Anime Faces<i class="fa fa-external-link-alt"></i></span>, 21551 张.</li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9kYXRhc2V0cy9zcGxjaGVyL2FuaW1lZmFjZWRhdGFzZXQ=">Anime Face Dataset<i class="fa fa-external-link-alt"></i></span>, 63632 张.</li>
</ul>
<p>合起来有 8 万多张 (前一个貌似是第二个的子集?).</p>
<p>但是最后只用了 2 万张那个, 因为 6 万的质量不是太高, 训练出来不是很稳定.</p>
<h2 id="依赖库"><a href="#依赖库" class="headerlink" title="依赖库"></a>依赖库</h2><p>主要用的原生 PyTorch, 训练和测试都是手写的, 其他库只是辅助输出和使用.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span>, <span class="type">Sequence</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> rich.progress</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim.adam <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataloader <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataset <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> make_grid</span><br></pre></td></tr></table></figure>

<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>这部分内容主要参考 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xhYm1sYWkvYW5ub3RhdGVkX2RlZXBfbGVhcm5pbmdfcGFwZXJfaW1wbGVtZW50YXRpb25z">annotated_deep_learning_paper_implementations<i class="fa fa-external-link-alt"></i></span> 这个仓库, 一个开源的复现各种论文模型的库, 但是参考的时候发现还是有很多问题, 所以仅供参考.</p>
<p>另外一个库则是 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2x1Y2lkcmFpbnMvZGVub2lzaW5nLWRpZmZ1c2lvbi1weXRvcmNo">denoising-diffusion-pytorch<i class="fa fa-external-link-alt"></i></span>, 是原论文的 PyTorch 实现, 但是和原论文的实现细节有很大不同, 所以也仅仅用于参考.</p>
<p>此外模型结构上还参考了一篇知乎帖子, <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NTU1Njg5MTA=">深入浅出扩散模型(Diffusion Model)系列：基石DDPM（源码解读篇）<i class="fa fa-external-link-alt"></i></span>, 这篇帖子是对 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xhYm1sYWkvYW5ub3RhdGVkX2RlZXBfbGVhcm5pbmdfcGFwZXJfaW1wbGVtZW50YXRpb25z">annotated_deep_learning_paper_implementations<i class="fa fa-external-link-alt"></i></span> 源码的分析, 省去了不少自己读代码的时间.</p>
<details class="note "><summary><p><strong>[点击展开]</strong> 模型代码</p>
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TimeEmbedding</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Sinusoidal Time Embedding.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, fourier_channels: <span class="built_in">int</span>, time_channels: <span class="built_in">int</span>, theta: <span class="built_in">int</span> = <span class="number">10000</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Sinusoidal Time Embedding.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            t: (B, )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            time_embedding: (B, time_c)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.fourier_channels = fourier_channels</span><br><span class="line">        self.time_channels = time_channels</span><br><span class="line">        self.theta = theta</span><br><span class="line">        self.half_dim = self.fourier_channels // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        self.mlp = nn.Sequential(</span><br><span class="line">            nn.Linear(self.fourier_channels, self.time_channels),</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Linear(self.time_channels, self.time_channels),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        emb_coef = math.log(self.theta) / (self.half_dim - <span class="number">1</span>)</span><br><span class="line">        emb_coef = torch.exp(torch.arange(self.half_dim) * -emb_coef)</span><br><span class="line"></span><br><span class="line">        self.emb_coef: torch.Tensor</span><br><span class="line">        self.register_buffer(<span class="string">&quot;emb_coef&quot;</span>, emb_coef, <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, t: torch.Tensor</span>):</span><br><span class="line">        emb = t[:, <span class="literal">None</span>] * self.emb_coef[<span class="literal">None</span>, :]</span><br><span class="line">        emb = torch.cat((emb.sin(), emb.cos()), dim=<span class="number">1</span>)</span><br><span class="line">        emb = self.mlp(emb)</span><br><span class="line">        <span class="keyword">return</span> emb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Residual block.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    A residual block has two convolution layers with group normalization.</span></span><br><span class="line"><span class="string">        Each resolution is processed with two residual blocks.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, out_channels: <span class="built_in">int</span>, time_channels: <span class="built_in">int</span>, num_groups: <span class="built_in">int</span> = <span class="number">32</span>, dropout: <span class="built_in">float</span> = <span class="number">0.1</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Residual block.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            x: (B, in_c, h, w)</span></span><br><span class="line"><span class="string">            t: (B, time_c)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            x: (B, out_c, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.GroupNorm(num_groups, in_channels),</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.time_emb = nn.Sequential(</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Linear(time_channels, out_channels),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            nn.GroupNorm(num_groups, out_channels),</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> in_channels != out_channels:</span><br><span class="line">            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.shortcut = nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, t: torch.Tensor</span>):</span><br><span class="line">        h = self.conv1(x)</span><br><span class="line">        h = h + self.time_emb(t)[:, :, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">        h = self.conv2(h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> h + self.shortcut(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AttentionBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multihead Attention block&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_channels: <span class="built_in">int</span>, num_heads: <span class="built_in">int</span> = <span class="number">1</span>, num_groups: <span class="built_in">int</span> = <span class="number">32</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Multihead Attention block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            x: (B, num_c, h, w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            x: (B, num_c, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.norm = nn.GroupNorm(num_groups, num_channels)</span><br><span class="line">        self.attn = nn.MultiheadAttention(num_channels, num_heads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line"></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        x = x.view(B, C, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        res, _ = self.attn(x, x, x, need_weights=<span class="literal">False</span>)</span><br><span class="line">        x = x + res</span><br><span class="line"></span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).view(B, C, H, W)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DownBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Down block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This combines `ResidualBlock` and `AttentionBlock`. These are used in the first half of U-Net at each resolution.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, out_channels: <span class="built_in">int</span>, time_channels: <span class="built_in">int</span>, has_attn: <span class="built_in">bool</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Down block.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            x: (B, in_c, h, w)</span></span><br><span class="line"><span class="string">            t: (B, time_c)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            x: (B, out_c, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.res = ResidualBlock(in_channels, out_channels, time_channels)</span><br><span class="line">        <span class="keyword">if</span> has_attn:</span><br><span class="line">            self.attn = AttentionBlock(out_channels)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.attn = nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, t: torch.Tensor</span>):</span><br><span class="line">        x = self.res(x, t)</span><br><span class="line">        x = self.attn(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MiddleBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Middle block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It combines a `ResidualBlock`, `AttentionBlock`, followed by another `ResidualBlock`.</span></span><br><span class="line"><span class="string">        This block is applied at the lowest resolution of the U-Net.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_channels: <span class="built_in">int</span>, time_channels: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Middle block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            x: (B, num_c, h, w)</span></span><br><span class="line"><span class="string">            t: (B, time_c)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            x: (B, num_c, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.res1 = ResidualBlock(num_channels, num_channels, time_channels)</span><br><span class="line">        self.attn = AttentionBlock(num_channels)</span><br><span class="line">        self.res2 = ResidualBlock(num_channels, num_channels, time_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, t: torch.Tensor</span>):</span><br><span class="line">        x = self.res1(x, t)</span><br><span class="line">        x = self.attn(x)</span><br><span class="line">        x = self.res2(x, t)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UpBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Up block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This combines `ResidualBlock` and `AttentionBlock`. These are used in the second half of U-Net at each resolution.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, out_channels: <span class="built_in">int</span>, time_channels: <span class="built_in">int</span>, has_attn: <span class="built_in">bool</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Up block.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            x: (B, in_c, h, w)</span></span><br><span class="line"><span class="string">            x_left: (B, out_c, h, w)</span></span><br><span class="line"><span class="string">            t: (B, time_c)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            x: (B, out_c, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.res = ResidualBlock(in_channels + out_channels, out_channels, time_channels)</span><br><span class="line">        <span class="keyword">if</span> has_attn:</span><br><span class="line">            self.attn = AttentionBlock(out_channels)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.attn = nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, x_left: torch.Tensor, t: torch.Tensor</span>):</span><br><span class="line">        x = torch.cat([x, x_left], <span class="number">1</span>)</span><br><span class="line">        x = self.res(x, t)</span><br><span class="line">        x = self.attn(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DownSample</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Scale down the feature map by 1/2&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_channels</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Down Sample</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            x: (B, num_c, h, w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            x: (B, num_c, h // 2, w // 2)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Conv2d(n_channels, n_channels, (<span class="number">3</span>, <span class="number">3</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UpSample</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Scale up the feature map by 2x&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_channels</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Up Sample</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            x: (B, num_c, h, w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            x: (B, num_c, h * 2, w * 2)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.ConvTranspose2d(num_channels, num_channels, (<span class="number">4</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UNet</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;U-Net used to predict noise.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        img_channels: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">        num_channels: <span class="built_in">int</span> = <span class="number">64</span>,</span></span><br><span class="line"><span class="params">        channel_multiples: <span class="type">Sequence</span>[<span class="built_in">int</span>] = (<span class="params"><span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span></span>),</span></span><br><span class="line"><span class="params">        has_attn: <span class="type">Sequence</span>[<span class="built_in">bool</span>] = (<span class="params"><span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span></span>),</span></span><br><span class="line"><span class="params">        num_blocks: <span class="built_in">int</span> = <span class="number">2</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;U-Net</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            img_channels: the number of channels in the image. 3 for RGB.</span></span><br><span class="line"><span class="string">            num_channels: number of channels in the initial feature map that we transform the image into.</span></span><br><span class="line"><span class="string">            channel_multiples: the list of channel multiple number at each resolution.</span></span><br><span class="line"><span class="string">            has_attn: a list of booleans that indicate whether to use attention at each resolution.</span></span><br><span class="line"><span class="string">            num_blocks: the number of `DownBlock` and `UpBlock` at each resolution.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">            x: (B, img_c, h, w)</span></span><br><span class="line"><span class="string">            t: (B, )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">            x: (B, img_c, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        num_resolutions = <span class="built_in">len</span>(channel_multiples)</span><br><span class="line">        time_channels = num_channels * <span class="number">4</span></span><br><span class="line"></span><br><span class="line">        self.time_emb = TimeEmbedding(num_channels, time_channels)</span><br><span class="line">        self.in_conv = nn.Conv2d(img_channels, num_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.out_conv = nn.Sequential(</span><br><span class="line">            nn.GroupNorm(<span class="number">32</span>, num_channels),</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Conv2d(num_channels, img_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=(<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Down and Up</span></span><br><span class="line">        self.down = nn.ModuleList()</span><br><span class="line">        self.up = nn.ModuleList()</span><br><span class="line">        in_c = num_channels</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_resolutions):</span><br><span class="line">            out_c = num_channels * channel_multiples[i]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># down blocks</span></span><br><span class="line">            self.down.append(DownBlock(in_c, out_c, time_channels, has_attn[i]))</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks - <span class="number">1</span>):</span><br><span class="line">                self.down.append(DownBlock(out_c, out_c, time_channels, has_attn[i]))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># up blocks</span></span><br><span class="line">            self.up.append(UpBlock(out_c, in_c, time_channels, has_attn[i]))</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">                self.up.append(UpBlock(out_c, out_c, time_channels, has_attn[i]))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># up/down sample</span></span><br><span class="line">            <span class="keyword">if</span> i &lt; num_resolutions - <span class="number">1</span>:</span><br><span class="line">                self.down.append(DownSample(out_c))</span><br><span class="line">                self.up.append(UpSample(out_c))</span><br><span class="line"></span><br><span class="line">            in_c = out_c</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Middle</span></span><br><span class="line">        self.middle = MiddleBlock(num_channels * channel_multiples[-<span class="number">1</span>], time_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, t: torch.Tensor</span>):</span><br><span class="line">        t = self.time_emb(t)</span><br><span class="line"></span><br><span class="line">        x = self.in_conv(x)</span><br><span class="line"></span><br><span class="line">        h = [x]</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.down:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, DownBlock):</span><br><span class="line">                x = m(x, t)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x = m(x)</span><br><span class="line">            h.append(x)</span><br><span class="line"></span><br><span class="line">        x = self.middle(x, t)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">reversed</span>(self.up):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, UpBlock):</span><br><span class="line">                x = m(x, h.pop(), t)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x = m(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(h) == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        x = self.out_conv(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GaussianDiffusion</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Gaussian Diffusion&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, eps_model: nn.Module, timesteps: <span class="built_in">int</span> = <span class="number">1000</span>, beta_min: <span class="built_in">float</span> = <span class="number">0.0001</span>, beta_max: <span class="built_in">float</span> = <span class="number">0.02</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Gaussian Diffusion</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            eps_model: epsilon theta model</span></span><br><span class="line"><span class="string">            timesteps: T.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.eps_model = eps_model</span><br><span class="line">        self.timesteps = timesteps</span><br><span class="line"></span><br><span class="line">        beta: torch.Tensor = torch.linspace(beta_min, beta_max, timesteps, dtype=torch.float32)</span><br><span class="line">        alpha: torch.Tensor = <span class="number">1.0</span> - beta</span><br><span class="line">        alpha_bar: torch.Tensor = torch.cumprod(alpha, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward parameters</span></span><br><span class="line">        self.q_mu_coef: torch.Tensor</span><br><span class="line">        self.register_buffer(<span class="string">&quot;q_mu_coef&quot;</span>, alpha_bar.sqrt(), <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.q_sigma: torch.Tensor</span><br><span class="line">        self.register_buffer(<span class="string">&quot;q_sigma&quot;</span>, (<span class="number">1.0</span> - alpha_bar).sqrt(), <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reverse parameters</span></span><br><span class="line">        self.p_mu_coef: torch.Tensor</span><br><span class="line">        self.register_buffer(<span class="string">&quot;p_mu_coef&quot;</span>, <span class="number">1.0</span> / alpha.sqrt(), <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.p_eps_coef: torch.Tensor</span><br><span class="line">        self.register_buffer(<span class="string">&quot;p_eps_coef&quot;</span>, beta / (<span class="number">1.0</span> - alpha_bar).sqrt(), <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.p_sigma: torch.Tensor</span><br><span class="line">        self.register_buffer(<span class="string">&quot;p_sigma&quot;</span>, beta.sqrt(), <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">q_sample</span>(<span class="params">self, x0: torch.Tensor, t: torch.Tensor, eps: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Forward from x0 to xt.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x0: (B, c, h, w)</span></span><br><span class="line"><span class="string">            t: (B, )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            xt: (B, c, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> eps <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            eps = torch.randn_like(x0)</span><br><span class="line"></span><br><span class="line">        mu = self.q_mu_coef.gather(-<span class="number">1</span>, t).view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>) * x0</span><br><span class="line">        sigma = self.q_sigma.gather(-<span class="number">1</span>, t).view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mu + sigma * eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">p_sample</span>(<span class="params">self, xt: torch.Tensor, t: torch.Tensor, eps: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Reverse from xt to xt_1.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            xt: (B, c, h, w)</span></span><br><span class="line"><span class="string">            t: (B, )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            xt_1: (B, c, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> eps <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            eps = torch.randn_like(xt)</span><br><span class="line"></span><br><span class="line">        eps_theta = self.eps_model(xt, t)</span><br><span class="line"></span><br><span class="line">        mu_coef = self.p_mu_coef.gather(-<span class="number">1</span>, t).view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        eps_coef = self.p_eps_coef.gather(-<span class="number">1</span>, t).view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        mu = mu_coef * (xt - eps_coef * eps_theta)</span><br><span class="line">        sigma = self.p_sigma.gather(-<span class="number">1</span>, t).view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mu + sigma * eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x0: torch.Tensor, t: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span>, noise: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Compute losses for x0.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x0: (B, c, h, w)</span></span><br><span class="line"><span class="string">            t: (B, )</span></span><br><span class="line"><span class="string">            noise: (B, c, h, w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            loss: MSE loss value</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> t <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            t = torch.randint(<span class="number">0</span>, self.timesteps, x0.shape[<span class="number">0</span>:<span class="number">1</span>], device=x0.device, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> noise <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            noise = torch.randn_like(x0)</span><br><span class="line"></span><br><span class="line">        xt = self.q_sample(x0, t, eps=noise)</span><br><span class="line">        eps_theta = self.eps_model(xt, t)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> F.mse_loss(noise, eps_theta)</span><br></pre></td></tr></table></figure>

</details>

<p>主要是实现一个 UNet, 并且结构如下.</p>
<p><img data-src="https://nn.labml.ai/unet/unet.png" alt="UNet"></p>
<p><img data-src="https://pic3.zhimg.com/80/v2-f396d21e0cfdfe324a2dc7a8636ac88e_1440w.webp" alt="UNet-DDPM"></p>
<p>第一个是原始 UNet 结构, 第二个是对应于 DDPM 的 UNet 结构, 参考一下理解原理即可.</p>
<p>对于扩散部分的代码, 可以参考很久之前的总结<a href="/posts/2022/10/29/diffusion-model/">扩散模型阅读笔记</a>, 里面有前向和反向的计算公式, 对着写就好了.</p>
<h2 id="主程序"><a href="#主程序" class="headerlink" title="主程序"></a>主程序</h2><p>包含训练和生成部分代码, 以及命令行参数选项.</p>
<details class="note "><summary><p><strong>[点击展开]</strong> 训练和采样代码</p>
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ProgressBar</span>(rich.progress.Progress):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            rich.progress.SpinnerColumn(),</span><br><span class="line">            rich.progress.TextColumn(<span class="string">&quot;[progress.description]&#123;task.description&#125;&quot;</span>),</span><br><span class="line">            rich.progress.BarColumn(),</span><br><span class="line">            rich.progress.TaskProgressColumn(<span class="string">&quot;[progress.percentage]&#123;task.completed:d&#125;/&#123;task.total:d&#125;&quot;</span>),</span><br><span class="line">            rich.progress.TimeElapsedColumn(),</span><br><span class="line">            rich.progress.TimeRemainingColumn(),</span><br><span class="line">            **kwargs</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Image Dataset.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, *folders: <span class="built_in">str</span>, img_size: <span class="built_in">int</span> = <span class="number">64</span>, img_mode: <span class="built_in">str</span> = <span class="string">&quot;RGB&quot;</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Anime Faces Dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            folders: dataset folders, containing pictures.</span></span><br><span class="line"><span class="string">            img_size: to resize images to (img_size, img_size)</span></span><br><span class="line"><span class="string">            img_mode: image mode, same as PIL options.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.paths = [<span class="built_in">str</span>(p) <span class="keyword">for</span> f <span class="keyword">in</span> folders <span class="keyword">for</span> p <span class="keyword">in</span> Path(f).iterdir()]</span><br><span class="line">        self.trans = T.Compose([</span><br><span class="line">            T.ToTensor(),</span><br><span class="line">            T.Resize(img_size, antialias=<span class="literal">True</span>),</span><br><span class="line">            T.CenterCrop(img_size),</span><br><span class="line">            T.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        self.random_flip = T.RandomHorizontalFlip()</span><br><span class="line"></span><br><span class="line">        self.img_mode = img_mode</span><br><span class="line"></span><br><span class="line">        <span class="comment"># load in memory to avoid io operations</span></span><br><span class="line">        self.imgs = [self.trans(Image.<span class="built_in">open</span>(p).convert(self.img_mode)) <span class="keyword">for</span> p <span class="keyword">in</span> self.paths]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.paths)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> self.random_flip(self.imgs[index])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Program</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Diffusion Program&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.args = args</span><br><span class="line"></span><br><span class="line">        self.img_mode: <span class="built_in">str</span> = &#123;<span class="number">1</span>: <span class="string">&quot;L&quot;</span>, <span class="number">3</span>: <span class="string">&quot;RGB&quot;</span>&#125;[args.img_channels]</span><br><span class="line">        self.imgtrans = T.Compose([</span><br><span class="line">            T.Normalize([-<span class="number">1</span>], [<span class="number">2</span>]),</span><br><span class="line">            T.ToPILImage(self.img_mode),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        self.model = GaussianDiffusion(</span><br><span class="line">            UNet(args.img_channels,</span><br><span class="line">                 args.num_channels,</span><br><span class="line">                 args.channel_multiples,</span><br><span class="line">                 args.has_attn,</span><br><span class="line">                 args.num_blocks),</span><br><span class="line">            args.timesteps,</span><br><span class="line">            args.beta_min,</span><br><span class="line">            args.beta_max</span><br><span class="line">        ).to(args.device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.args.train:</span><br><span class="line">            self.dataset = ImageDataset(*args.data_folders, img_size=args.img_size, img_mode=self.img_mode)</span><br><span class="line">            self.dataloader = DataLoader(self.dataset, args.batch_size, <span class="literal">True</span>)</span><br><span class="line">            self.optim = Adam(self.model.parameters(), args.lr)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.inference_mode()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ddpm</span>(<span class="params">self, n: <span class="built_in">int</span>, return_steps: <span class="built_in">bool</span> = <span class="literal">False</span>, step: <span class="built_in">int</span> = <span class="number">100</span></span>) -&gt; <span class="type">List</span>[torch.Tensor]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;DDPM Sample</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            n: n samples.</span></span><br><span class="line"><span class="string">            return_steps: if return steps.</span></span><br><span class="line"><span class="string">            step: if return steps, steps between steps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            x_steps: List of x, the last is the final result, each one has shape of (B, c, h, w).</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        n_steps = self.args.timesteps</span><br><span class="line"></span><br><span class="line">        x_steps = []</span><br><span class="line"></span><br><span class="line">        x = torch.randn([n, self.args.img_channels, self.args.img_size, self.args.img_size], device=self.args.device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> return_steps:</span><br><span class="line">            x_steps.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> ProgressBar() <span class="keyword">as</span> progress:</span><br><span class="line">            task_sample = progress.add_task(<span class="string">&quot;[red]DDPM Sample&quot;</span>, total=n_steps)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> torch.autocast(self.args.device):</span><br><span class="line">                <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(n_steps)):</span><br><span class="line">                    x = self.model.p_sample(x, x.new_full((n,), t, dtype=torch.long))</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (n_steps - t) % step == <span class="number">0</span>:</span><br><span class="line">                        x_steps.append(x)</span><br><span class="line"></span><br><span class="line">                    progress.advance(task_sample)</span><br><span class="line"></span><br><span class="line">        x_steps.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x_steps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_image</span>(<span class="params">self, x: torch.Tensor, path: <span class="built_in">str</span></span>):</span><br><span class="line">        x: Image.Image = self.imgtrans(x.clamp(-<span class="number">1.0</span>, <span class="number">1.0</span>))</span><br><span class="line">        x.save(path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_ckpt</span>(<span class="params">self, path: <span class="built_in">str</span></span>):</span><br><span class="line">        torch.save(self.model.state_dict(), path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_ckpt</span>(<span class="params">self, path: <span class="built_in">str</span></span>):</span><br><span class="line">        self.model.load_state_dict(torch.load(path, self.args.device))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self</span>) -&gt; <span class="type">List</span>[<span class="built_in">float</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Train model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            losses: Losses of each epoch.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        losses = []</span><br><span class="line">        self.model.train()</span><br><span class="line">        save_dir = Path(self.args.ckpt_save_dir)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> ProgressBar() <span class="keyword">as</span> progress:</span><br><span class="line">            task_epoch = progress.add_task(<span class="string">&quot;[#00DEF2]Epochs&quot;</span>, total=self.args.epochs)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(self.args.epochs):</span><br><span class="line">                task_batch = progress.add_task(<span class="string">&quot;[#00DF75]Batches&quot;</span>, total=<span class="built_in">len</span>(self.dataset))</span><br><span class="line"></span><br><span class="line">                epoch_losses = []</span><br><span class="line">                start_t = time.time()</span><br><span class="line">                <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.dataloader):</span><br><span class="line">                    data = data.to(args.device)</span><br><span class="line">                    self.optim.zero_grad()</span><br><span class="line">                    loss = self.model(data)</span><br><span class="line">                    loss.backward()</span><br><span class="line">                    self.optim.step()</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                        epoch_losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">                    progress.advance(task_batch, <span class="built_in">len</span>(data))</span><br><span class="line"></span><br><span class="line">                end_t = time.time()</span><br><span class="line">                epoch_mean_loss = <span class="built_in">sum</span>(epoch_losses) / <span class="built_in">len</span>(epoch_losses)</span><br><span class="line">                progress.<span class="built_in">print</span>(<span class="string">f&quot;[Epoch <span class="subst">&#123;epoch&#125;</span>] Loss: <span class="subst">&#123;epoch_mean_loss:<span class="number">.6</span>f&#125;</span> Elapsed: <span class="subst">&#123;(end_t - start_t) / <span class="number">60</span>:<span class="number">.2</span>f&#125;</span> min&quot;</span>)</span><br><span class="line">                losses.append(epoch_mean_loss)</span><br><span class="line"></span><br><span class="line">                self.save_ckpt(save_dir.joinpath(<span class="string">f&quot;ckpt-<span class="subst">&#123;epoch % <span class="number">5</span>&#125;</span>.pth&quot;</span>))</span><br><span class="line"></span><br><span class="line">                progress.remove_task(task_batch)</span><br><span class="line">                progress.advance(task_epoch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> losses</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">self, n: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Generate random images.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        imgs = self.ddpm(n)[-<span class="number">1</span>]</span><br><span class="line">        save_dir = Path(self.args.save_dir)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(imgs)):</span><br><span class="line">            self.save_image(imgs[i], save_dir.joinpath(<span class="string">f&quot;ddpm-<span class="subst">&#123;i&#125;</span>.png&quot;</span>))</span><br><span class="line"></span><br><span class="line">        all_img = make_grid(imgs)</span><br><span class="line">        <span class="keyword">if</span> self.args.img_channels == <span class="number">1</span>:</span><br><span class="line">            all_img = all_img[<span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">        self.save_image(all_img, save_dir.joinpath(<span class="string">f&quot;ddpm-all.png&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_forward_steps</span>(<span class="params">self, path: <span class="built_in">str</span></span>):</span><br><span class="line">        batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(self.dataloader)).to(self.args.device)</span><br><span class="line">        n = <span class="built_in">len</span>(batch)</span><br><span class="line">        forward_steps = [batch]</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">99</span>, self.args.timesteps, <span class="number">100</span>):</span><br><span class="line">            x_t = self.model.q_sample(batch, batch.new_full((n,), t, dtype=torch.long))</span><br><span class="line">            forward_steps.append(x_t)</span><br><span class="line">        self.save_image(torch.cat([torch.cat(v.unbind(), <span class="number">1</span>) <span class="keyword">for</span> v <span class="keyword">in</span> forward_steps], <span class="number">2</span>), path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_reverse_steps</span>(<span class="params">self, path: <span class="built_in">str</span></span>):</span><br><span class="line">        self.save_image(torch.cat([torch.cat(v.unbind(), <span class="number">1</span>) <span class="keyword">for</span> v <span class="keyword">in</span> self.ddpm(<span class="number">8</span>, <span class="literal">True</span>)], <span class="number">2</span>), path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.args.loadckpt:</span><br><span class="line">            self.load_ckpt(self.args.loadckpt)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.args.train:</span><br><span class="line">            <span class="comment"># self.save_forward_steps(&quot;run-forward.png&quot;)</span></span><br><span class="line">            self.save_reverse_steps(<span class="string">&quot;run-before.png&quot;</span>)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                self.train()</span><br><span class="line">            <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;[*] Stopped by user.&quot;</span>)</span><br><span class="line">            self.save_reverse_steps(<span class="string">&quot;run-after.png&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.generate(self.args.batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># data args</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--data-folders&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, nargs=<span class="string">&quot;*&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--img-channels&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">3</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--img-size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model args</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--num-channels&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">64</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--channel-multiples&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, nargs=<span class="string">&quot;+&quot;</span>, default=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>])</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--has-attn&quot;</span>, <span class="built_in">type</span>=<span class="keyword">lambda</span> x: x.lower() == <span class="string">&quot;t&quot;</span>, nargs=<span class="string">&quot;+&quot;</span>, default=[<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span>])</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--num-blocks&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># diffusion args</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--timesteps&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1000</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--beta-min&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--beta-max&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># train args</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--train&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--lr&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">1e-4</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--ckpt-save-dir&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;ckpt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># inference args</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--save-dir&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;output&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># run args</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--seed&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="literal">None</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--device&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>))</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--loadckpt&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="literal">None</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--batch-size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="built_in">print</span>(args)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.seed:</span><br><span class="line">        torch.manual_seed(args.seed)</span><br><span class="line">        torch.cuda.manual_seed(args.seed)</span><br><span class="line"></span><br><span class="line">    Program(args).run()</span><br></pre></td></tr></table></figure>

</details>

<h2 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h2><p>模型参数都用的默认值, 与原论文非常接近, 但是不知道为啥模型体积比预期大了一点.</p>
<p>学习率可能需要调整一两次, 实测可以先按 <code>1e-3</code> 跑个 10 ~ 20 轮, 然后按 <code>1e-4</code> 跑到损失差不多稳定 (30 ~ 40 轮), 有出图效果之后, 再按 <code>1e-5</code> 和 <code>1e-6</code> 一直跑到收敛.</p>
<p>学习率一定不能太大了, 否则很容易崩.</p>
<p>用全部的 8 万数据集质量不是很高, 所以只用了 2 万那个, 并且在读取数据集的时候加了随机水平翻转图像.</p>
<p>当然了, 毕竟是炼丹, 说不定有更玄乎的参数设置咔咔就收敛效果还好.</p>
<h2 id="炼丹结果"><a href="#炼丹结果" class="headerlink" title="炼丹结果"></a>炼丹结果</h2><p>采样的时候为了快一点, 加了 <code>inference_mode</code> 和 <code>autocast</code>, PyTorch 提供的推理模式和自动混合精度.</p>
<p>实测加了混合精度后只需要原本 60% 左右的时间, 确实有明显的加速优势.</p>
<p>放几张反向去噪的结果图, 效果还行, 颇有毕加索的美术风格.</p>
<details class="note success"><summary><p><strong>[点击展开]</strong> 未收敛时反向扩散结果</p>
</summary>
<p><img data-src="/static/image/ddpm/ckpt-1e03x10.png" alt="ckpt-1e03x10.png"><br><img data-src="/static/image/ddpm/ckpt-1e03x15.png" alt="ckpt-1e03x15.png"><br><img data-src="/static/image/ddpm/ckpt-1e03x20.png" alt="ckpt-1e03x20.png"><br><img data-src="/static/image/ddpm/ckpt-1e04x05.png" alt="ckpt-1e04x05.png"><br><img data-src="/static/image/ddpm/ckpt-1e04x10.png" alt="ckpt-1e04x10.png"><br><img data-src="/static/image/ddpm/ckpt-1e04x15.png" alt="ckpt-1e04x15.png"><br><img data-src="/static/image/ddpm/ckpt-1e03x20.png" alt="ckpt-1e04x20.png"><br><img data-src="/static/image/ddpm/ckpt-1e04x25.png" alt="ckpt-1e04x25.png"></p>

</details>

<details class="note success"><summary><p><strong>[点击展开]</strong> 收敛之后反向扩散结果</p>
</summary>
<p><img data-src="/static/image/ddpm/ckpt-1e07x10.png" alt="ckpt-1e07x10.png"><br><img data-src="/static/image/ddpm/ckpt-1e07x20.png" alt="ckpt-1e07x20.png"><br><img data-src="/static/image/ddpm/ckpt-1e08x10.png" alt="ckpt-1e08x10.png"><br><img data-src="/static/image/ddpm/ckpt-1e08x20.png" alt="ckpt-1e08x20.png"><br><img data-src="/static/image/ddpm/ckpt-1e09x10.png" alt="ckpt-1e09x10.png"><br><img data-src="/static/image/ddpm/ckpt-1e09x20.png" alt="ckpt-1e09x20.png"><br><img data-src="/static/image/ddpm/ckpt-1e10x10.png" alt="ckpt-1e10x10.png"><br><img data-src="/static/image/ddpm/ckpt-1e10x20.png" alt="ckpt-1e10x20.png"></p>

</details>

<details class="note success"><summary><p><strong>[点击展开]</strong> 同一组高斯噪声随模型收敛采样结果</p>
</summary>
<p><img data-src="/static/image/ddpm/ckpt-all.png" alt="ckpt-all.png"></p>

</details>

<p>最后放一个抽卡结果, 随机抽 64 张.</p>
<p><img data-src="/static/image/ddpm/sample-64.png" alt="sample-64.png"></p>
<p>说实话, 炼丹效果和数据集有相当大关系, 越高质量的数据集炼出来的模型越好, 越不容易出问题, 并且数据量越大生成的结果也越丰富<del>模型其实都不是什么特别重要的事情, 反正都是乱拟合一个</del>.</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzIwMDYuMTEyMzkucGRm">Denoising Diffusion Probabilistic Models<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hvam9uYXRoYW5oby9kaWZmdXNpb24=">diffusion<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NTU1Njg5MTA=">深入浅出扩散模型(Diffusion Model)系列：基石DDPM（源码解读篇）<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xhYm1sYWkvYW5ub3RhdGVkX2RlZXBfbGVhcm5pbmdfcGFwZXJfaW1wbGVtZW50YXRpb25z">annotated_deep_learning_paper_implementations<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2x1Y2lkcmFpbnMvZGVub2lzaW5nLWRpZmZ1c2lvbi1weXRvcmNo">denoising-diffusion-pytorch<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>代码块</category>
      </categories>
      <tags>
        <tag>DDPM</tag>
        <tag>动漫头像生成</tag>
        <tag>概率扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 OpenCV 进行图像对比</title>
    <url>//posts/2024/08/02/imgcmp/</url>
    <content><![CDATA[<p>记录一下最近写的一个小工具模块, 用来比较两张图像之间的相似度, 并且输出直方图差异以及像素差异.</p>
<span id="more"></span>

<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>目标是比较两张相同 RGB 图像的相似度, 看它们之间是否存在色彩阴影亮度之类的区别.</p>
<p>因此首先将图像读取后转换成 HLS 通道格式, 再依次求解每个通道上的直方图差异以及像素差分图.</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">HlsSimilarity = namedtuple(<span class="string">&quot;HlsSimilarity&quot;</span>, [<span class="string">&quot;H&quot;</span>, <span class="string">&quot;L&quot;</span>, <span class="string">&quot;S&quot;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_image_as_hls</span>(<span class="params">path: <span class="built_in">str</span>, blur_ksize: <span class="built_in">int</span> = <span class="number">0</span></span>) -&gt; np.ndarray:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;读取图像并转换成 HLS 格式.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    由于对比的时候过于灵敏, 所以有必要加一定程度的模糊.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        image: 形状为 (H, W, 3)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    img = cv2.imread(path, cv2.IMREAD_COLOR)</span><br><span class="line">    <span class="keyword">if</span> blur_ksize &gt; <span class="number">0</span>:</span><br><span class="line">        img = cv2.blur(img, (blur_ksize, blur_ksize))</span><br><span class="line">    img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS_FULL)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calc_image_hist_delta</span>(<span class="params">img1: <span class="built_in">str</span>, img2: <span class="built_in">str</span></span>) -&gt; <span class="type">Tuple</span>[np.ndarray, np.ndarray, np.ndarray]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算两张直方图差异</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        delta: (H, L, S) 三个分量的直方图差异</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    img1 = read_image_as_hls(img1)</span><br><span class="line">    img2 = read_image_as_hls(img2)</span><br><span class="line"></span><br><span class="line">    hist_delta = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        h1 = cv2.calcHist([img1], [i], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">255</span>]).flatten()</span><br><span class="line">        h2 = cv2.calcHist([img2], [i], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">255</span>]).flatten()</span><br><span class="line">        hist_delta.append(h1 - h2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">tuple</span>(hist_delta)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_colors</span>(<span class="params">cname: <span class="built_in">str</span> = <span class="string">&quot;hsv&quot;</span>, size: <span class="built_in">int</span> = <span class="number">256</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获得连续的调色板颜色序列&quot;&quot;&quot;</span></span><br><span class="line">    cmap = plt.get_cmap(cname, size)</span><br><span class="line">    <span class="keyword">return</span> [cmap(i)[:<span class="number">3</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(size)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calc_image_similarity</span>(<span class="params">img1: <span class="built_in">str</span>, img2: <span class="built_in">str</span>, blur_ksize: <span class="built_in">int</span> = <span class="number">15</span></span>) -&gt; HlsSimilarity:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算两张图像的相似度, 具体算法见 https://docs.opencv.org/4.5.5/d8/dc8/tutorial_histogram_comparison.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    此处使用 Bhattacharyya distance, 并且加了一定量的模糊处理.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        similarities: (H, L, S) 三个分量的相似度</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    img1 = read_image_as_hls(img1, blur_ksize)</span><br><span class="line">    img2 = read_image_as_hls(img2, blur_ksize)</span><br><span class="line"></span><br><span class="line">    similarities = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    similarities[<span class="number">0</span>] = <span class="number">1</span> - cv2.compareHist(</span><br><span class="line">        cv2.calcHist([img1], [<span class="number">0</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">255</span>]), cv2.calcHist([img2], [<span class="number">0</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">255</span>]), <span class="number">3</span></span><br><span class="line">    )</span><br><span class="line">    similarities[<span class="number">1</span>] = <span class="number">1</span> - cv2.compareHist(</span><br><span class="line">        cv2.calcHist([img1], [<span class="number">1</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">255</span>]), cv2.calcHist([img2], [<span class="number">1</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">255</span>]), <span class="number">3</span></span><br><span class="line">    )</span><br><span class="line">    similarities[<span class="number">2</span>] = <span class="number">1</span> - cv2.compareHist(</span><br><span class="line">        cv2.calcHist([img1], [<span class="number">2</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">255</span>]), cv2.calcHist([img2], [<span class="number">2</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">255</span>]), <span class="number">3</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> HlsSimilarity(*similarities)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_image_hist_delta</span>(<span class="params">img1: <span class="built_in">str</span>, img2: <span class="built_in">str</span>, path: <span class="built_in">str</span>, title: <span class="built_in">str</span> = <span class="string">&quot;Hist Delta of HLS Image (First - Second)&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;绘制差异直方图情况&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    delta_H, delta_L, delta_S = calc_image_hist_delta(img1, img2)</span><br><span class="line"></span><br><span class="line">    fig, axes = plt.subplots(<span class="number">3</span>, <span class="number">1</span>, squeeze=<span class="literal">True</span>, figsize=(<span class="number">12</span>, <span class="number">16</span>), dpi=<span class="number">300</span>)</span><br><span class="line">    fig.subplots_adjust(left=<span class="number">0.1</span>, right=<span class="number">0.9</span>, top=<span class="number">0.93</span>, bottom=<span class="number">0.07</span>)</span><br><span class="line">    fig.suptitle(title)</span><br><span class="line">    fig.supxlabel(<span class="string">&quot;Pixel Value&quot;</span>)</span><br><span class="line">    fig.supylabel(<span class="string">&quot;Pixel Count&quot;</span>)</span><br><span class="line"></span><br><span class="line">    axes: <span class="built_in">list</span>[plt.Axes]</span><br><span class="line">    ax_H, ax_L, ax_S = axes</span><br><span class="line"></span><br><span class="line">    x_len = <span class="built_in">len</span>(delta_H)</span><br><span class="line">    ax_H.bar(np.arange(x_len), delta_H, color=get_colors(<span class="string">&quot;hsv&quot;</span>, x_len))</span><br><span class="line">    ax_H.set_title(<span class="string">&quot;Delta of H Channel&quot;</span>)</span><br><span class="line">    ax_H.set_xticks(np.arange(<span class="number">0</span>, x_len, <span class="number">10</span>), np.arange(<span class="number">0</span>, x_len, <span class="number">10</span>), rotation=-<span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">    x_len = <span class="built_in">len</span>(delta_L)</span><br><span class="line">    ax_L.bar(np.arange(x_len), delta_L, color=get_colors(<span class="string">&quot;gray&quot;</span>, x_len))</span><br><span class="line">    ax_L.set_title(<span class="string">&quot;Delta of L Channel&quot;</span>)</span><br><span class="line">    ax_L.set_xticks(np.arange(<span class="number">0</span>, x_len, <span class="number">10</span>), np.arange(<span class="number">0</span>, x_len, <span class="number">10</span>), rotation=-<span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">    x_len = <span class="built_in">len</span>(delta_S)</span><br><span class="line">    ax_S.bar(np.arange(x_len), delta_S, color=get_colors(<span class="string">&quot;gray&quot;</span>, x_len))</span><br><span class="line">    ax_S.set_title(<span class="string">&quot;Delta of S Channel&quot;</span>)</span><br><span class="line">    ax_S.set_xticks(np.arange(<span class="number">0</span>, x_len, <span class="number">10</span>), np.arange(<span class="number">0</span>, x_len, <span class="number">10</span>), rotation=-<span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">    fig.savefig(path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_diff_image</span>(<span class="params">img1: <span class="built_in">str</span>, img2: <span class="built_in">str</span>, path: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;叠图查看差异, 如果尺寸不一样或者保存失败返回 False.&quot;&quot;&quot;</span></span><br><span class="line">    img1 = read_image_as_hls(img1)</span><br><span class="line">    img2 = read_image_as_hls(img2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> img1.shape != img2.shape:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    img1_H, img1_L, img1_S = cv2.split(img1)</span><br><span class="line">    img2_H, img2_L, img2_S = cv2.split(img2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 色相是 [0, 255] 的环形取值, 因此计算的时候要取环上短侧的距离</span></span><br><span class="line">    diff_H = np.<span class="built_in">min</span>([img1_H - img2_H, img2_H - img1_H], axis=<span class="number">0</span>)</span><br><span class="line">    diff_H = cv2.normalize(diff_H, <span class="literal">None</span>, <span class="number">0</span>, <span class="number">255</span>, cv2.NORM_MINMAX)</span><br><span class="line">    diff_L = cv2.absdiff(img1_L, img2_L)</span><br><span class="line">    diff_S = cv2.absdiff(img1_S, img2_S)</span><br><span class="line">    diff_img = np.concatenate([diff_H, diff_L, diff_S], axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> cv2.imwrite(path, diff_img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;img1&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;img2&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--out-hist&quot;</span>, default=<span class="string">&quot;hist.png&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--out-diff&quot;</span>, default=<span class="string">&quot;diff.png&quot;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    sim = calc_image_similarity(args.img1, args.img2)</span><br><span class="line">    <span class="built_in">print</span>(sim)</span><br><span class="line">    draw_image_hist_delta(args.img1, args.img2, args.out_hist)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> make_diff_image(args.img1, args.img2, args.out_diff):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;尺寸不同, 无法计算差分&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="运行效果"><a href="#运行效果" class="headerlink" title="运行效果"></a>运行效果</h2><p>输入两张图片, 例如:</p>
<div class="group-picture"><div class="group-picture-row"><div class="group-picture-column"><img data-src="/static/image/imgcmp/lenna1.png" alt="lenna1.png"></div><div class="group-picture-column"><img data-src="/static/image/imgcmp/lenna2.png" alt="lenna2.png"></div></div></div>

<p>可以得到相似度: HlsSimilarity(H=0.32851660966060825, L=0.6765325641597513, S=0.6573630520719462)</p>
<p>并且有差异图:</p>
<p><img data-src="/static/image/imgcmp/hist.png" alt="hist.png"></p>
<p><img data-src="/static/image/imgcmp/diff.png" alt="diff.png"></p>
<p>可以看出来左图比右图多了很多红色部分, 并且少一一丢丢的蓝色.</p>
<p>并且左图更亮, 且颜色饱和度更高.</p>
]]></content>
      <categories>
        <category>代码块</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>图像比对</tag>
      </tags>
  </entry>
  <entry>
    <title>解决 Github SSH 连接超时</title>
    <url>//posts/2024/01/17/githubssh-timeout/</url>
    <content><![CDATA[<p>解决 Github SSH 连接超时.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh -T git@github.com</span><br><span class="line">ssh: connect to host github.com port 22: Connection timed out</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<p>众所周知 Github 的网页端访问极其不稳定, 用 http 协议 clone 仓库的时候非常难受, 但是用公钥走 ssh 协议进行连接体感稳定很多.</p>
<p>但是最近 ssh 也不行了, 稳定连接超时, 本地一堆仓库都没办法进行推送.</p>
<p>网上搜了一大圈, 发现都是加 ssh 配置, 增加下面的内容:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Host github.com</span><br><span class="line">  Hostname ssh.github.com</span><br><span class="line">  Port 443</span><br></pre></td></tr></table></figure>

<p>意思是原先的 22 端口被墙了, 换个 443 的端口就好了.</p>
<p>这么试了之后确实好了, 但是总感觉哪里不对劲, 因为我的印象里, 在指定 <code>Hostname</code> 的情况下, <code>Host</code> 的作用是别名.</p>
<p>也就是说这个配置项的作用其实是将所有连接到 <code>github.com</code> 的换到了 <code>ssh.github.com</code>.</p>
<p>然后我把 <code>Port 443</code> 给注释了, 结果发现也能跑通, 这说明和端口压根没啥关系, 纯粹是域名的问题.</p>
<p>分别 ping 一下两个域名, 可以发现 <code>github.com</code> 完全不通, 但是 <code>ssh.github.com</code> 是通的.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ping github.com</span><br><span class="line"></span><br><span class="line">正在 Ping github.com [20.205.243.166] 具有 32 字节的数据:</span><br><span class="line">请求超时。</span><br><span class="line">请求超时。</span><br><span class="line">请求超时。</span><br><span class="line">请求超时。</span><br><span class="line"></span><br><span class="line">20.205.243.166 的 Ping 统计信息:</span><br><span class="line">    数据包: 已发送 = 4，已接收 = 0，丢失 = 4 (100% 丢失)，</span><br><span class="line"></span><br><span class="line">$ ping ssh.github.com</span><br><span class="line"></span><br><span class="line">正在 Ping ssh.github.com [20.205.243.160] 具有 32 字节的数据:</span><br><span class="line">来自 20.205.243.160 的回复: 字节=32 时间=95ms TTL=98</span><br><span class="line">来自 20.205.243.160 的回复: 字节=32 时间=98ms TTL=98</span><br><span class="line">来自 20.205.243.160 的回复: 字节=32 时间=111ms TTL=98</span><br><span class="line">来自 20.205.243.160 的回复: 字节=32 时间=98ms TTL=98</span><br><span class="line"></span><br><span class="line">20.205.243.160 的 Ping 统计信息:</span><br><span class="line">    数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，</span><br><span class="line">往返行程的估计时间(以毫秒为单位):</span><br><span class="line">    最短 = 95ms，最长 = 111ms，平均 = 100ms</span><br></pre></td></tr></table></figure>

<p>至此, 可以确定就是最近解析的主域名 <code>github.com</code> 的 IP 被彻底墙了, 但是供 ssh 连接的子域名 <code>ssh.github.com</code> IP 还活着.</p>
<p>因此, 解决方案就是添加下面的配置:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Host github.com</span><br><span class="line">  Hostname 20.205.243.160</span><br></pre></td></tr></table></figure>

<p>将现有的 <code>github.com</code> 主机名换一个可以用的 IP.</p>
<p>另外, 找到了 Github 官方的文档 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmdpdGh1Yi5jb20vZW4vYXV0aGVudGljYXRpb24vdHJvdWJsZXNob290aW5nLXNzaC91c2luZy1zc2gtb3Zlci10aGUtaHR0cHMtcG9ydA==">Using SSH over the HTTPS port<i class="fa fa-external-link-alt"></i></span>.</p>
<p>这里面教你如何在 22 端口不可用时, 转用 443 端口, 但是 443 端口必须使用 <code>ssh.github.com</code>. 这也是网上大部分教程的出处. 但是由于这个问题不是端口导致的, 因此方法有效只是巧合罢了.</p>
<p>最后, Github 官方提供了它们的服务 IP 范围, <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmdpdGh1Yi5jb20vZW4vYXV0aGVudGljYXRpb24va2VlcGluZy15b3VyLWFjY291bnQtYW5kLWRhdGEtc2VjdXJlL2Fib3V0LWdpdGh1YnMtaXAtYWRkcmVzc2Vz">About GitHub&#39;s IP addresses<i class="fa fa-external-link-alt"></i></span>, 从里面可以找一个 ssh 连接成功, 然后写到配置里.</p>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>SSH</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title>看雪 2023·KCTF 第十一题设计思路与题解</title>
    <url>//posts/2023/10/07/kctf-2023/</url>
    <content><![CDATA[<p>在我导安排下作为防守方出了个题到<span class="exturl" data-url="aHR0cHM6Ly9jdGYua2FueHVlLmNvbS9nYW1lLXRlYW1fbGlzdC0xOS0zMy5odG0=">看雪 2023·KCTF<i class="fa fa-external-link-alt"></i></span> 上, <span class="exturl" data-url="aHR0cHM6Ly9jdGYua2FueHVlLmNvbS9nYW1lLXNlYXNvbl9maWdodC0yMzYuaHRt">第十一题 步步逼近<i class="fa fa-external-link-alt"></i></span>, 有幸拿了精致奖, 第一次参加这类比赛, 属实是走大运了. 这里把出题思路和题解贴一下, 和看雪的是一样的, 原文链接 <span class="exturl" data-url="aHR0cHM6Ly9iYnMua2FueHVlLmNvbS90aHJlYWQtMjc4NDc4Lmh0bQ==">https://bbs.kanxue.com/thread-278478.htm<i class="fa fa-external-link-alt"></i></span>.</p>
<span id="more"></span>

<h2 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a>题目分析</h2><h3 id="输入与结果"><a href="#输入与结果" class="headerlink" title="输入与结果"></a>输入与结果</h3><p>简单试错以及使用 IDA 获取伪代码可以知道题目的输入是一个不超过 10 位的十进制数字, 并且将范围限制在了 4K (0x1000) 至 4G (0x100000000) 之间 (包含两头端点). 所以解出此题的关键在于弄清楚题目如何对输入的数字进行验证.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***** 省略前文 *****/</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Please input: &quot;</span>);</span><br><span class="line">  v0 = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> ( <span class="number">1</span> )</span><br><span class="line">  &#123;</span><br><span class="line">    v1 = _getchar();</span><br><span class="line">    <span class="keyword">if</span> ( v1 == <span class="number">10</span> )</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    v2 = v0 + <span class="number">1</span>;</span><br><span class="line">    _Buffer[v0] = v1;</span><br><span class="line">    <span class="keyword">if</span> ( v0 + <span class="number">1</span> &gt;= <span class="number">0xB</span> )</span><br><span class="line">      <span class="keyword">goto</span> LABEL_43;</span><br><span class="line">    _Buffer[v2] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> ( v0 == <span class="number">9</span> &amp;&amp; _getchar() != <span class="number">10</span> )</span><br><span class="line">      <span class="keyword">goto</span> LABEL_41;</span><br><span class="line">    ++v0;</span><br><span class="line">    <span class="keyword">if</span> ( v2 &gt;= <span class="number">10</span> )</span><br><span class="line">      <span class="keyword">goto</span> LABEL_10;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> ( v0 &gt;= <span class="number">0xB</span> )</span><br><span class="line">  &#123;</span><br><span class="line">LABEL_43:</span><br><span class="line">    __report_rangecheckfailure();</span><br><span class="line">    __debugbreak();</span><br><span class="line">    JUMPOUT(*(_DWORD *)__security_check_cookie);</span><br><span class="line">  &#125;</span><br><span class="line">  _Buffer[v0] = <span class="number">0</span>;</span><br><span class="line">LABEL_10:</span><br><span class="line">  v3 = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> ( _Buffer[<span class="number">0</span>] )</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">while</span> ( ++v3 &lt;= <span class="number">10</span> )</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">if</span> ( !_Buffer[v3] )</span><br><span class="line">        <span class="keyword">goto</span> LABEL_15;</span><br><span class="line">    &#125;</span><br><span class="line">    v3 = <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">LABEL_15:</span><br><span class="line">  <span class="keyword">if</span> ( sscanf_s(_Buffer, <span class="string">&quot;%lld&quot;</span>, &amp;x) == <span class="number">1</span> )</span><br><span class="line">  &#123;</span><br><span class="line">    v4 = sprintf_s(v18, <span class="number">0xB</span>u, <span class="string">&quot;%lld&quot;</span>, x);</span><br><span class="line">    <span class="keyword">if</span> ( v3 &gt; <span class="number">0</span> &amp;&amp; v4 &gt; <span class="number">0</span> &amp;&amp; v3 == v4 )</span><br><span class="line">    &#123;</span><br><span class="line">      v5 = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">while</span> ( _Buffer[v5] == v18[v5] )</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="keyword">if</span> ( ++v5 &gt;= v3 )</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="keyword">if</span> ( SHIDWORD(x) &gt;= <span class="number">0</span> &amp;&amp; (SHIDWORD(x) &gt; <span class="number">0</span> || (_DWORD)x) )</span><br><span class="line">          &#123;</span><br><span class="line">            v6 = FindWindowW(<span class="string">L&quot;OLLYDBG&quot;</span>, <span class="number">0</span>);</span><br><span class="line">            v7 = HIDWORD(x);</span><br><span class="line">            v8 = x;</span><br><span class="line">            <span class="keyword">if</span> ( v6 )</span><br><span class="line">            &#123;</span><br><span class="line">              v8 = x | <span class="number">0xFFFF</span>;</span><br><span class="line">              LODWORD(x) = x | <span class="number">0xFFFF</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> ( __PAIR__(HIDWORD(x), v8) - <span class="number">4096</span> &lt;= <span class="number">0xFFFFF000</span> )</span><br><span class="line"><span class="comment">/***** 省略后文 *****/</span></span><br></pre></td></tr></table></figure>

<p>如果输入错误, 则弹框提示 <code>Wrong answer!</code>, 输入正确则弹框提示 <code>Accepted!</code>.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***** 省略前文 *****/</span></span><br><span class="line">                    MessageBoxW(<span class="number">0</span>, <span class="string">L&quot;Accepted!&quot;</span>, <span class="string">L&quot;Result&quot;</span>, <span class="number">0x40</span>u);</span><br><span class="line">                    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">LABEL_41:</span><br><span class="line">  MessageBoxW(<span class="number">0</span>, <span class="string">L&quot;Wrong answer!&quot;</span>, <span class="string">L&quot;Result&quot;</span>, <span class="number">0x10</span>u);</span><br><span class="line"><span class="comment">/***** 省略后文 *****/</span></span><br></pre></td></tr></table></figure>

<h3 id="验证机制"><a href="#验证机制" class="headerlink" title="验证机制"></a>验证机制</h3><p>程序只有一些简单的反调试检测, 没有太多 anti, 主要难度还是在算法原理上, 因此可以比较容易逆向出算法流程和对应的伪代码.</p>
<p>核心部分是一个编码算法和一个解码算法, 而输入的序列号是两个算法的参数, 程序通过对随机输入进行编码与解码操作, 并检测是否能正确还原出原始输入序列来判断序列号是否正确.</p>
<p>用 IDA 可以还原出编码和解码算法的伪代码如下:</p>
<p>编码部分</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***** 省略前文 *****/</span></span><br><span class="line">    <span class="keyword">while</span> ( <span class="number">1</span> )</span><br><span class="line">    &#123;</span><br><span class="line">      v51 = v16;</span><br><span class="line">      v43 = v15;</span><br><span class="line">      <span class="keyword">if</span> ( v18 &gt;= <span class="number">10000</span> &amp;&amp; (v15 &lt; <span class="number">0</span> || v15 &lt;= <span class="number">0</span> &amp;&amp; !v16) )</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">if</span> ( v19 &gt;= <span class="number">20000</span> )</span><br><span class="line">      &#123;</span><br><span class="line">LABEL_38:</span><br><span class="line">        WaitForSingleObject(g_worker_mutex, <span class="number">0xFFFFFFFF</span>);</span><br><span class="line">        g_has_error = <span class="number">1</span>;</span><br><span class="line">        ReleaseMutex(g_worker_mutex);</span><br><span class="line">        v2 = v49;</span><br><span class="line">        <span class="keyword">goto</span> LABEL_39;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> ( v18 &gt;= <span class="number">10000</span> )</span><br><span class="line">      &#123;</span><br><span class="line">        v22 = *(_DWORD *)&amp;v14[<span class="number">4</span> * v19];</span><br><span class="line">        v23 = __PAIR__(v15, v16) % v22;</span><br><span class="line">        HIDWORD(v53) = HIDWORD(v23);</span><br><span class="line">        v24 = __PAIR__(v15, v51) / v22;</span><br><span class="line">        v15 = (<span class="type">unsigned</span> __int64)(__PAIR__(v15, v51) / v22) &gt;&gt; <span class="number">32</span>;</span><br><span class="line">        v16 = v24;</span><br><span class="line">        v14 = v45;</span><br><span class="line">        *(_DWORD *)&amp;v50[<span class="number">4</span> * v19++] = v23;</span><br><span class="line">        v18 = v46;</span><br><span class="line">        v17 = (<span class="type">int</span>)v40;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">      &#123;</span><br><span class="line">        v20 = *v40 + *(_DWORD *)(v17 + v54) * __PAIR__(v15, v16);</span><br><span class="line">        v15 = HIDWORD(v20);</span><br><span class="line">        v55 = v20;</span><br><span class="line">        v39 = *(_DWORD *)&amp;v45[<span class="number">4</span> * v19];</span><br><span class="line">        v16 = v20;</span><br><span class="line">        v53 = (<span class="type">signed</span> __int64)__PAIR__(v43, v51) % v39;</span><br><span class="line">        <span class="keyword">if</span> ( (<span class="type">signed</span> __int64)((<span class="type">signed</span> __int64)__PAIR__(v43, v51) / v39 * v20) &lt; (<span class="type">signed</span> __int64)__PAIR__(v56, v58) )</span><br><span class="line">        &#123;</span><br><span class="line">          v18 = v46 + <span class="number">1</span>;</span><br><span class="line">          v14 = v45;</span><br><span class="line">          v17 = (<span class="type">int</span>)(v40 + <span class="number">1</span>);</span><br><span class="line">          <span class="keyword">goto</span> LABEL_12;</span><br><span class="line">        &#125;</span><br><span class="line">        v21 = (<span class="type">signed</span> __int64)__PAIR__(v43, v51) / v39;</span><br><span class="line">        v15 = v21 &gt;&gt; <span class="number">32</span>;</span><br><span class="line">        v16 = v21;</span><br><span class="line">        v14 = v45;</span><br><span class="line">        *(_DWORD *)&amp;v50[<span class="number">4</span> * v19++] = v53;</span><br><span class="line">        v18 = v46;</span><br><span class="line">        v17 = (<span class="type">int</span>)v40;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">/***** 省略后文 *****/</span></span><br></pre></td></tr></table></figure>

<p>解码部分</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***** 省略前文 *****/</span></span><br><span class="line">    <span class="keyword">while</span> ( <span class="number">1</span> )</span><br><span class="line">    &#123;</span><br><span class="line">      v54 = v30;</span><br><span class="line">      v52 = v27;</span><br><span class="line">      <span class="keyword">if</span> ( v25 &lt; <span class="number">0</span> &amp;&amp; (v27 &lt; <span class="number">0</span> || v27 &lt;= <span class="number">0</span> &amp;&amp; !v30) )</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">if</span> ( v28 &lt; <span class="number">0</span> )</span><br><span class="line">        <span class="keyword">goto</span> LABEL_38;</span><br><span class="line">      <span class="keyword">if</span> ( v25 &lt; <span class="number">0</span> )</span><br><span class="line">      &#123;</span><br><span class="line">        v34 = *((_DWORD *)in_r + v28);</span><br><span class="line">        HIDWORD(v53) = (<span class="type">unsigned</span> __int64)(__PAIR__(v27, v54) % v34) &gt;&gt; <span class="number">32</span>;</span><br><span class="line">        v35 = __PAIR__(v27, v54) / v34;</span><br><span class="line">        v27 = (<span class="type">unsigned</span> __int64)(__PAIR__(v27, v54) / v34) &gt;&gt; <span class="number">32</span>;</span><br><span class="line">        v30 = v35;</span><br><span class="line">        v33 = (<span class="type">unsigned</span> <span class="type">int</span>)(__PAIR__(v52, v54) % v34) == v49[v28];</span><br><span class="line">LABEL_34:</span><br><span class="line">        <span class="keyword">if</span> ( !v33 )</span><br><span class="line">          <span class="keyword">goto</span> LABEL_38;</span><br><span class="line">        v25 = v47;</span><br><span class="line">        --v28;</span><br><span class="line">        v29 = (<span class="type">int</span>)v41;</span><br><span class="line">        v26 = v44;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">      &#123;</span><br><span class="line">        v31 = *(_DWORD *)v41 + *(_DWORD *)(v26 + v29) * __PAIR__(v27, v30);</span><br><span class="line">        v27 = HIDWORD(v31);</span><br><span class="line">        LODWORD(v53) = v31;</span><br><span class="line">        v32 = *((_DWORD *)in_r + v28);</span><br><span class="line">        v30 = v31;</span><br><span class="line">        v55 = __PAIR__(v52, v54) % v32;</span><br><span class="line">        b_high = (<span class="type">unsigned</span> __int64)(__PAIR__(v52, v54) / v32) &gt;&gt; <span class="number">32</span>;</span><br><span class="line">        b_low = __PAIR__(v52, v54) / v32;</span><br><span class="line">        <span class="keyword">if</span> ( (<span class="type">signed</span> __int64)(__PAIR__(v52, v54) / v32 * v31) &gt;= *(_QWORD *)parameters )</span><br><span class="line">        &#123;</span><br><span class="line">          v30 = b_low;</span><br><span class="line">          v27 = b_high;</span><br><span class="line">          v33 = v55 == v49[v28];</span><br><span class="line">          <span class="keyword">goto</span> LABEL_34;</span><br><span class="line">        &#125;</span><br><span class="line">        v25 = v47 - <span class="number">1</span>;</span><br><span class="line">        v26 = v44;</span><br><span class="line">        v29 = (<span class="type">int</span>)(v41 - <span class="number">4</span>);</span><br><span class="line">        --v47;</span><br><span class="line">        v41 -= <span class="number">4</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">/***** 省略后文 *****/</span></span><br></pre></td></tr></table></figure>

<p>算法流程不是太复杂, 可以看出是一种自定义的混合进制编解码算法, 而输入的序列号作为参数来控制算法正确运行, 算法涉及到的关键参数如下图:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***** 省略前文 *****/</span></span><br><span class="line">  in_r = _calloc(<span class="number">10000u</span>, <span class="number">4u</span>);</span><br><span class="line">  in = _calloc(<span class="number">10000u</span>, <span class="number">4u</span>);</span><br><span class="line">  v2 = in;</span><br><span class="line">  v49 = in;</span><br><span class="line">  out_r = (<span class="type">char</span> *)_calloc(<span class="number">20000u</span>, <span class="number">4u</span>);</span><br><span class="line">  v4 = out_r;</span><br><span class="line">  v45 = out_r;</span><br><span class="line">  out = (<span class="type">char</span> *)_calloc(<span class="number">20000u</span>, <span class="number">4u</span>);</span><br><span class="line"><span class="comment">/***** 省略片段 *****/</span></span><br><span class="line">    b_low = *(_DWORD *)parameters;</span><br><span class="line">    v17 = (<span class="type">int</span>)v49;</span><br><span class="line">    b_high = *((_DWORD *)parameters + <span class="number">1</span>);</span><br><span class="line"><span class="comment">/***** 省略后文 *****/</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>b</code>: 输入的序列号整数.</li>
<li><code>in</code>: 随机输入序列.</li>
<li><code>in_r</code>: 随机输入序列的进制序列.</li>
<li><code>out_</code> 开头的则是输出结果.</li>
</ul>
<p>解码算法流程与编码算法几乎一致, 但是把编码的输入和输出交换了一下, 同时进行了倒序处理, 并对解码序列与原始随机输入序列进行比较, 判断是否还原成功.</p>
<p>而验证步骤的关键伪代码还原如下:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***** 省略前文 ******/</span></span><br><span class="line">                  g_has_error = <span class="number">0</span>;</span><br><span class="line">                  v9 = <span class="number">0</span>;</span><br><span class="line">                  <span class="keyword">if</span> ( check_error_in_x(__PAIR__(v7, v8)) )</span><br><span class="line">                  &#123;</span><br><span class="line">                    <span class="keyword">if</span> ( !g_has_error )</span><br><span class="line">                    &#123;</span><br><span class="line">                      g_has_error = <span class="number">0</span>;</span><br><span class="line">                      <span class="keyword">if</span> ( check_error_in_x(__PAIR__(v7, v8) - <span class="number">1</span>) )</span><br><span class="line">                      &#123;</span><br><span class="line">                        <span class="keyword">if</span> ( g_has_error )</span><br><span class="line">                          v9 = <span class="number">1</span>;</span><br><span class="line">                      &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;</span><br><span class="line"><span class="comment">/***** 省略后文 ******/</span></span><br></pre></td></tr></table></figure>

<p>要求对于输入的 <code>b</code> 能够使算法正确工作, 但是 <code>b - 1</code> 不能使算法正确工作.</p>
<h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><h3 id="暴力枚举"><a href="#暴力枚举" class="headerlink" title="暴力枚举"></a>暴力枚举</h3><p>此题的输入数据范围是介于 4K 到 4G 之间的一个整数, 可以考虑把核心算法单独摘出来整理重写, 然后进行暴力枚举.</p>
<p>但是枚举的难度在于, 原程序使用的随机输入序列长度为 <code>10000</code>, 且使用多线程进行了约 <code>10000</code> 轮测试, 也就是说纯随机情况下, 如果数据量不够大, 很可能造成误判, 从而无法枚举出正确的序列号, 因此枚举的时间成本很高, 只是一个保底下策.</p>
<h3 id="公式枚举"><a href="#公式枚举" class="headerlink" title="公式枚举"></a>公式枚举</h3><p>程序的算法是一个用于混合进制序列的编解码算法, 且需要一个控制参数来使算法正确工作. 而程序的验证机制是 <code>b</code> 正确且 <code>b - 1</code> 错误, 可以合理推测能够使算法正确工作的参数不止一个, 应该是一个连续区间, 且题目的正确答案是这个区间的左端点, 因此我们需要找出参数的取值规律, 从而快速求解答案.</p>
<p>翻一下逆向后的代码, 可以找到程序使用的进制集是 <code>&#123; 2, 4, 5, 6, 7, 8, 13 &#125;</code>, 且输入和输出使用了同一组进制.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.rdata:004031C8 _TEST_RADIX_LEN:</span><br><span class="line">.rdata:004031C8                 dw 7, 0</span><br><span class="line">.rdata:004031CC ; int TEST_RADIX[]</span><br><span class="line">.rdata:004031CC _TEST_RADIX     dd 2, 4, 5, 6, 7, 8, 13 ; DATA XREF: do_error_check(x)+114</span><br><span class="line">.rdata:004031CC                                         ; do_error_check(x)+15E</span><br></pre></td></tr></table></figure>

<p>猜想 <code>b</code> 的取值与进制组合有关, 因此可以从简单的入手, 暴力枚举小区间, 寻找规律.</p>
<p>分别设置以下几种方式去进行枚举, 可以得到正确的取值区间如下:</p>
<ul>
<li>输入进制 <code>&#123; 2 &#125;</code>, 输出进制 <code>&#123; 2 &#125;</code>: <code>[1, 5], [7, 18], [21, 39], [43, 68], [73, 105], ...</code></li>
<li>输入进制 <code>&#123; 2 &#125;</code>, 输出进制 <code>&#123; 3 &#125;</code>: <code>[1, 7], [11, 26], [33, 57], [67, 100], [113, 155], ...</code></li>
<li>输入进制 <code>&#123; 3 &#125;</code>, 输出进制 <code>&#123; 3 &#125;</code>: <code>[1, 10], [17, 38], [51, 84], [103, 148], ...</code></li>
<li>输入进制 <code>&#123; 2 &#125;</code>, 输出进制 <code>&#123; 2, 3 &#125;</code>: <code>[1, 5], [7, 7], [11, 18], [21, 26], [33, 39], [43, 57], [67, 68], [73, 100], [113, 150], ...</code></li>
<li>输入进制 <code>&#123; 2, 3 &#125;</code>, 输出进制 <code>&#123; 2, 3 &#125;</code>: <code>[1, 5], [7, 7], [17, 18], [21, 26], [33, 38], [51, 57], [67, 68], [73, 84], [113, 148], ...</code></li>
</ul>
<p>观察一下可以发现, 对于混合进制的情况, 正确的取值区间是通过单个的输入输出进制的取值区间取交集得到的:</p>
<ul>
<li><code>&#123; 2 &#125;_&#123; 2, 3 &#125; = &#123; 2 &#125;_&#123; 2 &#125; &amp; &#123; 2 &#125;_&#123; 3 &#125;</code></li>
<li><code>&#123; 2, 3 &#125;_&#123; 2, 3 &#125; = &#123; 2 &#125;_&#123; 2, 3 &#125; &amp; &#123; 3 &#125;_&#123; 3 &#125;</code></li>
</ul>
<p>因此, 只要能找出单个的输入输出进制的取值区间规律就能解出题目.</p>
<p>继续观察寻找规律, 可以发现规律:</p>
<ul>
<li><code>&#123; 2 &#125;_&#123; 2 &#125;</code>: <code>[4 * n^2 - (4 + 2) * n + 3, 4 * n^2 + n]</code></li>
<li><code>&#123; 2 &#125;_&#123; 3 &#125;</code>: <code>[6 * n^2 - (6 + 2) * n + 3, 6 * n^2 + n]</code></li>
<li><code>&#123; 3 &#125;_&#123; 3 &#125;</code>: <code>[9 * n^2 - (9 + 2) * n + 3, 9 * n^2 + n]</code></li>
</ul>
<p>因此可以得到通项公式为: <code>[r1 * r2 * n^2 - (r1 * r2 + 2) * n + 3, r1 * r2 * n^2 + n]</code></p>
<p>而题目使用了 7 种不同的进制, 且输入输出进制相同, 因此共需要枚举 21 种情况, 然后取交集最终得到题目里正确的取值范围, 并取左端点作为序列号.</p>
<p>这里需要注意的是, 取交集这个操作并不高效, 但是可以翻过来操作, 每次将错误取值区间筛去, 能够更快速的计算出正确答案, 这里贴一下核心计算代码.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">search_b</span><span class="params">(<span class="type">long</span> <span class="type">long</span> start, <span class="type">long</span> <span class="type">long</span> end)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> p = <span class="number">0</span>;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> n_s = <span class="number">0</span>;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> n_e = <span class="number">0</span>;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> b1 = <span class="number">0</span>;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> b2 = <span class="number">0</span>;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> b_count = end - start + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span>* full_set = <span class="built_in">calloc</span>((<span class="type">size_t</span>)b_count, <span class="keyword">sizeof</span>(<span class="type">bool</span>));</span><br><span class="line">    <span class="keyword">if</span> (!full_set)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">memset</span>(full_set, <span class="number">1</span>, (<span class="type">size_t</span>)b_count * <span class="keyword">sizeof</span>(<span class="type">bool</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; in_r_len; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = i; j &lt; out_r_len; j++) &#123;</span><br><span class="line">            p = in_r[i] * out_r[j];</span><br><span class="line">            n_s = left_floor(p, start);</span><br><span class="line">            n_e = right_ceil(p, end);</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">long</span> <span class="type">long</span> n = n_s; n &lt;= n_e; n++) &#123;</span><br><span class="line">                b1 = left(p, n);</span><br><span class="line">                b2 = right(p, n);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (b1 &lt; start)</span><br><span class="line">                    b1 = start;</span><br><span class="line">                <span class="keyword">if</span> (b2 &gt; end)</span><br><span class="line">                    b2 = end;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">for</span> (<span class="type">long</span> <span class="type">long</span> b_idx = b1 - start; b_idx &lt;= b2 - start; b_idx++) &#123;</span><br><span class="line">                    full_set[b_idx] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">long</span> <span class="type">long</span> b_s = <span class="number">0</span>; b_s &lt; b_count; b_s++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (full_set[b_s]) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">long</span> <span class="type">long</span> b_e = b_s; b_e &lt; b_count; b_e++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (!full_set[b_e]) &#123;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;Valid: [%lld, %lld] Count: %lld\n&quot;</span>, b_s + start, b_e - <span class="number">1</span> + start, b_e - b_s);</span><br><span class="line">                    b_s = b_e;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (full_set)</span><br><span class="line">        <span class="built_in">free</span>(full_set);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="最终答案"><a href="#最终答案" class="headerlink" title="最终答案"></a>最终答案</h3><p>最后算出来题目的进制组合下 100 亿范围内只有这些正确区间:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Valid: [1, 5] Count: 5</span><br><span class="line">Valid: [7, 9] Count: 3</span><br><span class="line">Valid: [1898766093, 1898766391] Count: 299</span><br><span class="line">Valid: [79233213543, 79233230703] Count: 17161</span><br></pre></td></tr></table></figure>

<p>题目要求范围在 4K 到 4G 的范围, 因此序列号为 <code>1898766093</code>, 输入之后得到正确结果 <code>Accepted!</code>.</p>
<h2 id="题目及源代码"><a href="#题目及源代码" class="headerlink" title="题目及源代码"></a>题目及源代码</h2><p>看雪的帖子里有下载地址, 这里也贴一下蓝奏云的下载链接.</p>
<p>蓝奏云: <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pTnM5bzFiZHBnMGg=">2023KCTF竞赛.zip<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>看雪</tag>
        <tag>KCTF</tag>
        <tag>逆向</tag>
      </tags>
  </entry>
  <entry>
    <title>解决学习道路上的 &quot;最后 1 KB&quot;</title>
    <url>//posts/2022/08/14/kxsw/</url>
    <content><![CDATA[<p><code>Github</code> 时断时连? <code>git clone</code> 老是失败? 谷歌学术无法使用? ......</p>
<p>没有关系! 看了本篇以后, 从此不在担忧, 让你在互联网的世界里畅通无阻.</p>
<p>本篇为一篇小白入门, 旨在简单介绍解决上述问题的基本方案, 让你扫清上网时的 &quot;最后 1 KB&quot;.</p>
<span id="more"></span>

<h2 id="工具下载"><a href="#工具下载" class="headerlink" title="工具下载"></a>工具下载</h2><p>这里只说基于 <code>V2Ray</code> 的两个工具, 分别用于 PC 端和安卓端. 先附上两个工具的 Github 官方地址.</p>
<p>PC 端 <code>V2RayN</code>: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzJkdXN0L3YycmF5Ti8=">Github 项目地址<i class="fa fa-external-link-alt"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzJkdXN0L3YycmF5Ti9yZWxlYXNlcy8=">下载页面<i class="fa fa-external-link-alt"></i></span></p>
<p>安卓端 <code>V2RayNG</code>: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzJkdXN0L3YycmF5Tkcv">Github 项目地址<i class="fa fa-external-link-alt"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzJkdXN0L3YycmF5TkcvcmVsZWFzZXMv">下载页面<i class="fa fa-external-link-alt"></i></span></p>
<p>考虑到很多人一开始是没有这些工具的, 而这些工具的下载又可能需要工具本身支持, 所以额外放一个 <code>V2RayN-Core v5.32</code> 的网盘<span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pUG0wUzA5ajZ2cWgv">下载地址<i class="fa fa-external-link-alt"></i></span> (压缩包哈希校验会与官网下载不同, 因为重新打包过再上传的).</p>
<p><img data-src="/static/image/kxsw/vUBwJU.jpg" alt="vUBwJU.jpg"></p>
<h2 id="工具使用"><a href="#工具使用" class="headerlink" title="工具使用"></a>工具使用</h2><p>网上教程很多, 这里直接放一下看起来是官方的<span class="exturl" data-url="aHR0cHM6Ly92MnJheW4ub3JnLw==">教程网站<i class="fa fa-external-link-alt"></i></span>.</p>
<p>在这里只简单科普一下基本概念.</p>
<p>既然由于不可抗力导致直接连接网站的效果很差, 甚至无法连接, 那么我们可以找人帮忙, 找那些访问速度较好的 &quot;中间人&quot; 帮我们访问, 我们再从中间人那里间接获得需要的信息, 这种 &quot;中间人&quot; 就称为 &quot;节点&quot;.</p>
<p>但是我们自己是无法直接和节点进行交互的, 所以需要工具来帮助我们传递需求, 而对于 <code>V2Ray</code> 这一类工具客户端, 其工作方式是在你自己的机器上搭建一个本地的 &quot;代理服务器&quot;, 从而我们可以访问本地的代理服务器, 进而访问到节点, 下面放一个对比.</p>
<p>不使用工具前:</p>
<p><code>用户 --|--&gt; 目标网站</code></p>
<p>使用工具后:</p>
<p><code>用户 --&gt; 本地代理 --&gt; 节点 --&gt; 目标网站</code></p>
<p>所以对使用工具来说, 比较重要的信息是, 代理服务器设置是什么, 以及使用的节点是什么.</p>
<h3 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h3><p>PC 端上, <code>V2RayN</code> 的本地代理默认监听地址是 <code>127.0.0.1</code>, 其中 <code>http</code> 协议的端口是 <code>10809</code>, <code>socks</code> 协议的端口是 <code>10808</code>.</p>
<p>启动 <code>V2RayN</code> 客户端之后, 右键点击通知栏的图标, 在系统代理内有三个选项.</p>
<ul>
<li>清除系统代理: 清除掉在系统设置内的代理设置.</li>
<li>自动配置系统代理: 将系统设置内的代理设置为 <code>V2RayN</code> 的代理服务器.</li>
<li>不改变系统代理: 保持原有系统代理设置不变.</li>
</ul>
<p>这是个让我们快速更改系统代理设置的选项, 除此之外, 我们也可以手动去系统设置里的 <code>网络和 Internet -&gt; 代理 -&gt; 手动设置代理</code> 调整系统要使用的代理服务器.</p>
<p>当系统代理被设置之后, 凡是只能通过系统代理的软件 <code>http</code> 协议流量, 比如 <code>Edge</code> 和 <code>Chrome</code> 浏览器等, 都会经过 <code>V2RayN</code> 来转发给节点, 从而访问到目标网站.</p>
<p>但是某些程序是可以单独设置使用代理服务器的, 比如 <code>Firefox</code> 浏览器, 这种就需要自己去浏览器设置里手动设置代理.</p>
<p><img data-src="/static/image/kxsw/vUyCmd.png" alt="vUyCmd.png"></p>
<p>个人推荐备一个 <code>Firefox</code> 浏览器, 这样子可以单独把代理挂给浏览器而不是影响全局, 既可以访问国外网站也不影响使用 <code>Edge</code> 等浏览器访问国内网站.</p>
<h3 id="使用节点与订阅"><a href="#使用节点与订阅" class="headerlink" title="使用节点与订阅"></a>使用节点与订阅</h3><p>一个节点通常长这样.</p>
<p><code>&lt;协议&gt;://&lt;内容&gt;</code></p>
<p><code>vmess://55yL5ZWl5ZGi77yf5rKh5pyJ6IqC54K55L+h5oGv77yB</code></p>
<p>直接 <code>Ctrl + C</code> 复制内容然后进入客户端 <code>Ctrl + V</code> 就可以导入节点信息了.</p>
<p>这种时候就会有人说了, 一个个节点导入太麻烦, 而且节点说不定什么时候就会失效, 还得重新一个个找. 所以, 订阅地址它出现了.</p>
<p>比如有个白嫖订阅地址 <span class="exturl" data-url="aHR0cHM6Ly9qaWFuZy5uZXRsaWZ5LmNvbS8=">https://jiang.netlify.com/<i class="fa fa-external-link-alt"></i></span>, 你点开了直接看就会发现是一大堆的字符, 其实是一个个的节点信息, 并且每隔一段时间内容还不一样, 也就是节点信息被更新了.</p>
<p>那么, 只要往 <code>V2RayN</code> 客户端内添加这个订阅地址, 以后再使用 &quot;更新订阅&quot; 的功能, 客户端就会自动从这个地址获取节点信息并且更新该订阅下的所有节点为新节点, 为我们懒人带来福音.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>So, 为了解决上网的最后 &quot;1 KB&quot;, 我们需要首先获得工具, 然后获得节点 (或者获得订阅地址), 再然后开启软件设置节点与代理, 之后就可以在学习的道路上畅通无阻了<del>天翼 3G 太快了</del>.</p>
<p>这里贴一个可以白嫖的机场地址 <span class="exturl" data-url="aHR0cHM6Ly9wZXBzaWNvbGEubWUv">https://pepsicola.me<i class="fa fa-external-link-alt"></i></span> , 有免费订阅可以满足日常基本使用需求<del>不知道看到这篇文章的时候是否还进得去</del>.</p>
<p>尝试使用谷歌学术搜索一篇论文, 很 nice, 顷刻之间, 已尽数列出.</p>
<p><img data-src="/static/image/kxsw/vUc2TA.png" alt="vUc2TA.png"></p>
<p>PS: 就这么多了(。_。), 有兴趣的同学还请善用搜索引擎, 发挥互联网自主探索精神.</p>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>科学上网</tag>
      </tags>
  </entry>
  <entry>
    <title>NJ 树算法原理与实现</title>
    <url>//posts/2023/03/08/njtree/</url>
    <content><![CDATA[<p>邻接法 (Neighbor-Joining Method), 是一种利用进化距离数据重建系统进化树的方法, 用这个方法得到的进化树通常称为 NJ 树. 这是一种自底向上的聚类方法, 将每个个体看作一个类别, 然后依次两两聚合, 最终得到一整个聚合后的进化树.</p>
<p>本文简要介绍 NJ 树算法的基本流程与计算方法, 并在文末提供对应的 <code>python</code> 实现.</p>
<span id="more"></span>

<h2 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h2><h3 id="邻居"><a href="#邻居" class="headerlink" title="邻居"></a>邻居</h3><p><img data-src="/static/image/njtree/ppVbSaR.png" alt="ppVbSaR.png"></p>
<p>首先是关于&quot;邻居&quot;的定义, 在 NJ 树中, 一对&quot;邻居&quot;指的是在一个无根分叉树中仅仅通过一个内部结点连接起来一对分类单元 (OTU).</p>
<p>例如在上图中, $1$ 和 $2$ 可以视为一对邻居, 它们通过内部结点 $A$ 进行连结.</p>
<p>进一步, 可以对分类单元进行组合, 形成新的更大的分类单元与邻居对, 例如, $&lt;1, 2&gt;$ 和 $3$ 可以作为一对邻居, 它们通过内部结点 $B$ 进行连结, $&lt;5, 6&gt;$ 和 $&lt;7, 8&gt;$ 可以作为一对邻居, 它们通过内部结点 $D$ 进行连结.</p>
<h3 id="进化树构建流程"><a href="#进化树构建流程" class="headerlink" title="进化树构建流程"></a>进化树构建流程</h3><p><img data-src="/static/image/njtree/ppVqOHJ.png" alt="ppVqOHJ.png"></p>
<p>假设初始时没有任何分类单元聚集在一起, 算法起始于一个星状树, 如上图左侧所示. 算法的一步变换则是将左图变成了右图.</p>
<p>在这些分类单元中, 分类单元之间有着不同的距离远近, 右侧的图将 $1$ 和 $2$ 聚合在了一起, 并形成了一个新结点 $Y$, 将 $1$, $2$ 视作一个整体, 则相比于左图, $&lt;1, 2&gt;$ 作为新分类单元整体替换了左图里的分类单元 $1$ 和 $2$, 整个星状树减少了 1 个分类单元, 增加了 1 条内部分支, 每次选择要聚合的邻居时, 都是使得聚合后的新树总枝长最短. 如此循环, 则可以一步一步减少星状树的分类单元, 直至分类单元只剩下 3 个, 内部分支增加至 $N - 3$ 个.</p>
<p><img data-src="/static/image/njtree/ppVX9mD.png" alt="ppVX9mD.png"></p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p><img data-src="/static/image/njtree/ppVqOHJ.png" alt="ppVqOHJ.png"></p>
<h3 id="计算总枝长"><a href="#计算总枝长" class="headerlink" title="计算总枝长"></a>计算总枝长</h3><p>还是以这张图为例, 设初始时共有 $N$ 个分类单元, 设 $D_{ij}$ 指分类单元 $i$ 和 $j$ 之间的距离, $L_{ab}$ 指结点 $a$ 和 $b$ 之间的枝长. 整个树的总枝长为:</p>
<p>$$<br>S_O = \sum_{i=1}^{N}L_{iX}=\frac{1}{N-1}\sum_{i&lt;j}^{N}D_{ij}<br>$$</p>
<p>也就是每个结点到 $X$ 的枝长总和, 等价于分类单元两两之间距离求和后除以 $N-1$, 因为每个枝相当于数了 $N-1$ 次.</p>
<details class="note info"><summary><p>为什么是 $N-1$ ?</p>
</summary>
<p>$1$ 到 $X$ 的距离通过 $D_{ij}$ 数了 $N-1$ 次; $2$ 到 $X$ 的距离通过 $D_{12}$ 数了 $1$ 次, 通过 $D_{2j}$ 数了 $N-2$ 次, 以此类推.</p>

</details>

<h3 id="计算新增枝长后的总枝长"><a href="#计算新增枝长后的总枝长" class="headerlink" title="计算新增枝长后的总枝长"></a>计算新增枝长后的总枝长</h3><p>另一方面, 右侧图中 $X$ 和 $Y$ 结点之间的枝长计算方法为:</p>
<p>$$<br>\begin{aligned}<br>  L_{XY} &amp;= \frac{1}{2(N-2)}\left[\sum_{k=3}^{N}{(D_{1k}+D_{2k})} - {(N-2)(L_{1X}+L_{2X})} - {2\sum_{i=3}^{N}{L_{iY}}} \right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[\sum_{k=3}^{N}{(D_{1k}+D_{2k})} - {(N-2)D_{12}} - {\frac{2}{N-3}\sum_{3 \leq i&lt;j}^{N}D_{ij}} \right]<br>\end{aligned}<br>$$</p>
<p>第一项 $\sum_{k=3}^{N}{(D_{1k}+D_{2k})}$ 代表从结点 $1,2$ 到其余所有结点的距离, 包括 $L_{XY}$. 公式的后两项是为了减去多算的那部分距离, $(L_{1X}+L_{2X})$ 是 $1,2$ 到 $X$ 的距离, $\sum_{i=3}^{N}{L_{iY}}$ 是其余点到 $Y$ 的距离.</p>
<details class="note info"><summary><p>前面的那些系数怎么来的 ?</p>
</summary>
<p>在第一项中, $\sum_{k=3}^{N}{(D_{1k}+D_{2k})}$ 将 $1,2$ 到 $X$ 的边各数了 $N-2$ 次, $X$ 到 $Y$ 的边数了 $2(N-2)$ 次, $Y$ 到其余结点各数了 $2$ 次, 因此减去对应的次数后再除以 $2(N-2)$ 就是 $L_{XY}$ 的距离.</p>

</details>

<p>得到 $L_{XY}$ 之后, 可以计算右侧新图的总枝长:</p>
<p>$$<br>\begin{aligned}<br>  S_{12} &amp;= L_{XY} + (L_{1X} + L_{2X}) + \sum_{i=3}^{N}L_{iY} \\<br>  ~ &amp;= \frac{1}{2(N-2)}\sum_{k=3}^{N}(D_{1k} + D_{2k}) + \frac{1}{2}D_{12} + \frac{1}{N-2}\sum_{3 \leq i&lt;j}^{N}D_{ij}<br>\end{aligned}<br>$$</p>
<h3 id="构造新图"><a href="#构造新图" class="headerlink" title="构造新图"></a>构造新图</h3><p>通常来说, 并不会知道右图中 $1,2$ 究竟选择哪一对分类单元作为邻居, 因此需要计算所有的 $S_{ij}$, 并选择最小的那一对作为这一轮的选择.</p>
<p>假设 $1,2$ 就是这一轮选择出来的邻居, 则它们两个和 $X$ 会形成新的分类单元 $&lt;1,2&gt;$, 然后计算新分类单元与其余分类单元的距离:</p>
<p>$$<br>D_{&lt;1,2&gt;j} = \frac{1}{2}(D_{1j} + D_{2j}) \quad (3 \leq j \leq N)<br>$$</p>
<p>得到新距离之后, 还需要计算新分类单元 $&lt;1,2&gt;$ 内部的距离 $L_{1X}, L_{2X}$.</p>
<p>$$<br>\begin{aligned}<br>  L_{1X} &amp;= \frac{1}{2}(D_{12} + D_{1Z} - D_{2Z}) \\<br>  L_{2X} &amp;= \frac{1}{2}(D_{12} + D_{2Z} - D_{1Z})<br>\end{aligned}<br>$$</p>
<p>其中:</p>
<p>$$<br>\begin{aligned}<br>  D_{1Z} &amp;= \frac{1}{N-2}\sum_{i=3}^{N}D_{1i} \\<br>  D_{2Z} &amp;= \frac{1}{N-2}\sum_{i=3}^{N}D_{2i}<br>\end{aligned}<br>$$</p>
<p>在这一组公式里面, $Z$ 代表除去 $1,2$ 的所有结点形成的&quot;假想结点&quot;, 即 $1$ 通过 $Z$ 这个整体与 $2$ 相连. 则 $1,2$ 与 $Z$ 的距离分别为各自到 $Z$ 中其余结点距离的平均值.</p>
<h3 id="循环步骤"><a href="#循环步骤" class="headerlink" title="循环步骤"></a>循环步骤</h3><p>每选择一对合适的邻居, 则图上的分类单元就会减少 1 个, 直到图上的分类单元数量变成 3, 算法结束.</p>
<h2 id="公式化简"><a href="#公式化简" class="headerlink" title="公式化简"></a>公式化简</h2><p>在实际计算之前, 需要对原始公式进行一些化简变形.</p>
<p>首先是对每一轮都需要计算的新图总枝长公式进行变形, 以前文的 $S_{12}$ 为例:</p>
<p>$$<br>\begin{aligned}<br>  S_{12} &amp;= \frac{1}{2(N-2)}\sum_{k=3}^{N}(D_{1k} + D_{2k}) + \frac{1}{2}D_{12} + \frac{1}{N-2}\sum_{3 \leq i&lt;j}^{N}D_{ij} \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[\sum_{k=3}^{N}D_{1k} + \sum_{k=3}^{N}D_{2k} + (N-2)D_{12} + \sum_{3 \leq i&lt;j}^{N}D_{ij} + \sum_{3 \leq i&lt;j}^{N}D_{ij}\right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} - \left(D_{12} + \sum_{k=3}^{N}D_{1k}\right) - \left(D_{21} + \sum_{k=3}^{N}D_{2k}\right) + \left(D_{12} + \sum_{k=3}^{N}D_{1k} + \sum_{3 \leq i&lt;j}^{N}D_{ij}\right) + \left(D_{21} + \sum_{k=3}^{N}D_{2k} + \sum_{3 \leq i&lt;j}^{N}D_{ij}\right)\right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} - \sum_{k \ne 1}^{N}D_{1k} - \sum_{k \ne 2}^{N}D_{2k} + 2\sum_{i&lt;j}^{N}D_{ij}\right] \\<br>  ~ &amp;= \frac{1}{2}\left[D_{12} - \frac{1}{(N-2)}\sum_{k \ne 1}^{N}D_{1k} - \frac{1}{(N-2)}\sum_{k \ne 2}^{N}D_{2k}\right] + \frac{1}{(N-2)}\sum_{i&lt;j}^{N}D_{ij} \\<br>  ~ &amp;= C_1\left[D_{12} - \frac{1}{(N-2)}\sum_{k \ne 1}^{N}D_{1k} - \frac{1}{(N-2)}\sum_{k \ne 2}^{N}D_{2k}\right] + C_2<br>\end{aligned}<br>$$</p>
<p>经过化简之后, 可以看到, 只有方括号里的内容与要计算的邻居对 $1,2$ 有关, 其他量都可以看作这一轮的常量.</p>
<p>因为最终 $S_{ij}$ 是用于比较最小值, 所以只需要保证 $S_{ij}$ 的相对大小不变, 又 $C_1, C_2$ 均大于 $0$, 于是可以在实际计算中忽略掉常数项, 从而简化计算, 从而有:</p>
<p>$$<br>S_{ij} = D_{ij} - D_{iZ} - D_{jZ}<br>$$</p>
<p>其中:</p>
<p>$$<br>D_{iZ} = \frac{1}{(N-2)}\sum_{k \ne i}^{N}D_{ik}<br>$$</p>
<p>仍以前文的图为例, 在选择出最合适的邻居 $1,2$ 后, 会合并成新的分类单元 $&lt;1,2&gt;$, 需要在新图里计算 $&lt;1,2&gt;$ 和其余点的距离值, 以及内部距离 $L_{1X}, L_{2X}$.</p>
<p>新距离值就是 $D_{&lt;i,j&gt;k} = \frac{1}{2}(D_{ik} + D_{jk})$, 这里对 $L_{1X}, L_{2X}$ 进行变形化简.</p>
<p>$$<br>\begin{aligned}<br>  L_{1X} &amp;= \frac{1}{2}(D_{12} + D_{1Z} - D_{2Z}) \\<br>  ~ &amp;= \frac{1}{2}\left(D_{12} + \frac{1}{N-2}\sum_{i=3}^{N}D_{1i} - \frac{1}{N-2}\sum_{i=3}^{N}D_{2i}\right) \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} + \sum_{i=3}^{N}D_{1i} - \sum_{i=3}^{N}D_{2i}\right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} + \left(D_{12} + \sum_{i=3}^{N}D_{1i}\right) - \left(D_{21} + \sum_{i=3}^{N}D_{2i}\right)\right] \\<br>  ~ &amp;= \frac{1}{2(N-2)}\left[(N-2)D_{12} + \sum_{k \ne 1}^{N}D_{1k} - \sum_{k \ne 2}^{N}D_{2k}\right] \\<br>  ~ &amp;= \frac{1}{2}\left(D_{12} + \frac{1}{(N-2)}\sum_{k \ne 1}^{N}D_{1k} - \frac{1}{(N-2)}\sum_{k \ne 2}^{N}D_{2k}\right) \\<br>  L_{2X} &amp;= \frac{1}{2}\left(D_{12} + \frac{1}{(N-2)}\sum_{k \ne 2}^{N}D_{2k} - \frac{1}{(N-2)}\sum_{k \ne 1}^{N}D_{1k} \right)<br>\end{aligned}<br>$$</p>
<p>因此有:</p>
<p>$$<br>\begin{aligned}<br>  L_{iX} &amp;= \frac{1}{2}\left(D_{ij} + D_{iZ} - D_{jZ}\right) \\<br>  L_{jX} &amp;= \frac{1}{2}\left(D_{ij} + D_{jZ} - D_{iZ}\right)<br>\end{aligned}<br>$$</p>
<p>变形成这样有个好处, 就是能够复用前面算 $S_{ij}$ 时计算的 $D_{iZ}$ 结果.</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li>依次计算当前轮次的 $M_i$ 值, 得到 $M$ 向量 $(M_1, M_2, \ldots, M_N)$.</li>
<li>计算所有的 $S_{ij} ~ (1 \leq i &lt; j \leq N)$, 选择使 $S_{ij}$ 最小的 $i,j$ 作为这一轮的邻居.</li>
<li>计算新分类单元 $&lt;i,j&gt;$ 对其余点的新距离 $D_{&lt;i,j&gt;k} ~ (1 \leq k \leq N, k \ne i, j)$.</li>
<li>计算内部距离 $L_{iX}$ 和 $L_{jX}$.</li>
<li>更新当前分类单元数 $N = N-1$, 如果 $N &gt; 3$, 则转步骤 1 继续, 否则结束计算.</li>
</ol>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> rich <span class="keyword">import</span> progress</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">neighbor_joining</span>(<span class="params">_otu: <span class="type">List</span>[<span class="built_in">str</span>], _dist: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">float</span>]]</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        _otu: names of otus</span></span><br><span class="line"><span class="string">        _dist: distances dict for otus, (i, j) -&gt; dist, i less than j</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># init</span></span><br><span class="line">    nodes = [&#123;<span class="string">&quot;name&quot;</span>: e, <span class="string">&quot;parent&quot;</span>: <span class="literal">None</span>&#125; <span class="keyword">for</span> e <span class="keyword">in</span> _otu]</span><br><span class="line">    n = <span class="built_in">len</span>(nodes)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># otu_distances: used to record otu distances</span></span><br><span class="line">    otu_distances: np.ndarray = np.array(_dist, dtype=np.float_)</span><br><span class="line">    otu_distances = np.concatenate([otu_distances, np.zeros((n - <span class="number">2</span>, n))], axis=<span class="number">0</span>)</span><br><span class="line">    otu_distances = np.concatenate([otu_distances, np.zeros((<span class="number">2</span> * n - <span class="number">2</span>, n - <span class="number">2</span>))], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># branch_lengths: used to record branch lengths</span></span><br><span class="line">    branch_lengths = np.zeros_like(otu_distances)</span><br><span class="line"></span><br><span class="line">    current_otus = <span class="built_in">list</span>(<span class="built_in">range</span>(n))</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> progress.track(<span class="built_in">range</span>(n - <span class="number">3</span>)):</span><br><span class="line">        n = <span class="built_in">len</span>(current_otus)</span><br><span class="line">        otu_dists = otu_distances[current_otus, ...][..., current_otus]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calc D to Z</span></span><br><span class="line">        otu_dists_to_others: np.ndarray = np.<span class="built_in">sum</span>(otu_dists, axis=<span class="number">0</span>) / (n - <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calc S</span></span><br><span class="line">        graph_branch_length = otu_dists - otu_dists_to_others.reshape(-<span class="number">1</span>, <span class="number">1</span>) - otu_dists_to_others.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># choose min (i, j)</span></span><br><span class="line">        otu1, otu2 = <span class="built_in">min</span>(((i, j) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n)), key=<span class="keyword">lambda</span> x: graph_branch_length[x])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># make new otu and node</span></span><br><span class="line">        n1, n2, n3 = current_otus[otu1], current_otus[otu2], <span class="built_in">len</span>(nodes)</span><br><span class="line">        new_node = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">f&quot;#<span class="subst">&#123;n3&#125;</span>&quot;</span>, <span class="string">&quot;parent&quot;</span>: <span class="literal">None</span>, <span class="string">&quot;children&quot;</span>: (n1, n2)&#125;</span><br><span class="line">        nodes[n1][<span class="string">&quot;parent&quot;</span>] = n3</span><br><span class="line">        nodes[n2][<span class="string">&quot;parent&quot;</span>] = n3</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update otu distances</span></span><br><span class="line">        otu_distances[n3, ...] = (otu_distances[n1, ...] + otu_distances[n2, ...]) / <span class="number">2</span></span><br><span class="line">        otu_distances[..., n3] = (otu_distances[..., n1] + otu_distances[..., n2]) / <span class="number">2</span></span><br><span class="line">        otu_distances[n3, [n1, n2, n3]] = <span class="number">0</span></span><br><span class="line">        otu_distances[[n1, n2, n3], n3] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># update branch lengths</span></span><br><span class="line">        branch_lengths[n1, n3] = branch_lengths[n3, n1] = (</span><br><span class="line">            otu_distances[n1, n2] + otu_dists_to_others[otu1] - otu_dists_to_others[otu2]</span><br><span class="line">            - otu_distances[nodes[n1].get(<span class="string">&quot;children&quot;</span>, (n1, n1))]</span><br><span class="line">        ) / <span class="number">2</span></span><br><span class="line">        branch_lengths[n2, n3] = branch_lengths[n3, n2] = (</span><br><span class="line">            otu_distances[n2, n1] + otu_dists_to_others[otu2] - otu_dists_to_others[otu1]</span><br><span class="line">            - otu_distances[nodes[n2].get(<span class="string">&quot;children&quot;</span>, (n2, n2))]</span><br><span class="line">        ) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># remove n1 &amp; n2</span></span><br><span class="line">        current_otus.remove(n1)</span><br><span class="line">        current_otus.remove(n2)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add n3</span></span><br><span class="line">        nodes.append(new_node)</span><br><span class="line">        current_otus.append(n3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># join rest three otus</span></span><br><span class="line">    n3 = current_otus.pop()</span><br><span class="line">    n2 = current_otus.pop()</span><br><span class="line">    n1 = current_otus.pop()</span><br><span class="line"></span><br><span class="line">    nr = <span class="built_in">len</span>(nodes)</span><br><span class="line">    root_node = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">f&quot;#<span class="subst">&#123;nr&#125;</span>&quot;</span>, <span class="string">&quot;parent&quot;</span>: <span class="literal">None</span>, <span class="string">&quot;children&quot;</span>: (n1, n2, n3)&#125;</span><br><span class="line">    nodes[n1][<span class="string">&quot;parent&quot;</span>] = nr</span><br><span class="line">    nodes[n2][<span class="string">&quot;parent&quot;</span>] = nr</span><br><span class="line">    nodes[n3][<span class="string">&quot;parent&quot;</span>] = nr</span><br><span class="line"></span><br><span class="line">    branch_lengths[n1, nr] = branch_lengths[nr, n1] = (</span><br><span class="line">        otu_distances[n1, n2] + otu_distances[n1, n3] - otu_distances[n2, n3]</span><br><span class="line">        - otu_distances[nodes[n1].get(<span class="string">&quot;children&quot;</span>, (n1, n1))]</span><br><span class="line">    ) / <span class="number">2</span></span><br><span class="line">    branch_lengths[n2, nr] = branch_lengths[nr, n2] = (</span><br><span class="line">        otu_distances[n2, n1] + otu_distances[n2, n3] - otu_distances[n1, n3]</span><br><span class="line">        - otu_distances[nodes[n2].get(<span class="string">&quot;children&quot;</span>, (n2, n2))]</span><br><span class="line">    ) / <span class="number">2</span></span><br><span class="line">    branch_lengths[n3, nr] = branch_lengths[nr, n3] = (</span><br><span class="line">        otu_distances[n3, n1] + otu_distances[n3, n2] - otu_distances[n1, n2]</span><br><span class="line">        - otu_distances[nodes[n3].get(<span class="string">&quot;children&quot;</span>, (n3, n3))]</span><br><span class="line">    ) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    nodes.append(root_node)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nodes, branch_lengths</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_njtree</span>(<span class="params">nodes: <span class="type">List</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]], branch_lengths: np.ndarray</span>):</span><br><span class="line">    lines = []</span><br><span class="line"></span><br><span class="line">    stack = []</span><br><span class="line">    <span class="keyword">for</span> i, node <span class="keyword">in</span> <span class="built_in">enumerate</span>(nodes):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node[<span class="string">&quot;parent&quot;</span>]:</span><br><span class="line">            stack.append((<span class="number">0</span>, <span class="number">0</span>, i, node))</span><br><span class="line">    <span class="keyword">while</span> stack:</span><br><span class="line">        level, count, idx, top = stack.pop()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> level &gt; <span class="number">0</span>:</span><br><span class="line">            level_branchs = []</span><br><span class="line">            pre_level = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> _level, _, _, _ <span class="keyword">in</span> stack[:<span class="built_in">len</span>(stack)-count]:</span><br><span class="line">                <span class="keyword">if</span> _level &gt; pre_level:</span><br><span class="line">                    level_branchs.append(<span class="string">&quot;    &quot;</span> * (_level - pre_level - <span class="number">1</span>) + <span class="string">&quot;│   &quot;</span>)</span><br><span class="line">                    pre_level = _level</span><br><span class="line">            level_branchs.append(<span class="string">&quot;    &quot;</span> * (level - pre_level - <span class="number">1</span>) + (<span class="string">&quot;├──&quot;</span> <span class="keyword">if</span> count &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;└──&quot;</span>))</span><br><span class="line">            edge_length = <span class="string">f&quot;(<span class="subst">&#123;branch_lengths[idx, top[<span class="string">&#x27;parent&#x27;</span>]]:<span class="number">.6</span>f&#125;</span>)&quot;</span></span><br><span class="line">            lines.append(<span class="string">&quot;&quot;</span>.join((*level_branchs, top[<span class="string">&quot;name&quot;</span>], edge_length)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            lines.append(top[<span class="string">&quot;name&quot;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, child <span class="keyword">in</span> <span class="built_in">enumerate</span>(top.get(<span class="string">&quot;children&quot;</span>, [])):</span><br><span class="line">            stack.append((level + <span class="number">1</span>, i, child, nodes[child]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;\n&quot;</span>.join(lines)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    r = neighbor_joining(</span><br><span class="line">        <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">str</span>, <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">9</span>))),</span><br><span class="line">        [[<span class="number">0</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">11</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">13</span>, <span class="number">17</span>],</span><br><span class="line">         [<span class="number">7</span>,  <span class="number">0</span>,  <span class="number">5</span>,  <span class="number">8</span>,  <span class="number">10</span>, <span class="number">13</span>, <span class="number">10</span>, <span class="number">14</span>],</span><br><span class="line">         [<span class="number">8</span>,  <span class="number">5</span>,  <span class="number">0</span>,  <span class="number">5</span>,  <span class="number">7</span>,  <span class="number">10</span>, <span class="number">7</span>,  <span class="number">11</span>],</span><br><span class="line">         [<span class="number">11</span>, <span class="number">8</span>,  <span class="number">5</span>,  <span class="number">0</span>,  <span class="number">8</span>,  <span class="number">11</span>, <span class="number">8</span>,  <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">10</span>, <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">0</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">10</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">13</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">5</span>,  <span class="number">0</span>,  <span class="number">9</span>,  <span class="number">13</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">10</span>, <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">6</span>,  <span class="number">9</span>,  <span class="number">0</span>,  <span class="number">8</span>],</span><br><span class="line">         [<span class="number">17</span>, <span class="number">14</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">10</span>, <span class="number">13</span>, <span class="number">8</span>,  <span class="number">0</span>]]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tree = draw_njtree(r[<span class="number">0</span>], r[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(tree)</span><br></pre></td></tr></table></figure>

<p>输出内容:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#13</span><br><span class="line">├──#12(1.000000)</span><br><span class="line">│   ├──8(6.000000)</span><br><span class="line">│   └──7(2.000000)</span><br><span class="line">├──#11(2.000000)</span><br><span class="line">│   ├──#10(1.000000)</span><br><span class="line">│   │   ├──#8(2.000000)</span><br><span class="line">│   │   │   ├──2(2.000000)</span><br><span class="line">│   │   │   └──1(5.000000)</span><br><span class="line">│   │   └──3(1.000000)</span><br><span class="line">│   └──4(3.000000)</span><br><span class="line">└──#9(2.000000)</span><br><span class="line">    ├──6(4.000000)</span><br><span class="line">    └──5(1.000000)</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9hY2FkZW1pYy5vdXAuY29tL21iZS9hcnRpY2xlLzQvNC80MDYvMTAyOTY2NA==">The Neighbor-joining Method: A New Method for Reconstructing Phylogenetic Trees<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>聚类算法</tag>
        <tag>生信</tag>
        <tag>NJ 树</tag>
      </tags>
  </entry>
  <entry>
    <title>PCA 算法原理与实现</title>
    <url>//posts/2023/02/18/pca/</url>
    <content><![CDATA[<p>PCA 算法, 也就是主成分分析法 (Principal Component Analysis), 是一种数据降维算法, 能够在尽可能保留数据特征的同时压缩数据, 降低数据复杂度, 便于数据分析的进行.</p>
<p>本文简要介绍 PCA 算法的基本思想与数学推导, 并在文末提供对应的 <code>python</code> 实现.</p>
<span id="more"></span>

<h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>有一组 $p$ 维向量 $X_{n \times p} = \begin{bmatrix}<br>  \boldsymbol{x}_1 \\<br>  \boldsymbol{x}_2 \\<br>  \vdots \\<br>  \boldsymbol{x}_n<br>\end{bmatrix} = \begin{bmatrix}<br>  x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1p} \\<br>  x_{21} &amp; x_{22} &amp; \ldots &amp; x_{2p} \\<br>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>  x_{n1} &amp; x_{n2} &amp; \ldots &amp; x_{np}<br>\end{bmatrix}$, 需要通过一种方法使得它们变成一组 $q~(q &lt; p)$ 维向量 $Y_{n \times q} = \begin{bmatrix}<br>  \boldsymbol{y}_1 \\<br>  \boldsymbol{y}_2 \\<br>  \vdots \\<br>  \boldsymbol{y}_n<br>\end{bmatrix} = \begin{bmatrix}<br>  y_{11} &amp; y_{12} &amp; \ldots &amp; y_{1q} \\<br>  y_{21} &amp; y_{22} &amp; \ldots &amp; y_{2q} \\<br>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>  y_{n1} &amp; y_{n2} &amp; \ldots &amp; y_{nq}<br>\end{bmatrix}$, 在降低维数的同时, 尽可能减少信息损失.</p>
<h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><h3 id="信息重分配"><a href="#信息重分配" class="headerlink" title="信息重分配"></a>信息重分配</h3><p>对于一个向量 $\boldsymbol{x}_i = \begin{pmatrix}x_{i1}, x_{i2}, \ldots, x_{ip}\end{pmatrix}$, $p$ 个值代表了该向量在 $p$ 个方向上的不同特征, 而信息量大小的直接表现就是对数据的区分程度. 如果说在某一维上的值越能对不同的 $\boldsymbol{x}$ 进行区分, 则数据的<strong>离散程度</strong>就越大, 它所包含的信息量就越多, 最终这 $p$ 维共同完成了对 $X$ 所有数据的区分.</p>
<p>对于一组数据 $X$ 来说, 信息总量是确定的, 原始的 $X$ 中信息的分配方式是按某种分布分摊在 $p$ 个维度中.</p>
<p>因此, 在 PCA 方法中, 我们希望:</p>
<ul>
<li>经过变换之后的数据 $Y$, 能够对每一维的信息含量进行调整, 可以将整体数据的信息量先尽可能的分配到第 1 维, 然后分配到第 2 维, 第 3 维, ..., 直到最后一维</li>
<li>在新的数据 $Y$ 中, 每一维之间的<strong>关联性</strong>尽可能小, 最好是不相关, 这样子就能让信息独立的被分配到每一维中, 不会在不同维之间产生维间信息.</li>
</ul>
<p>上述有两个问题需要解决, 同一维之间的离散程度和不同维之间的关联性. 而在数学上, 方差和协方差可以很好的解决这两个问题.</p>
<h3 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h3><p>$X$ 是一个 $n \times p$ 的矩阵, 如果能找到一个 $q \times p$ 的矩阵 $W$ 满足对信息分配的要求, 对 $X$ 进行线性变换, 使得 $Y^T = WX^T$, 就可以得到降维后 $n \times q$ 的数据表示 $Y$.</p>
<p>$$<br>\begin{aligned}<br>  Y^T &amp;= \begin{bmatrix}{\boldsymbol{y}_1}^T &amp; {\boldsymbol{y}_2}^T &amp; \ldots &amp; {\boldsymbol{y}_n}^T\end{bmatrix} \\<br>  ~&amp;= WX^T \\<br>  ~&amp;= \begin{bmatrix}<br>    \boldsymbol{w}_1 \\<br>    \boldsymbol{w}_2 \\<br>    \vdots \\<br>    \boldsymbol{w}_q<br>  \end{bmatrix} \begin{bmatrix}{\boldsymbol{x}_1}^T &amp; {\boldsymbol{x}_2}^T &amp; \ldots &amp; {\boldsymbol{x}_n}^T\end{bmatrix}<br>\end{aligned}<br>$$</p>
<h2 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h2><p>我们的目标是, 寻找一个 $W$ , 使得新数据 $Y^T$ 同一维上的方差最大化, 不同维之间的协方差最小化.</p>
<p>为了方便数据处理, 我们假设 $X$ 已经经过均值和方差的归一化处理, 即 $X = \frac{X - E(X)}{\sqrt{D(X)}}$, 这样子均值为 0, 方便后续计算.</p>
<p>首先是方差与协方差的公式:</p>
<p>$$<br>\begin{aligned}<br>  Cov(X, Y) &amp;= E(XY) - E(X)E(Y) \\<br>  D(X) &amp;= E(X^2) - E^2(X)<br>\end{aligned}<br>$$</p>
<p>因为数据已经经过归一化处理, 所以可以简化成:</p>
<p>$$<br>\begin{aligned}<br>  Cov(X, Y) &amp;= E(XY) = \frac{1}{n}\sum_{i=1}^{n}x_iy_i \\<br>  D(X) &amp;= E(X^2) = \frac{1}{n}\sum_{i=1}^{n}x_i^2<br>\end{aligned}<br>$$</p>
<p>现在, 需要把数据 $Y$ 的方差与协方差进行表示, 定义矩阵 $Y_{Cov}$ 为 $Y$ 的协方差矩阵, 有:</p>
<p>$$<br>\begin{aligned}<br>  Y_{Cov} &amp;= \frac{1}{n}Y^TY \\<br>  ~&amp;= \frac{1}{n} \begin{bmatrix}<br>    y_{11} &amp; y_{21} &amp; \ldots &amp; y_{n1} \\<br>    y_{12} &amp; y_{22} &amp; \ldots &amp; y_{n2} \\<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>    y_{1q} &amp; y_{2q} &amp; \ldots &amp; y_{nq}<br>  \end{bmatrix} \begin{bmatrix}<br>    y_{11} &amp; y_{12} &amp; \ldots &amp; y_{1q} \\<br>    y_{21} &amp; y_{22} &amp; \ldots &amp; y_{2q} \\<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>    y_{n1} &amp; y_{n2} &amp; \ldots &amp; y_{nq}<br>  \end{bmatrix} \\<br>  ~&amp;= \begin{bmatrix}<br>    \frac{1}{n}\sum_{i=1}^{n}y_{i1}^2 &amp; \frac{1}{n}\sum_{i=1}^{n}y_{i1}y_{i2} &amp; \ldots &amp; \frac{1}{n}\sum_{i=1}^{n}y_{i1}y_{iq} \\<br>    \frac{1}{n}\sum_{i=1}^{n}y_{i2}y_{i1} &amp; \frac{1}{n}\sum_{i=1}^{n}y_{i2}^2 &amp; \ldots &amp; \frac{1}{n}\sum_{i=1}^{n}y_{i2}y_{iq} \\<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>    \frac{1}{n}\sum_{i=1}^{n}y_{iq}y_{i1} &amp; \frac{1}{n}\sum_{i=1}^{n}y_{iq}y_{i2} &amp; \ldots &amp; \frac{1}{n}\sum_{i=1}^{n}y_{iq}^2<br>  \end{bmatrix}<br>\end{aligned}<br>$$</p>
<p>可以看到协方差矩阵的主对角线上是 $q$ 个维度上的方差, 而其余位置则是两两之间的协方差, 并且协方差矩阵还是一个实对称矩阵. 所以我们的目标就是让 $Y_{Cov}$ 除了主对角线以外的部分尽量接近 0.</p>
<p>同理可以得到 $X_{Cov} = \frac{1}{n}X^TX$.</p>
<p>下面推导 $Y_{Cov}$ 与原始数据 $X$ 之间的关系.</p>
<p>$$<br>\begin{aligned}<br>  Y_{Cov} &amp;= \frac{1}{n}Y^TY \\<br>    ~&amp;= \frac{1}{n}(WX^T)(WX^T)^T \\<br>    ~&amp;= \frac{1}{n}WX^TXW^T \\<br>    ~&amp;= WX_{Cov}W^T<br>\end{aligned}<br>$$</p>
<p>结合我们的目标可以发现, $Y_{Cov}$ 的最优情况其实就是实对称矩阵 $X_{Cov}$ 的对角化矩阵, 而 $W$ 就是能够满足 $X_{Cov}$ 对角化的矩阵.</p>
<p>关于实对称矩阵的对角化, 线代里面有详细的介绍, 这里简单提一下结论.</p>
<div class="note info"><p>对于一个 $n \times n$ 的实对称矩阵 $D$, 一定可以找到 $n$ 个单位正交特征向量, 组成矩阵 $E = \begin{bmatrix}<br>\boldsymbol{e}_1 \\<br>  \boldsymbol{e}_2 \\<br>  \vdots \\<br>  \boldsymbol{e}_n<br>\end{bmatrix}$, 使得 $\Lambda = EDE^T = \begin{bmatrix}<br>  \lambda_1 &amp; ~ &amp; ~ &amp; ~ \\<br>  ~ &amp; \lambda_2 &amp; ~ &amp; ~ \\<br>  ~ &amp; ~ &amp; \ddots &amp; ~ \\<br>  ~ &amp; ~ &amp; ~ &amp;\lambda_n<br>\end{bmatrix}$, 其中 $\Lambda$ 是对角矩阵, 对角元素是特征向量对应的特征值.</p>
</div>

<p>因此, 对于实对称矩阵 $X_{Cov}$, 总能通过求其特征值与特征向量, 得到一个满足要求的 $W$ 使其对角化, 得到 $Y_{Cov}$.</p>
<p>到这里还没有完全结束, $X_{Cov}$ 是 $p$ 维实对称矩阵, 因此一定存在 $p$ 个特征值与特征向量, 而我们的目标是降维, 因此 $W$ 只需要选择其中的 $q$ 个特征向量组成一个 $q \times p$ 的矩阵即可.</p>
<p>从最后对角化的结果来看, $Y_{Cov}$ 的对角线上, 也就是新数据每一维的方差值, 其实就是 $W$ 按顺序特征向量对应的特征值. 那么为了充分保留原数据里的信息, 需要将特征向量按特征值大小进行降序排列, 然后依次选取前 $q$ 个特征向量去组成最终的 $W$ 矩阵.</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>输入: $X_{n \times p}$, $q~(q \leq p)$</p>
<p>输出: $Y_{n \times q}$</p>
<ol>
<li>对 $X$ 进行均值方差归一化.</li>
<li>求解 $X_{Cov} = \frac{1}{n}X^TX$.</li>
<li>求出 $X_{Cov}$ 的 $p$ 个特征值 $\lambda_1, \lambda_2, \ldots, \lambda_p$, 及其对应的特征向量 $\boldsymbol{w}_1, \boldsymbol{w}_2, \ldots, \boldsymbol{w}_p$.</li>
<li>将 $\boldsymbol{w}_1, \boldsymbol{w}_2, \ldots, \boldsymbol{w}_p$ 按 $\lambda_1, \lambda_2, \ldots, \lambda_p$ 降序排列, 得到 $\boldsymbol{w}&#39;_1, \boldsymbol{w}&#39;_2, \ldots, \boldsymbol{w}&#39;_p$.</li>
<li>选取 $\boldsymbol{w}&#39;_1, \boldsymbol{w}&#39;_2, \ldots, \boldsymbol{w}&#39;_q$, 组成变换矩阵 $W = \begin{bmatrix}<br> \boldsymbol{w}&#39;_1 \\<br> \boldsymbol{w}&#39;_2 \\<br> \vdots \\<br> \boldsymbol{w}&#39;_q<br>\end{bmatrix}$</li>
<li>计算 $Y^T = WX^T$, 得到降维后的新数据 $Y$.</li>
</ol>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pca</span>(<span class="params">X: np.ndarray, n_compnents: <span class="built_in">int</span></span>) -&gt; np.ndarray:</span><br><span class="line">    n, p = X.shape</span><br><span class="line">    q = n_compnents</span><br><span class="line"></span><br><span class="line">    <span class="comment"># normalization</span></span><br><span class="line">    X = (X - np.mean(X, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)) / np.std(X, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># covariance of x</span></span><br><span class="line">    X_cov = (<span class="number">1</span> / n) * X.T @ X</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute eigenwerts and eigenvectors</span></span><br><span class="line">    w, v = np.linalg.eigh(X_cov)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># sort by descending order</span></span><br><span class="line">    w = w[::-<span class="number">1</span>]</span><br><span class="line">    v = v[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># choose top q vectors</span></span><br><span class="line">    W = v[:q]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute Y</span></span><br><span class="line">    Y = (W @ X.T).T</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9vdXJhcmNoaXZlLm90YWdvLmFjLm56L2JpdHN0cmVhbS9oYW5kbGUvMTA1MjMvNzUzNC9PVUNTLTIwMDItMTIucGRm">A tutorial on principal components analysis<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>数据降维</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在 PyPI 上发布一个包</title>
    <url>//posts/2023/11/05/pypi/</url>
    <content><![CDATA[<p>基于上一篇<a href="/posts/2023/11/04/ncmdump/">NCM 文件批量转换 (保留专辑和封面信息)</a>, 记录一下自己第一次往 PyPI 上发布包的过程.</p>
<p>本文结合 Python 官方教程 <span class="exturl" data-url="aHR0cHM6Ly9wYWNrYWdpbmcucHl0aG9uLm9yZy9lbi9sYXRlc3QvdHV0b3JpYWxzL3BhY2thZ2luZy1wcm9qZWN0cy8=">Packaging Python Projects<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L2luZGV4Lmh0bWw=">Setuptools<i class="fa fa-external-link-alt"></i></span> 的 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L3VzZXJndWlkZS8=">User guide<i class="fa fa-external-link-alt"></i></span> 进行打包和发布.</p>
<span id="more"></span>

<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ncmdump-py</span><br><span class="line">  ├─ ncmdump</span><br><span class="line">  │   ├─ core.py</span><br><span class="line">  │   ├─ crypto.py</span><br><span class="line">  │   ├─ __init__.py</span><br><span class="line">  │   └─ __main__.py</span><br><span class="line">  ├─ .gitignore</span><br><span class="line">  ├─ LICENSE</span><br><span class="line">  ├─ pyproject.toml</span><br><span class="line">  └─ README.md</span><br></pre></td></tr></table></figure>

<p>这是本项目的目录结构, 其中 <code>ncmdump-py</code> 是项目根目录, 而 <code>ncmdump</code> 是我们要发布的包, 其他文件是一些项目文件.</p>
<p>这种结构被称为 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L3VzZXJndWlkZS9wYWNrYWdlX2Rpc2NvdmVyeS5odG1sI2ZsYXQtbGF5b3V0">flat-layout<i class="fa fa-external-link-alt"></i></span> 布局, 也就是直接将要构建的包放在项目的根目录下.</p>
<p>除此之外还有 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L3VzZXJndWlkZS9wYWNrYWdlX2Rpc2NvdmVyeS5odG1sI3NyYy1sYXlvdXQ=">src-layout<i class="fa fa-external-link-alt"></i></span> 和用于单模块构建的 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L3VzZXJndWlkZS9wYWNrYWdlX2Rpc2NvdmVyeS5odG1sI3NpbmdsZS1tb2R1bGUtZGlzdHJpYnV0aW9u">single-module-distribution<i class="fa fa-external-link-alt"></i></span>. 此外 <code>Setuptools</code> 还支持各种详细的自定义功能, 具体可以看 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L3VzZXJndWlkZS9wYWNrYWdlX2Rpc2NvdmVyeS5odG1s">Package Discovery and Namespace Packages<i class="fa fa-external-link-alt"></i></span> 页面.</p>
<h2 id="安装必要的工具库"><a href="#安装必要的工具库" class="headerlink" title="安装必要的工具库"></a>安装必要的工具库</h2><p>使用 <code>pip install build</code> 安装 <code>build</code> 库. 这是一个命令行工具, 能够自动下载 <code>setuptools</code> 和其他构建时的必要依赖, 之后通过 <code>python -m build</code> 即可完成项目构建.</p>
<p>另一个工具是 <code>twine</code>, 使用 <code>pip install twine</code> 安装, 该工具用来将我们构建后的文件上传至 PyPI 中.</p>
<h2 id="编写项目配置文件"><a href="#编写项目配置文件" class="headerlink" title="编写项目配置文件"></a>编写项目配置文件</h2><p><code>setuptools</code> 支持三种方式编写项目配置文件, 在项目根目录下创建 <code>pyproject.toml</code>, <code>setup.cfg</code> 或者 <code>setup.py</code>.</p>
<p>这里我们使用推荐的 <code>pyproject.toml</code> 方式, 并且尽量避免使用 <code>setup.py</code> (<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmdhbnNzbGUuaW8vYXJ0aWNsZXMvMjAyMS8xMC9zZXR1cC1weS1kZXByZWNhdGVkLmh0bWw=">Why you shouldn’t invoke setup.py directly<i class="fa fa-external-link-alt"></i></span>).</p>
<p>下面贴出本项目的 <code>pyproject.toml</code>, 并对其进行解释.</p>
<figure class="highlight toml"><table><tr><td class="code"><pre><span class="line"><span class="section">[build-system]</span></span><br><span class="line"><span class="attr">requires</span> = [<span class="string">&quot;setuptools&quot;</span>]</span><br><span class="line"><span class="attr">build-backend</span> = <span class="string">&quot;setuptools.build_meta&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[project]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;ncmdump-py&quot;</span></span><br><span class="line"><span class="attr">authors</span> = [</span><br><span class="line">    &#123;name = <span class="string">&quot;ww-rm&quot;</span>, email = <span class="string">&quot;ww-rm@qq.com&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"><span class="attr">description</span> = <span class="string">&quot;Dump ncm files to mp3 or flac files.&quot;</span></span><br><span class="line"><span class="attr">requires-python</span> = <span class="string">&quot;&gt;=3.7&quot;</span></span><br><span class="line"><span class="attr">dependencies</span> = [</span><br><span class="line">    <span class="string">&quot;mutagen&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Pillow&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pycryptodome&quot;</span>,</span><br><span class="line">    <span class="string">&quot;rich&quot;</span>,</span><br><span class="line">]</span><br><span class="line"><span class="attr">dynamic</span> = [<span class="string">&quot;version&quot;</span>, <span class="string">&quot;readme&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="section">[project.urls]</span></span><br><span class="line"><span class="attr">&quot;Homepage&quot;</span> = <span class="string">&quot;https://github.com/ww-rm/ncmdump-py&quot;</span></span><br><span class="line"><span class="attr">&quot;Bug Tracker&quot;</span> = <span class="string">&quot;https://github.com/ww-rm/ncmdump-py/issues&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[tool.setuptools]</span></span><br><span class="line"><span class="attr">packages</span> = [<span class="string">&quot;ncmdump&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="section">[tool.setuptools.dynamic]</span></span><br><span class="line"><span class="attr">version</span> = &#123;attr = <span class="string">&quot;ncmdump.__version__&quot;</span>&#125;</span><br><span class="line"><span class="attr">readme</span> = &#123;file = [<span class="string">&quot;README.md&quot;</span>], content-type = <span class="string">&quot;text/markdown&quot;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>首先是 <code>build-system</code>, 必填项, 该键下面定义了使用什么方式进行构建, 这里使用 <code>setuptools</code>, 一般不需要更改.</p>
<p>接着下面的是 <code>project</code> 键, 这下面有很多关于项目的配置, 并且和 PyPI 项目页面上有对应关系, 这里挑一些关键的来解释.</p>
<p><code>name</code> 是包的名字, 指的是用 <code>pip</code> 安装时指定的名字, 在代码导入的时候还是和包本身文件夹名字相同. 比如这个项目, 安装的命令是 <code>pip install ncmdump-py</code>, 但是代码导入的时候是 <code>import ncmdump</code>.</p>
<p><code>dependencies</code> 定义了项目的依赖库, 语法和 <code>requirements.txt</code> 一样, 列表里每一项都是一个依赖, 详细语法可以参考 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L3VzZXJndWlkZS9kZXBlbmRlbmN5X21hbmFnZW1lbnQuaHRtbA==">Dependencies Management in Setuptools<i class="fa fa-external-link-alt"></i></span>.</p>
<p><code>dynamic</code> 定义了一些变量, 常见的就是定义版本号和项目文档, 毕竟手动填写繁琐且容易出错. 它需要与后面 <code>tool.setuptools.dynamic</code> 进行对应. 详细语法可以参考 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L3VzZXJndWlkZS9weXByb2plY3RfY29uZmlnLmh0bWwjZHluYW1pYy1tZXRhZGF0YQ==">Dynamic Metadata<i class="fa fa-external-link-alt"></i></span> 页面内容.</p>
<p>更多与 <code>pyproject.toml</code> 有关的内容可以参考 <span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L3VzZXJndWlkZS9weXByb2plY3RfY29uZmlnLmh0bWw=">Configuring setuptools using pyproject.toml files<i class="fa fa-external-link-alt"></i></span>, 以及 Python 官方 <span class="exturl" data-url="aHR0cHM6Ly9wYWNrYWdpbmcucHl0aG9uLm9yZy9lbi9sYXRlc3Qvc3BlY2lmaWNhdGlvbnMvZGVjbGFyaW5nLXByb2plY3QtbWV0YWRhdGEv">Declaring project metadata<i class="fa fa-external-link-alt"></i></span> 页面规定的项目配置项.</p>
<h2 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h2><p>首先确保已经安装了前文说的 <code>build</code> 库, 以及准备了一个合适的版本号和 <code>LICENSE</code> 文件, 可以参考 <span class="exturl" data-url="aHR0cHM6Ly9zZW12ZXIub3JnLw==">Semantic Versioning<i class="fa fa-external-link-alt"></i></span> 与 <span class="exturl" data-url="aHR0cHM6Ly9jaG9vc2VhbGljZW5zZS5jb20v">Choose an open source license<i class="fa fa-external-link-alt"></i></span> 让自己的项目看起来更规范一点.</p>
<p>然后就是傻瓜式构建, 在当前根目录下运行:</p>
<p><code>python -m build</code></p>
<p>然后就会生成一个 <code>dist</code> 文件夹, 里面包含打包好的项目文件.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ncmdump-py</span><br><span class="line">  └─ dist</span><br><span class="line">      ├─ ncmdump_py-1.0.1-py3-none-any.whl</span><br><span class="line">      └─ ncmdump-py-1.0.1.tar.gz</span><br></pre></td></tr></table></figure>

<h2 id="发布"><a href="#发布" class="headerlink" title="发布"></a>发布</h2><p>首先确保已经安装了前文说的 <code>twine</code> 库, 然后需要去 <span class="exturl" data-url="aHR0cHM6Ly90ZXN0LnB5cGkub3JnLw==">TestPyPI<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy8=">PyPI<i class="fa fa-external-link-alt"></i></span> 分别注册自己的账号.</p>
<p>其中 <code>TestPyPI</code> 是用来测试的, 而 <code>PyPI</code> 是真实发布页, 建议第一次尝试还是用 <code>TestPyPI</code> 先测试熟悉一下流程, 避免出错无法修改. 下面的内容将分别说明在 <code>TestPyPI</code> 和 <code>PyPI</code> 上的命令差异.</p>
<p>这里先说说遇到的小问题, 在写本文时, <code>TestPyPI</code> 和 <code>PyPI</code> 在注册账号后, 已经强制要求开启双因素认证 (2FA), 但是开启了双因素认证的账号不能使用账密的形式上传文件, 因此成功注册账号后, 我们还需要去申请一个通用的 API token.</p>
<p>在 <code>Account settings</code> 中往下翻, 可以找到 <code>API tokens</code> 设置项, 我们选择 <code>Add API token</code>, 并且将 <code>Scope</code> 选择为 <code>Entire account (all projects)</code> (第一次发布肯定只能选成全局的).</p>
<p>添加完成之后, 我们需要及时的<strong>将 token 复制并保存</strong>下来, 之后再进来就<strong>不会显示</strong> token 了.</p>
<p>然后使用 <code>twine</code> 进行上传.</p>
<div class="tabs" id="upload-by-twine"><ul class="nav-tabs"><li class="tab active"><a href="#upload-by-twine-1">TestPyPI</a></li><li class="tab"><a href="#upload-by-twine-2">PyPI</a></li></ul><div class="tab-content"><div class="tab-pane active" id="upload-by-twine-1"><p><code>python -m twine upload --repository testpypi dist/*</code></p></div><div class="tab-pane" id="upload-by-twine-2"><p><code>python -m twine upload dist/*</code></p></div></div></div>

<p>运行之后, 会要求你输入 <code>username</code> 和 <code>password</code>. 在使用 token 的情况下, <code>username</code> 填 <code>__token__</code>, 而 <code>password</code> 填刚刚复制并保存下来的 token 字符串.</p>
<p>成功上传之后, 会显示上传后的页面链接.</p>
<p>然后可以通过 <code>pip</code> 测试一下是否可以正常安装:</p>
<div class="tabs" id="install-by-pip"><ul class="nav-tabs"><li class="tab active"><a href="#install-by-pip-1">TestPyPI</a></li><li class="tab"><a href="#install-by-pip-2">PyPI</a></li></ul><div class="tab-content"><div class="tab-pane active" id="install-by-pip-1"><p><code>pip install -i https://test.pypi.org/simple/ ncmdump-py</code></p></div><div class="tab-pane" id="install-by-pip-2"><p><code>pip install ncmdump-py</code></p></div></div></div>

<p>最后的最后, 如果不想每次都输入用户名和密码, 我们可以写一份 <code>~/.pypirc</code> 配置文件.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[testpypi]</span><br><span class="line">username = __token__</span><br><span class="line">password = &lt;token value&gt;</span><br><span class="line"></span><br><span class="line">[pypi]</span><br><span class="line">username = __token__</span><br><span class="line">password = &lt;token value&gt;</span><br></pre></td></tr></table></figure>

<p>Windows 下把文件放在用户主目录 <code>%USERPROFILE%</code> (<code>C:\Users\&lt;UserName&gt;</code>) 下即可, 之后每次运行 <code>twine upload</code> 就会自动读取 token 完成上传.</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9wYWNrYWdpbmcucHl0aG9uLm9yZy9lbi9sYXRlc3QvdHV0b3JpYWxzL3BhY2thZ2luZy1wcm9qZWN0cy8=">Packaging Python Projects<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9zZXR1cHRvb2xzLnB5cGEuaW8vZW4vbGF0ZXN0L2luZGV4Lmh0bWw=">Setuptools<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9zZW12ZXIub3JnLw==">Semantic Versioning<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9jaG9vc2VhbGljZW5zZS5jb20v">Choose an open source license<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pypi</tag>
        <tag>setuptools</tag>
        <tag>python 包发布</tag>
      </tags>
  </entry>
  <entry>
    <title>ECC 算法原理简介与实现</title>
    <url>//posts/2022/12/07/simple-ecc/</url>
    <content><![CDATA[<p>本文记于某次密码作业课余, 提供对 ECC 算法的简要介绍与简单实现, 文末附有代码.</p>
<span id="more"></span>

<h2 id="理论介绍"><a href="#理论介绍" class="headerlink" title="理论介绍"></a>理论介绍</h2><h3 id="素域上的离散椭圆曲线"><a href="#素域上的离散椭圆曲线" class="headerlink" title="素域上的离散椭圆曲线"></a>素域上的离散椭圆曲线</h3><p>形如 $y^2 = x^3 + ax + b \bmod p$ 的曲线叫椭圆曲线, 其中需满足 $p$ 是大于 $3$ 的素数, 且 $4a^3 + 27b^2 \ne 0 \bmod p$.</p>
<p>先不看 $\bmod$ 记号, 那么这就是一条普通的连续曲线, 可以按照普通的方程求解, 给定一个 $x$, 就可以求出来对应的 $y$. 容易看出来, 这条曲线是关于 $x$ 轴对称的, 因此它的图像大概长下面这种样子.</p>
<p><img data-src="/static/image/simple-ecc/zcG6gI.png" alt="zcG6gI.png"></p>
<p>可以有几种不同的形式, 但是基本上差不多.</p>
<p>那么加了 $\bmod$ 记号之后有什么不同呢? 刚刚是根据实数域画出来的连续曲线, 那么加上 $\bmod$ 之后, 曲线还是这条曲线, 但是坐标取值范围变成了整数范围, 且取值在 $[0, p-1]$ 之间.</p>
<p>也就是从这条曲线上挑出了一些离散的整数解, 不仅能够满足这个曲线方程, 同时 $x$ 和 $y$ 的取值范围在 $[0, p-1]$, 也就是对 $p$ 取模, 所有的数据运算都在模 $p$ 下进行, 因此将这种曲线记为 $y^2 = x^3 + ax + b \bmod p$.</p>
<p>所以, ECC 中使用的椭圆曲线并不是一条真正连续的曲线, 而是由很多离散的点组成的.</p>
<h3 id="椭圆曲线上的运算"><a href="#椭圆曲线上的运算" class="headerlink" title="椭圆曲线上的运算"></a>椭圆曲线上的运算</h3><p>既然要使用椭圆曲线进行计算, 那么先得定义在椭圆曲线上的运算.</p>
<p>我们都学过向量的运算, 其中最基本的两种运算是加法和数乘.</p>
<p>如果设 $\vec{a}$, $\vec{b}$ 是两个向量, 那么我们可以计算 $\vec{a}+\vec{b}$ 的值, 这称为<strong>向量加法</strong>.</p>
<p>我还可以计算 $\vec{a}$ 与自己的相加运算, 计算 $k$ 个 $\vec{a}$ 连续相加, 并简记为 $k\vec{a}$, 这称为<strong>向量数乘</strong>.</p>
<p>可以看出, 第二种情况虽然有个&quot;乘&quot;字, 但是仍然属于加法运算的一种, 至此, 向量关于加法的运算已经基本上齐全了, 但是还缺少一些特殊情况定义.</p>
<p>首先是 $0$ 的定义, 此处指的是抽象的 $0$, 不是数字 $0$, 也就是对于向量运算来说, 需要有一个 $0$ 值的概念, 它在加法运算中不会影响运算本身, 通常就将其定义为全零向量 $\vec{0}$, 也可称其为<strong>单位元</strong>.</p>
<p>而在定义完单位元之后, 可以定义向量取负, 依靠于 $\vec{0}$ 来进行的, 如果有 $-\vec{a}$, 则 $\vec{a} + (-\vec{a}) = \vec{0}$, 这样就通过单位元定义了加法的逆运算减法的规则, 因为减去一个原向量等于加上原向量的相反向量, 而相反向量满足上述关于单位元的等式, 因而可以求出相反向量的具体取值. 在这里, 相反向量称之为原向量的<strong>逆元</strong>.</p>
<p>至此, 我们成功在向量中定义了这些基本概念:</p>
<ul>
<li>加法 ($\vec{a} + \vec{b}$)</li>
<li>数乘 ($k\vec{a}$)</li>
<li>单位元 ($\vec{0}$)</li>
<li>逆元 ($-\vec{a}$)</li>
</ul>
<p>那么, 把上述中的&quot;向量&quot;全部换成别的东西, 我们就可以定义出一套新的数据运算, 而对于椭圆曲线, 我们将&quot;向量&quot;换成所有满足椭圆曲线方程的点, 定义了椭圆曲线上的点运算规则.</p>
<p>接下来就是对于点加法具体过程的定义, 用一张图来直观解释椭圆曲线上点是如何进行&quot;相加&quot;的.</p>
<p><img data-src="/static/image/simple-ecc/zcYiWj.png" alt="zcYiWj.png"></p>
<p>设 $P$, $Q$ 为椭圆曲线上的两点, 则 $P+Q$ 就是 $P$, $Q$ 连线与曲线的交点关于 $x$ 轴的对称点.</p>
<p>当 $P$, $Q$ 重合时, 取切线与曲线的交点的对称点作为加法结果, 也就是 $2P$.</p>
<p>当 $P$, $Q$ 关于 $x$ 轴对称时, 定义相加结果为无穷远点, 视作加法的单位元点, 记为 $O$, 同时易得此时 $P$, $Q$ 互为对方的逆元.</p>
<h3 id="椭圆曲线运算公式"><a href="#椭圆曲线运算公式" class="headerlink" title="椭圆曲线运算公式"></a>椭圆曲线运算公式</h3><p>运算公式按照普通的解析几何去求解即可, 在此直接给出公式, 分为两点不重合和重合的情况.</p>
<p>设曲线方程是 $y^2 = x^3 + ax + b$, $R(x_3, y_3)=P(x_1, y_1) + Q(x_2, y_2)$, 则:</p>
<p>$$<br>\left\{<br>  \begin{align*}<br>    x_3 &amp;= \lambda^2 - x_1 - x_2 \\<br>    y_3 &amp;= \lambda(x_1 - x_3) - y_1<br>  \end{align*}<br>\right.<br>$$</p>
<p>其中, 当 $P(x_1, y_1) \ne Q(x_2, y_2)$, 即两点不重合时,</p>
<p>$$<br>\lambda = \frac{y_2 - y_1}{x_2 - x_1}<br>$$</p>
<p>当 $P(x_1, y_1) = Q(x_2, y_2)$, 即两点重合时,</p>
<p>$$<br>\lambda = \frac{3x_1^2+a}{2y_1}<br>$$</p>
<h3 id="其他概念"><a href="#其他概念" class="headerlink" title="其他概念"></a>其他概念</h3><p>一些代码实现时需要知道的概念, 在此简单记录.</p>
<ul>
<li>循环群: 循环群是一些点的集合, 群内存在一个特殊点 $G$, 在这个群内的任何一个点, 都可以由 $G, 2G, ..., nG$ 表示, 对 $G$ 的 $n$ 次加法运算能够遍历群中的每个点, 群的大小是 $n$.</li>
<li>生成元: 循环群中的 $G$ 称为这个循环群的生成元.</li>
<li>阶: 指循环群或者生成元的阶, 就是生成元所在循环群的大小 $n$.</li>
<li>模逆运算: 指求解方程 $ax \equiv 1 \bmod p$, 即 $a$ 在模 $p$ 运算下的&quot;倒数&quot;.</li>
</ul>
<h2 id="椭圆曲线代码实现"><a href="#椭圆曲线代码实现" class="headerlink" title="椭圆曲线代码实现"></a>椭圆曲线代码实现</h2><h3 id="曲线与点的定义"><a href="#曲线与点的定义" class="headerlink" title="曲线与点的定义"></a>曲线与点的定义</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int64_t</span> x;</span><br><span class="line">    <span class="type">int64_t</span> y;</span><br><span class="line">&#125; EccPoint;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int64_t</span> a;</span><br><span class="line">    <span class="type">int64_t</span> b;</span><br><span class="line">    <span class="type">int64_t</span> p;</span><br><span class="line">&#125; EC; <span class="comment">// y^2 = x^3 + ax + b (mod p)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    EccPoint pt;</span><br><span class="line">    <span class="type">int64_t</span> n;</span><br><span class="line">&#125; GenPoint;</span><br></pre></td></tr></table></figure>

<h3 id="辅助运算"><a href="#辅助运算" class="headerlink" title="辅助运算"></a>辅助运算</h3><p>模 $p$ 运算和模逆运算.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int64_t</span> <span class="title function_">modp</span><span class="params">(<span class="type">int64_t</span> x, <span class="type">int64_t</span> p)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">while</span> (x &lt; <span class="number">0</span>) x += p;</span><br><span class="line">    x %= p;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int64_t</span> <span class="title function_">inverse</span><span class="params">(<span class="type">int64_t</span> x, <span class="type">int64_t</span> p)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int64_t</span> q = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int64_t</span> r = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> r1 = p;</span><br><span class="line">    <span class="type">int64_t</span> r2 = x;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> t1 = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int64_t</span> t2 = <span class="number">1</span>;</span><br><span class="line">    <span class="type">int64_t</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (r2 &gt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        q = r1 / r2, r = r1 % r2;</span><br><span class="line">        r1 = r2, r2 = r;</span><br><span class="line"></span><br><span class="line">        t = t1 - q * t2;</span><br><span class="line">        t1 = t2, t2 = t;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    t1 = modp(t1, p);</span><br><span class="line">    <span class="keyword">return</span> t1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="点加与数乘"><a href="#点加与数乘" class="headerlink" title="点加与数乘"></a>点加与数乘</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">addpt</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EC* ec,</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EccPoint* pt1, <span class="type">const</span> EccPoint* pt2,</span></span><br><span class="line"><span class="params">    EccPoint* new_pt</span></span><br><span class="line"><span class="params">)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (pt1-&gt;x == <span class="number">-1</span> &amp;&amp; pt1-&gt;y == <span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        new_pt-&gt;x = pt2-&gt;x;</span><br><span class="line">        new_pt-&gt;y = pt2-&gt;y;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (pt2-&gt;x == <span class="number">-1</span> &amp;&amp; pt2-&gt;y == <span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        new_pt-&gt;x = pt1-&gt;x;</span><br><span class="line">        new_pt-&gt;y = pt1-&gt;y;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int64_t</span> lambda = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int64_t</span> new_x = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int64_t</span> new_y = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (pt1-&gt;x == pt2-&gt;x)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Unit</span></span><br><span class="line">            <span class="keyword">if</span> (pt1-&gt;y + pt2-&gt;y == ec-&gt;p)</span><br><span class="line">            &#123;</span><br><span class="line">                new_pt-&gt;x = <span class="number">-1</span>;</span><br><span class="line">                new_pt-&gt;y = <span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Same</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (pt1-&gt;y == pt2-&gt;y)</span><br><span class="line">            &#123;</span><br><span class="line">                lambda = (<span class="number">3</span> * pt1-&gt;x * pt1-&gt;x + ec-&gt;a) * inverse(<span class="number">2</span> * pt1-&gt;y, ec-&gt;p);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Different</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int64_t</span> delta_x = <span class="number">0</span>;</span><br><span class="line">            <span class="type">int64_t</span> delta_y = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            delta_x = modp((pt2-&gt;x - pt1-&gt;x), ec-&gt;p);</span><br><span class="line">            delta_y = modp((pt2-&gt;y - pt1-&gt;y), ec-&gt;p);</span><br><span class="line">            lambda = delta_y * inverse(delta_x, ec-&gt;p);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        lambda %= ec-&gt;p;</span><br><span class="line"></span><br><span class="line">        new_x = modp((lambda * lambda - pt1-&gt;x - pt2-&gt;x), ec-&gt;p);</span><br><span class="line">        new_y = modp((lambda * (pt1-&gt;x - new_x) - pt1-&gt;y), ec-&gt;p);</span><br><span class="line"></span><br><span class="line">        new_pt-&gt;x = new_x;</span><br><span class="line">        new_pt-&gt;y = new_y;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">mulpt</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EC* ec,</span></span><br><span class="line"><span class="params">    <span class="type">uint64_t</span> k, <span class="type">const</span> EccPoint* pt,</span></span><br><span class="line"><span class="params">    EccPoint* new_pt</span></span><br><span class="line"><span class="params">)</span></span><br><span class="line">&#123;</span><br><span class="line">    new_pt-&gt;x = <span class="number">-1</span>;</span><br><span class="line">    new_pt-&gt;y = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">64</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        addpt(ec, new_pt, new_pt, new_pt);</span><br><span class="line">        <span class="keyword">if</span> (k &amp; <span class="number">0x8000000000000000</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            addpt(ec, new_pt, pt, new_pt);</span><br><span class="line">        &#125;</span><br><span class="line">        k &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="计算椭圆曲线的所有点及其阶"><a href="#计算椭圆曲线的所有点及其阶" class="headerlink" title="计算椭圆曲线的所有点及其阶"></a>计算椭圆曲线的所有点及其阶</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">uint8_t</span> <span class="title function_">isprime</span><span class="params">(<span class="type">int64_t</span> x)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">2</span>; i &lt; (<span class="type">int64_t</span>)sqrtl((<span class="type">long</span> <span class="type">double</span>)x); i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (x % i == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int64_t</span> <span class="title function_">compute_ptrank</span><span class="params">(<span class="type">const</span> EC* ec, <span class="type">const</span> EccPoint* pt)</span></span><br><span class="line">&#123;</span><br><span class="line">    EccPoint tmp = &#123; pt-&gt;x, pt-&gt;y &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> rank = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        addpt(ec, &amp;tmp, pt, &amp;tmp);</span><br><span class="line">        <span class="keyword">if</span> (tmp.x == pt-&gt;x &amp;&amp; tmp.y == pt-&gt;y)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        rank++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> rank;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_points</span><span class="params">(EC* ec)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;EC: &#123; a = %lld, b = %lld, p = %lld &#125;\n&quot;</span>, ec-&gt;a, ec-&gt;b, ec-&gt;p);</span><br><span class="line">    <span class="keyword">if</span> (modp(<span class="number">4</span> * ec-&gt;a * ec-&gt;a * ec-&gt;a + <span class="number">27</span> * ec-&gt;b * ec-&gt;b, ec-&gt;p) == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Params Invalid!\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int64_t</span> pt_count = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int64_t</span> y_sqr = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int64_t</span> y = <span class="number">0</span>;</span><br><span class="line">        <span class="type">uint8_t</span> find = <span class="number">0</span>;</span><br><span class="line">        EccPoint pt_tmp = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">        <span class="type">int64_t</span> pt_rank = <span class="number">0</span>;</span><br><span class="line">        <span class="type">char</span> prime_rank = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int64_t</span> x = <span class="number">0</span>; x &lt; ec-&gt;p; x++)</span><br><span class="line">        &#123;</span><br><span class="line">            y_sqr = modp((x * x * x + ec-&gt;a * x + ec-&gt;b), ec-&gt;p);</span><br><span class="line">            find = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span> (y_sqr &lt; (ec-&gt;p - <span class="number">1</span>) * (ec-&gt;p - <span class="number">1</span>))</span><br><span class="line">            &#123;</span><br><span class="line">                y = (<span class="type">int64_t</span>)sqrtl((<span class="type">long</span> <span class="type">double</span>)y_sqr);</span><br><span class="line">                <span class="keyword">if</span> (y * y == y_sqr)</span><br><span class="line">                &#123;</span><br><span class="line">                    find = <span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                y_sqr += ec-&gt;p;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (find)</span><br><span class="line">            &#123;</span><br><span class="line">                pt_tmp.x = x;</span><br><span class="line">                pt_tmp.y = y;</span><br><span class="line">                pt_rank = compute_ptrank(ec, &amp;pt_tmp);</span><br><span class="line">                prime_rank = (isprime(pt_rank) ? <span class="string">&#x27;P&#x27;</span> : <span class="string">&#x27;C&#x27;</span>);</span><br><span class="line">                pt_count++;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;(%5lld, %5lld)[%5lld][%c], &quot;</span>, pt_tmp.x, pt_tmp.y, pt_rank, prime_rank);</span><br><span class="line">                <span class="keyword">if</span> (pt_count % <span class="number">4</span> == <span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (y != <span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    pt_tmp.y = ec-&gt;p - y;</span><br><span class="line">                    pt_count++;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;(%5lld, %5lld)[%5lld][%c], &quot;</span>, pt_tmp.x, pt_tmp.y, pt_rank, prime_rank);</span><br><span class="line">                    <span class="keyword">if</span> (pt_count % <span class="number">4</span> == <span class="number">0</span>)</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;(%5d, %5d)[%5d][%c]\n&quot;</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="string">&#x27;C&#x27;</span>);</span><br><span class="line">        pt_count++;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;EccPoints Count: %lld\n&quot;</span>, pt_count);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="使用椭圆曲线进行数据加密"><a href="#使用椭圆曲线进行数据加密" class="headerlink" title="使用椭圆曲线进行数据加密"></a>使用椭圆曲线进行数据加密</h2><p>前面只是实现了关于椭圆曲线的运算, 现在需要使用这个运算来构建一个密码算法, 这其中使用到的问题称为椭圆曲线上的离散对数问题.</p>
<h3 id="ECDLP"><a href="#ECDLP" class="headerlink" title="ECDLP"></a>ECDLP</h3><p>设曲线为 $y^2 = x^3 + ax + b \bmod p$, $p$ 为大于 $3$ 的素数, 且 $4a^3 + 27b^2 \ne 0 \bmod p$.</p>
<p>曲线上的一个循环群记为 $&lt;G, n&gt;$, $G$ 是群的生成元, $n$ 是群的阶, 且 $n$ 为素数.</p>
<p>设 $P$, $Q$ 是群上的两点, 且 $Q = tP$, $t$ 为正整数且 $t \in [1, n-1]$.</p>
<p>则已知 $t$, $P$, 要计算 $Q$ 是简单的, 但是反过来, 已知 $P$, $Q$, 要计算 $t$ 是困难的, 这就是椭圆曲线上的离散对数问题.</p>
<h3 id="公私钥的选取"><a href="#公私钥的选取" class="headerlink" title="公私钥的选取"></a>公私钥的选取</h3><p>根据前面 ECDLP 的定义, 定义用户的私钥为 $d$, 可以为集合 $\{1, 2, ..., n-1\}$ 中的一个随机数, 公钥为 $Q$, 且 $Q = dG$, $G$ 是循环群 $&lt;G, n&gt;$ 的生成元. 其余所有和椭圆曲线有关的参数均是公开已知, 只有 $d$ 的值是秘密保留的, 当 $p$ 足够大时, 求解 $d$ 是困难的.</p>
<h3 id="一个简单的加解密方案"><a href="#一个简单的加解密方案" class="headerlink" title="一个简单的加解密方案"></a>一个简单的加解密方案</h3><p>设 $d$ 为用户私钥, $Q$ 为用户公钥, 明文数据为 $M$, 且 $0 \leq M \leq n-1$.</p>
<p>加密:</p>
<ol>
<li>选择一个随机数 $k$, 且 $k \in \{1, 2, ..., n-1\}$.</li>
<li>计算点 $X_1(x_1, y_1) = kQ$, 如果 $x_1 = 0$, 则转步骤 1.</li>
<li>计算点 $X_2(x_2, y_2) = kG$.</li>
<li>计算密文 $C \equiv Mx_1 \bmod n$.</li>
<li>以 $(X_2, C)$ 作为 $M$ 的最终密文.</li>
</ol>
<p>解密:</p>
<ol>
<li>计算 $X_1(x_1, y_1) = dX_2 = d(kG) = k(dG) = kQ$.</li>
<li>计算明文 $M \equiv Cx_1^{-1} \bmod n$.</li>
</ol>
<h2 id="加解密算法的实现"><a href="#加解密算法的实现" class="headerlink" title="加解密算法的实现"></a>加解密算法的实现</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    EC ec;</span><br><span class="line">    GenPoint genpt;</span><br><span class="line">&#125; ECDLP;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">encrypt_blk</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">const</span> ECDLP* ecdlp,</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EccPoint* pubkey,</span></span><br><span class="line"><span class="params">    <span class="type">int64_t</span> plain,</span></span><br><span class="line"><span class="params">    EccPoint* cipher_pt, <span class="type">int64_t</span>* cipher</span></span><br><span class="line"><span class="params">)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int64_t</span> rndk = <span class="number">0</span>;</span><br><span class="line">    EccPoint x1 = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    &#123;</span><br><span class="line">        rndk = rand() % (ecdlp-&gt;genpt.n - <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">        mulpt(&amp;ecdlp-&gt;ec, rndk, pubkey, &amp;x1);</span><br><span class="line">    &#125; <span class="keyword">while</span> (x1.x == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    mulpt(&amp;ecdlp-&gt;ec, rndk, &amp;ecdlp-&gt;genpt.pt, cipher_pt);</span><br><span class="line">    *cipher = (plain * x1.x) % ecdlp-&gt;genpt.n;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">decrypt_blk</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">const</span> ECDLP* ecdlp,</span></span><br><span class="line"><span class="params">    <span class="type">int64_t</span> prikey,</span></span><br><span class="line"><span class="params">    <span class="type">const</span> EccPoint* cipher_pt, <span class="type">int64_t</span> cipher,</span></span><br><span class="line"><span class="params">    <span class="type">int64_t</span>* plain</span></span><br><span class="line"><span class="params">)</span></span><br><span class="line">&#123;</span><br><span class="line">    EccPoint x1 = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">    mulpt(&amp;ecdlp-&gt;ec, prikey, cipher_pt, &amp;x1);</span><br><span class="line">    *plain = (cipher * inverse(x1.x, ecdlp-&gt;genpt.n)) % ecdlp-&gt;genpt.n;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="包含文件与主程序"><a href="#包含文件与主程序" class="headerlink" title="包含文件与主程序"></a>包含文件与主程序</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    srand((<span class="type">uint32_t</span>)time(<span class="literal">NULL</span>));</span><br><span class="line">    ECDLP ecdlp = &#123; &#123; <span class="number">2</span>, <span class="number">11</span>, <span class="number">49177</span> &#125;, &#123;&#123;<span class="number">1</span>, <span class="number">14445</span>&#125;, <span class="number">49031</span>&#125; &#125;;</span><br><span class="line">    <span class="comment">// print_points(&amp;ecdlp.ec);</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Curve Params: &#123; a = %lld, b = %lld, p = %lld &#125;\n&quot;</span>, ecdlp.ec.a, ecdlp.ec.b, ecdlp.ec.p);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;GenPoint: &#123; pt: (%lld, %lld), n: %lld &#125;\n&quot;</span>, ecdlp.genpt.pt.x, ecdlp.genpt.pt.y, ecdlp.genpt.n);</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> prikey = <span class="number">149</span>;</span><br><span class="line">    EccPoint pubkey = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">    mulpt(&amp;ecdlp.ec, prikey, &amp;ecdlp.genpt.pt, &amp;pubkey);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Prikey: %lld Pubkey: (%lld, %lld)\n&quot;</span>, prikey, pubkey.x, pubkey.y);</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> plain = <span class="number">23456</span>;</span><br><span class="line">    <span class="type">int64_t</span> cipher = <span class="number">-1</span>;</span><br><span class="line">    EccPoint cipher_pt = &#123; <span class="number">0</span> &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Plain: %lld\n&quot;</span>, plain);</span><br><span class="line"></span><br><span class="line">    encrypt_blk(&amp;ecdlp, &amp;pubkey, plain, &amp;cipher_pt, &amp;cipher);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Cipher: (%lld, %lld), %lld\n&quot;</span>, cipher_pt.x, cipher_pt.y, cipher);</span><br><span class="line"></span><br><span class="line">    decrypt_blk(&amp;ecdlp, prikey, &amp;cipher_pt, cipher, &amp;plain);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Plain: %lld\n&quot;</span>, plain);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>公钥算法</tag>
        <tag>椭圆曲线密码</tag>
      </tags>
  </entry>
  <entry>
    <title>SM9 算法中的塔式扩张公式推导</title>
    <url>//posts/2023/12/04/sm9fpex/</url>
    <content><![CDATA[<p>本篇记录一下在实现 SM9 算法时塔式扩张部分的公式推导与代码实现. 由于没有系统学习过相关数学理论, 因此只是根据有限的认识完成了推导, 可能存在不严谨之处.</p>
<span id="more"></span>

<h2 id="SM9-扩域元素的表示"><a href="#SM9-扩域元素的表示" class="headerlink" title="SM9 扩域元素的表示"></a>SM9 扩域元素的表示</h2><p>以下来自 GB/T 38635.1-2020 A.2 部分 &quot;扩域元素的表示&quot; 小节原文内容.</p>
<p>$F_{q^{12}}$ 的 $1\text{-}2\text{-}4\text{-}12$ 塔式扩张:</p>
<p>$$<br>\begin{align*}<br>  &amp; F_{q^{2}}[u] = F_{q}[u]/(u^2 - \alpha), &amp;&amp; \alpha = -2 \\<br>  &amp; F_{q^{4}}[v] = F_{q^{2}}[v]/(v^2 - \xi), &amp;&amp; \xi = u \\<br>  &amp; F_{q^{12}}[w] = F_{q^{4}}[w]/(w^3 - v), &amp;&amp; v^2 = \xi<br>\end{align*}<br>$$</p>
<p>其中, 第一次的 2 次扩张约化多项式为: $x^2 - \alpha, \alpha=-2$;</p>
<p>第二次进行 2 次扩张的约化多项式为: $x^2 - u, u^2 = \alpha, u = \sqrt{-2}$;</p>
<p>第三次进行 3 次扩张的约化多项式为: $x^3-v, v^2=u, v = \sqrt{\sqrt{-2}}$.</p>
<p>$u$ 属于 $F_{q^{2}}$, 表示为 $(1, 0)$.</p>
<p>$v$ 属于 $F_{q^{4}}$, 表示为 $(0, 1, 0, 0)$, 也可以用 $F_{q^{2}}$ 元素表示为 $((0, 1), (0, 0))$.</p>
<h2 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h2><p>加法和减法就是类似于向量运算, 每个位置进行加减并模 $p$ 即可, 因此只需要推导乘法和模逆运算.</p>
<h3 id="2-次扩域"><a href="#2-次扩域" class="headerlink" title="2 次扩域"></a>2 次扩域</h3><p>设 $X = (x_1, x_0), Y = (y_1, y_0), Z = (z_1, z_0)$, 且 $Z = X \cdot Y$, 约化多项式为: $u^2 - \alpha, \alpha=-2$.</p>
<p>则 $Z$ 可以表示为:</p>
<p>$$<br>\begin{align*}<br>  (z_1, z_0) &amp;= (x_1, x_0) \cdot (y_1, y_0) \\<br>  ~ &amp;= (x_1u + x_0)(y_1u + y_0) \\<br>  ~ &amp;= x_1y_1u^2 + (x_1y_0 + x_0y_1)u + x_0y_0 \\<br>  ~ &amp;= (x_1y_0 + x_0y_1)u + (\alpha x_1y_1 + x_0y_0) \\<br>  ~ &amp;= (x_1y_0 + x_0y_1, \alpha x_1y_1 + x_0y_0)<br>\end{align*}<br>$$</p>
<p>所以:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  z_1 &amp;= x_1y_0 + x_0y_1 \\<br>  z_0 &amp;= \alpha x_1y_1 + x_0y_0<br>\end{align*}<br>\right.<br>$$</p>
<p>然后设 $Y = X^{-1}$, 也就是求 $X$ 的模逆:</p>
<p>$$<br>(0, 1) = (x_1, x_0) \cdot (y_1, y_0)<br>$$</p>
<p>即解二元一次方程组:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  0 &amp;= x_1y_0 + x_0y_1 \\<br>  1 &amp;= \alpha x_1y_1 + x_0y_0<br>\end{align*}<br>\right.<br>$$</p>
<p>解得:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  y_1 &amp;= \frac{x_1}{\alpha x_1^2 - x_0^2} \\<br>  y_0 &amp;= \frac{-x_0}{\alpha x_1^2 - x_0^2}<br>\end{align*}<br>\right.<br>$$</p>
<p>上述公式将 $F_{q^{2}}$ 中的运算全部变成 $F_{q}$ 中的运算, 所有元素计算后均需要模 $p$.</p>
<h3 id="4-次扩域"><a href="#4-次扩域" class="headerlink" title="4 次扩域"></a>4 次扩域</h3><p>设 $X = (X_1, X_0), Y = (Y_1, Y_0), Z = (Z_1, Z_0)$, 且 $Z = X \cdot Y$, 约化多项式为: $v^2 - u, u^2 = \alpha, u = \sqrt{-2}$.</p>
<p>其中 $X = (X_1, X_0) = (x_3, x_2, x_1, x_0)$ 是 $F_{q^{4}}$ 上的元素, $X_1, X_0$ 都是 $F_{q^{2}}$ 上的元素, $Y$ 和 $Z$ 同理.</p>
<p>仿照第一次 2 次扩张的过程, 则 $Z$ 可以表示为:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  Z_1 &amp;= X_1Y_0 + X_0Y_1 \\<br>  Z_0 &amp;= u X_1Y_1 + X_0Y_0<br>\end{align*}<br>\right.<br>$$</p>
<p>其中 $u X_1Y_1 = (1, 0) \cdot X_1 \cdot Y_1$, 可以直接使用上一节中 $F_{q^{2}}$ 上的运算完成.</p>
<p>同理可得模逆运算为:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  Y_1 &amp;= \frac{X_1}{u X_1^2 - X_0^2} \\<br>  Y_0 &amp;= \frac{-X_0}{u X_1^2 - X_0^2}<br>\end{align*}<br>\right.<br>$$</p>
<p>其中 $u X_1^2 = (1, 0) \cdot X_1 \cdot X_1$.</p>
<h3 id="12-次扩域"><a href="#12-次扩域" class="headerlink" title="12 次扩域"></a>12 次扩域</h3><p>设 $X = (X_2, X_1, X_0), Y = (Y_2, Y_1, Y_0), Z = (Z_2, Z_1, Z_0)$, 且 $Z = X \cdot Y$, 约化多项式为: $w^3-v, v^2=u, v = \sqrt{\sqrt{-2}}$.</p>
<p>其中 $X = (X_2, X_1, X_0) = (x_{11}, x_{10}, \ldots, x_0)$ 是 $F_{q^{12}}$ 上的元素, $X_2, X_1, X_0$ 都是 $F_{q^{4}}$ 上的元素, $Y$ 和 $Z$ 同理.</p>
<p>则 $Z$ 可以表示为:</p>
<p>$$<br>\begin{align*}<br>  (Z_2, Z_1, Z_0) &amp;= (X_2, X_1, X_0) \cdot (Y_2, Y_1, Y_0) \\<br>  ~ &amp;= (X_2 w^2 + X_1w + X_0)(Y_2 w^2 + Y_1w + Y_0) \\<br>  ~ &amp;= X_2Y_2w^4 + (X_2Y_1 + X_1Y_2)w^3 + (X_2Y_0 + X_1Y_1 + X_0Y_2)w^2 + (X_1Y_0 + X_0Y_1)w + X_0Y_0 \\<br>  ~ &amp;= (X_2Y_0 + X_1Y_1 + X_0Y_2)w^2 + (vX_2Y_2 + X_1Y_0 + X_0Y_1)w + (vX_2Y_1 + vX_1Y_2 + X_0Y_0) \\<br>  ~ &amp;= (X_2Y_0 + X_1Y_1 + X_0Y_2, vX_2Y_2 + X_1Y_0 + X_0Y_1, v(X_2Y_1 + X_1Y_2) + X_0Y_0)<br>\end{align*}<br>$$</p>
<p>所以:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  Z_2 &amp;= X_2Y_0 + X_1Y_1 + X_0Y_2 \\<br>  Z_1 &amp;= vX_2Y_2 + X_1Y_0 + X_0Y_1 \\<br>  Z_0 &amp;= v(X_2Y_1 + X_1Y_2) + X_0Y_0<br>\end{align*}<br>\right.<br>$$</p>
<p>其中 $v = ((0, 1), (0, 0)) = (0, 1, 0, 0)$, 可以用 $F_{q^{4}}$ 完成计算.</p>
<p>设 $Y = X^{-1}$, 求 $X$ 的模逆:</p>
<p>$$<br>(\mathbf{0}_{F_{q^4}}, \mathbf{0}_{F_{q^4}}, \mathbf{1}_{F_{q^4}}) = (X_2, X_1, X_0) \cdot (Y_2, Y_1, Y_0)<br>$$</p>
<p>即解三元一次方程组:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  \mathbf{0}_{F_{q^4}} &amp;= X_2Y_0 + X_1Y_1 + X_0Y_2 \\<br>  \mathbf{0}_{F_{q^4}} &amp;= vX_2Y_2 + X_1Y_0 + X_0Y_1 \\<br>  \mathbf{1}_{F_{q^4}} &amp;= v(X_2Y_1 + X_1Y_2) + X_0Y_0<br>\end{align*}<br>\right.<br>$$</p>
<p>解得:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  Y_2 &amp;= \frac{X_1^2 - X_2X_0}{\mathbf{det}_{F_{q^4}}} \\<br>  Y_1 &amp;= \frac{vX_2^2 - X_1X_0}{\mathbf{det}_{F_{q^4}}} \\<br>  Y_0 &amp;= \frac{X_0^2 - vX_2X_1}{\mathbf{det}_{F_{q^4}}}<br>\end{align*}<br>\right.<br>$$</p>
<p>其中 $\mathbf{det}_{F_{q^4}} = v^2X_2^3 + vX_1^3 + X_0^3 - 3 \cdot (vX_2X_1X_0)$, 符号 $\cdot$ 表示 $F_{q^4}$ 上的标量乘法运算.</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>用 python 简单实现一下上述涉及的所有运算.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line">Fp2Ele = <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line">Fp4Ele = <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line">Fp12Ele = <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line">FpExEle = <span class="type">Tuple</span>[<span class="built_in">int</span>, ...]</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PrimeFiledEx</span>(<span class="title class_ inherited__">PrimeField</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Fp2, Fp4, Fp12 operations.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, p: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.p = p</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inv</span>(<span class="params">self, x: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">return</span> inverse(x, self.p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addex</span>(<span class="params">self, X: FpExEle, Y: FpExEle</span>) -&gt; FpExEle:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>((i1 + i2) % self.p <span class="keyword">for</span> i1, i2 <span class="keyword">in</span> <span class="built_in">zip</span>(X, Y))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">subex</span>(<span class="params">self, X: FpExEle, Y: FpExEle</span>) -&gt; FpExEle:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>((i1 - i2) % self.p <span class="keyword">for</span> i1, i2 <span class="keyword">in</span> <span class="built_in">zip</span>(X, Y))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">negex</span>(<span class="params">self, X: FpExEle</span>) -&gt; FpExEle:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>(self.p - i <span class="keyword">for</span> i <span class="keyword">in</span> X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">smulex</span>(<span class="params">self, k: <span class="built_in">int</span>, X: FpExEle</span>) -&gt; FpExEle:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>((k * i) % self.p <span class="keyword">for</span> i <span class="keyword">in</span> X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mul2</span>(<span class="params">self, X: Fp2Ele, Y: Fp2Ele</span>) -&gt; Fp2Ele:</span><br><span class="line">        x1, x0 = X</span><br><span class="line">        y1, y0 = Y</span><br><span class="line">        x1y1 = x1 * y1</span><br><span class="line">        x0y0 = x0 * y0</span><br><span class="line">        z1 = ((x1 + x0) * (y1 + y0) - x1y1 - x0y0) % self.p</span><br><span class="line">        z0 = (x0y0 - <span class="number">2</span> * x1y1) % self.p</span><br><span class="line">        <span class="keyword">return</span> z1, z0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inv2</span>(<span class="params">self, X: Fp2Ele</span>) -&gt; Fp2Ele:</span><br><span class="line">        x1, x0 = X</span><br><span class="line">        invdet = self.inv(<span class="number">2</span> * x1 * x1 + x0 * x0)</span><br><span class="line">        y1 = (-x1 * invdet) % self.p</span><br><span class="line">        y0 = (x0 * invdet) % self.p</span><br><span class="line">        <span class="keyword">return</span> y1, y0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mul4</span>(<span class="params">self, X: Fp4Ele, Y: Fp4Ele</span>) -&gt; Fp4Ele:</span><br><span class="line">        a, m = self.addex, self.mul2</span><br><span class="line">        X1, X0 = X[:<span class="number">2</span>], X[<span class="number">2</span>:]</span><br><span class="line">        Y1, Y0 = Y[:<span class="number">2</span>], Y[<span class="number">2</span>:]</span><br><span class="line">        U = (<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        X1mY1 = m(X1, Y1)</span><br><span class="line">        X0mY0 = m(X0, Y0)</span><br><span class="line"></span><br><span class="line">        X1aX0_m_Y1aY0 = m(a(X1, X0), a(Y1, Y0))</span><br><span class="line">        Z1 = <span class="built_in">tuple</span>((i1 - i2 - i3) % self.p <span class="keyword">for</span> i1, i2, i3 <span class="keyword">in</span> <span class="built_in">zip</span>(X1aX0_m_Y1aY0, X1mY1, X0mY0))</span><br><span class="line">        Z0 = a(m(U, X1mY1), X0mY0)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Z1 + Z0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inv4</span>(<span class="params">self, X: Fp4Ele</span>) -&gt; Fp4Ele:</span><br><span class="line">        m, n, s = self.mul2, self.negex, self.subex</span><br><span class="line">        X1, X0 = X[:<span class="number">2</span>], X[<span class="number">2</span>:]</span><br><span class="line">        U = (<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        UmX1mX1_s_X0mX0 = s(m(U, m(X1, X1)), m(X0, X0))</span><br><span class="line">        invdet = self.inv2(UmX1mX1_s_X0mX0)</span><br><span class="line"></span><br><span class="line">        Y1 = m(X1, invdet)</span><br><span class="line">        Y0 = m(n(X0), invdet)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Y1 + Y0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mul12</span>(<span class="params">self, X: Fp12Ele, Y: Fp12Ele</span>) -&gt; Fp12Ele:</span><br><span class="line">        a, m = self.addex, self.mul4</span><br><span class="line">        X2, X1, X0 = X[:<span class="number">4</span>], X[<span class="number">4</span>:<span class="number">8</span>], X[<span class="number">8</span>:]</span><br><span class="line">        Y2, Y1, Y0 = Y[:<span class="number">4</span>], Y[<span class="number">4</span>:<span class="number">8</span>], Y[<span class="number">8</span>:]</span><br><span class="line">        V = (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        X2mY2, X1mY1, X0mY0 = m(X2, Y2), m(X1, Y1), m(X0, Y0)</span><br><span class="line">        X2aX1, X2aX0, X1aX0 = a(X2, X1), a(X2, X0), a(X1, X0)</span><br><span class="line">        Y2aY1, Y2aY0, Y1aY0 = a(Y2, Y1), a(Y2, Y0), a(Y1, Y0)</span><br><span class="line"></span><br><span class="line">        X2aX1_m_Y2aY1 = m(X2aX1, Y2aY1)</span><br><span class="line">        X2aX0_m_Y2aY0 = m(X2aX0, Y2aY0)</span><br><span class="line">        X1aX0_m_Y1aY0 = m(X1aX0, Y1aY0)</span><br><span class="line"></span><br><span class="line">        VmX2mY2 = m(V, X2mY2)</span><br><span class="line">        X2mY1_a_X1Y2 = <span class="built_in">tuple</span>((i1 - i2 - i3) % self.p <span class="keyword">for</span> i1, i2, i3 <span class="keyword">in</span> <span class="built_in">zip</span>(X2aX1_m_Y2aY1, X2mY2, X1mY1))</span><br><span class="line"></span><br><span class="line">        Z2 = <span class="built_in">tuple</span>((i1 - i2 - i3 + i4) % self.p <span class="keyword">for</span> i1, i2, i3, i4 <span class="keyword">in</span> <span class="built_in">zip</span>(X2aX0_m_Y2aY0, X2mY2, X0mY0, X1mY1))</span><br><span class="line">        Z1 = <span class="built_in">tuple</span>((i1 + i2 - i3 - i4) % self.p <span class="keyword">for</span> i1, i2, i3, i4 <span class="keyword">in</span> <span class="built_in">zip</span>(VmX2mY2, X1aX0_m_Y1aY0, X1mY1, X0mY0))</span><br><span class="line">        Z0 = a(m(V, X2mY1_a_X1Y2), X0mY0)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Z2 + Z1 + Z0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inv12</span>(<span class="params">self, X: Fp12Ele</span>) -&gt; Fp12Ele:</span><br><span class="line">        m, s = self.mul4, self.subex</span><br><span class="line">        X2, X1, X0 = X[:<span class="number">4</span>], X[<span class="number">4</span>:<span class="number">8</span>], X[<span class="number">8</span>:]</span><br><span class="line">        V = (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        VmX2 = m(V, X2)</span><br><span class="line">        VmX1 = m(V, X1)</span><br><span class="line"></span><br><span class="line">        X1mX1_s_X2mX0 = s(m(X1, X1), m(X2, X0))</span><br><span class="line">        VmX2mX2_s_X1X0 = s(m(VmX2, X2), m(X1, X0))</span><br><span class="line">        X0mX0_s_VmX2mX1 = s(m(X0, X0), m(VmX2, X1))</span><br><span class="line"></span><br><span class="line">        det = <span class="built_in">tuple</span>((i1 + i2 + i3) % self.p <span class="keyword">for</span> i1, i2, i3 <span class="keyword">in</span> <span class="built_in">zip</span>(m(VmX2, VmX2mX2_s_X1X0), m(VmX1, X1mX1_s_X2mX0), m(X0, X0mX0_s_VmX2mX1)))</span><br><span class="line">        invdet = self.inv4(det)</span><br><span class="line"></span><br><span class="line">        Y2 = m(X1mX1_s_X2mX0, invdet)</span><br><span class="line">        Y1 = m(VmX2mX2_s_X1X0, invdet)</span><br><span class="line">        Y0 = m(X0mX0_s_VmX2mX1, invdet)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Y2 + Y1 + Y0</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9vcGVuc3RkLnNhbXIuZ292LmNuL2J6Z2svZ2IvbmV3R2JJbmZvP2hjbm89QjdBMEQ3REZGNDExQ0QwQUFFNzYxMzVBREU5MTg4NkE=">信息安全技术 SM9标识密码算法 第1部分：总则<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vaGVzaHVjaGFvL3AvODE5NjMwNy5odG1s">伽罗瓦域(有限域)GFq^12上元素的1→2→4→12塔式扩张(1)------第一次扩张<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vaGVzaHVjaGFvL3AvODE5ODQ5NC5odG1s">伽罗瓦域(有限域)GFq^12上元素的1→2→4→12塔式扩张(2)------第二次扩张<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>SM9</tag>
        <tag>塔式扩张</tag>
        <tag>扩域运算</tag>
      </tags>
  </entry>
  <entry>
    <title>SM9 算法中 $g_{U, V}(Q)$ 的展开优化</title>
    <url>//posts/2024/06/16/sm9gfn/</url>
    <content><![CDATA[<p>本篇记录一下在实现 SM9 算法时对函数 $g_{U, V}(Q)$ 稀疏乘法的公式推导与优化实现.</p>
<span id="more"></span>

<h2 id="十二次扩域上的稀疏乘法"><a href="#十二次扩域上的稀疏乘法" class="headerlink" title="十二次扩域上的稀疏乘法"></a>十二次扩域上的稀疏乘法</h2><p>$$<br>\begin{align*}<br>     U &amp;= (x_U, y_U, z_U) \rightarrow (x_1, y_1) \\<br>     V &amp;= (x_V, y_V, z_V) \rightarrow (x_2, y_2) \\<br>     Q &amp;= (x_Q, y_Q, z_Q) \rightarrow (x_3, y_3) \\<br>     U&#39; &amp;= (x&#39;_U, y&#39;_U, z&#39;_U) \rightarrow (x&#39;_1, y&#39;_1) \\<br>     V&#39; &amp;= (x&#39;_V, y&#39;_V, z&#39;_V) \rightarrow (x&#39;_2, y&#39;_2)<br>\end{align*}<br>$$</p>
<p>$U, V, Q$ 是 $E(F_{q^{12}})$ 上的点, $U&#39;, V&#39;$ 是扭曲线上的点, 也是函数的直接输入值.</p>
<p>$Q$ 输入时在 $E(F_{q})$ 上, 但是可以直接通过塔式扩张转换到 $E(F_{q^{12}})$ 上.</p>
<p>根据雅各比加重坐标系转换公式和扭曲线转换公式可得:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>    x_1 &amp;= \frac{x_U}{z_U^2} = \frac{x_U&#39;}{\omega^2} = \frac{x_U&#39;}{\omega^2 z_U&#39;^2} \\<br>    y_1 &amp;= \frac{y_U}{z_U^3} = \frac{y_U&#39;}{\omega^3} = \frac{y_U&#39;}{\omega^3 z_U&#39;^3}<br>\end{align*}<br>\right.<br>$$</p>
<p>可以看到根据 $z$ 的次数, 分母会乘上同次数的 $\omega$, 这在 $F_{q^{12}}$ 上相当于是把这个 $F_{q^{2}}$ 元素次数加一, 也就是改变这个元素的位置.</p>
<p>同理有:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>    x_2 &amp;= \frac{x_V}{z_V^2} \\<br>    y_2 &amp;= \frac{y_V}{z_V^3}<br>\end{align*}<br>\right.<br>$$</p>
<p>$$<br>\left\{<br>\begin{align*}<br>    x_3 &amp;= \frac{x_Q}{z_Q^2} \\<br>    y_3 &amp;= \frac{y_Q}{z_Q^3}<br>\end{align*}<br>\right.<br>$$</p>
<p>根据公式有:</p>
<p>$$<br>\begin{align*}<br>     \lambda_1 &amp;= \frac{3x_2^2}{2y_2} \\<br>     \lambda_2 &amp;= \frac{y_1 - y_2}{x_1 - x_2}<br>\end{align*}<br>$$</p>
<p>则:</p>
<p>$$<br>\begin{align*}<br>g_{V, V}(Q) &amp;= \lambda_1(x_3 - x_2) + y_2 - y_3 \\<br>~ &amp;= \frac{3x_2^2(x_3-x_2)}{2y_2} + y_2 - y_3 \\<br>~ &amp;= \frac{3x_3}{2}\frac{x_2^2}{y_2} - \frac{3}{2}\frac{x_2^3}{y_2} + y_2 - y_3 \\<br>~ &amp;= \frac{\frac{3}{2} x_3 x_V^2}{y_V z_V} - \frac{\frac{3}{2}x_V^3}{y_V z_V^3} + \frac{y_V}{z_V^3} - y_3 \\<br>~ &amp;= \frac{\frac{3}{2} x_Q x_V^2}{z_Q^2 y_V z_V} - \frac{\frac{3}{2}x_V^3}{y_V z_V^3} + \frac{y_V} {z_V^3} - \frac{y_Q} {z_Q^3} \\<br>~ &amp;= \frac{\frac{3}{2} x_Q z_Q x_V^2 z_V^2 + z_Q^3(y_V^2 - \frac{3}{2}x_V^3) - y_Q y_V z_V^3}{z_Q^3 y_V z_V^3}<br>\end{align*}<br>$$</p>
<p>$$<br>\begin{align*}<br>g_{U, V}(Q) &amp;= \lambda_2(x_3 - x_2) + y_2 - y_3 \\<br>~ &amp;= \frac{y_1 - y_2}{x_1 - x_2}(x_3 - x_2) + y_2 - y_3 \\<br>~ &amp;= \frac{\frac{y_U}{z_U^3} - \frac{y_V}{z_V^3}}{\frac{x_U}{z_U^2} - \frac{x_V}{z_V^2}}(x_3 - \frac{x_V}{z_V^2}) + \frac{y_V}{z_V^3} - y_3 \\<br>~ &amp;= \frac{y_U z_V^3 - y_V z_U^3}{z_Uz_V(x_U z_V^2 - x_V z_U^2)}(x_3 - \frac{x_V}{z_V^2}) + \frac{y_V}{z_V^3} - y_3 \\<br>~ &amp;= \frac{y_U z_V^3 - y_V z_U^3} {z_Uz_V(x_U z_V^2 - x_V z_U^2)}\frac{x_3 z_V^2 - x_V}{z_V^2} + \frac{y_V - y_3 z_V^3}{z_V^3} \\<br>~ &amp;= \frac{z_V(y_U z_V^3 - y_V z_U^3)(x_3 z_V^2 - x_V) + z_Uz_V(x_U z_V^2 - x_V z_U^2)(y_V - y_3 z_V^3)}{z_Uz_V(x_U z_V^2 - x_V z_U^2)z_V^3} \\<br>~ &amp;= \frac{t_2 x_3 z_V^2 + t_1 y_V - t_2 x_V - t_1 y_3 z_V^3}{t_1 z_V^3} \\<br>~ &amp;= \frac{t_2 \frac{x_Q}{z_Q^2} z_V^2 + t_1 y_V - t_2 x_V - t_1 \frac{y_Q}{z_Q^3} z_V^3} {t_1 z_V^3} \\<br>~ &amp;= \frac{x_Q z_Q t_2 z_V^2 + z_Q^3(t_1 y_V - t_2 x_V) - y_Q t_1 z_V^3} {z_Q^3 t_1 z_V^3}<br>\end{align*}<br>$$</p>
<p>其中:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>    t_1 &amp;= z_Uz_V(x_U z_V^2 - x_V z_U^2) \\<br>    t_2 &amp;= z_V(y_U z_V^3 - y_V z_U^3)<br>\end{align*}<br>\right.<br>$$</p>
<p>当 $U, V$ 为相反点, 即 $x_1 = x_2, y_1 + y_2 = 0$ 时:</p>
<p>$$<br>\begin{align*}<br>g_{V, -V}(Q) &amp;= x_3 - x_2 \\<br>~ &amp;= \frac{x_Q}{z_Q^2} - \frac{x_V}{z_V^2} \\<br>~ &amp;= \frac{x_Q z_V^2 - z_Q^2 x_V}{z_Q^2 z_V^2}<br>\end{align*}<br>$$</p>
<p>在代码实现时, 通过展开, 可以将计算控制在 $F_{q^{2}}$ 上, 且分开算分子分母, 可以有效避免求逆, 延迟到在最后计算 $FinalExp$ 时对总的分母计算一次逆.</p>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>SM9</tag>
        <tag>SM9优化</tag>
        <tag>稀疏乘法</tag>
      </tags>
  </entry>
  <entry>
    <title>一次意外的 Github SSH 连接失败</title>
    <url>//posts/2024/01/15/ssh-github/</url>
    <content><![CDATA[<p>记录一次失败的 Github SSH 连接问题排查过程.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh -T git@github.com</span><br><span class="line">git@github.com: Permission denied (publickey).</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>自己 Windows 系统上很早生成了一对 ssh 密钥用于 Github 仓库访问, 然后想在 Ubuntu 的虚拟机里也用同样的密钥去访问 Github, 于是乎直接用 Xftp 连接虚拟机传了上去, 放到 <code>~/.ssh/</code> 目录下.</p>
<p>但是 clone 仓库时, 出现了如下报错:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone git@github.com:ww-rm/&lt;repo&gt;.git</span><br><span class="line">正克隆到 &#x27;&lt;repo&gt;&#x27;...</span><br><span class="line">sign_and_send_pubkey: signing failed for RSA &quot;/home/&lt;username&gt;/.ssh/id_rsa&quot; from agent: agent refused operation</span><br><span class="line">git@github.com: Permission denied (publickey).</span><br><span class="line">fatal: 无法读取远程仓库。</span><br><span class="line"></span><br><span class="line">请确认您有正确的访问权限并且仓库存在。</span><br></pre></td></tr></table></figure>

<h2 id="上下求索"><a href="#上下求索" class="headerlink" title="上下求索"></a>上下求索</h2><p>很迷茫, 自己 Windows 上一直都是用的这个密钥, 复制过去咋就不认了?</p>
<p>于是搜索一波, 找到了 Github Docs 的 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmdpdGh1Yi5jb20vZW4vYXV0aGVudGljYXRpb24vdHJvdWJsZXNob290aW5nLXNzaC9lcnJvci1wZXJtaXNzaW9uLWRlbmllZC1wdWJsaWNrZXk=">Error: Permission denied (publickey)<i class="fa fa-external-link-alt"></i></span> 页面.</p>
<p>按照上面说的, 用命令 <code>ssh -T git@github.com</code> 分别在 Windows 上和 Ubuntu 上都测试一遍.</p>
<p>然后 Windows 给了一个愉快的输出:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Hi ww-rm! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br></pre></td></tr></table></figure>

<p>但是 Ubuntu 还是失败:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sign_and_send_pubkey: signing failed for RSA &quot;/home/&lt;username&gt;/.ssh/id_rsa&quot; from agent: agent refused operation</span><br><span class="line">git@github.com: Permission denied (publickey).</span><br></pre></td></tr></table></figure>

<p>我把目光落在 <code>agent refused operation</code> 这个提示上.</p>
<p>一番搜索之后, 得到的结论大部分都是说 key 没有添加, 要使用 <code>ssh-add</code> 命令. 于是再次尝试.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh-add ~/.ssh/id_rsa</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">@         WARNING: UNPROTECTED PRIVATE KEY FILE!          @</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">Permissions 0644 <span class="keyword">for</span> <span class="string">&#x27;/home/&lt;username&gt;/.ssh/id_rsa&#x27;</span> are too open.</span><br><span class="line">It is required that your private key files are NOT accessible by others.</span><br><span class="line">This private key will be ignored.</span><br></pre></td></tr></table></figure>

<p>这下子报错很明白了, 它告诉我们由于私钥权限太开放了, 所以忽略了这个密钥. 用 <code>ll</code> 看一眼也能发现文件权限是 <code>-rw-r--r--</code>.</p>
<h2 id="真相"><a href="#真相" class="headerlink" title="真相"></a>真相</h2><p>Xftp 在上传文件的时候, 文件权限自动给了 <code>644</code>, 然后 <code>ssh</code> 忽略了这种高权限的不安全密钥文件.</p>
<p>所以解决方案就是用 <code>chmod</code> 修改私钥的文件权限, 把组权限去掉, 也就是将原本 <code>644</code> 的权限改成 <code>600</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> 600 ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure>

<p>修改完之后再次使用 <code>ssh -T git@github.com</code> 在 Ubuntu, 就能成功连接了.</p>
]]></content>
      <categories>
        <category>杂学</category>
      </categories>
      <tags>
        <tag>SSH</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Windows 上编译安装 NUPACK</title>
    <url>//posts/2024/05/11/py-nupack/</url>
    <content><![CDATA[<p>之前项目里用到了 <span class="exturl" data-url="aHR0cHM6Ly9udXBhY2sub3JnLw==">NUPACK<i class="fa fa-external-link-alt"></i></span> 这个软件, 用来做引物二级结构预测, 但是就<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLm51cGFjay5vcmcvc3RhcnQv">官方文档<i class="fa fa-external-link-alt"></i></span>上来看, 只提供了 Linux 下的 Python 库以及源码, 并且就算是 Windows 也是直接推荐的 WSL2 子系统. 虽然项目部署到服务器上运行直接就是 Linux 环境, 但是富有折腾精神的咱还是决定在 Windows 上尝试编译安装一下, 因此有了本文记录全部的编译踩坑过程.</p>
<p>太长不看: 直接前往仓库 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL251cGFjay13aW4=">nupack-win<i class="fa fa-external-link-alt"></i></span> 下载安装包.</p>
<span id="more"></span>

<h2 id="项目概况"><a href="#项目概况" class="headerlink" title="项目概况"></a>项目概况</h2><p>这次使用的是 <code>v4.0.1.8</code> 的 NUPACK 源码. 项目是基于 <span class="exturl" data-url="aHR0cHM6Ly9jbWFrZS5vcmcv">CMake<i class="fa fa-external-link-alt"></i></span> 的, 并且使用了 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL21pY3Jvc29mdC92Y3BrZw==">vcpkg<i class="fa fa-external-link-alt"></i></span> 作为包管理器, 在官方文档中有 Mac/Linux 环境下的源码安装步骤 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLm51cGFjay5vcmcvc3RhcnQvI3NvdXJjZS1pbnN0YWxsYXRpb24=">Source installation<i class="fa fa-external-link-alt"></i></span> 可供参考.</p>
<p>由于 CMake 和 vcpkg 都是比较好跨平台的, 因此我们只需要在 Windows 上复现它的这些步骤就大功告成.<del>事实是被编译环境暴打.</del></p>
<h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p>首先是准备 Windows 上的 MinGW + Clang 编译环境, 这里参考微软官方的 vcpkg 文档 <span class="exturl" data-url="aHR0cHM6Ly9sZWFybi5taWNyb3NvZnQuY29tL2VuLXVzL3ZjcGtnL3VzZXJzL3BsYXRmb3Jtcy9taW5ndw==">Mingw-w64<i class="fa fa-external-link-alt"></i></span>, 以及 <span class="exturl" data-url="aHR0cHM6Ly93d3cubXN5czIub3JnLw==">MSYS2<i class="fa fa-external-link-alt"></i></span> 的安装步骤.</p>
<p>不同的地方在于, 我们需要同时安装 Clang 和 GCC 两套工具链, 因为部分库可能在 Clang 下编译失败, 但是 GCC 可以.</p>
<p>安装好 MSYS2 之后, 分别启动 <code>MSYS2 CLANG64</code> 和 <code>MSYS2 MINGW</code> 两个终端, 然后用用命令分别安装对应的工具链 <span class="exturl" data-url="aHR0cHM6Ly9wYWNrYWdlcy5tc3lzMi5vcmcvZ3JvdXBzL21pbmd3LXc2NC1jbGFuZy14ODZfNjQtdG9vbGNoYWlu">mingw-w64-clang-x86_64-toolchain<i class="fa fa-external-link-alt"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9wYWNrYWdlcy5tc3lzMi5vcmcvZ3JvdXBzL21pbmd3LXc2NC14ODZfNjQtdG9vbGNoYWlu">mingw-w64-x86_64-toolchain<i class="fa fa-external-link-alt"></i></span>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pacman -S mingw-w64-clang-x86_64-toolchain</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pacman -S mingw-w64-x86_64-toolchain</span><br></pre></td></tr></table></figure>

<p>完事之后可以看看 <code>clang</code> 和 <code>gcc</code> 的版本.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ clang --version</span><br><span class="line">clang version 17.0.6</span><br><span class="line">Target: x86_64-w64-windows-gnu</span><br><span class="line">Thread model: posix</span><br><span class="line">InstalledDir: D:/Program Files/msys64/clang64/bin</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ gcc --version</span><br><span class="line">gcc.exe (Rev3, Built by MSYS2 project) 13.2.0</span><br><span class="line">Copyright (C) 2023 Free Software Foundation, Inc.</span><br><span class="line">This is free software; see the <span class="built_in">source</span> <span class="keyword">for</span> copying conditions.  There is NO</span><br><span class="line">warranty; not even <span class="keyword">for</span> MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span><br></pre></td></tr></table></figure>

<p>如无特殊说明, 后续步骤里的命令默认都是在 <code>CLANG64</code> 环境里执行.</p>
<h2 id="安装依赖库"><a href="#安装依赖库" class="headerlink" title="安装依赖库"></a>安装依赖库</h2><p>解压 <code>nupack-4.0.1.8.zip</code>, 导航进入 <code>source</code> 目录.</p>
<p>全篇最困难的地方当属安装依赖库, 我们遵循一个原则, 那就是能用原项目 vcpkg 版本里的内容就尽量用原项目的, 出问题了再换成新的.</p>
<p>所以我们还要先 clone 一个最新的 vcpkg 备用.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> git@github.com:microsoft/vcpkg.git</span><br><span class="line">Cloning into <span class="string">&#x27;vcpkg&#x27;</span>...</span><br><span class="line">remote: Enumerating objects: 233259, <span class="keyword">done</span>.</span><br><span class="line">remote: Counting objects: 100% (12697/12697), <span class="keyword">done</span>.</span><br><span class="line">remote: Compressing objects: 100% (969/969), <span class="keyword">done</span>.</span><br><span class="line">remote: Total 233259 (delta 12286), reused 11775 (delta 11728), pack-reused 220562</span><br><span class="line">Receiving objects: 100% (233259/233259), 69.10 MiB | 4.18 MiB/s, <span class="keyword">done</span>.</span><br><span class="line">Resolving deltas: 100% (155206/155206), <span class="keyword">done</span>.</span><br><span class="line">Updating files: 100% (11336/11336), <span class="keyword">done</span>.</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> vcpkg &amp;&amp; git show-ref --heads</span><br><span class="line">a1212c93cabaa9c5c36c1ffdb4bddd59fdf31e43 refs/heads/master</span><br></pre></td></tr></table></figure>

<p>首先得把原项目 <code>external/vcpkg</code> 下的 <code>scripts</code> 文件夹一整个替换掉, 因为旧版本有些操作完成不了, 且下载的编译工具不是最新的.</p>
<p>然后按正常步骤运行 <code>bootstrap-vcpkg.sh</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ./external/vcpkg/bootstrap-vcpkg.sh</span><br><span class="line">Downloading https://github.com/microsoft/vcpkg-tool/releases/download/2024-04-23/vcpkg.exe -&gt; D:\Projects\VsProjects\nupack-4.0.1.8\<span class="built_in">source</span>\external\vcpkg\vcpkg.exe (using IE proxy: 127.0.0.1:10809)... <span class="keyword">done</span>.</span><br><span class="line">Validating signature... <span class="keyword">done</span>.</span><br><span class="line"></span><br><span class="line">vcpkg package management program version 2024-04-23-d6945642ee5c3076addd1a42c331bbf4cfc97457</span><br><span class="line"></span><br><span class="line">See LICENSE.txt <span class="keyword">for</span> license information.</span><br><span class="line">Telemetry</span><br><span class="line">---------</span><br><span class="line">vcpkg collects usage data <span class="keyword">in</span> order to <span class="built_in">help</span> us improve your experience.</span><br><span class="line">The data collected by Microsoft is anonymous.</span><br><span class="line">You can opt-out of telemetry by re-running the bootstrap-vcpkg script with -disableMetrics,</span><br><span class="line">passing --disable-metrics to vcpkg on the <span class="built_in">command</span> line,</span><br><span class="line">or by setting the VCPKG_DISABLE_METRICS environment variable.</span><br><span class="line"></span><br><span class="line">Read more about vcpkg telemetry at docs/about/privacy.md</span><br></pre></td></tr></table></figure>

<p>安装之前记得先在终端里设置一下默认的 triplet.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> VCPKG_DEFAULT_TRIPLET=x64-mingw-dynamic</span><br><span class="line"><span class="built_in">export</span> VCPKG_DEFAULT_HOST_TRIPLET=x64-mingw-dynamic</span><br></pre></td></tr></table></figure>

<p>结合官方教程里的步骤以及 <code>cmake/Libraries.cmake</code> 和 <code>cmake/BuildCXX.cmake</code> 里的内容, 所有要安装的包大概可以分成下面几类.</p>
<ol>
<li><p>需要先更新 port 版本</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">openblas yaml-cpp fmt spdlog</span><br></pre></td></tr></table></figure>

<p> 这些库由于旧版本有一些 bug, 或者由于某些神秘问题导致在 MinGW 环境下安装失败, 但是通过把 port 换成最新的就能正常安装.</p>
<ul>
<li><code>openblas</code>: 被作为依赖包安装, 但是貌似存在某些不正确的依赖关系, 换成新版本后能正常安装.</li>
<li><code>yaml-cpp</code>: 最后链接的时候找不到某个符号, 新版本已经修复了符号没导出的问题, 详见 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2piZWRlci95YW1sLWNwcC9pc3N1ZXMvMTAyNg==">#1026<i class="fa fa-external-link-alt"></i></span>.</li>
<li><code>fmt</code>: 最后编译的时候会报错找不到某个头文件, 新版本修复了这个问题, 详见 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZtdGxpYi9mbXQvcHVsbC8zNjYz">#3663<i class="fa fa-external-link-alt"></i></span>.</li>
<li><code>spdlog</code>: 由于依赖 <code>fmt</code> 库, 所以必须和 <code>fmt</code> 一起更新.</li>
</ul>
</li>
<li><p>直接装, 在 <code>CLANG64</code> 下就能一步到位.</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">taskflow libsimdpp blas lapack armadillo nlohmann-json magic-enum protobuf</span><br></pre></td></tr></table></figure></li>
<li><p>需要 GCC 环境安装, 在 <code>MINGW64</code> 下一步到位.</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">boost-core boost-preprocessor boost-functional boost-container boost-variant boost-iterator boost-align boost-sort boost-algorithm boost-serialization boost-multi-index</span><br></pre></td></tr></table></figure></li>
<li><p>特殊情况</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gecode tbb</span><br></pre></td></tr></table></figure>

<p> 这两个库在 MinGW 环境编译的时候存在一些配置问题, 会导致安装的时候出现一些语法和链接错误, 因此单独 fork 了仓库并修改了一些报错的配置和代码.</p>
<ul>
<li><code>gecode</code>: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL2dlY29kZS9jb21taXQvYjc3ZDIyZTRjNmIzYjY0NDllNGUzN2NiMWJlMmMxNmIyNjlmNGQzOQ==">增加了 ws2_32 的链接选项<i class="fa fa-external-link-alt"></i></span>.</li>
<li><code>tbb</code>: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL29uZVRCQi9jb21taXQvNThhMDNiMDVlNjZhZTNhNGY2OWYwMmVmMjQ0OGI3ZDJiMTcyMmFjNQ==">去掉了对于宏 __MINGW32__ 的前后不一致判断<i class="fa fa-external-link-alt"></i></span>.</li>
</ul>
<p> 然后把对应的 port 文件改成修改后自己的仓库地址, 就能安装成功.</p>
</li>
</ol>
<h2 id="运行-CMake"><a href="#运行-CMake" class="headerlink" title="运行 CMake"></a>运行 CMake</h2><p>在参考 NUPACK 官方源码安装教程的基础上, 用以下命令运行 CMake. 运行前确保目录被清空.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_POSITION_INDEPENDENT_CODE=ON -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DVCPKG_TARGET_TRIPLET=x64-mingw-dynamic -DREBIND_PYTHON_INCLUDE=<span class="string">&quot;/d/CondaEnvs/py39/include&quot;</span></span><br></pre></td></tr></table></figure>

<p>这里比较关键的是要指定 <code>-DVCPKG_TARGET_TRIPLET</code>, 其余选项基本类似.</p>
<p>然后需要直接指定 <code>-DREBIND_PYTHON_INCLUDE</code>, 貌似由于平台路径格式差异, 导致无法正确地自动探测 Python 头文件的位置.</p>
<p>在运行之前, 还需要解决下面这些问题.</p>
<h3 id="解决库查找错误"><a href="#解决库查找错误" class="headerlink" title="解决库查找错误"></a>解决库查找错误</h3><p>也不知道是哪的配置问题, 在 Windows 下生成的 lib 文件后缀都是 <code>.dll.a</code>, 但是配置文件使用 <code>find_library</code> 按路径直接查找的时候找不到, 只能查找 <code>.a</code> 或者 <code>.so</code> 后缀的, 因此需要去 <code>cmake/Libraries.cmake</code> 里把库名都改一下, 补一个 <code>.dll</code> 进去.</p>
<p>类似这样:</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(<span class="keyword">NOT</span> LAPACK_LIBRARIES)</span><br><span class="line">    <span class="comment"># find_library(LAPACK_LIBRARIES lapack)</span></span><br><span class="line">    <span class="keyword">find_library</span>(LAPACK_LIBRARIES lapack.dll)</span><br><span class="line"><span class="keyword">endif</span>()</span><br></pre></td></tr></table></figure>

<p>但是 <code>lapack</code> 和 <code>blas</code> 这两个库用到了 <code>find_package</code>, 且由于按本地路径直接查找, 因此还是需要去 <code>external/vcpkg/installed/x64-mingw-dynamic/lib</code> 下面手动改一下库文件名, 建议直接复制一份, 把复制的文件改个后缀.</p>
<ul>
<li><code>liblapack.dll.a</code> -&gt; <code>liblapack.a</code></li>
<li><code>libopenblas.dll.a</code> -&gt; <code>libopenblas.a</code></li>
</ul>
<h3 id="解决-Python-包含目录错误"><a href="#解决-Python-包含目录错误" class="headerlink" title="解决 Python 包含目录错误"></a>解决 Python 包含目录错误</h3><p>直接使用自带的 <code>-DREBIND_PYTHON</code> 和 <code>-DREBIND_PYTHON_INCLUDE</code> 参数是存在问题的, 一是 Windows 下路径格式不适配, 二是项目本身 <code>external/rebind/CMakeLists.txt:12</code> 附近的代码就写的有问题, 所以手动改改.</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># if ($&#123;REBIND_PYTHON_INCLUDE&#125;) # 这里的原本的判断存在问题, 永远是假</span></span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">NOT</span> <span class="string">&quot;$&#123;REBIND_PYTHON_INCLUDE&#125;&quot;</span> <span class="keyword">STREQUAL</span> <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">message</span>(<span class="string">&quot;-- Using specified Python include&quot;</span>)</span><br><span class="line">    <span class="keyword">set</span>(python_include <span class="variable">$&#123;REBIND_PYTHON_INCLUDE&#125;</span>) <span class="comment"># 仿照 else 部分对变量 python_include 赋值</span></span><br><span class="line">    <span class="keyword">set_property</span>(GLOBAL PROPERTY rebind_python_include <span class="variable">$&#123;REBIND_PYTHON_INCLUDE&#125;</span>)</span><br><span class="line"><span class="keyword">else</span>()</span><br><span class="line">    <span class="keyword">execute_process</span>(</span><br><span class="line">        <span class="keyword">COMMAND</span> <span class="variable">$&#123;REBIND_PYTHON&#125;</span> -c <span class="string">&quot;import sys, sysconfig; sys.stdout.write(sysconfig.get_paths()[&#x27;include&#x27;])&quot;</span></span><br><span class="line">        RESULT_VARIABLE python_stat OUTPUT_VARIABLE python_include</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> (python_stat)</span><br><span class="line">        <span class="keyword">message</span>(FATAL_ERROR <span class="string">&quot;Failed to deduce include directory from &#x27;$&#123;REBIND_PYTHON&#125;&#x27; executable.\nMaybe specify REBIND_PYTHON_INCLUDE directly.&quot;</span>)</span><br><span class="line">    <span class="keyword">endif</span>()</span><br><span class="line">    <span class="keyword">message</span>(<span class="string">&quot;-- Using Python include directory deduced from REBIND_PYTHON=$&#123;REBIND_PYTHON&#125;&quot;</span>)</span><br><span class="line">    <span class="keyword">set_property</span>(GLOBAL PROPERTY rebind_python_include <span class="variable">$&#123;python_include&#125;</span>)</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">message</span>(<span class="string">&quot;-- Using Python include directory $&#123;python_include&#125;&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>修改之后再编译就不会报 <code>Python.h</code> 头文件找不到这样的错误了.</p>
<h3 id="解决-yaml-cpp-的警告"><a href="#解决-yaml-cpp-的警告" class="headerlink" title="解决 yaml-cpp 的警告"></a>解决 yaml-cpp 的警告</h3><p>运行之后可能会报关于 <code>yaml-cpp</code> 的警告:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CMake Warning (dev) at cmake/BuildCXX.cmake:133 (target_link_libraries):</span><br><span class="line">  The library that is being linked to, yaml-cpp, is marked as being</span><br><span class="line">  deprecated by the owner.  The message provided by the developer is:</span><br><span class="line"></span><br><span class="line">  The target yaml-cpp is deprecated and will be removed in version 0.10.0.</span><br><span class="line">  Use the yaml-cpp::yaml-cpp target instead.</span><br></pre></td></tr></table></figure>

<p>这是新版本 <code>yaml-cpp</code> 的开发者警告, 可以选择去 <code>cmake/BuildCXX.cmake:133</code> 里面按照提示把 <code>yaml-cpp</code> 改成 <code>yaml-cpp::yaml-cpp</code> 再重新运行命令.</p>
<h2 id="生成目标文件"><a href="#生成目标文件" class="headerlink" title="生成目标文件"></a>生成目标文件</h2><p>参考教程的基础上, 用以下命令生成目标文件.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cmake --build . --target nupack-python --verbose -j8</span><br></pre></td></tr></table></figure>

<p>其中 <code>-j8</code> 可以自行修改, 用来多线程加快编译速度, 太高可能会爆内存.</p>
<h3 id="解决参数路径错误"><a href="#解决参数路径错误" class="headerlink" title="解决参数路径错误"></a>解决参数路径错误</h3><p>不出意外会得到下面的报错.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[ 44%] Running cpp protocol buffer compiler on proto/public.proto</span><br><span class="line">/d/Projects/VsProjects/nupack-4.0.1.8/source/external/vcpkg/installed/x64-mingw-dynamic/tools/protobuf/protoc.exe --cpp_out :/d/Projects/VsProjects/nupack-4.0.1.8/source/build-py39/include/nupack/ -I /d/Projects/VsProjects/nupack-4.0.1.8/source /d/Projects/VsProjects/nupack-4.0.1.8/source/proto/public.proto</span><br><span class="line">/d/Projects/VsProjects/nupack-4.0.1.8/source/build-py39/include/nupack/: No such file or directory</span><br><span class="line">make[3]: *** [CMakeFiles/libnupack.dir/build.make:75: include/nupack/proto/public.pb.h] Error 1</span><br><span class="line">make[3]: Leaving directory &#x27;/d/Projects/VsProjects/nupack-4.0.1.8/source/build-py39&#x27;</span><br><span class="line">make[2]: *** [CMakeFiles/Makefile2:128: CMakeFiles/libnupack.dir/all] Error 2</span><br><span class="line">make[2]: Leaving directory &#x27;/d/Projects/VsProjects/nupack-4.0.1.8/source/build-py39&#x27;</span><br><span class="line">make[1]: *** [CMakeFiles/Makefile2:280: CMakeFiles/nupack-python.dir/rule] Error 2</span><br><span class="line">make[1]: Leaving directory &#x27;/d/Projects/VsProjects/nupack-4.0.1.8/source/build-py39&#x27;</span><br><span class="line">make: *** [Makefile:234: nupack-python] Error 2</span><br></pre></td></tr></table></figure>

<p>这是由于其中一条命令中的参数 <code>--cpp_out</code> 后面跟的路径前面多了个冒号 <code>:</code>, 也不知道在哪配置的.</p>
<p>所以在运行命令之前, 还得先把上一步生成的生成文件里的内容改一下, 位于 <code>CMakeFiles/libnupack.dir/build.make:75</code>.</p>
<p>这一步每次重新生成的时候都要手动改<del>纯纯折磨</del>.</p>
<h3 id="解决-format-security-警告"><a href="#解决-format-security-警告" class="headerlink" title="解决 format-security 警告"></a>解决 format-security 警告</h3><p>编译途中会有一个关于格式字符串的不安全警告.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">external/backward-cpp/backward.hpp:3646:14: warning:</span><br><span class="line">      format string is not a string literal (potentially insecure) [-Wformat-security]</span><br><span class="line"> 3646 |       printf(lpMsgBuf);</span><br><span class="line">      |              ^~~~~~~~</span><br></pre></td></tr></table></figure>

<p>我们可以根据提示信息改成 <code>printf(&quot;%s&quot;, lpMsgBuf)</code>.</p>
<h3 id="解决-simdpp-包含目录错误"><a href="#解决-simdpp-包含目录错误" class="headerlink" title="解决 simdpp 包含目录错误"></a>解决 simdpp 包含目录错误</h3><p>重新生成会报错找不到 <code>simdpp</code> 相关的头文件.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">include/nupack/math/SIMD.h:19:14: fatal error:</span><br><span class="line">      &#x27;simdpp/simd.h&#x27; file not found</span><br><span class="line">   19 | #    include &lt;simdpp/simd.h&gt;</span><br><span class="line">      |              ^~~~~~~~~~~~~~~</span><br></pre></td></tr></table></figure>

<p>这是原项目自己加的一个私有 port, 估计是没配置好, 所以我们直接在顶层 <code>CMakeLists.txt</code> 里用 <code>include_directories</code> 自己加进去, 比如这样.</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">include_directories</span>(</span><br><span class="line">    <span class="string">&quot;/d/Projects/VsProjects/nupack-4.0.1.8/source/external/vcpkg/installed/x64-mingw-dynamic/include/libsimdpp-2.1&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="解决类型错误"><a href="#解决类型错误" class="headerlink" title="解决类型错误"></a>解决类型错误</h3><p>重新生成会报错有一处类型不兼容.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">external/rebind/source/Module.cc:106:17: error:</span><br><span class="line">      assigning to &#x27;hashfunc&#x27; (aka &#x27;long long (*)(_object *)&#x27;) from incompatible type</span><br><span class="line">      &#x27;long (PyObject *) noexcept&#x27; (aka &#x27;long (_object *) noexcept&#x27;): different return type</span><br><span class="line">      (&#x27;Py_hash_t&#x27; (aka &#x27;long long&#x27;) vs &#x27;long&#x27;)</span><br><span class="line">  106 |     o.tp_hash = type_index_hash;</span><br><span class="line">      |                 ^~~~~~~~~~~~~~~</span><br></pre></td></tr></table></figure>

<p>这是因为 Windows 下 <code>long long</code> 和 <code>long</code> 类型位长不一致导致的, 所以直接去源码 <code>external/rebind/source/Module.cc:80</code> 处把返回值类型 <code>long</code> 改成 <code>long long</code>.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">long</span> <span class="type">long</span> <span class="title">type_index_hash</span><span class="params">(PyObject *o)</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;<span class="type">long</span> <span class="type">long</span>&gt;(<span class="built_in">cast_object</span>&lt;TypeIndex&gt;(o).<span class="built_in">hash_code</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="解决符号重定义错误"><a href="#解决符号重定义错误" class="headerlink" title="解决符号重定义错误"></a>解决符号重定义错误</h3><p>在最后的链接环节, 还会出现符号重定义错误.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ld.lld: error: duplicate symbol: rebind::Holder&lt;rebind::Var&gt;::type</span><br><span class="line">&gt;&gt;&gt; defined at CMakeFiles/nupack-python.dir/external/rebind/source/Python.cc.obj</span><br><span class="line">&gt;&gt;&gt; defined at CMakeFiles/nupack-python.dir/external/rebind/source/Module.cc.obj</span><br><span class="line"></span><br><span class="line">ld.lld: error: duplicate symbol: rebind::Holder&lt;rebind::TypeIndex&gt;::type</span><br><span class="line">&gt;&gt;&gt; defined at CMakeFiles/nupack-python.dir/external/rebind/source/Python.cc.obj</span><br><span class="line">&gt;&gt;&gt; defined at CMakeFiles/nupack-python.dir/external/rebind/source/Module.cc.obj</span><br><span class="line"></span><br><span class="line">ld.lld: error: duplicate symbol: rebind::Holder&lt;rebind::Function&gt;::type</span><br><span class="line">&gt;&gt;&gt; defined at CMakeFiles/nupack-python.dir/external/rebind/source/Python.cc.obj</span><br><span class="line">&gt;&gt;&gt; defined at CMakeFiles/nupack-python.dir/external/rebind/source/Module.cc.obj</span><br><span class="line"></span><br><span class="line">ld.lld: error: duplicate symbol: rebind::Holder&lt;rebind::ArrayBuffer&gt;::type</span><br><span class="line">&gt;&gt;&gt; defined at CMakeFiles/nupack-python.dir/external/rebind/source/Module.cc.obj</span><br><span class="line">&gt;&gt;&gt; defined at CMakeFiles/nupack-python.dir/external/rebind/source/Cast.cc.obj</span><br></pre></td></tr></table></figure>

<p>不过这个我看了一下源码, 大概率是因为模板的实例化导致的重定义. 但是由于对 c++ 语法也不是很懂, 试了很久没改出来, 所以暴力解决, 三合一大法, 把涉及重定义的几个模块的源码合并到一份源码里, 只生成一个 <code>obj</code> 文件, 在这一份文件里就不会由于反复实例化模板导致重定义了.</p>
<p>直接把:</p>
<ul>
<li><code>external/rebind/source/Cast.cc</code></li>
<li><code>external/rebind/source/Python.cc</code></li>
<li><code>external/rebind/source/Module.cc</code> (注意之前修改过一次)</li>
</ul>
<p>复制到一份新的 <code>external/rebind/source/Cast_Python_Module.cc</code> 文件里.</p>
<p>然后修改 <code>external/rebind/CMakeLists.txt:49</code> 附近代码:</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set_property</span>(GLOBAL PROPERTY rebind_module_files</span><br><span class="line">    <span class="comment"># $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/source/Python.cc</span></span><br><span class="line">    <span class="comment"># $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/source/Module.cc</span></span><br><span class="line">    <span class="comment"># $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/source/Cast.cc</span></span><br><span class="line">    <span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/source/Globals.cc</span><br><span class="line">    <span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/source/Cast_Python_Module.cc</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="解决-Python-符号未定义错误"><a href="#解决-Python-符号未定义错误" class="headerlink" title="解决 Python 符号未定义错误"></a>解决 Python 符号未定义错误</h3><p>最后, 也不知道哪没配置好, 会得到一大堆关于 Python 库符号未定义的错误, 像这样的:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ld.lld: error: undefined symbol: __declspec(dllimport) PyObject_CallObject</span><br></pre></td></tr></table></figure>

<p>似乎只是因为在 Windows 下没有指定 Python 链接库, 所以根据要绑定的 Python 版本, 直接在顶级 <code>CMakeLists.txt</code> 里用 <code>link_directories</code> 和 <code>link_libraries</code> 直接打补丁修复, 类似于下面这样. 库目录和命令里的 <code>-DREBIND_PYTHON_INCLUDE</code> 指定的包含目录相互匹配.</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">link_directories</span>(</span><br><span class="line">    <span class="string">&quot;/d/CondaEnvs/py39/libs&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">link_libraries</span>(</span><br><span class="line">    python39</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>需要注意的是, 不能链接 <code>python3</code>, 必须链接特定版本的库 (比如 <code>python39</code>), 否则还是会出现个别符号未定义.</p>
<h3 id="解决-ImageHlp-符号未定义"><a href="#解决-ImageHlp-符号未定义" class="headerlink" title="解决 ImageHlp 符号未定义"></a>解决 ImageHlp 符号未定义</h3><p>最后的最后, 链接的时候还存在一些符号未定义, 大概长这样.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ld.lld: error: undefined symbol: __declspec(dllimport) SymGetModuleBase64</span><br><span class="line">ld.lld: error: undefined symbol: __declspec(dllimport) StackWalk64</span><br><span class="line">ld.lld: error: undefined symbol: __declspec(dllimport) ImageNtHeader</span><br></pre></td></tr></table></figure>

<p>还是在 Windows 下少链接了一些库, 经过一番搜索, 找到一个可行的<span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvMjY0MDU0MjAvdzY0LW1pbmd3LWxsdm1zdXBwb3J0LWEtdW5kZWZpbmVkLXJlZmVyZW5jZS10by1pbXA=">解决方案<i class="fa fa-external-link-alt"></i></span>, 直接在顶级 <code>CMakeLists.txt</code> 的 <code>link_libraries</code> 里添加对 <code>imagehlp</code> 的链接即可.</p>
<h2 id="生成-Python-包"><a href="#生成-Python-包" class="headerlink" title="生成 Python 包"></a>生成 Python 包</h2><p>首先需要修改一下生成目录下的 <code>setup.py</code>, 也可以在生成之前直接修改源码的 <code>package/setup.py</code>, 就不用每次修改.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;nupack&#x27;</span>,</span><br><span class="line">    version=<span class="string">&#x27;@PROJECT_VERSION@&#x27;</span>,</span><br><span class="line">    description=<span class="string">&#x27;Nucleic Acid Package&#x27;</span>,</span><br><span class="line">    url=<span class="string">&#x27;www.nupack.org&#x27;</span>,</span><br><span class="line">    <span class="comment"># package_data=&#123;&#x27;nupack&#x27;: [&#x27;cpp.so&#x27;, &#x27;parameters/*&#x27;]&#125;,</span></span><br><span class="line">    package_data=&#123;<span class="string">&#x27;nupack&#x27;</span>: [<span class="string">&#x27;cpp.pyd&#x27;</span>, <span class="string">&#x27;parameters/*&#x27;</span>, <span class="string">&quot;*.dll&quot;</span>]&#125;,</span><br><span class="line">    packages=find_packages(include=(<span class="string">&#x27;nupack**&#x27;</span>,)),</span><br><span class="line">    scripts=[],</span><br><span class="line">    distclass=BinaryDistribution,</span><br><span class="line">    cmdclass=&#123;<span class="string">&#x27;install&#x27;</span>: InstallPlatlib&#125;,</span><br><span class="line">    install_requires=[</span><br><span class="line">        <span class="string">&#x27;pyyaml&gt;=5.0.0&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;scipy&gt;=1.0&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;numpy&gt;=1.17&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;pandas&gt;=1.1.0&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;jinja2&gt;=2.0&#x27;</span>,</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>在 Windows 下 Python 的扩展模块文件名后缀是 <code>.pyd</code>, 所以得把编译后生成的 <code>cpp.so</code> 重命名成 <code>cpp.pyd</code>.</p>
<p>然后刚刚编译生成的 <code>cpp.pyd</code>, 还依赖于我们编译环境里以及安装的一些库的动态链接库 DLL 文件, 所以还得挨个把这些 DLL 文件复制过来和 <code>cpp.pyd</code> 放在同一个目录下一起打包进去. 如果缺少某些库则在 <code>import nupack</code> 的时候会有类似下面的报错信息.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: DLL load failed while importing cpp: 找不到指定的模块。</span><br></pre></td></tr></table></figure>

<details class="note info"><summary><p><em>如何知道哪些 DLL 文件是必需的?</em></p>
</summary>
<p>有两种方案, 首先这些必需的 DLL 来自于两部分:</p>
<ul>
<li>MSYS2 环境变量里的系统库.</li>
<li>通过 vcpkg 安装的第三方库.</li>
</ul>
<p>因此第一种方式是把所有可能的系统库和第三方库安装后生成的 DLL 文件都复制到 <code>cpp.pyd</code> 一起, 然后启动 <code>python</code> 会话并 <code>import cpp</code>, 此时将所有复制过来的 DLL 文件尝试删除, 最后留下来提示正在占用无法删除的就是必需 DLL.</p>
<p>第二种方式是使用 <span class="exturl" data-url="aHR0cHM6Ly93d3cuZGVwZW5kZW5jeXdhbGtlci5jb20v">Dependency Walker<i class="fa fa-external-link-alt"></i></span> 查看 <code>cpp.pyd</code> 依赖的 DLL 文件, 并在系统目录和第三方库目录里对照, 看看涉及哪些就复制哪些, Dependency Walker 可能会把 VC 运行时的 DLL 也算进去 (就是一大堆名字里带 <code>api-ms</code> 的), 但是一般情况下电脑上都是装了的, 如果最后真没有的话可以去 <span class="exturl" data-url="aHR0cHM6Ly9sZWFybi5taWNyb3NvZnQuY29tL2VuLXVzL2NwcC93aW5kb3dzL2xhdGVzdC1zdXBwb3J0ZWQtdmMtcmVkaXN0">Microsoft Visual C++ Redistributable latest supported downloads<i class="fa fa-external-link-alt"></i></span> 这里下载安装最新的运行时库.</p>

</details>

<p>系统依赖库:</p>
<ul>
<li><code>libc++.dll</code>: 位于 MSYS2 安装目录的 <code>clang64/bin</code> 下面.</li>
</ul>
<p>其余都是我们安装的库及其依赖的库, 均位于 <code>external/vcpkg/installed/x64-mingw-dynamic/bin</code> 下, 共 16 个:</p>
<ul>
<li><code>libgcc_s_seh-1.dll</code></li>
<li><code>libgecodefloat.dll</code></li>
<li><code>libgecodeint.dll</code></li>
<li><code>libgecodekernel.dll</code></li>
<li><code>libgecodeminimodel.dll</code></li>
<li><code>libgecodesearch.dll</code></li>
<li><code>libgecodeset.dll</code></li>
<li><code>libgecodesupport.dll</code></li>
<li><code>libgfortran-5.dll</code></li>
<li><code>liblapack.dll</code></li>
<li><code>libopenblas.dll</code></li>
<li><code>libprotobuf.dll</code></li>
<li><code>libquadmath-0.dll</code></li>
<li><code>libtbb12.dll</code></li>
<li><code>libwinpthread-1.dll</code></li>
<li><code>libyaml-cpp.dll</code></li>
</ul>
<p>然后导航进生成目录下, 使用命令 <code>python -m build</code> 进行打包, 则会在 <code>dist</code> 下生成打包后的源码和 whl 安装包.</p>
<p>之后可以使用 <code>pip install</code> 直接安装 <code>whl</code> 文件, 并运行命令 <code>python -m pytest -v --pyargs nupack</code> 来测试功能是否正常, 应当是 <code>45</code> 个测试用例全部通过, 无任何警告和错误.</p>
<h2 id="解决路径错误"><a href="#解决路径错误" class="headerlink" title="解决路径错误"></a>解决路径错误</h2><p>直接在源码目录下面测试没测出来 bug, 但是去别的目录下就会发生报错.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RuntimeError: C++: : &quot;failed to open parameter file &quot; (Model.cc, line 50)</span><br></pre></td></tr></table></figure>

<p>有问题的源码在 <code>source/Model.cc:35</code> 附近.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">json <span class="title">ParameterFile::open</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    string name = path;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">path_exists</span>(name)) &#123;</span><br><span class="line">        vec&lt;string&gt; defaults;</span><br><span class="line">        <span class="comment">// boost::split(defaults, DefaultParametersPath, [](char c) &#123;return c == &#x27;:&#x27;;&#125;, boost::token_compress_on); // Windows 下不能按冒号 : 分割, 换成分号 ;</span></span><br><span class="line">        boost::<span class="built_in">split</span>(defaults, DefaultParametersPath, [](<span class="type">char</span> c) &#123;<span class="keyword">return</span> c == <span class="string">&#x27;;&#x27;</span>;&#125;, boost::token_compress_on);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> <span class="type">const</span> &amp;d : defaults) &#123;</span><br><span class="line">            name = <span class="built_in">path_join</span>(d, path);</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">path_exists</span>(name)) <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">path_exists</span>(name)) &#123;</span><br><span class="line">        <span class="keyword">auto</span> s = <span class="built_in">get_env</span>(<span class="string">&quot;NUPACKHOME&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (!s.<span class="built_in">empty</span>()) name = <span class="built_in">path_join</span>(<span class="built_in">path_join</span>(s, <span class="string">&quot;parameters&quot;</span>), path);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::ifstream <span class="title">file</span><span class="params">(name)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (!file.<span class="built_in">good</span>()) &#123;</span><br><span class="line">        vec&lt;string&gt; directories = &#123;<span class="string">&quot;.&quot;</span>, DefaultParametersPath, <span class="string">&quot;$NUPACKHOME/parameters&quot;</span>&#125;;</span><br><span class="line">        <span class="built_in">NUPACK_ERROR</span>(<span class="string">&quot;failed to open parameter file &quot;</span>, path, directories);</span><br><span class="line">    &#125;</span><br><span class="line">    json j;</span><br><span class="line">    file &gt;&gt; j;</span><br><span class="line">    <span class="keyword">return</span> j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>原代码直接按冒号 <code>:</code> 对默认参数文件路径进行分割, 类似环境变量那种, 但是在 Windows 上会错误地把盘符后面的冒号切了, 所以找不到文件. 不过这地方可以曲线一下, 就是手动设置 <code>NUPACKHOME</code> 环境变量, 这部分的寻找逻辑倒是没有问题.</p>
<p>此外还有两个地方路径格式也有问题, 也一并修改一下.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">OSError: [Errno 22] Invalid argument: &#x27;blah\\0\\checkpoint\\2024-05-13T10:46:49.json&#x27;</span><br><span class="line">OSError: [Errno 22] Invalid argument: &#x27;design-checkpoint\\2024-05-13T10:46:50.json&#x27;</span><br></pre></td></tr></table></figure>

<p>在 Windows 下面文件名不能包含 <code>:</code>, 因此去源码里简单修改一下即可, 位于 <code>python/design/components.py:96</code> 附近, 干脆换一个时间格式得了.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">WriteToFileCheckpoint</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path, timespec=<span class="string">&#x27;seconds&#x27;</span></span>):</span><br><span class="line">        self.path = pathlib.Path(path)</span><br><span class="line">        self.timespec = timespec</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, result</span>):</span><br><span class="line">        <span class="comment"># time = datetime.datetime.now().isoformat(timespec=self.timespec)</span></span><br><span class="line">        time = datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line">        self.path.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        path = self.path/<span class="string">&#x27;&#123;&#125;.json&#x27;</span>.<span class="built_in">format</span>(time)</span><br><span class="line">        path.write_text(result.to_json().dump(indent=<span class="number">4</span>))</span><br></pre></td></tr></table></figure>

<p>不过改了之后还需要把配套使用了 <code>fromisoformat</code> 的地方也一并修改, 位于 <code>python/design/trials.py:96</code> 附近.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_checkpoints</span>(<span class="params">self, where=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> where <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        where = self.checkpoint/<span class="string">&#x27;checkpoint&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> where.exists():</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sorted</span>(</span><br><span class="line">        (i <span class="keyword">for</span> i <span class="keyword">in</span> where.iterdir() <span class="keyword">if</span> i.suffix == <span class="string">&#x27;.json&#x27;</span>),</span><br><span class="line">        reverse=<span class="literal">True</span>, </span><br><span class="line">        <span class="comment"># key=lambda p: datetime.datetime.fromisoformat(p.stem) # 此处应该是可以直接按字符串大小进行比较的, 和按时间比较应该结果相同</span></span><br><span class="line">        key=<span class="keyword">lambda</span> p: p.stem</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<h2 id="静态链接"><a href="#静态链接" class="headerlink" title="静态链接"></a>静态链接</h2><p>编译成功之后整个 <code>cpp.pyd</code> 加上所有的 <code>dll</code> 文件合起来有约莫 67 MB 大小, 打包之后的 <code>whl</code> 文件也还有 18 MB 左右, 感觉有点太大, 所以之后又尝试了一下按静态的方式去链接第三方库.</p>
<p>所做的改动也不多, 把前面用到的所有 <code>x64-mingw-dynamic</code> 都换成 <code>x64-mingw-static</code>, 这样在安装和链接第三方库的时候就会默认都用静态库的方式, 个别不支持静态库的会自动切换成动态库模式, 甚至 <code>cmake/Libraries.cmake</code> 里的库名也都可以不用改了, 因为安装的静态库后缀就只有一个单独的 <code>.a</code>. 不过 <code>lapack</code> 这个库还是得手动改后缀, 因为它不支持静态库, 仍然是安装的动态库.</p>
<p>最后依赖的第三方库 DLL 文件也减少到 6 个, 整个 <code>cpp.pyd</code> 加上所有 <code>dll</code> 文件合起来只有 45 MB, 打包后的 <code>whl</code> 文件降低到 13 MB 左右.</p>
<p>然后会产生一个新的问题, 原项目关于 Python 模块符号的导出写的有点小问题, 导致打包后的库在导入的时候会报错找不到符号.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: dynamic module does not define module export function (PyInit_cpp)</span><br></pre></td></tr></table></figure>

<p>这个问题也比较好解决, 在文件 <code>external/rebind/source/Module.cc:203</code> (最后被合并到了 <code>external/rebind/source/Cast_Python_Module.cc</code> 里了) 处附近, 我们可以增加 Python 头文件提供的导出符号宏定义 <code>Py_EXPORTED_SYMBOL</code>.</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">Py_EXPORTED_SYMBOL PyObject* <span class="title">REBIND_CAT</span><span class="params">(PyInit_, REBIND_MODULE)</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">Py_Initialize</span>();</span><br><span class="line">    <span class="keyword">return</span> rebind::<span class="built_in">raw_object</span>([&amp;]() -&gt; rebind::Object &#123;</span><br><span class="line">        rebind::Object mod &#123;<span class="built_in">PyModule_Create</span>(&amp;rebind_definition), <span class="literal">true</span>&#125;;</span><br><span class="line">        <span class="keyword">if</span> (!mod) <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">        rebind::<span class="built_in">init</span>(rebind::<span class="built_in">document</span>());</span><br><span class="line">        rebind::Object dict = <span class="built_in">initialize</span>(rebind::<span class="built_in">document</span>());</span><br><span class="line">        <span class="keyword">if</span> (!dict) <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">        rebind::<span class="built_in">incref</span>(+dict);</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">PyModule_AddObject</span>(+mod, <span class="string">&quot;document&quot;</span>, +dict) &lt; <span class="number">0</span>) <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">        <span class="keyword">return</span> mod;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里不需要用 <code>PyMODINIT_FUNC</code>, 因为会重复定义 <code>extern &quot;C&quot;</code>.</p>
<p>不过懒得再全部重新按静态方式编译链接一次, 所以 Github 上都是放的动态链接的版本<del>上传完了无聊试试才发现静态链接一路畅通无阻且体积小性价比又高</del>.</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>本次编译过程所有修改后的差异文件均放在自己的 Github 上了, 包括在自己电脑上打包好的 <code>whl</code> 文件 (动态链接版本) 也一并放上去了, 仓库地址是 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL251cGFjay13aW4=">nupack-win<i class="fa fa-external-link-alt"></i></span>, 直接去 Releases 页面下载即可.</p>
<p>从五一放假开始折腾, 前前后后大约折腾了一周多才编译出来, 可以说是把能踩的坑都踩了个遍, 让我深刻的认识到不同操作系统不同编译环境的天壤之别, 期间也试过用 msvc 和 gcc 去编译, 但是一坨的警告和错误让我彻底转向 clang. <del>不过那些警告和错误看着挺有道理的, 怎么 clang 就不管了呢?</del></p>
<p>虽然之后自己的项目要用这个的时候大概率是在 Linux 环境运行, 用不到 Windows 的库了, 但是这么折腾一下也挺有收获, 至少浅浅的使用了一下三大主流 C 编译器, 以及熟悉了一下 CMake 和 vcpkg 的使用方法, 希望这次踩的坑将来都不会踩了吧~</p>
]]></content>
      <categories>
        <category>码记</category>
      </categories>
      <tags>
        <tag>NUPACK</tag>
        <tag>MSYS2</tag>
        <tag>MinGW</tag>
        <tag>Clang</tag>
      </tags>
  </entry>
  <entry>
    <title>网页预览碧蓝航线动态立绘</title>
    <url>//posts/2024/12/22/spinejs-azurlane/</url>
    <content><![CDATA[<p>恰逢最近<span class="exturl" data-url="aHR0cHM6Ly93aWtpLmJpbGlnYW1lLmNvbS9ibGh4LzIwMjQlRTUlQjklQjQxMiVFNiU5QyU4ODE5JUU2JTk3JUE1MTA6MDAlRTYlQjglQUYlRTUlOEMlQkElRTYlOTQlQjklRTUlQkIlQkE=">碧蓝航线新版本更新<i class="fa fa-external-link-alt"></i></span>, 又双叒叕增加了一批新船立绘和角色皮肤, 本人作为前指挥官<del>兼LSP</del>, 最近也没啥事, 于是又下回来用以前的资源爽抽了一波.</p>
<p>虽然氪金是不可能再氪了, 但是包还是能拆的, 刚好最近闲着, 再加上之前有使用 Spine 运行时的经验, 决定写个在线预览动绘的网页挂在博客上.</p>
<p>成品见<a href="/azurlane/">碧蓝航线动态立绘在线预览 (持续更新)</a>, 页面上有使用说明, 可以在线预览动态皮肤 (不是 Live2D), 皮肤资源也会不定期更新.</p>
<span id="more"></span>

<h2 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h2><h3 id="Spine-运行时"><a href="#Spine-运行时" class="headerlink" title="Spine 运行时"></a>Spine 运行时</h3><p>主要还是用官方的运行时库 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0Vzb3RlcmljU29mdHdhcmUvc3BpbmUtcnVudGltZXMvdHJlZS8zLjgvc3BpbmUtdHM=">spine-ts<i class="fa fa-external-link-alt"></i></span>, 剩下的就是写一个大概的前端页面, 提供交互功能.</p>
<p>官方例子挺详细的, 而且源码也都有, 不过这里提一嘴建议直接用 <code>webgl</code> 版本, 最开始写的时候图简单用的 <code>canvas</code> 版本, 但是 <code>canvas</code> 版本既不支持 premultiplyAlpha, 也不支持 clipping, 而且性能也堪忧.</p>
<p>官方库主要是封装了利用 <code>webgl</code> 渲染的过程, 所以我们只需要处理资源加载以及画面显示位置等等.</p>
<h3 id="资源接口"><a href="#资源接口" class="headerlink" title="资源接口"></a>资源接口</h3><p>拆包拆出来的动态立绘资源将近 1 GB, 不过还是可以老办法, 开个新仓库并且部署 pages 功能, 这样子就能在网站域名子路径下访问资源了, 也不会污染其他仓库.</p>
<p>仓库见 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL2F6dXJsYW5lX3NwaW5lcGFpbnRpbmc=">azurlane_spinepainting<i class="fa fa-external-link-alt"></i></span>, 里面的资源应该是可以通过以 <code>/azurlane_spinepainting/</code> 为前缀的链接访问到的, 就是速度有点慢, 加上资源本身也大, 加载一个皮肤很可能要个一两分钟, 同时由于不可抗力还可能访问失败, 强烈建议科学上网访问.</p>
<h3 id="前端页面"><a href="#前端页面" class="headerlink" title="前端页面"></a>前端页面</h3><p>说实话几乎没怎么写过前端, 因此 gpt 简直救我狗命, 不然不知道要写到猴年马月去了.</p>
<p>一番思索决定在现有的 Markdown 文件里写 html, 不单独写页面, 这样能有效利用博客现成的主题.</p>
<p>页面大概分上下两部分, 第一部分是 <code>船名_皮肤名</code> 这样的链接列表, 第二部分是一个 <code>canvas</code> 元素的预览画面, 用户可以通过点击皮肤链接来加载并切换下面的预览画面.</p>
<p>皮肤列表用 js 动态生成, 不过也还是需要自己在代码里固定一个映射表, 提供名称以及资源位置啥的.</p>
<p>预览界面几乎是原封不动照着 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0Vzb3RlcmljU29mdHdhcmUvc3BpbmUtcnVudGltZXMvYmxvYi8zLjgvc3BpbmUtdHMvd2ViZ2wvZXhhbXBsZS9pbmRleC5odG1s">spine-webgl<i class="fa fa-external-link-alt"></i></span> 的样例实现的, 但是重新封装了部分功能, 例如支持多个骨骼按序渲染, 并且调整了画面参数.</p>
<p>预览画面也实现了一些交互功能, 例如 PC 上可以用鼠标拖动缩放, 移动设备也可以用手势动作进行拖动缩放, 也支持选择查看模型下不同的动画.<del>毕竟部分动绘皮肤也有特触.</del></p>
<h2 id="页面效果"><a href="#页面效果" class="headerlink" title="页面效果"></a>页面效果</h2><p>最后的效果大概长这样:</p>
<p><img data-src="/static/image/spinejs-azurlane/page-preview.jpg" alt="page-preview.jpg"></p>
<p><img data-src="/static/image/spinejs-azurlane/canvas-preview1.gif" alt="page-preview1.gif"></p>
<p><img data-src="/static/image/spinejs-azurlane/canvas-preview2.gif" alt="page-preview2.gif"></p>
<p><img data-src="/static/image/spinejs-azurlane/canvas-preview3.gif" alt="page-preview3.gif"></p>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>也算是个小的前端项目? 源码都在博客仓库的 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL3d3LXJtLmdpdGh1Yi5pby90cmVlL21haW4vc291cmNlL2F6dXJsYW5l">source/azurlane<i class="fa fa-external-link-alt"></i></span> 路径下 (未来可能会挪位置, 但是反正都在这个仓库).</p>
<p>基本上都是和 gpt 交互然后改出来的代码, 不得不说 gpt 真是写前端利器.</p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p>立绘资源在仓库 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL2F6dXJsYW5lX3NwaW5lcGFpbnRpbmc=">azurlane_spinepainting<i class="fa fa-external-link-alt"></i></span>.</p>
<p>不过网页端功能和性能都有限, 这里趁机推销一下自己的小项目 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL0Rlc2tTcGluZQ==">DeskSpine<i class="fa fa-external-link-alt"></i></span>, 目前还没彻底完工<del>咕咕咕</del>, 但是基本功能已经差不多了<del>能用</del>, 是我基于过去项目 <a href="/posts/2023/08/30/desktopsprite/">DesktopSprite</a> 用 C# 重写的, 使用方法上也差不多, 但是比之前性能好上很多<del>bug也少很多</del>, 也增加了一些更好用的功能, 欢迎有兴趣的指挥官前来体验.    </p>
]]></content>
      <categories>
        <category>码记</category>
      </categories>
      <tags>
        <tag>碧蓝航线</tag>
        <tag>spine</tag>
        <tag>spine-js</tag>
        <tag>Azur Lane</tag>
        <tag>动态立绘</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 transformers.Pipeline 迭代生成数据</title>
    <url>//posts/2024/05/07/py-transformers-genexpr/</url>
    <content><![CDATA[<p>最近需要用 <a href="https://huggingface.co/docs/transformers/index"><code>transformers</code></a> 这个库载入大模型进行特征提取, 但是受限于硬件条件, 不能将所有输入推理后的结果放在内存里, 只能退而求其次分批推理然后写入本地. 于是顺势探索了一下 <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kb2NzL3RyYW5zZm9ybWVycy9tYWluX2NsYXNzZXMvcGlwZWxpbmVz">Pipelines<i class="fa fa-external-link-alt"></i></span> 的用法.</p>
<span id="more"></span>

<h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>基本用法参考官方文档 <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kb2NzL3RyYW5zZm9ybWVycy9waXBlbGluZV90dXRvcmlhbA==">Pipelines for inference<i class="fa fa-external-link-alt"></i></span>.</p>
<p>比如通过下面的方式加载一个 <a href="https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.FeatureExtractionPipeline"><code>FeatureExtractionPipeline</code></a>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fe_pipline = pipeline(</span><br><span class="line">    <span class="string">&quot;feature-extraction&quot;</span>,</span><br><span class="line">    model=AutoModelForTextEncoding.from_pretrained(self.encoder_dir),  <span class="comment"># BERT 模型</span></span><br><span class="line">    tokenizer=AutoTokenizer.from_pretrained(self.encoder_dir),</span><br><span class="line">    device=self.device</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>然后这样子进行推理.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs = [ <span class="string">&quot;A B C D E&quot;</span>, <span class="string">&quot;F G H J K&quot;</span> ]  <span class="comment"># 两条输入</span></span><br><span class="line">outputs = fe_pipline(inputs, batch_size=self.batch_size, return_tensors=<span class="literal">False</span>)  <span class="comment"># (2, L, E)</span></span><br></pre></td></tr></table></figure>

<p>这种方式可以一次性得到 <code>inputs</code> 的所有推理结果.</p>
<h2 id="分批输入"><a href="#分批输入" class="headerlink" title="分批输入"></a>分批输入</h2><p>官方提供了一个分批输入的示例, <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kb2NzL3RyYW5zZm9ybWVycy9tYWluX2NsYXNzZXMvcGlwZWxpbmVzI3BpcGVsaW5lLWJhdGNoaW5n">Pipeline batching<i class="fa fa-external-link-alt"></i></span>.</p>
<blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> transformers.pipelines.pt_utils <span class="keyword">import</span> KeyDataset</span><br><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">dataset = datasets.load_dataset(<span class="string">&quot;imdb&quot;</span>, name=<span class="string">&quot;plain_text&quot;</span>, split=<span class="string">&quot;unsupervised&quot;</span>)</span><br><span class="line">pipe = pipeline(<span class="string">&quot;text-classification&quot;</span>, device=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> out <span class="keyword">in</span> pipe(KeyDataset(dataset, <span class="string">&quot;text&quot;</span>), batch_size=<span class="number">8</span>, truncation=<span class="string">&quot;only_first&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(out)</span><br><span class="line">    <span class="comment"># [&#123;&#x27;label&#x27;: &#x27;POSITIVE&#x27;, &#x27;score&#x27;: 0.9998743534088135&#125;]</span></span><br><span class="line">    <span class="comment"># Exactly the same output as before, but the content are passed</span></span><br><span class="line">    <span class="comment"># as batches to the model</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>这个示例里指定了每次处理的批大小为 <code>8</code>, 同时返回了可迭代结果, 可以按照每次一条的方式获得输出结果.</p>
<p>不过在实际测试的时候发现, 当我给定 <code>list</code> 类型的 <code>inputs</code> 时, 推理的时候确实是分批推理的, 但是最后返回结果的时候, 其实是把所有结果合在一起返回了一个大的 <code>list</code>.</p>
<p>这和我的需求还是有一丢丢差距的, 我希望的是每次推理一个批次之后, 只返回一个批次的结果, 然后继续迭代下一个批次, 这样占用的内存大小最多不超过一个批次.</p>
<h2 id="迭代输出"><a href="#迭代输出" class="headerlink" title="迭代输出"></a>迭代输出</h2><p>继续找一下文档, 还能发现一些示例 <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kb2NzL3RyYW5zZm9ybWVycy9tYWluX2NsYXNzZXMvcGlwZWxpbmVzI3RyYW5zZm9ybWVycy5waXBlbGluZQ==">The pipeline abstraction<i class="fa fa-external-link-alt"></i></span>.</p>
<p>其中提到了:</p>
<blockquote>
<p>For ease of use, a generator is also possible:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">pipe = pipeline(<span class="string">&quot;text-classification&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data</span>():</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># This could come from a dataset, a database, a queue or HTTP request</span></span><br><span class="line">        <span class="comment"># in a server</span></span><br><span class="line">        <span class="comment"># Caveat: because this is iterative, you cannot use `num_workers &gt; 1` variable</span></span><br><span class="line">        <span class="comment"># to use multiple threads to preprocess data. You can still have 1 thread that</span></span><br><span class="line">        <span class="comment"># does the preprocessing while the main runs the big inference</span></span><br><span class="line">        <span class="keyword">yield</span> <span class="string">&quot;This is a test&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> out <span class="keyword">in</span> pipe(data()):</span><br><span class="line">    <span class="built_in">print</span>(out)</span><br><span class="line">    <span class="comment"># &#123;&quot;text&quot;: &quot;NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD NIGHT HUSBAND&quot;&#125;</span></span><br><span class="line">    <span class="comment"># &#123;&quot;text&quot;: ....&#125;</span></span><br><span class="line">    <span class="comment"># ....</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>也就是说 <code>Pipeline</code> 还支持未知长度的生成器输入, 在这种情况下, 对 <code>pipeline</code> 的调用没有返回全部结果, 而是一个迭代器, 每次能获取其中一条结果.</p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>不过还是不太放心, 官方文档只有一些示例, 对接口参数和返回值的描述并不是很清晰, 所以干脆 F12 看看内部源码.</p>
<p><code>transformers</code> 版本为 <code>4.31.0</code>.</p>
<p>关键函数为 <code>transformers.pipelines.base.Pipeline.__call__</code>. 这里摘出来相关的代码片段</p>
<blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@add_end_docstrings(<span class="params">PIPELINE_INIT_ARGS</span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pipeline</span>(<span class="title class_ inherited__">_ScikitCompat</span>):</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, inputs, *args, num_workers=<span class="literal">None</span>, batch_size=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        is_dataset = Dataset <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(inputs, Dataset)</span><br><span class="line">        is_generator = <span class="built_in">isinstance</span>(inputs, types.GeneratorType)</span><br><span class="line">        is_list = <span class="built_in">isinstance</span>(inputs, <span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">        is_iterable = is_dataset <span class="keyword">or</span> is_generator <span class="keyword">or</span> is_list</span><br><span class="line"></span><br><span class="line">        <span class="comment"># TODO make the get_iterator work also for `tf` (and `flax`).</span></span><br><span class="line">        can_use_iterator = self.framework == <span class="string">&quot;pt&quot;</span> <span class="keyword">and</span> (is_dataset <span class="keyword">or</span> is_generator <span class="keyword">or</span> is_list)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> is_list:</span><br><span class="line">            <span class="keyword">if</span> can_use_iterator:</span><br><span class="line">                final_iterator = self.get_iterator(</span><br><span class="line">                    inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params</span><br><span class="line">                )</span><br><span class="line">                outputs = <span class="built_in">list</span>(final_iterator)</span><br><span class="line">                <span class="keyword">return</span> outputs</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> self.run_multi(inputs, preprocess_params, forward_params, postprocess_params)</span><br><span class="line">        <span class="keyword">elif</span> can_use_iterator:</span><br><span class="line">            <span class="keyword">return</span> self.get_iterator(</span><br><span class="line">                inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">elif</span> is_iterable:</span><br><span class="line">            <span class="keyword">return</span> self.iterate(inputs, preprocess_params, forward_params, postprocess_params)</span><br><span class="line">        <span class="keyword">elif</span> self.framework == <span class="string">&quot;pt&quot;</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(self, ChunkPipeline):</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">next</span>(</span><br><span class="line">                <span class="built_in">iter</span>(</span><br><span class="line">                    self.get_iterator(</span><br><span class="line">                        [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.run_single(inputs, preprocess_params, forward_params, postprocess_params)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>可以看到对输入 <code>inputs</code> 的进行了类型判断, 然后返回值的类型则根据 <code>inputs</code> 的类型由最后的 <code>if ... else ...</code> 决定.</p>
<p>在使用框架是 <code>pytorch</code> 的情况下, 这里大致分成两大类情况:</p>
<ul>
<li>输入是 <code>list</code> 类型, 那么返回值一定被处理成和输入数据长度一样的 <code>list</code> 进行返回.</li>
<li>输入是可迭代的 (<code>is_iterable</code>), 那么返回一个迭代器.</li>
</ul>
<p><code>get_iterator</code> 会返回一个 <code>PipelineIterator</code> 对象, 在指定了 <code>batch_size</code> 的情况下, 内部会保存一个结果缓冲区, 当缓冲区非空则迭代输出下一个结果, 直到缓冲区空, 则进行下一批的推理, 并更新缓冲区.</p>
<p>这个设计倒是完美符合了我的需求, 但是实际使用的时候还是踩了坑.</p>
<p>原本以为把输入换成 <code>iter(inputs)</code> 就可以按迭代方式输出了, 但是却报错了, 仔细看看源码才发现, 这里其中一个判断是 <code>isinstance(inputs, types.GeneratorType)</code>, 也就是判断输入是否是生成器. 而在 Python 里, <code>Generator</code> 是 <code>Iterator</code> 的子类, 因此二者都是可迭代的 (<code>Iterable</code>), 但是输入是 <code>Iterator</code> 的时候, 此处的逻辑却无法将它判断成可迭代的对象.</p>
<p>又翻了一下源码, 看上去只需要判断是迭代器就行了, 并没有用到生成器的特性, 因此严重怀疑这里是不是写代码的人没注意这个问题搞错了......</p>
<p>不过问题不大, Python 提供了很优雅的生成器表达式语法糖, 不用写繁琐的生成器函数, 只需要 <code>(v for v in inputs)</code> 就能把可迭代对象包装成生成器, 之后就能愉快的使用它的缓冲区输出功能了~</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>当然也有别的曲线救国方案, 从它的逻辑上看, 只要不是 <code>list</code> 并且 <code>can_use_iterator</code> 就可以得到输出迭代器, 那么还可以把输出包装成 <code>torch.utils.data.Dataset</code>, 不过这个显然没有使用生成器表达式方便.</p>
]]></content>
      <categories>
        <category>码记</category>
      </categories>
      <tags>
        <tag>transformers</tag>
        <tag>Pipeline</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯测试开发实习面试经验分享</title>
    <url>//posts/2024/03/19/tencent-intership-interview/</url>
    <content><![CDATA[<p>腾讯 IEG 25 届测试开发实习生面试经验分享.</p>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>寒假前发了一个腾讯的专项实习通知, 时间很早, 2月底就开始投了.</p>
<p>然而寒假还是摸了一个月的鱼, 不过抱着试一试的心态, 月底还是投了一下测试开发, 毕竟力扣才刚开始刷, 八股一行没看, 心里着实慌得很, 而且还是第一次面试. 虽然在此之前偶尔刷到过一些面经, 但是真的轮到自己的时候, 还是很紧张的.</p>
<p>投了简历之后, 要先做一个测评, 必须要做了才能进下一个流程.</p>
<p>测评分三部分:</p>
<ol>
<li>第一部分是一大堆选择题加一道简答题, 就是一些职场场景题, 按自己想法慢慢做就行了.</li>
<li>第二部分和第一部分差不多, 但是只有选择题.</li>
<li>第三部分是智力题, 和公务员的行测差不多, 说实话我几乎都是蒙的, 但是问题不大.</li>
</ol>
<p>三部分可以分开做, 不过确实要一点耐心和时间, 总共做了 30 + 30 + 30 = 90 分钟的时间.</p>
<p>做完之后就可以等着面试邀请函了, 邮箱和短信都会有通知.</p>
<p>2 月底做的测评, 3 月初收到的面试邀请函, 中间隔了 5 天左右, 所以还是要稍微等一等.</p>
<p>下面进正文. 信息发布群里的相关负责人说这一次投递相当于是实习的提前批, 因此可能面试流程看上去比秋招紧凑很多, 总共 3 轮:</p>
<ol>
<li>初试 (程序面). 其实就是技术面.</li>
<li>复试 (初试). 也是技术面.</li>
<li>HR 面试 (复试). 和 HR 聊天环节.</li>
</ol>
<h2 id="初试"><a href="#初试" class="headerlink" title="初试"></a>初试</h2><p>收到邀请函后一天进行一面.</p>
<h3 id="算法题"><a href="#算法题" class="headerlink" title="算法题"></a>算法题</h3><p>开始面试之后, 面试官简单问了一下平常用什么语言居多, 电脑上是不是装了对应的 IDE, 然后发了两道题说先做一下, 给了 1 个小时的时间.</p>
<p>题目可以在自己电脑写并且调试, 这一点相当友好, 有熟悉的环境和工具确实写起来压力小很多.</p>
<p>但是腾讯会议远程面试, 这一面我全程都是共享桌面和开着视频的, 因此大伙也不要有什么侥幸心理, 冷静下来认真写代码就行了.</p>
<p>题目不难, 就是选的力扣两道中等题, 一道是很经典的动态规划, 虽然之前没写过但是很熟悉解法, 很快就解决了.</p>
<p>另外一道是一个双指针题, 好消息是, 它在我仅有的刷了的几十道题目里. 不过坏消息是, 当时刷的时候是临时想出来的奇怪方法, 面试的时候已经完全忘记当时咋写的了.<del>好在最后凭借模糊的记忆又临时想出来一个方法, 以至于面试官专门要我讲了一下这题思路.</del></p>
<p>总共花了大概半个小时吧, 把两道题写完之后, 面试官会自己阅读代码, 并不需要提交然后测试样例或者讲解思路啥的, 主要是看你的代码书写习惯, 以及你算法思路的正确性, 当然你自己肯定得把题面里给的几个简单例子验证一下.<del>测开不测试这合理吗</del>.</p>
<p>建议大家养成良好的代码风格, 平常多注重代码的可阅读性, 能让人比较容易的看清你的代码思路. 共享屏幕让面试官看着写代码还是有点压力的<del>相当于有人看着你写数学题</del>, 代码写的清楚点就算最后没做出来也能和面试官交流自己的思路, 不至于啥好印象都没有.</p>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>写完代码之后开始问八股了, 总结为: 真叫人摸不着头脑.jpg</p>
<p>其实问的问题都不难, 真不难, 但是无奈我也是真没准备, 一丁点都没准备的那种.</p>
<p>上来就是几个操作系统相关的问题, 我最近一次学操作系统还是大二的时候, 咱就是说, 真不记得啥了.</p>
<p>问了进程怎么管理的, 进程和线程区别, 虚拟内存怎么管理的, 堆和栈的区别, 线程同步的方法.</p>
<p>我只能凭着记忆勉强答一下, 也就一些基本概念吧.<del>甚至虚拟内存连概念都不记得了.</del></p>
<p>然后还问了一些其他的, 比如快速排序怎么实现的, 负数是如何表示的, 先进先出和后进先出的区别, 甚至还问了一下知不知道关系数据库的范式是什么.<del>八百年前学的东西了, 我仅存的记忆告诉我似乎是用在表设计的时候减少冗余提高效率的.</del></p>
<p>不过这一面是技术面, 面试官也是懂的, 也不会对着标准答案死抠定义, 你清楚这个知识点的话, 面试官听了自然明白, 尽量把自己会的内容清楚的表述出来就行, 不会的也就说自己对这方面应用的少, 不是很了解.</p>
<h3 id="项目经历"><a href="#项目经历" class="headerlink" title="项目经历"></a>项目经历</h3><p>由于我没有实习经历, 所以接下来就直接问简历上的项目.<del>害, 之前看群里说一面可能就是撕几道题, 结果自己完全没看一下项目内容, 都忘得差不多了.</del></p>
<p>我写了 4 个上去, 2 个个人项目, 2 个团队合作项目.</p>
<p>面试官首先问觉得这几个项目里难度最高的是哪个, 能否介绍一下项目内容.</p>
<p>我说了一个个人项目, <a href="/posts/2023/08/30/desktopsprite/">基于 Spine 的碧蓝航线桌宠</a>, 这个是当时自己感兴趣做的, 虽然是基于学习的心态做的自娱自乐程序, 但是确实对我来说挺难的, 因为专业从未接触过计算机图形学相关的内容, 而且也自学了一下原生的 win32 开发, 期间还遇到一些数学问题, 都折腾了挺久的.</p>
<p>介绍了一下为什么做这个项目, 项目实现了些啥, 觉得最难的地方在哪, 怎么解决的诸如此类的.</p>
<p>主要还是要熟悉自己的项目, 向面试官充分展示自己的能力水平, 不要让面试官觉得就是照着网上的教程随便做做了事, 要能体现自己在做这个项目途中解决问题的能力, 以及对自己的提升收获.</p>
<p>不过运气比较好的是, 由于这一面远程面试我一开始是共享屏幕的, 加之这个项目是个桌宠, 很适合展示, 自己电脑上也一直在用, 源码也都还在, 所以就直接给面试官展示项目效果了. 顺带连源码都一起被看了一下, 问了一些具体逻辑的实现方法和类的设计.</p>
<p>这个项目问完之后还问了其他的项目, 这个看具体情况吧, 认真答就好了.<del>也看自己的吹牛能力.</del></p>
<h3 id="初试尾声"><a href="#初试尾声" class="headerlink" title="初试尾声"></a>初试尾声</h3><p>最后有一些经典的反问环节, 不过我当时太紧张了, 也没问啥, 反倒是面试官引导我是不是要了解点什么.</p>
<p>其实事后想想以后可以提前准备一下的, 毕竟你投了简历, 肯定有一些想要了解的基本情况对吧.</p>
<h2 id="复试"><a href="#复试" class="headerlink" title="复试"></a>复试</h2><p>结果出的很快, 刚面完晚上就收到复试邀请函了, 于是直接约的后一天继续二面.</p>
<h3 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h3><p>简单介绍一下自己, 学校, 专业, 研究方向, 个人能力, 实习经历, 项目经历 (其实就是把自己简历上的内容过一遍, 只是我没经验, 结果被动的等着面试官问经历了, 没把话题聊开).</p>
<p>经历简单描述一下就好, 可以等待面试官后续提问, 也可以自己主动介绍详细一点, 突出自己的技术栈.</p>
<h3 id="自由交流"><a href="#自由交流" class="headerlink" title="自由交流"></a>自由交流</h3><p>如果说一面注重你的表面能力, 比如具体的代码能力, 项目经历, 量化的指标啥的, 那么这一面侧重于你的综合能力.</p>
<p>从自我介绍开始, 最好的方式是你有所侧重的介绍自己, 然后让面试官能够自然而然的切入到一个你熟悉的话题里, 比如你介绍到某个项目经历时, 可以先发制人说说自己印象很深的点, 采用了什么技术, 掌握了什么技能, 之后面试官就会以此为话题继续深入了解你的能力.<del>别像我一样傻不拉几的.</del></p>
<p>不同于一面, 这一面问题都比较发散并深入, 其实也更加注重于将来的工作内容, 例如我投的是测试开发, 除了问我项目的技术问题外, 还会着重问我项目的性能优化, 如何减少资源占用, 如何让整个项目结果更好, 而不仅仅是实现功能.</p>
<p>同时问题也更偏向实际工程应用, 并不只是单纯实现一个算法片段, 而是要对项目的整体结构有清晰的认知, 知道项目的瓶颈在哪, 自己又是如何考虑解决的.</p>
<p>拿我前面那个桌宠项目来说, 面试官除了问基本的项目逻辑外, 着重问了是否关注过程序的性能优化, 如何优化渲染过程中 CPU, 内存, GPU 的占用问题, 如何提高渲染的性能. 不过我没有系统性学习过, 对这些内容只能尽量答一些, 并且有些方面我也确实从没考虑过 (例如内存占用, 桌宠占用太小完全没考虑过).</p>
<p>感觉还是挺注重程序性能的, 可能是游戏测开的原因?</p>
<p>这部分内容太自由了, 都是思想上的交流, 可参考性很低, 比较看面试官, 认真回答自己的思考结果就好了.</p>
<h3 id="场景题"><a href="#场景题" class="headerlink" title="场景题"></a>场景题</h3><p>聊完简历上的内容之后, 还是来了道场景题.</p>
<p>具体的场景就不说了, 抽象一下就是, 有一群人, 他们之间存在好友关系, 假设这群人一定可以被划分成两个集合, 并且每个集合内的人互相不存在好友关系, 要如何实现这个划分过程.</p>
<p>害, 说实话我一开始毫无头绪, 然后想了半天给了一个时间和空间复杂度都很高的方法, 显然是不太行的. 之后就是和面试官继续交流, 怎么优化算法. 这期间我乱扯了很多, 但是估计都没找到正道. 最后时间快到了, 我说我感觉暂时想不出来更好的方案了, 面试官也就结束这部分了.</p>
<p>感觉这部分拉了, 自己平时确实也没怎么关注一些这样的算法问题. 不过就算不知道也要积极的说出自己的想法, 和面试官交流, 让面试官看到你解决问题的过程.</p>
<p>(事后了解了一下这玩意叫二分图, 所有的顶点可以被划分为两个独立的集合, 使得每条边的两个顶点分别属于不同的集合. 其实挺简单的, 但是没办法, 面试的时候还完全没看图论相关内容.)</p>
<h3 id="复试尾声"><a href="#复试尾声" class="headerlink" title="复试尾声"></a>复试尾声</h3><p>最后也是有经典的反问过程, 不过这次总结了一面的经验, 提前想好了要问些啥, 倒是得到了一些自己想要了解的内容. 比如开发语言和用的技术, 项目管理制度啥的. 提前准备一下就能趁着这个机会向面试官了解一下自己意向工作的地方如何.</p>
<h2 id="HR-面试"><a href="#HR-面试" class="headerlink" title="HR 面试"></a>HR 面试</h2><p>大概隔了一周时间, 终于收到三面邀请, 差点以为要挂了<del>二面太拉了</del>.</p>
<p>这一面是非技术面, 上来自我介绍一下, 然后主要是人事和你聊聊天, 问问你的个人情况, 现在在做的内容, 看看你对工作的态度, 面对问题的解决思路, 确认一下你的个人信息和工作意向, 比较轻松的氛围, 注意一下言谈举止就好.</p>
<p>时间也不长, 不到半小时就结束了, 这一面基本就是走走流程, 不出意外面完等后续就好.</p>
<p><del>个人认为, 只要不和面试官打起来这一面都不至于挂.</del></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>三面之后大概一周就能收到人事发来的 Offer 了, 需要在系统或者邮件里确认接受即可, 具体的入职事项可以和跟自己对接的 HR 进行沟通了解.</p>
<p>总结一下整个面试的话, 确实是投的早加运气好吧, 感觉有这么一些比较令面试官满意的地方:</p>
<ul>
<li>一面两道手撕很顺畅<del>甚至面试官说我写挺快的?</del></li>
<li>然后简历里有一个面试官刚好比较感兴趣的项目. 感觉这个是最重要的, 有一个对口的项目真的很加分.</li>
</ul>
<p>当然由于准备不充分, 也存在很多问题, 包括但不限于:</p>
<ul>
<li>八股完全没看, 全凭记忆回答.</li>
<li>也没好好复习自己的项目内容, 问的时候很多东西自己也记不起来当时咋写的了.</li>
<li>场景题也答的一塌糊涂, 刚开始一点思路都无, 也是自己平常这方面接触太少.</li>
<li>没准备一个良好的自我介绍, 老是等着面试官被动提问.</li>
<li>等等等等...</li>
</ul>
<p>通过面试才能知道自己有很多需要提升的地方, 应该朝着哪些方面提升自己, 也只有不断面试才能消除自己对面试的紧张感, 让自己能够在面试中充分的展现自己最好的状态.</p>
<p>最后, 祝各位同学都能顺利通过面试, 收到自己心仪的 Offer~</p>
<p><img data-src="/static/image/tencent-intership-interview/sign_img.png" alt="tencent_offer"></p>
]]></content>
      <categories>
        <category>经验分享</category>
      </categories>
      <tags>
        <tag>腾讯</tag>
        <tag>面经</tag>
        <tag>实习</tag>
        <tag>测试开发</tag>
        <tag>IEG</tag>
      </tags>
  </entry>
  <entry>
    <title>&quot;网安本科速通&quot; 系列后记</title>
    <url>//posts/2022/08/19/wast-afterword/</url>
    <content><![CDATA[<p>终于写完了最后一篇! (撒花~), <a href="/categories/%E7%BD%91%E5%AE%89%E6%9C%AC%E7%A7%91%E9%80%9F%E9%80%9A/">点我查看全系列内容</a>.</p>
<p>虽然这个系列就此完结, 但是只是因为我觉得再写下去已经不算速通的内容了, 我只写了最基本的必需内容.</p>
<p>我相信如果真的好好看完了的话, 应付一下平常的作业应该绰绰有余了. 但是如果真的想要学有所获, 这个系列里的东西真的太浅了, 每一篇都只是入个门而已, 你得花上看这个系列的十倍以上的时间去学习, 去尝试.</p>
<p>这个系列也算是对本科四年一些知识点的总结吧, 都是蜻蜓点水般的带过, 希望日后自己再看到时, 还能够想起来都学了些啥.</p>
<p>就这样了, 网安本科速通, 完成!</p>
<p><img data-src="/static/image/wast-afterword/zzz.gif" alt="zzz.gif"></p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>后记</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 PyTorch 的手写数字分类</title>
    <url>//posts/2022/08/18/wast-dl/</url>
    <content><![CDATA[<p>本篇算是对 <code>pytorch</code> 这一 <code>python</code> 深度学习库神器的入门教程, 以手写数字分类这一经典问题做示例, 来概括一下如何使用 <code>pytorch</code> 来搭建一个自定义的网络结构, 并加以训练.</p>
<span id="more"></span>

<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>所需的第三方库.</p>
<p><code>scikit-learn</code>: 并没有用到里面的算法, 但是小调一下里面现成的指标评价函数, 减少不必要的重复劳动.</p>
<p><code>pytorch</code>: 本篇要使用的核心库, 安装方式需要在<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">官网<i class="fa fa-external-link-alt"></i></span>查询, 且按需安装 <code>cuda</code> 工具.</p>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">example/</span><br><span class="line">    digit_data/</span><br><span class="line">        train/</span><br><span class="line">            0/</span><br><span class="line">                1.jpg</span><br><span class="line">                2.jpg</span><br><span class="line">                ...</span><br><span class="line">            ...</span><br><span class="line">            9/</span><br><span class="line">                ...</span><br><span class="line">                XXX.jpg</span><br><span class="line">        test/</span><br><span class="line">            ...</span><br><span class="line">    main.py</span><br><span class="line">    main.ipynb</span><br></pre></td></tr></table></figure>

<p><img data-src="/static/image/wast-dl/vrAZse.png" alt="vrAZse.png"></p>
<h2 id="并不快速的快速上手"><a href="#并不快速的快速上手" class="headerlink" title="并不快速的快速上手"></a>并不快速的快速上手</h2><h3 id="导入所需要的所有库"><a href="#导入所需要的所有库" class="headerlink" title="导入所需要的所有库"></a>导入所需要的所有库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_files</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, f1_score, precision_score, recall_score</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision.io <span class="keyword">import</span> read_image</span><br><span class="line"><span class="keyword">from</span> torchvision.io.image <span class="keyword">import</span> ImageReadMode</span><br><span class="line"></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br></pre></td></tr></table></figure>

<p>除了导入必需的库之外, 还设置了一个全局变量 <code>DEVICE</code>, 后续代码会使用它, 将计算放在 <code>DEVICE</code> 指定的硬件上进行计算, 推荐尽量用 gpu, 速度快很多, 当然对于这个小小的示例程序, cpu 也是能算的.</p>
<h3 id="构建自己的数据集"><a href="#构建自己的数据集" class="headerlink" title="构建自己的数据集"></a>构建自己的数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path</span>):</span><br><span class="line">        data = load_files(path, load_content=<span class="literal">False</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line">        self.inputs = data[<span class="string">&quot;filenames&quot;</span>]</span><br><span class="line">        self.targets = data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.targets)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        input_ = read_image(self.inputs[item], ImageReadMode.GRAY).<span class="built_in">float</span>().to(DEVICE)</span><br><span class="line">        target = torch.tensor([self.targets[item]]).long().to(DEVICE)</span><br><span class="line">        <span class="keyword">return</span> (input_, target)</span><br></pre></td></tr></table></figure>

<p>在 <code>pytorch</code>, 通过继承类 <code>Dataset</code>, 并且重写 <code>__init__</code>, <code>__len__</code> 和 <code>__getitem__</code> 来构建自定义数据集.</p>
<p><code>__init__</code>: 通常在构造函数里定义如何获取原始数据集.</p>
<p><code>__len__</code>: 定义数据集的大小计算方式.</p>
<p><code>__getitem__</code>: 定义如何通过索引来获取一个样本.</p>
<p>这里我们使用之前用过的 <code>load_files</code> 来加载数据集的路径, 并使用 <code>pytorch</code> 提供的图像读取函数 <code>read_image</code> 读取样本.</p>
<h3 id="搭建一个简单的神经网络"><a href="#搭建一个简单的神经网络" class="headerlink" title="搭建一个简单的神经网络"></a>搭建一个简单的神经网络</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyNetwork</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, intput_size=<span class="number">28</span>, input_channels=<span class="number">1</span>, output_size=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.convpooling = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channels, <span class="number">16</span>, <span class="number">5</span>),           <span class="comment"># 28 - 4 = 24</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),                            <span class="comment"># 24 // 2 = 14</span></span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">64</span>, <span class="number">3</span>),                       <span class="comment"># 14 - 2 = 12</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),                            <span class="comment"># 12 // 2 = 6</span></span><br><span class="line">        )</span><br><span class="line">        _size = ((intput_size - <span class="number">4</span>) // <span class="number">2</span> - <span class="number">2</span>) // <span class="number">2</span></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Flatten(<span class="number">1</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*_size*_size, output_size)      <span class="comment"># 64*6*6 -&gt; 10</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = self.convpooling(inputs)</span><br><span class="line">        outputs = self.fc(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>

<p>通过继承 <code>Module</code> 类并重写其中的 <code>__init__</code> 和 <code>forward</code> 来自定义网络结构与前向传播方式.</p>
<p><code>__init__</code>: 在构造函数里给出自定义网络的所有层次结构. 使用 <code>Module</code> 的子类进行定义, 会自动将需要学习的参数注册到整个网络结构上.</p>
<p><code>forward</code>: 定义输入数据如何进行前向传播, 也就是如何使用在构造函数里定义的各个网络层.</p>
<p>这里对于手写数字分类问题, 我们写了一个简单的两层 CNN 网络, 并加上一个全连接层.</p>
<p>网络的输入是 <code>input_size*input_size</code> 大小, 通道数为 <code>input_channels</code> 的图片, 而输出则是 <code>output_size</code> 的一个分类向量, 每个位置代表不同类别的得分.</p>
<p>代码注释里给出了每一层样本大小的变化情况, 每一层之间需要相互对齐才能正确计算.</p>
<h3 id="定义评价指标函数"><a href="#定义评价指标函数" class="headerlink" title="定义评价指标函数"></a>定义评价指标函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">eval_metrics</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    acc = accuracy_score(y_true, y_pred)</span><br><span class="line">    p = precision_score(y_true, y_pred, average=<span class="string">&quot;macro&quot;</span>, zero_division=<span class="number">0</span>)</span><br><span class="line">    r = recall_score(y_true, y_pred, average=<span class="string">&quot;macro&quot;</span>, zero_division=<span class="number">0</span>)</span><br><span class="line">    f1 = f1_score(y_true, y_pred, average=<span class="string">&quot;macro&quot;</span>, zero_division=<span class="number">0</span>)</span><br><span class="line">    report = classification_report(y_true, y_pred, digits=<span class="number">4</span>, zero_division=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (acc, p, r, f1, report)</span><br></pre></td></tr></table></figure>

<p>这里调用了 <code>scikit-learn</code> 的一些常用指标计算函数, 包括准确率, 精度, 召回率, F1 得分, 以及一份汇总结果.</p>
<p>输入数据就是真实标签与预测标签.</p>
<h3 id="定义训练函数"><a href="#定义训练函数" class="headerlink" title="定义训练函数"></a>定义训练函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_data_loader, criterion, optimizer</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    loss_list = []</span><br><span class="line">    pred_list = []</span><br><span class="line">    true_list = []</span><br><span class="line">    <span class="keyword">for</span> inputs, targets <span class="keyword">in</span> train_data_loader:</span><br><span class="line">        targets = targets.flatten()</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        loss_list.append(loss.item())</span><br><span class="line">        pred_list.append(outputs.argmax(dim=-<span class="number">1</span>).cpu().numpy())</span><br><span class="line">        true_list.append(targets.cpu().numpy())</span><br><span class="line"></span><br><span class="line">    y_pred = np.concatenate(pred_list)</span><br><span class="line">    y_true = np.concatenate(true_list)</span><br><span class="line"></span><br><span class="line">    loss = np.mean(loss_list)</span><br><span class="line">    result = eval_metrics(y_true, y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (loss, *result)</span><br></pre></td></tr></table></figure>

<p>训练函数有四个参数.</p>
<p><code>model</code>: 模型, 也就是前面我们自己定义的神经网络实例.</p>
<p><code>train_data_loader</code>: 训练数据集加载器. 是一个 <code>DataLoader</code> 实例, 可以进行迭代从里面按批次大小获得训练数据.</p>
<p><code>criterion</code>: 损失函数, 用来计算每次输出与真实标签之间的损失值, 并进行反向传播计算梯度.</p>
<div class="note info"><p>需要注意的是, 对 <code>targets</code> 使用了一次 <code>flatten</code> 操作.<br>因为使用 <code>DataLoader</code> 对数据集进行加载时, 每次是按照 <code>batch_size</code> 来批量获取的, 因此会自动将单个样本进行拼接变成一个 batch. 所以 <code>targets</code> 是 <code>(batch_size, 1)</code> 的形状.<br>但是我们要使用的损失函数是 <code>CrossEntropy</code> 交叉熵损失函数, 它的输入要求真实标签是一个一维的向量 <code>(batch_size, )</code>, 因此使用 <code>flatten</code> 对 <code>targets</code> 进行展平操作.</p>
</div>

<p><code>optimizer</code>: 优化器, 在使用之前已经将 <code>model</code> 中需要训练的参数注册进去, 每次调用 <code>step</code> 方法可以对 <code>model</code> 注册的参数通过梯度进行更新.</p>
<p>训练的流程共有以下几步.</p>
<ol>
<li>将 <code>model</code> 转为 <code>train</code> 模式.</li>
<li>迭代数据集加载器, 按批次获取每一次要学习的样本.</li>
<li>将样本喂进 <code>model</code> 进行前向传播, 并计算损失.</li>
<li>清空优化器中上一次梯度值.</li>
<li>从损失处开始反向传播, 计算本次参数需进行学习的梯度.</li>
<li>调用优化器的 <code>step</code>, 根据梯度值完成对网络参数的更新.</li>
</ol>
<p>后面还有一些额外的统计操作, 用来记录本次训练过程时的平均损失和准确度等情况.</p>
<h3 id="定义评估函数"><a href="#定义评估函数" class="headerlink" title="定义评估函数"></a>定义评估函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, eval_data_loader, criterion</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    loss_list = []</span><br><span class="line">    pred_list = []</span><br><span class="line">    true_list = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> inputs, targets <span class="keyword">in</span> eval_data_loader:</span><br><span class="line">            targets = targets.flatten()</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">            loss_list.append(loss.item())</span><br><span class="line">            pred_list.append(torch.argmax(outputs, dim=-<span class="number">1</span>).cpu().numpy())</span><br><span class="line">            true_list.append(targets.cpu().numpy())</span><br><span class="line"></span><br><span class="line">    y_pred = np.concatenate(pred_list)</span><br><span class="line">    y_true = np.concatenate(true_list)</span><br><span class="line"></span><br><span class="line">    loss = np.mean(loss_list)</span><br><span class="line">    result = eval_metrics(y_true, y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (loss, *result)</span><br></pre></td></tr></table></figure>

<p>评估函数的过程与训练函数类似, 不同之处在于前者的参数里没有优化器, 因为评估函数用于模型在测试集上进行测试, 不需要反向传播与参数更新的操作.</p>
<p>评估函数的关键是 <code>torch.no_grad</code> 操作, 在此上下文内对 <code>model</code> 的操作不会计算任何梯度值, 只会进行单纯的前向求值计算操作.</p>
<h3 id="定义训练超参数"><a href="#定义训练超参数" class="headerlink" title="定义训练超参数"></a>定义训练超参数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">seed = <span class="number">1</span></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line">batch_size = <span class="number">500</span></span><br><span class="line">epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed(seed)</span><br></pre></td></tr></table></figure>

<p>这里我们设置了学习率和训练轮数, 由于只是示例因此轮数只有 5 来展示效果.</p>
<p>将随机数种子列入了超参数并且固定了 <code>torch</code> 随机数模块的种子, 目的是为了稳定复现结果.</p>
<h3 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_dataset = MyDataset(<span class="string">&quot;./digit_data/train/&quot;</span>)</span><br><span class="line">test_dataset = MyDataset(<span class="string">&quot;./digit_data/test/&quot;</span>)</span><br><span class="line">train_dataloader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataloader = DataLoader(test_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br></pre></td></tr></table></figure>

<p>导入了自己的手写数字数据集并使用 <code>DataLoader</code> 来进行加载, 可以设置是否打乱与批次大小等加载参数.</p>
<h3 id="实例化模型训练需要的对象"><a href="#实例化模型训练需要的对象" class="headerlink" title="实例化模型训练需要的对象"></a>实例化模型训练需要的对象</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MyNetwork().to(DEVICE)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss().to(DEVICE)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<p>模型使用了默认参数, 数据集图片大小为 <code>28*28</code>, 且加上了 <code>to(DEVICE)</code>. 在前面构建数据集部分也使用了 <code>to(DEVICE)</code> 操作, 其目的是为了保证所有要参与计算的 <code>Tensor</code> 都在同一个硬件设备上进行计算.</p>
<p>然后是实例化损失函数与优化器. 在优化器的参数中需要填入 <code>model</code> 所有需要更新的网络参数, 并填入学习率.</p>
<p>优化器选择了 <code>Adam</code>, 一个几乎万用的优化器.</p>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===============================&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-------------------------------&quot;</span>)</span><br><span class="line">    *train_metrics, _ = train(model, train_dataloader, loss_fn, optimizer)</span><br><span class="line">    *evaluate_metrics, _ = evaluate(model, test_dataloader, loss_fn)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Train Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125; F1: &#123;:.4f&#125;(&#123;:.4f&#125;/&#123;:.4f&#125;)&quot;</span>.<span class="built_in">format</span>(*train_metrics))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Eval  Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125; F1: &#123;:.4f&#125;(&#123;:.4f&#125;/&#123;:.4f&#125;)&quot;</span>.<span class="built_in">format</span>(*evaluate_metrics))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;===============================&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>得到如下训练过程输出.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">===============================</span><br><span class="line">Epoch 1</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 11.0961 Acc: 0.4295 F1: 0.4297(0.4272/0.4281)</span><br><span class="line">Eval  Loss: 0.7999 Acc: 0.8052 F1: 0.8232(0.8059/0.8014)</span><br><span class="line">===============================</span><br><span class="line">Epoch 2</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.8910 Acc: 0.8009 F1: 0.8002(0.8000/0.7999)</span><br><span class="line">Eval  Loss: 0.3495 Acc: 0.9106 F1: 0.9111(0.9103/0.9103)</span><br><span class="line">===============================</span><br><span class="line">Epoch 3</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.4862 Acc: 0.8683 F1: 0.8675(0.8675/0.8674)</span><br><span class="line">Eval  Loss: 0.2554 Acc: 0.9324 F1: 0.9324(0.9322/0.9320)</span><br><span class="line">===============================</span><br><span class="line">Epoch 4</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.3536 Acc: 0.9016 F1: 0.9013(0.9008/0.9010)</span><br><span class="line">Eval  Loss: 0.2114 Acc: 0.9396 F1: 0.9393(0.9397/0.9393)</span><br><span class="line">===============================</span><br><span class="line">Epoch 5</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.2802 Acc: 0.9173 F1: 0.9170(0.9170/0.9169)</span><br><span class="line">Eval  Loss: 0.1861 Acc: 0.9470 F1: 0.9474(0.9471/0.9469)</span><br><span class="line">===============================</span><br></pre></td></tr></table></figure>

<p>训练时每训练一轮同时也在测试集上评估一次, 可以看到两个损失值都是成功下降, 且正确率逐步上升. 有时间的话可以多训练几轮, 看看损失值的变化情况.</p>
<h3 id="输出最终的测试结果"><a href="#输出最终的测试结果" class="headerlink" title="输出最终的测试结果"></a>输出最终的测试结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">*_, report = evaluate(model, test_dataloader, loss_fn)</span><br><span class="line"><span class="built_in">print</span>(report)</span><br></pre></td></tr></table></figure>

<p>输出.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0     0.9344    0.9913    0.9620       460</span><br><span class="line">           1     0.9653    0.9737    0.9695       571</span><br><span class="line">           2     0.9176    0.9660    0.9412       530</span><br><span class="line">           3     0.9346    0.9720    0.9529       500</span><br><span class="line">           4     0.9459    0.9440    0.9449       500</span><br><span class="line">           5     0.9566    0.9671    0.9618       456</span><br><span class="line">           6     0.9644    0.9372    0.9506       462</span><br><span class="line">           7     0.9467    0.9023    0.9240       512</span><br><span class="line">           8     0.9585    0.8978    0.9271       489</span><br><span class="line">           9     0.9503    0.9192    0.9345       520</span><br><span class="line"></span><br><span class="line">    accuracy                         0.9470      5000</span><br><span class="line">   macro avg     0.9474    0.9471    0.9469      5000</span><br><span class="line">weighted avg     0.9474    0.9470    0.9468      5000</span><br></pre></td></tr></table></figure>

<p>其实就是再次调用了一下 <code>evaluate</code> 函数, 但是输出了 report 结果.</p>
<p>可以看到正确率尚可, 达到了 0.94 多, 多训练几轮说不定会更高. 贴一下训练了 22 轮的结果.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0     0.9620    0.9913    0.9764       460</span><br><span class="line">           1     0.9758    0.9895    0.9826       571</span><br><span class="line">           2     0.9701    0.9792    0.9746       530</span><br><span class="line">           3     0.9839    0.9760    0.9799       500</span><br><span class="line">           4     0.9739    0.9720    0.9730       500</span><br><span class="line">           5     0.9759    0.9759    0.9759       456</span><br><span class="line">           6     0.9868    0.9697    0.9782       462</span><br><span class="line">           7     0.9631    0.9688    0.9659       512</span><br><span class="line">           8     0.9710    0.9571    0.9640       489</span><br><span class="line">           9     0.9706    0.9519    0.9612       520</span><br><span class="line"></span><br><span class="line">    accuracy                         0.9732      5000</span><br><span class="line">   macro avg     0.9733    0.9731    0.9732      5000</span><br><span class="line">weighted avg     0.9733    0.9732    0.9732      5000</span><br></pre></td></tr></table></figure>

<p><del>提高了足足 <strong>3 个百分点</strong>! 足以让我们发一篇 CVPR 了!</del> 看得出没有太明显的提升, 一是数据集较小, 二是网络结构比较简单, 不过也足以见到神经网络的强大了.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>万变不离其宗, 虽然本篇是一个只是一个非常精简的手写数字分类, 但是麻雀虽小五脏俱全, 再大型再复杂的网络结构, 它的基本流程都离不开那几个步骤, 唯一没提到了可能就是面对长时间训练情况下, 怎么 &quot;断点续训&quot; 记录存档点, 这个靠自己摸索了. <del>都是网安的了, 自学什么的早就会了吧.</del></p>
<p>实际中, 很少真的自己手搓网络了, 就算是学习论文里的模型, 也都是尽可能的直接拉开源代码下来跑. 那么学习本篇的主要目的是知道使用 <code>pytorch</code> 的最基本的几个步骤, 在看开源代码时, 能够快速找到各个部件都在哪, 理解作者的项目组织方式, 并且必要时可以对源代码做出一定的调整.</p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p><code>pytorch</code> 的官方网站: <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">https://pytorch.org/<i class="fa fa-external-link-alt"></i></span>.</p>
<p>这个官方网站挺好的, 不仅文档详细, 同时也提供了很多示例教学, 很适合入门或者详细了解各种接口.</p>
<p>另附上项目中使用的数据集下载地址, <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pVFBrSzA5cGZuaGE=">点击下载<i class="fa fa-external-link-alt"></i></span>.</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>pytorch</tag>
        <tag>手写数字分类</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 与 Github 入门</title>
    <url>//posts/2022/08/15/wast-gitandgithub/</url>
    <content><![CDATA[<p><code>git</code> 你可能用不到但是 <code>github</code> 肯定用得到, 因为面对一大堆代码任务, 谁都想去<del>抄</del>借鉴一下他人优秀的代码.</p>
<p>因此本篇将向萌新们介绍一下版本管理工具 <code>git</code> 与全世界最大的代码托管平台 <code>github</code> 的基本使用方法.</p>
<span id="more"></span>

<h2 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h2><p>先说 <code>github</code>, 简单粗暴的理解就是, <code>github</code> 是一个专属于代码的云盘, 全世界的人都可以在上面存储自己的代码, 并且可以让大家都来查看自己的代码.</p>
<p>平常如果遇到一些不会的代码问题, 多半用搜索引擎搜出来的都是 CSDN 和博客园或者知乎的内容, 偶尔可以见到一些个人博客<del>比如我这个</del>. 个人博客可能质量稍好, 毕竟是自己经营的, 大概率会认真写点东西放上去, 但是前三者就不一定了, 可能同样的内容都被复制的有包浆了. 因此我们如果想要进一步提升自己的 Coding 水平, 就需要看更高质量的内容, 所以我们把目光投向了 <code>github</code>.</p>
<p><code>github</code> 的最大宗旨就是开源, 任何人都可以发布自己的代码并且让他人一起协同合作. 得益于此, <code>github</code> 上面有很多经典的大型开源项目可供学习, 并且小项目的完整度和质量也比一众博客高出不少, 是我们<del>抄</del>借鉴代码的好去处.</p>
<p><code>github</code> 的官网地址是 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLw==">https://github.com/<i class="fa fa-external-link-alt"></i></span>, 由于不可抗力, 访问不太稳定, 但是可以通过科学上网解决, 可以参考我前一篇文章<a href="/posts/2022/08/15/wast-gitandgithub/">解决学习道路上的 &quot;最后 1 KB&quot;</a>快速入门一下. 进去之后就可以像普通的搜索引擎那样使用, 但是是搜索 <code>github</code> 的所有项目仓库 (多用英语搜, 结果会更理想).</p>
<h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><p><code>git</code> 和 <code>github</code> 长得很像但是完全是两回事, 后者是一个存放代码的地方, 但是前者是一个代码版本管理工具.</p>
<p>罗马不是一天建成的, 代码也不是一天肝完的, 前一天写完的代码, 后一天就会出现 bug, 因此对一份代码不间断的进行修修补补是常事. 如果是毕业论文, 倒还是可以给文件名自己加上一个版本号, 比如 &quot;最终版&quot;, &quot;最终版 v2&quot;...... 但是对于代码文件, 这就不太适用了.</p>
<p>一是代码文件将来会修改的次数可能太多, 一份文件动辄十几二十次, 取这么多版本号不太现实, 二是无法很好的对比每一个版本每次的修改变动, 无法让人一目了然每次修改都改了啥.</p>
<p>因此 <code>git</code> 的出现很好解决了上述问题, 下面简要介绍几个常用的 <code>git</code> 命令和基本概念.</p>
<h3 id="安装-Git"><a href="#安装-Git" class="headerlink" title="安装 Git"></a>安装 Git</h3><p>首先当然是安装 <code>git</code>, 官网地址 <span class="exturl" data-url="aHR0cHM6Ly9naXQtc2NtLmNvbS8=">https://git-scm.com/<i class="fa fa-external-link-alt"></i></span>, 点进去直接 &quot;Downloads&quot; 最新版本进行安装, 安装时有一些选项值得注意一下.</p>
<p><img data-src="/static/image/wast-gitandgithub/vaPitJ.png" alt="vaPitJ.png">]</p>
<p>这两个可以勾上, 这样子右键菜单里会加入这两个快捷项, 方便我们随处快速打开 <code>git</code> 终端.</p>
<p><img data-src="/static/image/wast-gitandgithub/vaPtnf.png" alt="vaPtnf.png"></p>
<p>然后是这个, 使用 <code>VS Code</code> 作为 <code>git</code> 的默认文本编辑器. 要求我们安装了 <code>VS Code</code>, 然后勾选这个选项. 这个意思是一旦 <code>git</code> 出现需要我们手动敲一点文本内容的时候, 会弹出来 <code>VS Code</code> 界面作为输入界面. 强烈建议换掉, 一是好看二是省事<del>珍爱生命, 远离 Vim</del>.</p>
<p><img data-src="/static/image/wast-gitandgithub/vaPTjx.png" alt="vaPTjx.png"></p>
<p>然后是这个, 也是建议选下面的, 曾经 <code>git</code> 的主分支默认叫 <code>master</code>, 但是现在大部分新项目都叫 <code>main</code> 了. 不是什么大问题, 但是建议按新的约定来<del>紧随时代潮流</del>.</p>
<p>后面的选项就可以不用太在意了, 直接一路 Next 就行了, 反正之后都还可以自己手动调整设置项.</p>
<h3 id="使用-Git"><a href="#使用-Git" class="headerlink" title="使用 Git"></a>使用 Git</h3><p>这里只介绍待会要用到的命令和一些基本概念, 毕竟是入门<del>主要是太懒不想写</del>, 具体的细节可以自己看官方文档或者使用搜索引擎学习.</p>
<p><code>git init</code>: 初始化一个本地仓库.</p>
<p>想要使用 <code>git</code> 来管理一个项目, 首先需要使用该命令让 <code>git</code> 将一个项目文件夹标记为需要被 <code>git</code> 进行管理的仓库. 运行完成后, 项目文件夹下就会多出来一个 <code>.git</code> 文件夹, 代表这个项目文件夹已经是一个合法的 <code>git</code> 仓库了.</p>
<p><code>git add &lt;文件&gt;</code>: 临时储存文件变动.</p>
<p>当我们的代码文件发生改动时, 使用该命令进行临时存储, 所谓 &quot;临时&quot;, 是指我们还没有完成一次完整的修改, 但是需要临时保存一下已经做过的修改步骤, 让我们在进一步修改时好进行对比.</p>
<p><code>git commit -m &lt;信息&gt;</code>: 提交一次改动.</p>
<p>当我们已经完成了一次修改, 使用了 <code>add</code> 进行了存储, 并且想要把这次修改确定下来, 形成一次记录时, 需要使用该命令. 其中 &quot;信息&quot; 部分是一个很重要的内容, 是对这一次提交的一个简要说明, 日后我们可以很方便的根据当时提交时填的信息来确定提交的内容, 也可以从大量提交中快速检索与某些特定目的相关的提交.</p>
<p><code>git log --graph --oneline --all</code>: 使用图形化方式查看所有分支的提交记录.</p>
<p>使用该命令可以查看所有提交记录以及各提交记录的哈希值, 有助于我们迅速了解整个仓库的提交历史记录.</p>
<p><code>git show &lt;提交 id&gt;</code>: 查看某一次提交的具体内容.</p>
<p>&quot;提交 id&quot; 就是使用 <code>git log</code> 查到的提交记录哈希值, 显示之后会得到文件变动记录以及各文件具体的修改情况.</p>
<h3 id="简单的实践一下"><a href="#简单的实践一下" class="headerlink" title="简单的实践一下"></a>简单的实践一下</h3><p>以我们之前曾经创建过的一个 <code>example</code> 项目举例, 来使用 <code>git</code> 对其进行本地版本管理, 项目文件结构如下所示.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">example/</span><br><span class="line">    env/</span><br><span class="line">    main.py</span><br></pre></td></tr></table></figure>

<p>总共两部分, 一个是 <code>env</code> 文件夹, <code>python</code> 的虚拟环境, 另一个是我们的源文件 <code>main.py</code>, 我们的目标是只提交 <code>main.py</code>, 而忽略虚拟环境 <code>env</code>, 因为环境严格来说并不需要记录到整个项目里, 每次使用时可以重新生成. 完整的命令执行记录如图所示.</p>
<p><img data-src="/static/image/wast-gitandgithub/vaVnBt.png" alt="vaVnBt.png"></p>
<p>首先进入 <code>example</code> 文件夹, 然后使用 <code>ls</code> 命令查看了一下文件夹内的内容. 之后便是 <code>init -&gt; add -&gt; commit</code> 的一连串操作.</p>
<p>需要注意的地方是, 第一次使用 <code>commit</code> 时, 会给予我们图上的提示信息, 意思是提交时需要指定作者信息. 也就是对于每次提交, <code>git</code> 必须记录是 &quot;谁&quot; 提交了这次修改, 并且是通过 &quot;邮箱&quot; 和 &quot;用户名&quot; 两个信息来确定身份的. 这里我们直接按照提示信息里说的, 设置一下自己的邮箱和用户名, 然后重新使用 <code>commit</code> 命令进行提交即可.</p>
<p><img data-src="/static/image/wast-gitandgithub/vaVI8e.png" alt="vaVI8e.png"></p>
<p>然后我们使用 <code>log</code> 和 <code>show</code> 两个命令查看一下刚刚的提交记录, 其中 <code>+</code> 表示文件内新增的行, 而 <code>-</code> 表示删去的行, 一般来说如果是对某一行进行了修改则会是 <code>+</code> 和 <code>-</code> 交替出现, 这里只有 <code>+</code> 是因为提交了一份全新的文件.</p>
<h2 id="使用-Git-管理-Github-上的项目"><a href="#使用-Git-管理-Github-上的项目" class="headerlink" title="使用 Git 管理 Github 上的项目"></a>使用 Git 管理 Github 上的项目</h2><h3 id="Git-分支简介"><a href="#Git-分支简介" class="headerlink" title="Git 分支简介"></a>Git 分支简介</h3><p>如果 <code>git</code> 的功能仅限于本地管理, 那也就止步于此了, 其最强大的功能还是与 <code>github</code> 结合, 从而实现本地与远程同步的版本管理.</p>
<p>这里需要先介绍一下 <code>git</code> 进行版本管理的一个重要概念 &quot;分支&quot;.</p>
<p>当我们使用 <code>git init</code> 命令创建本地仓库时, 其实就有了第一个分支, 也是我们的主分支 <code>main</code>, 名字就是在安装 <code>git</code> 时设定的默认名称.</p>
<p>当我们对仓库进行操作并提交记录时, <code>git</code> 需要知道当前仓库正处于哪一个分支上, 并把提交记录在这个分支上, 形成分支上的一个个节点. 从而很多次提交之后, 这个分支会逐渐变长, 并且上面的节点数变多, 每一个节点就是每一次提交记录.</p>
<p>当你某天想让你的代码形成另外一个版本时, 但是并不想影响主分支上的内容时, 就可以从主分支的某个节点开始, 延伸出另一条新分支, 从而让两个分支上的内容同时存在且互不干扰. 可想而知, 当分支数多了之后, 分支图将会是一个树形结构.</p>
<p>本地仓库是如此, 对于远程仓库来说也是类似的. 当我们需要将本地的代码仓库同步放到 <code>Github</code> 上进行管理时, 则需要添加仓库内的 &quot;远程分支&quot; 信息.</p>
<p>远程分支与本地的分支像并列的关系, 它们之间形成关联并进行追踪, 从而你可以指定本地的某个分支与远程的某个分支进行关联并同步. 最终远程仓库的远程分支就像是本地仓库分支的一份 &quot;备份&quot;, 无论是哪一边有改动, 都可以通过 <code>git</code> 指令来进行互相同步.</p>
<p>这里放上一个经典的图形化 <code>git</code> 操作学习网站 <span class="exturl" data-url="aHR0cHM6Ly9sZWFybmdpdGJyYW5jaGluZy5qcy5vcmcv">Leanr Git Branching<i class="fa fa-external-link-alt"></i></span>, 有助于快速理解 <code>git</code> 的分支概念<del>几乎我所有认识的学长都推荐过</del>.</p>
<h3 id="在-Github-上发布第一个项目"><a href="#在-Github-上发布第一个项目" class="headerlink" title="在 Github 上发布第一个项目"></a>在 Github 上发布第一个项目</h3><p>首先, 你得注册一个 <code>Github</code> 账号, 点 <code>Sign up</code> 之后自己琢磨吧.</p>
<p>注册好之后, 你的个人界面网址应该就是 <code>https://github.com/&lt;用户名&gt;/</code>, 并且进去后界面大概长的像下面的样子.</p>
<p><img data-src="/static/image/wast-gitandgithub/vaLItP.png" alt="vaLItP.png"></p>
<p>但是在创建仓库发布项目之前, 还有一步重要的事情, 往自己的 <code>Github</code> 里添加 <code>ssh</code> 连接公钥, 可能现在你还不清楚是什么但是照着教程做即可, 既可以提高安全性也可以避免一些麻烦. (如果有喜欢尝试的同学可以试一下走 <code>http</code> 协议的方式, <code>Github</code> 已经不推荐并且由于不可抗力网络质量也很差.)</p>
<p>贴上官方的<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmdpdGh1Yi5jb20vY24vYXV0aGVudGljYXRpb24vY29ubmVjdGluZy10by1naXRodWItd2l0aC1zc2g=">教程<i class="fa fa-external-link-alt"></i></span>, 同时下面也会简要描述一下步骤.</p>
<div class="note info"><p>1.生成自己的 ssh 公钥<br>如果曾经已经生成过的同学可以酌情跳过这一步.<br>打开 <code>git bash</code> 或者 <code>cmd</code>, 输入以下指令.<br><code>ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</code><br>其中 <code>-C</code> 后面跟的是注释内容, 一般填一个能够标识身份的邮箱地址. 之后一路回车即可.<br>成功生成之后, 可以使用 <code>ls</code> 和 <code>cat</code> 命令查看生成的文件与公钥内容.<br>所有操作和成功生成后的结果如下图所示.<br><img data-src="/static/image/wast-gitandgithub/vwila8.png" alt="vwila8.png"><br>2.将公钥添加到 Github<br>回到 <code>github</code> 的个人主页面, 进入 &quot;Settings&quot; 界面, 在左侧选择 &quot;SSH and GPG Keys&quot;, 然后选择 <code>New SSH Key</code>, 并将<strong>公钥文件 <code>id_rsa.pub</code></strong> 的内容复制进去, 注意是<strong>公钥文件 <code>id_rsa.pub</code></strong>.<br><img data-src="/static/image/wast-gitandgithub/vwi2s1.png" alt="vwi2s1.png"></p>
</div>

<p>继续回到我们的 <code>Github</code> 个人主页面, 点击页面右上角的加号, 选择 &quot;New repository&quot;, 创建我们的第一个项目仓库.</p>
<p><img data-src="/static/image/wast-gitandgithub/v0E9gg.png" alt="v0E9gg.png"></p>
<p>如图所示填好必要的信息, 其中选项 public 即代表这是一个公开仓库, 任何人都可以在 <code>github</code> 上访问并查看里面的文件内容.</p>
<p>创建完成后, 会显示三种后续的操作, 在这里我们选择第二种, &quot;将已有的仓库从命令行推送&quot;.</p>
<p>进入你的本地仓库, 打开 <code>git bash</code> 并依次执行下面三条命令.</p>
<p><code>git remote add origin git@github.com:&lt;用户名&gt;/&lt;仓库名&gt;.git</code>: 将远程主机与仓库地址添加到本地仓库配置中, 主机名 <code>origin</code>, 地址为 <code>ssh</code> 地址 <code>git@github.com:&lt;用户名&gt;/&lt;仓库名&gt;.git</code></p>
<p><code>git branch -M main</code>: 可选步骤, 将当前分支重命名为 <code>main</code>, 此前我们的分支名已经是 <code>main</code> 了.</p>
<p><code>git push -u origin main</code>: 将本地分支 <code>main</code> 推送到远程主机 <code>origin</code>, 并且远程分支名与本地相同也为 <code>main</code>.</p>
<p>执行完成后稍等一会刷新一下页面, 就可以看到 <code>github</code> 上已经有本地仓库的内容了.</p>
<h3 id="在本地管理远程项目"><a href="#在本地管理远程项目" class="headerlink" title="在本地管理远程项目"></a>在本地管理远程项目</h3><p>这部分主要介绍平常敲代码时常用的命令流.</p>
<p><code>git pull</code>: 进行写代码时的第一步, 使用该命令可以将远程仓库里的最新记录同步至本地.</p>
<p><code>git add &lt;文件&gt;</code>: 写代码中途或者写完代码后, 将修改后的文件进行储存.</p>
<p><code>git commit -m &lt;信息&gt;</code>: 将所有通过 <code>add</code> 存储的内容进行提交, 产生一次记录.</p>
<p><code>git push</code>: 将本地所有的提交记录同步推送到远程仓库.</p>
<h2 id="在-VS-Code-中使用-Git"><a href="#在-VS-Code-中使用-Git" class="headerlink" title="在 VS Code 中使用 Git"></a>在 VS Code 中使用 Git</h2><p>前面花了很长的篇幅讲解 <code>git</code> 的各种使用, 并且有着非常多的命令, 很容易让人头晕. 但是好在大部分命令都是重复相似的, 因此, 为了省事, 绝大多数开发工具都支持图形化的 <code>git</code> 命令操作, 从而避免了命令行的痛苦. 但是在使用时仍然需要知道每一个按键选项与命令的基本对应关系, 清楚每一步具体做了什么.</p>
<p><code>VS Code</code> 本身自带对 <code>git</code> 的支持, 且已经能够满足基本使用. 打开我们的 <code>example</code> 项目, 左边切换到 <code>源代码管理</code> 的面板.</p>
<p><img data-src="/static/image/wast-gitandgithub/v0naB4.png" alt="v0naB4.png"></p>
<p>在这里可以看到本地仓库的所有更改, 我们可以手动切换一下视图模式, 以树形式查看, 方便与资源管理器的视图对应.</p>
<p>可以看到存在两部分变动, 且标记为 <code>U</code>, 意为 &quot;未跟踪&quot;, 也就是它是一份新文件, 如果是曾经有过记录则是 <code>M</code>. 点击左侧的文件名, 还可以在右方的窗口里预览文件的每一行更改情况.</p>
<p>我们选择 <code>main.py</code> 一行右侧的 <code>+</code> 号, &quot;暂存更改&quot;, 其行为等价于 <code>add</code> 操作.</p>
<p><img data-src="/static/image/wast-gitandgithub/v0uFrF.png" alt="v0uFrF.png"></p>
<p>操作之后 <code>main.py</code> 被放入 &quot;暂存的更改&quot; 中, 此时可以在上方的输入框中键入信息, 然后点提交, 该步骤等价于 <code>git commit</code> 操作.</p>
<p>如果没有暂存的更改, 则所有的更改都将会被提交. 如果提交信息为空, 则会弹出界面让你输入信息.</p>
<p><img data-src="/static/image/wast-gitandgithub/v0KiWt.png" alt="v0KiWt.png"></p>
<p>提交完成后, <code>VS Code</code> 左下角将会如图所示, 有一个双箭头圆圈且有数字标记, 意为本地比远程多一次提交记录, 点击圆圈, <code>VS Code</code> 会将本地仓库与远程仓库进行自动同步, 其操作等价于先进行 <code>pull</code> 再进行 <code>push</code>.</p>
<p>一般来说, 推荐使用命令行创建仓库以及关联远程仓库等初始化操作, 之后再使用图形化界面进行每天的提交和同步操作. 此外, 如果觉得 <code>VS Code</code> 原生支持不够, 还有丰富的插件可以选择, 比如 <code>GitLens</code> 诸如此类.</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>尽可能的把平常高频使用的内容都写上去了, 虽然感觉写的很长但是仍然很难把每一件事都写的很清楚, 只能是把表面写一写, 内部的细节原理不是这个入门篇能一次性搞定, 还得靠自己平日善用搜索引擎和官方文档.</p>
<p>这里贴一下 <code>git</code> 与 <code>github</code> 的文档地址, <span class="exturl" data-url="aHR0cHM6Ly9naXQtc2NtLmNvbS9kb2Nz">https://git-scm.com/docs<i class="fa fa-external-link-alt"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmdpdGh1Yi5jb20vY24=">https://docs.github.com/cn<i class="fa fa-external-link-alt"></i></span>, 熟能生巧~</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>经典问题之文本分类</title>
    <url>//posts/2022/08/17/wast-ml/</url>
    <content><![CDATA[<p>成为一个熟练的调包侠是速通的关键要素之一, 在无数的课程大作业和小任务中, 使用机器学习来解决一些问题算是经典中的经典<del>典中典</del>, 比如通过文本分类来实现垃圾邮件过滤. 因此本篇将基于 <code>python</code> 中最常用的机器学习库 <code>scikit-learn</code>, 用朴素贝叶斯模型来完成一次文本分类任务.</p>
<span id="more"></span>

<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>需要的第三方库.</p>
<p><code>jieba</code>: 一个中文分词库, 可以将一个句子分成一个个的单词.</p>
<p><code>scikit-learn</code>: <code>python</code> 中最常用的机器学习库, 内置多种模型与算法, 开箱即用.</p>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">example/</span><br><span class="line">    data/</span><br><span class="line">        财经/</span><br><span class="line">            1.txt</span><br><span class="line">            2.txt</span><br><span class="line">            ...</span><br><span class="line">            200.txt</span><br><span class="line">        房产/</span><br><span class="line">            1.txt</span><br><span class="line">            ...</span><br><span class="line">            200.txt</span><br><span class="line">        XXX/</span><br><span class="line">            XXX.txt</span><br><span class="line">        ...</span><br><span class="line">    main.py</span><br><span class="line">    main.ipynb</span><br></pre></td></tr></table></figure>

<p><img data-src="/static/image/wast-ml/vBh4sA.png" alt="vBh4sA.png"></p>
<h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><h3 id="导入所有需要用到的库"><a href="#导入所有需要用到的库" class="headerlink" title="导入所有需要用到的库"></a>导入所有需要用到的库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_files</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br></pre></td></tr></table></figure>

<h3 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">raw_data = load_files(<span class="string">&quot;./data/&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>, shuffle=<span class="literal">True</span>, decode_error=<span class="string">&quot;ignore&quot;</span>, random_state=<span class="number">1</span>)</span><br><span class="line">data_x = raw_data[<span class="string">&quot;data&quot;</span>]</span><br><span class="line">data_y = raw_data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">index2label = raw_data[<span class="string">&quot;target_names&quot;</span>]</span><br><span class="line">label2index = &#123;l: i <span class="keyword">for</span> i, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(index2label)&#125;</span><br><span class="line"><span class="comment"># print(len(data_x), data_x[1])</span></span><br><span class="line"><span class="comment"># print(len(data_y), data_y[1])</span></span><br><span class="line"><span class="comment"># print(index2label)</span></span><br><span class="line"><span class="comment"># print(label2index)</span></span><br><span class="line"><span class="comment">## ========== Output ==========</span></span><br><span class="line"><span class="comment">## 1400 她们深陷美妆圈分享好货停不下来...更多的是时间与心思。</span></span><br><span class="line"><span class="comment">## 1400 3</span></span><br><span class="line"><span class="comment">## [&#x27;家居&#x27;, &#x27;房产&#x27;, &#x27;教育&#x27;, &#x27;时尚&#x27;, &#x27;时政&#x27;, &#x27;科技&#x27;, &#x27;财经&#x27;]</span></span><br><span class="line"><span class="comment">## &#123;&#x27;家居&#x27;: 0, &#x27;房产&#x27;: 1, &#x27;教育&#x27;: 2, &#x27;时尚&#x27;: 3, &#x27;时政&#x27;: 4, &#x27;科技&#x27;: 5, &#x27;财经&#x27;: 6&#125;</span></span><br><span class="line"><span class="comment">## ============================</span></span><br></pre></td></tr></table></figure>

<p>数据的读取直接使用现成的库函数 <code>load_files</code>, 需要满足一定的目录结构才能直接使用, 即数据集文件夹下面是类别文件夹, 类别文件夹下面是每一份数据文件.</p>
<p>读取之后返回的对象包含所有的原始数据与自动生成的标签, 从 <code>index2label</code> 和 <code>label2index</code> 可以看到数字标签与类别文字的对应关系.</p>
<p>如果是其他形式的数据集, 需要自己写加载函数. 加载后的获取的内容与上面的应当类似, 有数字标签及其与文字类别的对应关系, 以及样本与标签相互对应的两个有序列表.</p>
<h3 id="划分训练集与测试集"><a href="#划分训练集与测试集" class="headerlink" title="划分训练集与测试集"></a>划分训练集与测试集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_x, test_x, train_y, test_y = train_test_split(</span><br><span class="line">    data_x, data_y, train_size=<span class="number">0.7</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>, stratify=data_y, random_state=<span class="number">1</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># print(f&quot;train_x: &#123;len(train_x)&#125;&quot;)</span></span><br><span class="line"><span class="comment"># print(f&quot;test_x: &#123;len(test_x)&#125;&quot;)</span></span><br><span class="line"><span class="comment">## ========== Output ==========</span></span><br><span class="line"><span class="comment">## train_x: 979</span></span><br><span class="line"><span class="comment">## test_x: 421</span></span><br><span class="line"><span class="comment">## ============================</span></span><br></pre></td></tr></table></figure>

<p>继续调包来划分数据集, 并且填入参数, 按 7:3 划分训练集与测试集.</p>
<p>其中 <code>stratify</code> 参数含义为按比例划分, 即训练集与测试集的各类别之间的比例与提供的 <code>data_y</code> 比例一致, 即划分前的总比例.</p>
<h3 id="对数据集进行特征提取"><a href="#对数据集进行特征提取" class="headerlink" title="对数据集进行特征提取"></a>对数据集进行特征提取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv = CountVectorizer(tokenizer=jieba.lcut)</span><br><span class="line">train_x = cv.fit_transform(train_x)</span><br><span class="line">test_x = cv.transform(test_x)</span><br></pre></td></tr></table></figure>

<p>因为我们最终是使用朴素贝叶斯模型进行文本分类, 因此需要得到一些离散特征.</p>
<p>这部分使用了 <code>CountVectorizer</code> 来进行特征提取, 它可以使用 <code>tokenizer</code> 对数据集进行分词并统计, 在内部构建一个词典, 将每个单词映射到一个序号, 进而把每个样本变成一个向量.</p>
<p><code>CountVectorizer.fit</code>: 接受数据集进行拟合, 更新内部的词典.<br><code>CountVectorizer.transform</code>: 接受数据集, 按照内部的词典将每个样本转换成向量形式.</p>
<p>在这里我们使用 <code>fit_transform</code> 来处理训练集, 这是两步合并操作, 意思是使用训练集来构建词典并将训练集向量化.</p>
<p>但是只使用 <code>transform</code> 来处理测试集, 也就是使用训练集上的词典来向量化测试集. 这个比较好理解, 因为对于模型来说, 通过训练集训练, 理论上来说是不知道测试集的内容的, 因此不需要让词典更新测试集的词汇.</p>
<h3 id="构建模型并拟合"><a href="#构建模型并拟合" class="headerlink" title="构建模型并拟合"></a>构建模型并拟合</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MultinomialNB()</span><br><span class="line">model.fit(train_x, train_y)</span><br></pre></td></tr></table></figure>

<p>我们选择 <code>MultinomialNB</code> 模型, 因为它是 <code>sklearn</code> 中适合处理离散特征的贝叶斯模型, 有很多可调节的参数, 这里从简, 直接全部默认参数.</p>
<p>把训练集喂进模型的 <code>fit</code> 函数, 然后等待一会训练过程.</p>
<h3 id="在测试集上测试准确性"><a href="#在测试集上测试准确性" class="headerlink" title="在测试集上测试准确性"></a>在测试集上测试准确性</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y, target_names=index2label))</span><br></pre></td></tr></table></figure>

<p>将测试集的样本喂进训练之后的模型 <code>predict</code> 函数中得到 <code>pred_y</code>. 我们直接调包来计算各项指标 (当然包里还有其他分别计算各项指标的函数), 得到如下输出.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">          家居       0.88      0.97      0.92        60</span><br><span class="line">          房产       1.00      0.80      0.89        60</span><br><span class="line">          教育       0.82      1.00      0.90        60</span><br><span class="line">          时尚       1.00      0.98      0.99        60</span><br><span class="line">          时政       0.91      0.85      0.88        60</span><br><span class="line">          科技       1.00      0.97      0.98        61</span><br><span class="line">          财经       0.98      0.98      0.98        60</span><br><span class="line"></span><br><span class="line">    accuracy                           0.94       421</span><br><span class="line">   macro avg       0.94      0.94      0.94       421</span><br><span class="line">weighted avg       0.94      0.94      0.94       421</span><br></pre></td></tr></table></figure>

<p>可以看到效果不错, 稍低一点的是 &quot;房产&quot; 与 &quot;时政&quot;, 召回率较低, 猜测可能被误分类到 &quot;家居&quot; 和 &quot;教育&quot; 里面去了.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实做一个调包侠还是挺简单的, 不到 50 行代码就实现了一个看起来似乎挺麻烦的事, 但是能够正确调包的前提是知道各个模型的基本原理, 能够构建合适的特征并选择合适的模型, 同时也需要对常用的机器学习库的 api 有一定了解和使用经验, 不然连调包侠也当不了 X﹏X.</p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p><code>scikit-learn</code> 官方文档: <span class="exturl" data-url="aHR0cHM6Ly9zY2lraXQtbGVhcm4ub3JnL3N0YWJsZS9pbmRleC5odG1s">https://scikit-learn.org/stable/index.html<i class="fa fa-external-link-alt"></i></span> (其实这文档很少看, 不如搜索引擎现搜).</p>
<p>另外贴一下文章里面用的数据集网盘地址, <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pVHZLejA5cGNxOGI=">点击下载<i class="fa fa-external-link-alt"></i></span>.</p>
<p>没啥其他相关资源了, 课上好好学<del>课下慢慢搜</del>就完事了.</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>scikit-learn</tag>
        <tag>文本分类</tag>
      </tags>
  </entry>
  <entry>
    <title>再遇文本分类</title>
    <url>//posts/2022/08/19/wast-nlp/</url>
    <content><![CDATA[<p>这是<a href="/categories/%E7%BD%91%E5%AE%89%E6%9C%AC%E7%A7%91%E9%80%9F%E9%80%9A/">网安本科速通</a>系列的最后一篇了, 主题还是 <code>pytorch</code>, 但是问题换成了 <code>NLP</code>, 并且还是以经典的文本分类作为示例, 数据集使用与前面<a href="/posts/2022/08/17/wast-ml/">经典问题之文本分类</a>相同的一份小数据集, 方便进行比较.</p>
<p>阅读本篇前需要先看前两篇, <a href="/posts/2022/08/17/wast-ml/">经典问题之文本分类</a>与<a href="/posts/2022/08/18/wast-dl/">基于 PyTorch 的手写数字分类</a>. 本篇的项目代码和数据集是以前两篇作为基础的, 并且也会精简正文内容.</p>
<span id="more"></span>

<h2 id="环境准备与项目结构"><a href="#环境准备与项目结构" class="headerlink" title="环境准备与项目结构"></a>环境准备与项目结构</h2><p>环境使用 <code>pytorch</code> 环境.</p>
<p>项目结构与文本分类项目结构一致, 并且使用相同的数据集.</p>
<h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><h3 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_files</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, f1_score, precision_score, recall_score</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line"></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br></pre></td></tr></table></figure>

<p>前两个项目的结合, 都是些常规库.</p>
<h3 id="构建数据集"><a href="#构建数据集" class="headerlink" title="构建数据集"></a>构建数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vocabulary</span>:</span><br><span class="line">    PAD = <span class="string">&quot;&lt;PAD&gt;&quot;</span></span><br><span class="line">    UNK = <span class="string">&quot;&lt;UNK&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.token2id = &#123;self.PAD: <span class="number">0</span>, self.UNK: <span class="number">1</span>&#125;</span><br><span class="line">        self.id2token = [self.PAD, self.UNK]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.token2id)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_token</span>(<span class="params">self, token</span>):</span><br><span class="line">        <span class="keyword">if</span> token <span class="keyword">not</span> <span class="keyword">in</span> self.token2id:</span><br><span class="line">            self.token2id[token] = <span class="built_in">len</span>(self.token2id)</span><br><span class="line">            self.id2token.append(token)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, text</span>):</span><br><span class="line">        <span class="keyword">return</span> [self.token2id.get(x, self.token2id[self.UNK]) <span class="keyword">for</span> x <span class="keyword">in</span> text]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, ids</span>):</span><br><span class="line">        <span class="keyword">return</span> [self.id2token[x] <span class="keyword">for</span> x <span class="keyword">in</span> ids]</span><br></pre></td></tr></table></figure>

<p>先写一个词表类, 这个词表可以按需求添加生词, 并且将分词后的文本进行词与序号之间的编解码操作, 核心目的是提供文本向量化的能力.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_raw_data</span>(<span class="params">path</span>):</span><br><span class="line">    raw_data = load_files(path, encoding=<span class="string">&quot;utf8&quot;</span>, shuffle=<span class="literal">True</span>, decode_error=<span class="string">&quot;ignore&quot;</span>, random_state=<span class="number">1</span>)</span><br><span class="line">    data_x = raw_data[<span class="string">&quot;data&quot;</span>]</span><br><span class="line">    data_y = raw_data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">    index2label = raw_data[<span class="string">&quot;target_names&quot;</span>]</span><br><span class="line">    label2index = &#123;l: i <span class="keyword">for</span> i, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(index2label)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (data_x, data_y), (index2label, label2index)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">data_x, data_y</span>):</span><br><span class="line">    data_x = [jieba.lcut(s) <span class="keyword">for</span> s <span class="keyword">in</span> data_x]</span><br><span class="line">    train_x, test_x, train_y, test_y = train_test_split(</span><br><span class="line">        data_x, data_y, train_size=<span class="number">0.7</span>,</span><br><span class="line">        shuffle=<span class="literal">True</span>, stratify=data_y, random_state=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    vocab = Vocabulary()</span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> train_x:</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> text:</span><br><span class="line">            vocab.add_token(word)</span><br><span class="line"></span><br><span class="line">    train_x = [vocab.encode(x) <span class="keyword">for</span> x <span class="keyword">in</span> train_x]</span><br><span class="line">    test_x = [vocab.encode(x) <span class="keyword">for</span> x <span class="keyword">in</span> test_x]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (train_x, test_x, train_y, test_y), vocab</span><br></pre></td></tr></table></figure>

<p>然后封装一下之前文本分类项目里的数据集加载操作, 手动使用 <code>jieba.lcut</code> 进行分词并构建词表, 最后返回划分好的训练集与测试集.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        self.inputs = x</span><br><span class="line">        self.targets = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.inputs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        input_ = torch.tensor(self.inputs[item]).long().to(DEVICE)</span><br><span class="line">        target = torch.tensor([self.targets[item]]).long().to(DEVICE)</span><br><span class="line">        <span class="keyword">return</span> (input_, target)</span><br></pre></td></tr></table></figure>

<p>自定义数据集类, 与数字分类项目里的定义方式类似, 但是输入参数换成直接获取前面预处理好的数据集.</p>
<h3 id="定义神经网络结构"><a href="#定义神经网络结构" class="headerlink" title="定义神经网络结构"></a>定义神经网络结构</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyNetwork</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, output_size=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        _embedding_size = <span class="number">128</span></span><br><span class="line">        _hidden_size = <span class="number">128</span></span><br><span class="line">        _filter_sizes = (<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, _embedding_size)</span><br><span class="line">        self.dropout = nn.Dropout()</span><br><span class="line">        self.convs = nn.ModuleList([nn.Conv1d(_embedding_size, _hidden_size, k) <span class="keyword">for</span> k <span class="keyword">in</span> _filter_sizes])</span><br><span class="line">        self.fc = nn.Linear(_hidden_size * <span class="built_in">len</span>(_filter_sizes), output_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_convpool</span>(<span class="params">self, x</span>):</span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="keyword">for</span> conv <span class="keyword">in</span> self.convs:</span><br><span class="line">            output = torch.relu(conv(x))                                <span class="comment"># (128, L) -&gt; (128, L-k+1)</span></span><br><span class="line">            output = torch.max_pool1d(output, output.size(<span class="number">2</span>)).squeeze() <span class="comment"># (128, L-k+1) -&gt; (128,)</span></span><br><span class="line">            outputs.append(output)</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, -<span class="number">1</span>)                                   <span class="comment"># (128,) -&gt; (384,)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = self.embedding(inputs)                                <span class="comment"># (L,) -&gt; (L, 128)</span></span><br><span class="line">        outputs = self.dropout(outputs)                                 <span class="comment"># </span></span><br><span class="line">        outputs = outputs.transpose(<span class="number">1</span>, <span class="number">2</span>)                               <span class="comment"># (L, 128) -&gt; (128, L)</span></span><br><span class="line">        outputs = self._convpool(outputs)                               <span class="comment"># (128, L) -&gt; (384,)</span></span><br><span class="line">        outputs = self.fc(outputs)                                      <span class="comment"># (384,) -&gt; (7,)</span></span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>

<p>继续使用与数字分类中相同的卷积结构, 也就是 <code>TextCNN</code>, 卷积核选择经典的三个值. 各个步骤的维度变化在注释里有标注.</p>
<h3 id="定义指标评价函数"><a href="#定义指标评价函数" class="headerlink" title="定义指标评价函数"></a>定义指标评价函数</h3><p>见<a href="/posts/2022/08/18/wast-dl/#%E5%AE%9A%E4%B9%89%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E5%87%BD%E6%95%B0">定义评价指标函数</a>.</p>
<h3 id="训练与评估函数"><a href="#训练与评估函数" class="headerlink" title="训练与评估函数"></a>训练与评估函数</h3><p>见<a href="/posts/2022/08/18/wast-dl/#%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0">定义训练函数</a>与<a href="/posts/2022/08/18/wast-dl/#%E5%AE%9A%E4%B9%89%E8%AF%84%E4%BC%B0%E5%87%BD%E6%95%B0">定义评估函数</a></p>
<h3 id="校对函数-collate-fn"><a href="#校对函数-collate-fn" class="headerlink" title="校对函数 (collate_fn)"></a>校对函数 (collate_fn)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">data: <span class="built_in">list</span></span>):</span><br><span class="line">    inputs, targets = <span class="built_in">map</span>(<span class="built_in">list</span>, <span class="built_in">zip</span>(*data))</span><br><span class="line">    inputs = pad_sequence(inputs, batch_first=<span class="literal">True</span>)</span><br><span class="line">    targets = torch.stack(targets)</span><br><span class="line">    <span class="keyword">return</span> inputs, targets</span><br></pre></td></tr></table></figure>

<p>这个东西可能第一次见, 并且用了一些很奇怪的操作, 比如那个 <code>map</code>, 但是首先要明白这个函数用于干什么.</p>
<p>回忆我们在数字分类项目里使用 <code>DataLoader</code> 时, 它可以给我们提供一个 loader 来迭代我们自定义的 <code>Dataset</code>. <code>Dataset</code> 每次取出来的东西是一个二元组, 里面包含样本与标签两部分, 而 <code>Dataloader</code> 又能够按 <code>batch_size</code> 的大小批量获取这些二元组, 形成一个 <code>list</code>. 这个长度为 <code>batch_size</code>, 内容为二元组的 <code>list</code> 就是 <code>collate_fn</code> 的输入参数.</p>
<p>再看 <code>map</code> 那一行操作, 涉及了几个 <code>python</code> 函数用法, 这里直接说结论, 它将 <code>data</code> 里的样本与标签拆分成了两个单独的 <code>list</code>.</p>
<p>然后再说 <code>pad_sequence</code> 操作, 对于神经网络来说, 所有的计算过程都是矩阵计算, 但是对于文本任务, 每个样本句子长度几乎都不是相同的, 因此需要进行对齐操作, 对短句进行填充. 需要注意的是, 默认参数里的填充值是 <code>0</code>, 这与我们前面词表里的定义是一致的, 如果不一致则需要手动填一下.</p>
<p>最后是参数的返回值, 直接对应了我们从 loader 里迭代数据时获取的变量形式, 此处就是和之前一样, 分别返回样本列表与标签列表.</p>
<h3 id="定义训练超参数"><a href="#定义训练超参数" class="headerlink" title="定义训练超参数"></a>定义训练超参数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">seed = <span class="number">1</span></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">epochs = <span class="number">25</span></span><br><span class="line"></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed(seed)</span><br></pre></td></tr></table></figure>

<p>与前面的项目类似, 但是 <code>batch_size</code> 设的稍小一些, 因为对于文本处理, 按批次训练时, 进行了填充操作, 越大的 <code>batch_size</code> 能够得到越快的训练速度, 但是在一个 <code>batch</code> 内会引入更多不必要的 <code>0</code> 填充值, 可以酌情尝试调整.</p>
<h3 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(data_x, data_y), (index2label, label2index) = load_raw_data(<span class="string">&quot;./data/&quot;</span>)</span><br><span class="line">(train_x, test_x, train_y, test_y), vocab = preprocess(data_x, data_y)</span><br><span class="line"></span><br><span class="line">train_dataset = MyDataset(train_x, train_y)</span><br><span class="line">test_dataset = MyDataset(test_x, test_y)</span><br><span class="line">train_dataloader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size, collate_fn=collate_fn)</span><br><span class="line">test_dataloader = DataLoader(test_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size, collate_fn=collate_fn)</span><br></pre></td></tr></table></figure>

<p>最大的不同就是添加了 <code>collate_fn</code> 参数, 其余的都是之前涉及过的操作.</p>
<h3 id="实例化模型训练需要的对象"><a href="#实例化模型训练需要的对象" class="headerlink" title="实例化模型训练需要的对象"></a>实例化模型训练需要的对象</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MyNetwork(<span class="built_in">len</span>(vocab)).to(DEVICE)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss().to(DEVICE)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<p>与之前的定义也是几乎一致的, 唯一的不同就是 <code>MyNetwork</code> 多了一个 <code>vocab_size</code> 的参数需要传进去, 其他参数都用的默认值.</p>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>代码见<a href="/posts/2022/08/18/wast-dl/#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">训练模型</a>, 这里只贴一下后 5 轮的训练结果.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">===============================</span><br><span class="line">Epoch 21</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0071 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1102 Acc: 0.9667 F1: 0.9669(0.9669/0.9667)</span><br><span class="line">===============================</span><br><span class="line">Epoch 22</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0055 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1099 Acc: 0.9644 F1: 0.9645(0.9645/0.9643)</span><br><span class="line">===============================</span><br><span class="line">Epoch 23</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0056 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1062 Acc: 0.9644 F1: 0.9645(0.9645/0.9643)</span><br><span class="line">===============================</span><br><span class="line">Epoch 24</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0048 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1019 Acc: 0.9667 F1: 0.9669(0.9669/0.9667)</span><br><span class="line">===============================</span><br><span class="line">Epoch 25</span><br><span class="line">-------------------------------</span><br><span class="line">Train Loss: 0.0042 Acc: 1.0000 F1: 1.0000(1.0000/1.0000)</span><br><span class="line">Eval  Loss: 0.1051 Acc: 0.9644 F1: 0.9645(0.9645/0.9643)</span><br><span class="line">===============================</span><br></pre></td></tr></table></figure>

<p>可以看到在训练集上已经完全拟合了, 并且测试集上 F1 得分也高达 0.9645.</p>
<h3 id="输出最终的测试结果"><a href="#输出最终的测试结果" class="headerlink" title="输出最终的测试结果"></a>输出最终的测试结果</h3><p>代码见<a href="/posts/2022/08/18/wast-dl/#%E8%BE%93%E5%87%BA%E6%9C%80%E7%BB%88%E7%9A%84%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C">输出最终的测试结果</a>, 这里只贴一下输出结果.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0     0.9524    1.0000    0.9756        60</span><br><span class="line">           1     0.9667    0.9667    0.9667        60</span><br><span class="line">           2     1.0000    1.0000    1.0000        60</span><br><span class="line">           3     0.9649    0.9167    0.9402        60</span><br><span class="line">           4     0.9833    0.9833    0.9833        60</span><br><span class="line">           5     0.9333    0.9180    0.9256        61</span><br><span class="line">           6     0.9508    0.9667    0.9587        60</span><br><span class="line"></span><br><span class="line">    accuracy                         0.9644       421</span><br><span class="line">   macro avg     0.9645    0.9645    0.9643       421</span><br><span class="line">weighted avg     0.9644    0.9644    0.9642       421</span><br></pre></td></tr></table></figure>

<p>可以和之前使用朴素贝叶斯的文本分类做个比较, 可以看到还是有明显提升的, <code>2</code> 号类别甚至已经完全正确了. 当然这个对比不是很科学, 毕竟这是一个很小的数据集, 而且两者都还有大量的可调整空间. 朴素贝叶斯里有很多超参数, 而且样本的特征提取也有待进一步升级; <code>TextCNN</code> 网络里也有很多超参数可调, 比如词向量的长度等等.</p>
<p>不过神经网络的强处正是在于能够自动提取深层次特征, 避免了人工构造特征的麻烦, 也就是非常擅长 &quot;找规律&quot;, 只要数据集充足, 选择合适的网络结构, 然后经过一番超参数调整之后, 效果都不会很差. <del>就是玄学炼丹.</del></p>
<h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><p>各个模块的使用方法可以去看 <code>pytorch</code> 的<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">官方网站<i class="fa fa-external-link-alt"></i></span>, 项目中使用的数据集在前面的文章里也有, 这里再贴一下, <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pVHZLejA5cGNxOGI=">点击下载<i class="fa fa-external-link-alt"></i></span>.</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>nlp</tag>
        <tag>深度学习</tag>
        <tag>pytorch</tag>
        <tag>文本分类</tag>
      </tags>
  </entry>
  <entry>
    <title>打造一个舒适的 Python 编程环境</title>
    <url>//posts/2022/08/13/wast-pythonandvsc/</url>
    <content><![CDATA[<p>网安专业几乎 99% 的作业都可以用 <code>python</code> 来解决, 除了大一大二一些特别的专业课, 需要折腾一下 <code>c</code> 语言, 之后其余的所有网安专业必修与选修的大作业, 都多多少少和 &quot;大数据&quot;, &quot;人工智能&quot; 挂钩, 里面涉及了很多数据处理与分析, 这类任务用 <code>python</code> 写将会非常方便, 因为已经有了许多的第三方包让我们直接使用.</p>
<p>因此本篇主要基于个人经验介绍一下比较舒适的 <code>python</code> 编程环境设置, 让大家能够把精力放在<del>抄</del>写代码上, 而不是被环境弄的头疼.</p>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>从本篇开始, 基本上算是完全的个人经验分享. 由于我自己是网安专业而非信安, 因此可能分享的内容对网安同学适用性更好, 不过信安同学可以酌情参考. 如果还没分专业, 也可以参考一下将来可能需要点一些啥技能来速通网安各个课程作业.</p>
<p>如果对 <code>VS Code</code> 没有了解, 可以看前一篇<a href="/posts/2022/08/11/wast-vscandvs/">给新生的编程工具推荐与基本使用方法</a>, 这里面讲了 <code>VS Code</code> 的基本使用方法. 而本篇将会基于 <code>VS Code</code>, 打造一个相对舒适的 <code>python</code> 编程环境.</p>
<h2 id="安装-Python"><a href="#安装-Python" class="headerlink" title="安装 Python"></a>安装 Python</h2><p>第一步肯定是安装 <code>python</code>, 官网就是 <span class="exturl" data-url="aHR0cHM6Ly93d3cucHl0aG9uLm9yZy8=">https://www.python.org/<i class="fa fa-external-link-alt"></i></span>.</p>
<p>可以选择下最新版, 不过不是那么的推荐, 而是适当旧一点, 比如现在最新的版本是 <code>3.10.6</code>, 那么可以下 <code>3.8.10</code> (<code>3.8.x</code> 发布的最后一个有安装包的版本). 这样子兼容度大一点. (曾经遇见过要装的某个包还没发布适配新版本 <code>python</code> 的版本, 害得我又重装降级了 <code>python</code>).</p>
<p>这里直接提供 <a href="https://www.python.org/downloads/release/python-3810/"><code>Python 3.8.10</code></a> 的官方下载页面, 点进去之后选 &quot;Windows installer (64-bit)&quot; 这个版本就好了.</p>
<p>下载好之后双击进入安装界面. 下面两项都勾上, 并且选择 &quot;Customize installation&quot;.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vtamNQ.png" alt="vtamNQ.png"></p>
<p>这一面也是直接全勾.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vtaN4J.png" alt="vtaN4J.png"></p>
<p>再次 Next 之后, 这个界面里, 勾选 &quot;Install for all users&quot;, 并且可以在下方调整 <code>python</code> 的安装路径. 推荐装到 D 盘或者其他方便找到的地方, 比如 <code>D:\Program Files\Python38</code>.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vtd9VU.png" alt="vtd9VU.png"></p>
<p>重启一下电脑, 快捷键 <code>Win + R</code>, 输入 <code>cmd</code> 打开命令提示符, 敲一下 <code>python --version</code>, 如下图所示则安装成功.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vtdqeK.png" alt="vtdqeK.png"></p>
<h2 id="Python-虚拟环境"><a href="#Python-虚拟环境" class="headerlink" title="Python 虚拟环境"></a>Python 虚拟环境</h2><h3 id="虚拟环境简介"><a href="#虚拟环境简介" class="headerlink" title="虚拟环境简介"></a>虚拟环境简介</h3><p>关于虚拟环境的详细介绍很多, 必应一搜就有很多<span class="exturl" data-url="aHR0cHM6Ly9jbi5iaW5nLmNvbS9zZWFyY2g/cT1weXRob24lRTclOUElODQlRTglOTklOUElRTYlOEIlOUYlRTclOEUlQUYlRTUlQTIlODMlRTYlOTglQUYlRTQlQkIlODAlRTQlQjklODg=">结果<i class="fa fa-external-link-alt"></i></span>, 有时间可以慢慢理解.</p>
<p>当你写代码时, 不可能完全都靠自己从零开始, 这样子很低效<del>并且很蠢</del>, 所以对于 <code>python</code> 而言, 写代码之前确定并安装合适的第三方包就是基本操作.</p>
<p>然而, 第三方包在发布的时候, 可能会存在许多不同的版本, 不同项目之间所需要的包版本也不尽相同, 会造成巨大的兼容问题 (比如万恶的 <code>tensorflow 1.x</code> 和 <code>tensorflow 2.x</code>). 这种时候就需要使用虚拟环境.</p>
<p>虚拟环境可以简单认为是 &quot;<code>python</code> 和对应的包的副本&quot;, 最基本的要素是环境内的 <code>python</code> 版本和包的版本. 每一个环境之间的 <code>python</code> 和包版本都是相互独立的. 这样子在运行项目时, 我们可以选择特定的某一个环境, 从而使用某个特定的 <code>python</code> 版本与包版本.</p>
<h3 id="虚拟环境管理"><a href="#虚拟环境管理" class="headerlink" title="虚拟环境管理"></a>虚拟环境管理</h3><p>网上很多推荐使用 <span class="exturl" data-url="aHR0cHM6Ly93d3cuYW5hY29uZGEuY29tLw==">Anaconda<i class="fa fa-external-link-alt"></i></span> 来进行包和环境的管理, 我觉得可以但没必要, 一是臃肿二是让新手有点摸不着头脑. 不过等熟练之后用倒是个不错的选择.</p>
<p>这里只介绍一下 <code>python</code> 自带的 <code>venv</code> 模块使用以及第三方包 <code>virtualenvwrapper-win</code> 的使用.</p>
<h4 id="在环境中安装第三方包"><a href="#在环境中安装第三方包" class="headerlink" title="在环境中安装第三方包"></a>在环境中安装第三方包</h4><p>一般来说, 安装完 <code>python</code> 之后, 就会有一个 &quot;本地环境&quot;, 而将除本地环境之外的其他环境通常 &quot;虚拟环境&quot;.</p>
<p>在运行 <code>python</code> 程序时, 是按照所指定的 <code>python</code> 解释器来决定使用的环境的.</p>
<p>我们在命令行里可以直接使用 <code>python</code> 指令, 实际上是因为我们在安装时勾选了 &quot;Add Python 3.8 to PATH&quot;, 在环境变量 <code>PATH</code> 中添加了本地环境中 <code>python</code> 解释器的路径, 所以在使用 <code>python</code> 指令时, 实际上就是使用了本地环境.</p>
<p>通常主要使用内置的 <code>pip</code> 模块进行第三方包的管理, 并且有以下几个常用命令.</p>
<ul>
<li><p><code>&lt;解释器&gt; -m pip list &lt;包名&gt;</code>: 列出当前环境所有安装的包.</p>
</li>
<li><p><code>&lt;解释器&gt; -m pip install &lt;包名&gt;</code>: 安装包.</p>
</li>
<li><p><code>&lt;解释器&gt; -m pip install &lt;包名&gt;</code>: 卸载包.</p>
</li>
</ul>
<p><code>&lt;解释器&gt;</code> 就是你要进行包管理的环境的解释器 <code>python.exe</code> 路径, 对于本地环境来说就是直接使用的 <code>python</code> 命令.</p>
<p><code>-m pip</code> 表示调用了指定解释器中的 <code>pip</code> 模块进行包的管理.</p>
<p><code>&lt;包名&gt;</code> 则是你需要的包的 &quot;安装名称&quot;, 一般来说它和 <code>import</code> 语句的名字是一致的, 但是也有可能不一样, 推荐去官方的包发布网站 <span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy8=">https://pypi.org/<i class="fa fa-external-link-alt"></i></span> 上进行搜索.</p>
<p>除此之外, <code>pip</code> 也支持使用 <code>whl</code> 文件或者源码安装, 具体的可以自行进一步学习.</p>
<h4 id="创建并使用虚拟环境"><a href="#创建并使用虚拟环境" class="headerlink" title="创建并使用虚拟环境"></a>创建并使用虚拟环境</h4><p>最简单的创建方法是使用自带的 <code>venv</code> 模块, 命令如下.</p>
<p><code>python -m venv &lt;路径&gt;</code></p>
<p>比如使用 <code>python -m venv env</code> 则会在当前目录下生成一个 <code>env</code> 文件夹, 这里面就包含了名为 <code>env</code> 的虚拟环境的解释器以及第三方库.</p>
<p>另外比较重要的文件是 <code>activate</code> 与 <code>deactivate</code>, 用于激活和退出虚拟环境.</p>
<p>具体的使用在后面的部分<a href="#%E5%9C%A8-VS-Code-%E4%B8%AD%E4%BD%BF%E7%94%A8-Python">在 VS Code 中使用 Python</a> 中再进行说明.</p>
<p>另一种方案是使用第三方库 <code>virtualenvwrapper-win</code> 来辅助我们管理虚拟环境.</p>
<p>使用 <code>python -m pip install virtualenvwrapper-win</code> 进行安装. 安装完后, 即可以在命令行中使用以下几个常用命令对机器上的虚拟环境进行集中管理.</p>
<ul>
<li><code>mkvirtualenv &lt;虚拟环境名称&gt;</code>: 创建虚拟环境.</li>
<li><code>workon &lt;虚拟环境名称&gt;</code>: 激活对应的虚拟环境.</li>
<li><code>rmvirtualenv &lt;虚拟环境名称&gt;</code>: 删除虚拟环境.</li>
</ul>
<p>前面的 <code>venv</code> 模块常常用于某个项目内的临时环境, 而 <code>virtualenvwrapper-win</code> 这个第三方工具主要用于你希望自己的电脑上常驻某些不同类别的环境, 并对它们方便的进行集中管理.</p>
<p>默认该模块创建的环境都将位于 <code>%USERPROFILE%\envs</code> 文件夹下,可以通过环境变量 <code>WORKON_HOME</code> 来自定义你希望的存储位置.</p>
<h3 id="常用的第三方包"><a href="#常用的第三方包" class="headerlink" title="常用的第三方包"></a>常用的第三方包</h3><p>对于速通网安, 有一些常用的第三方库总结, 在这里把我自己常用的包情况列举一下.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 用于格式化和检测代码规范的工具</span><br><span class="line">autopep8</span><br><span class="line">pylint</span><br><span class="line"></span><br><span class="line"># 与爬虫有关的库</span><br><span class="line">lxml</span><br><span class="line">beautifulsoup4</span><br><span class="line">requests</span><br><span class="line"></span><br><span class="line"># 与数据处理有关的库</span><br><span class="line">numpy</span><br><span class="line">pandas</span><br><span class="line">matplotlib</span><br><span class="line"></span><br><span class="line"># 机器学习以及深度学习相关的库</span><br><span class="line">opencv-python</span><br><span class="line">scikit-learn</span><br><span class="line"># torch</span><br><span class="line"># torchaudio</span><br><span class="line"># torchvision</span><br><span class="line"></span><br><span class="line"># 在 VS Code 内使用 jupyter notebook 有关的库</span><br><span class="line">ipykernel</span><br><span class="line">jupyter</span><br></pre></td></tr></table></figure>

<p>其中 <code>torch</code> 的安装需要前往官网 <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">https://pytorch.org/<i class="fa fa-external-link-alt"></i></span> 按说明进行安装.</p>
<h2 id="在-VS-Code-中使用-Python"><a href="#在-VS-Code-中使用-Python" class="headerlink" title="在 VS Code 中使用 Python"></a>在 VS Code 中使用 Python</h2><p>这一节将会实践一下前面所有的内容, 在 <code>VS Code</code> 中使用 <code>python</code> 完成一次向量乘法计算.</p>
<p>打开之前曾经创建的 <code>example</code> 文件夹, 并且新建一个终端.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vNUegI.png" alt="vNUegI.png"></p>
<p>我们使用以下命令为这个项目建立一个单独的虚拟环境, 取名为 <code>env</code>.</p>
<p><code>python -m venv env</code></p>
<p><img data-src="/static/image/wast-pythonandvsc/vNami4.png" alt="vNami4.png"></p>
<p>命令执行完成后, 左边的资源管理器面板上多出来一个 <code>env</code> 文件夹, 这就是我们刚刚创建好的虚拟环境. 我们使用 <code>.\env\Scripts\activate</code> 在终端中激活这个虚拟环境, 激活完成后可以看到终端的提示信息前面多了一个 <code>(env)</code> 标记, 表示当前终端处于 <code>env</code> 的虚拟环境之下.</p>
<p>如果出现不能执行的情况, 可以参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGF4aW9uZzEzMTQvcC8xNjI2NTU0OS5odG1s">这篇博客<i class="fa fa-external-link-alt"></i></span>解决权限问题. 或者在 <code>VS Code</code> 的设置里把默认的终端类型调成 <code>cmd</code> 而不是 <code>powershell</code>, 我推荐改成 <code>cmd</code> 一劳永逸. <del><code>powershell</code> 屁事多</del>.</p>
<p>解决完问题之后就如下图所示了.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vNdYn0.png" alt="vNdYn0.png"></p>
<p>此时在终端里直接执行 <code>python</code> 有关的命令, 都会映射到虚拟环境里的命令.</p>
<p>然后我们继续, 使用 <code>pip</code> 向虚拟环境里添加一个第三方库 <code>numpy</code>.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vNwSvn.png" alt="vNwSvn.png"></p>
<p>顺利安装完成之后, 可以看到左边的 <code>env</code> 文件夹里 <code>site-packages</code> 下多出来一个 <code>numpy</code> 的文件夹, 这就是我们刚刚安装好的第三方库了. 同时终端里给了我们一个 <code>WARNING</code>, 提示我们可以对 <code>pip</code> 模块进行升级. 虽然影响不是很大, 不过推荐复制它提供的指令升一下级, 这样 <code>pip</code> 在查找和安装包时能够使用最新的功能, 减小安装失败的风险<del>主要是有彩色进度条</del>.</p>
<p>然后清空之前 <code>main.py</code> 里面的代码, 并且敲入以下新的内容.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vNDSvd.png" alt="vNDSvd.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    vector1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">    vector2 = np.array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(np.dot(vector1, vector2))</span><br><span class="line">    <span class="built_in">print</span>(np.multiply(vector1, vector2))</span><br></pre></td></tr></table></figure>

<p>会发现 <code>import</code> 语句的 <code>numpy</code> 有黄色波浪线, 同时下面的 &quot;问题&quot; 面板有写出来原因, 意思是没有 <code>numpy</code> 这个库.</p>
<p>这是因为虽然我们刚刚在终端里是已经成功激活了虚拟环境, 但是对于 <code>VS Code</code> 来说, 它并不关心终端里是什么情况, 而是对于这个项目来说, 它需要使用什么环境来处理项目内容, 所以我们还需要在下方的状态栏里切换 <code>VS Code</code> 对于当前项目使用的 <code>python</code> 环境.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vN0OpQ.png" alt="vN0OpQ.png"></p>
<p>点击下方状态栏的环境选择, 并且切换到刚刚创建的 <code>env</code> 环境, 此时下方的环境已经换成了 <code>&#39;env&#39;:venv</code>, 并且刚刚的黄色波浪线与问题也消失了.</p>
<p>此时我们可以选择在激活了虚拟环境的终端里运行这份代码, 或者使用快捷键 <code>Ctrl + F5</code> 让 <code>VS Code</code> 帮我们运行. 这里展示一下在终端里直接运行的结果, 可以看到成功输出, 一个是向量内积结果, 一个是向量按位乘法结果.</p>
<p><img data-src="/static/image/wast-pythonandvsc/vNDsPO.png" alt="vNDsPO.png"></p>
<h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>到这里就结束了, 说实话只讲了 <code>VS Code</code> 中使用 <code>python</code> 的最基本技巧, 这些操作之后写代码的时候多操作几次应该就烂熟于心了.</p>
<p>但是对于进校没多久的萌新们来说, 估计看的还是很晕的, 因为有很多新名词, 特别是 &quot;环境变量&quot; 这种, 可能是完全第一次听说, 而且也容易出问题. 所以还是建议多动手尝试尝试, 并且善用搜索引擎, 多翻几篇博客, 总会能够找到适合你问题的解决方案.</p>
<p>就这样了, 下回单独写写怎么合理的科学上网, 为使用 <code>Github</code> <del>抄代码</del>打下坚实基础.</p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>新手入门</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>VS Code</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 Requests 的爬虫入门</title>
    <url>//posts/2022/08/16/wast-spider/</url>
    <content><![CDATA[<p>本篇是基于 <code>python</code> 语言及其第三方库 <code>requests</code> 的爬虫入门, 实现一个最简单的爬虫, 从网页上自动化获取我们能想要的信息.</p>
<span id="more"></span>

<p>教程要开始加速了! 从本篇开始, 默认你已经有了一些编程基础, 并且对 <code>python</code> 已经有过不少的使用经验, 将以速通为根本目的, 进行示范性操作, 而不会过深的涉及代码原理. <del>努力成为一个调包侠吧!</del></p>
<h2 id="工具与环境准备"><a href="#工具与环境准备" class="headerlink" title="工具与环境准备"></a>工具与环境准备</h2><p>浏览器: <code>Edge</code>, <code>Chrome</code>, <code>Firefox</code> 均可, 推荐使用 <code>Firefox</code>, 抓包更方便.</p>
<p><code>python</code> 的第三方库: <code>beautifulsoup4</code>, <code>lxml</code>, <code>requests</code>.</p>
<h2 id="爬虫基本原理"><a href="#爬虫基本原理" class="headerlink" title="爬虫基本原理"></a>爬虫基本原理</h2><p>爬虫的本质是在模仿用户操作浏览器的过程.</p>
<p>我们平常看到的网页内容, 都是通过操作浏览器, 浏览器再向服务器请求内容从而呈现给用户, 省去复杂的网络通信过程之后, 可以简要概括成下面的流程图.</p>
<p><img data-src="/static/image/wast-spider/v0cQQx.png" alt="v0cQQx.png"></p>
<p>我们的目标就是使用代码来完成其中的发出请求和接收响应的过程.</p>
<h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><p>下面以百度热搜的游戏榜为例, 梳理一下每一步, 最后写一个爬虫出来.</p>
<h3 id="分析网站"><a href="#分析网站" class="headerlink" title="分析网站"></a>分析网站</h3><p>这是第一步也是最重要的一步, 通常使用浏览器的开发人员工具, 对你想要抓取的页面进行网络请求分析, 观察请求是如何发起, 想要的内容响应返回后出现在什么地方.</p>
<p>目标网页网址为 <code>https://top.baidu.com/board?tab=game</code>, 浏览器查看一下长这样.</p>
<p><img data-src="/static/image/wast-spider/v0hSFU.png" alt="v0hSFU.png"></p>
<p>我们的目标是获得整个榜按顺序所有游戏的<strong>名字</strong>, <strong>热搜指数</strong>, <strong>类型</strong>以及<strong>详情页链接</strong>.</p>
<p>打开我们的 <code>Firefox</code> 浏览器 (其他浏览器也是类似的), 首先快捷键 <code>F12</code> 或者更多工具里打开 &quot;开发者工具&quot;, 并切换到 &quot;网络&quot; 选项卡.</p>
<p><img data-src="/static/image/wast-spider/v0hhc9.png" alt="v0hhc9.png"></p>
<p>此时我们的页面停留在目标页面, 并且没有任何的记录信息, 因此我们选择 &quot;重新载入&quot; 或者刷新一次页面, 让浏览器重新发起一次请求.</p>
<p><img data-src="/static/image/wast-spider/v04mBq.png" alt="v04mBq.png"></p>
<p>查看网络请求的第一项, 也就是向目标网址发起的请求, 并选择右侧的响应选项卡, 可以看到我们要的内容已经预览出来了.</p>
<p>所以我们确定爬取内容的方案, 就是直接请求目标网址, 然后获得文本内容响应即可.</p>
<h3 id="请求网页"><a href="#请求网页" class="headerlink" title="请求网页"></a>请求网页</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">res = requests.get(<span class="string">&quot;https://top.baidu.com/board?tab=game&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(res.status_code)</span><br><span class="line"></span><br><span class="line">Path(<span class="string">&quot;a.html&quot;</span>).write_text(res.text, encoding=<span class="string">&quot;utf8&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>代码如上所示, 我们在这里解释一下关键代码 <code>requests.get</code>.</p>
<p>在之前的网络请求面板中, 除了看到了响应, 我们还能够看到左侧的信息栏里, 有 &quot;状态&quot; 与 &quot;方法&quot; 两个取值, 分别为 <code>200</code> 和 <code>GET</code>.</p>
<p>方法: 当浏览器向服务器发出请求时, 请求是有不同类型的, 其基本的区分标志就是该请求的方法 (Method), 常见的有 <code>GET</code> 与 <code>POST</code>, 此处则为 <code>GET</code> 请求方法.</p>
<p>状态: 当服务器送回响应时, 除了相应的内容, 还会有一个基本要素 &quot;响应状态码&quot; (Status Code), 用来标识此次请求操作的结果 (而非请求需要的内容), 可以通过状态码来判断返回内容的类别. 通常为 <code>2XX</code>, <code>4XX</code> 等三位数字, 此处的 <code>200</code> 则是表示请求成功, 并正确的返回了响应内容.</p>
<p>所以代码里的 <code>requests.get</code> 就是对参数里的 url 使用 <code>GET</code> 方法发起了请求, 并将响应存储到了 <code>res</code> 变量中, 随后将响应的状态码打印出来.</p>
<p>将响应的文本内容保存至本地文件 <code>a.html</code> 中, 等待后续进一步分析.</p>
<h3 id="分析网页结构与内容"><a href="#分析网页结构与内容" class="headerlink" title="分析网页结构与内容"></a>分析网页结构与内容</h3><p>与网站的交互就到此暂告一段落了, 接下来是对网页内容的分析, 从中提取出我们想要的内容.</p>
<p>在 <code>VS Code</code> 中打开刚刚保存的 <code>a.html</code>, 并且使用自带格式化程序整理一下, 再使用 <code>Ctrl + F</code> 搜索内容中的关键词进行快速定位.</p>
<p><img data-src="/static/image/wast-spider/v0oHrd.png" alt="v0oHrd.png"></p>
<p>定位完成后, 我们分析数据附近的结构.</p>
<p><img data-src="/static/image/wast-spider/v0TFZn.png" alt="v0TFZn.png"></p>
<p>贴一个缩小后的图, 由 <code>html</code> 的树形结构可以知道, 红框里的每一个 <code>&lt;div&gt;</code> 块内就是榜上排名的其中一项游戏数据, 而它们的嵌套结构也很容易分析, 所有红框所示的数据都位于 <code>&lt;main&gt;</code> 的第二个 <code>&lt;div&gt;</code> 的第一个 <code>&lt;div&gt;</code> 的第二个 <code>&lt;div&gt;</code> 内, 不过这个嵌套有点稍长, 我们尝试看看最近的一个 <code>div</code> 是否有独特性.</p>
<p>使用 <code>Ctrl + F</code> 搜索最里层的 <code>&lt;div&gt;</code> 块的属性 <code>style</code> 的内容 <code>margin-bottom:20px</code>, 惊喜的发现只查找到了一个, 所以我们待会可以直接定位到这一层, 然后依次获取它下面的子级 <code>&lt;div&gt;</code> 内容, 也就是我们要的数据.</p>
<p>我们继续分析红框所示的 <code>&lt;div&gt;</code> 块内容, 它的内容由 3 部分组成, 分别是 <code>&lt;a&gt;</code>, <code>&lt;div&gt;</code> 和 <code>&lt;div&gt;</code>, 而我们需要的内容就位于后两个 <code>&lt;div&gt;</code> 中.</p>
<p>按同样的方式可以继续分析最终的文本数据位于何处, 此处不再赘述.</p>
<h3 id="从网页内容提取数据"><a href="#从网页内容提取数据" class="headerlink" title="从网页内容提取数据"></a>从网页内容提取数据</h3><p>面对这种有良好嵌套结构层次的网页, 我们使用 <code>beautifulsoup4</code> 对其进行内容解析, 下面直接贴代码.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">soup = BeautifulSoup(res.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">items_div = soup.find(<span class="string">&quot;div&quot;</span>, &#123;<span class="string">&quot;style&quot;</span>: <span class="string">&quot;margin-bottom:20px&quot;</span>&#125;).find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">for</span> div <span class="keyword">in</span> items_div:</span><br><span class="line">    index = div.find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">0</span>].find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].get_text(strip=<span class="literal">True</span>)</span><br><span class="line">    name = div.find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].find(<span class="string">&quot;a&quot;</span>, recursive=<span class="literal">False</span>).find(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>).get_text(strip=<span class="literal">True</span>)</span><br><span class="line">    link = div.find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].find(<span class="string">&quot;a&quot;</span>, recursive=<span class="literal">False</span>).attrs[<span class="string">&quot;href&quot;</span>]</span><br><span class="line">    type_ = div.find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">1</span>].find_all(<span class="string">&quot;div&quot;</span>, recursive=<span class="literal">False</span>)[<span class="number">0</span>].get_text(strip=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>\t<span class="subst">&#123;index&#125;</span>\t<span class="subst">&#123;type_&#125;</span>\t<span class="subst">&#123;link&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>代码中变量 <code>items_div</code> 其中一个 <code>div</code> 的 <code>html</code> 内容也附上.</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;category-wrap_iQLoo square_1ULM9&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;img-wrapper_29V76&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">href</span>=<span class="string">&quot;https://www.baidu.com/s?wd=%E5%8E%9F%E7%A5%9E+%E6%B8%B8%E6%88%8F<span class="symbol">&amp;amp;</span>sa=fyb_game_all<span class="symbol">&amp;amp;</span>rsv_dl=fyb_game_all&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;index_1Ew5p c-index-bg1&quot;</span>&gt;</span> 1 <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span></span></span><br><span class="line"><span class="tag">            <span class="attr">src</span>=<span class="string">&quot;https://fyb-1.cdn.bcebos.com/fyb-1/20220811/4d0a80d59a3675130cf61eff31e3ae41?x-bce-process=image/resize,m_fill,w_214,h_214&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">alt</span>=<span class="string">&quot;&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;border_3WfEn&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;trend_2RttY&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;img-wrap_JPOmE trend-icon_1Z3Cd&quot;</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span></span></span><br><span class="line"><span class="tag">                <span class="attr">src</span>=<span class="string">&quot;//fyb-pc-static.cdn.bcebos.com/static/asset/icon-same_886375f242bd1538af21a9721f16b170.png&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;hot-index_1Bl1a&quot;</span>&gt;</span> 228934 <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;text_1lUwZ&quot;</span>&gt;</span> 热搜指数 <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">&quot;line_3-bzA&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">src</span>=<span class="string">&quot;//fyb-pc-static.cdn.bcebos.com/static/asset/line-bg@2x_95cb5a089159c6d5a959a596d460d60a.png&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content_1YWBm&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.baidu.com/s?wd=%E5%8E%9F%E7%A5%9E+%E6%B8%B8%E6%88%8F<span class="symbol">&amp;amp;</span>sa=fyb_game_all<span class="symbol">&amp;amp;</span>rsv_dl=fyb_game_all&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">class</span>=<span class="string">&quot;title_dIF3B &quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;c-single-text-ellipsis&quot;</span>&gt;</span> 原神 <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--s-frag--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;intro_1l0wp&quot;</span>&gt;</span> 类型：单机游戏 <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;c-single-text-ellipsis desc_3CTjT&quot;</span>&gt;</span></span><br><span class="line">            陌生的天空下，少年少女立于尘沙。你们是一对旅行中的双子，从世界之外漂流而来。你的血亲被陌生的神灵带走，而你也被神封印，陷入沉眠。再度醒来，天地间风景已变……《原神》是由米哈游自研的一款全新开放世界冒险RPG。你将在游戏中探索一个被称作「提瓦特」的幻想世界。在这广阔的世界中，你可以踏遍七国，邂逅性格各异、能力独特的同伴，与他们一同对抗强敌，踏上寻回血亲之路；也可以不带目的地漫游，沉浸在充满生机的世界</span><br><span class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.baidu.com/s?wd=%E5%8E%9F%E7%A5%9E+%E6%B8%B8%E6%88%8F<span class="symbol">&amp;amp;</span>sa=fyb_game_all<span class="symbol">&amp;amp;</span>rsv_dl=fyb_game_all&quot;</span></span></span><br><span class="line"><span class="tag">                <span class="attr">class</span>=<span class="string">&quot;look-more_3oNWC&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span> 查看更多<span class="symbol">&amp;gt;</span> <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--/s-frag--&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>代码稍显冗长, 首先是获得 <code>soup</code>, 也就是解析好的文档内容, 然后是反复的调用核心函数 <code>find</code> 和 <code>find_all</code>.</p>
<p><code>bs4</code> 的理念是, 整个文档 <code>soup</code> 会被视作一个文档树, 且其中的子节点也是相同的小文档树, 形成一个递归结构. 而使用这两个函数则可以很方便的在树中进行遍历与查找.</p>
<p>两个函数参数相同, 详情可以查阅使用文档, 唯一不同的地方是 <code>find</code> 只获取找到的第一个节点而 <code>find_all</code> 则会获取所有节点返回一个列表. 我们给所有的调用都加上了 <code>recursive=False</code>, 这样可以确保让我们一层一层依次往下而不是递归获取内部所有节点, 每一层节点的序号和文档内部的实际情况相对应, 可以自行对比看看每一行是怎么来的.</p>
<p><code>get_text</code> 用来获取当前节点内部所有的文本内容, 加上参数后可以去除首尾的空白.</p>
<h3 id="接下来干什么"><a href="#接下来干什么" class="headerlink" title="接下来干什么"></a>接下来干什么</h3><p>获得数据之后, 我们可以选择保存到文件进行存储.</p>
<p>但是我们获取的东西非常有限, 仅仅只是一个排行榜, 不过在这些数据里, 有一项是详情链接, 后续可以进一步对详情链接的页面进行分析, 从而实现对详情页面内容的抓取, 让爬虫爬的更远一点.</p>
<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p>这次文章内容很简短, 仅仅是实践了一下最基本过程, 并且随着网站数据更新, 页面结构随时会发生变化, 因此还需多多练习.</p>
<p>有很多与爬虫相关的内容, 可以搜索相关的关键词进行进一步学习, 一并贴在下面了.</p>
<p><code>http 协议</code>: 进一步了解请求中的方法和响应中的状态码的含义, 掌握更多浏览器与服务器交互的细节过程.</p>
<p><code>html 文档结构</code>: 了解网页的树形结构, 学习 <code>html</code> 语法.</p>
<p><code>正则表达式</code>: 除了使用 <code>beautifulsoup4</code> 这样的工具结构化处理网页, 也可以按规则直接搜索你想要的所有结果.</p>
<p>一些库的官方文档地址.</p>
<p><code>requests</code>: <span class="exturl" data-url="aHR0cHM6Ly9yZXF1ZXN0cy5yZWFkdGhlZG9jcy5pby8=">https://requests.readthedocs.io/<i class="fa fa-external-link-alt"></i></span></p>
<p><code>beautifulsoup4</code>: <span class="exturl" data-url="aHR0cHM6Ly93d3cuY3J1bW15LmNvbS9zb2Z0d2FyZS9CZWF1dGlmdWxTb3VwL2JzNC9kb2Mv">https://www.crummy.com/software/BeautifulSoup/bs4/doc/<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>必备技能</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>requests</tag>
      </tags>
  </entry>
  <entry>
    <title>给新生的编程工具推荐与基本使用方法</title>
    <url>//posts/2022/08/11/wast-vscandvs/</url>
    <content><![CDATA[<p>此帖面向大一新生刚入门的编程小白, 作为编程工具的常规推荐, 大佬请直接无视orz.</p>
<p>主要讲解一下 <code>Visual Studio Code</code> 和 <code>Visual Studio</code> 的基本使用.</p>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为一个合格的网络空间安全专业本科生, 平常课程作业中最常使用的编程语言应该就是 <code>c</code> 和 <code>python</code>. (信息安全专业也可以参考)</p>
<p><code>c</code> 应该会伴随你四年的本科生涯, 并且将会是大部分人接触的第一门语言, 大一也会有一门课叫 &quot;C语言程序设计&quot;, 这个课包括理论课与实验课两个课头, 相信大家还是会学有所获的.</p>
<p>而 <code>python</code>, 就我这一届来看, 并没有开设和 <code>python</code> 相关的语言课程, 但是, 从速通网安的角度来说, <code>python</code> 是非常推荐学一下的, 毕竟有很多现成的库, 网上的相关资源也非常丰富, 同时很适合做各种课程大作业. <del>人生苦短, 我学python</del>.</p>
<p>所以就我四年的本科使用经验来说, <code>Visual Studio Code</code> 和 <code>Visual Studio</code> 用来写上述两种语言的体验还是非常舒适的, 所以在此进行推荐和软件的使用方法入门.</p>
<h2 id="Visual-Studio-Code"><a href="#Visual-Studio-Code" class="headerlink" title="Visual Studio Code"></a>Visual Studio Code</h2><p>首先是 <code>VS Code</code>. 从本质上来说, <code>VS Code</code> 是一个多功能的文本编辑器, 不管你是否需要写代码, 我都建议你在电脑上装一个, 可以极大的提高你的文本处理效率. <del>珍爱生命, 远离记事本</del>.</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>官网地址是 <span class="exturl" data-url="aHR0cHM6Ly9jb2RlLnZpc3VhbHN0dWRpby5jb20v">https://code.visualstudio.com/<i class="fa fa-external-link-alt"></i></span>. 进去之后的界面现在长这样.</p>
<p><img data-src="/static/image/wast-vscandvs/vGcccj.jpg" alt="vGcccj.jpg"></p>
<p>可以直接点 Download 下载然后快速安装, 不过我不是那么的推荐, 因为直接点下载的是 User 版本, 可能会有奇怪的权限问题. 推荐下能够获取系统权限的版本比较好, 并且可以安装在系统目录.</p>
<p>所以按下图直接点到其他版本的选择页面, 选 64 bit System 版本下载.</p>
<p><img data-src="/static/image/wast-vscandvs/vGgPvd.png" alt="vGgPvd.png"></p>
<p><img data-src="/static/image/wast-vscandvs/vGgNPU.png" alt="vGgNPU.png"></p>
<p>下载完之后点击安装, 接下来提一下几个比较有用的安装选项, 可以极大的提高你的使用体验.</p>
<p><img data-src="/static/image/wast-vscandvs/vGRJ9U.png" alt="vGRJ9U.png"></p>
<p>这个界面上的选项建议全勾上, 第 2 个和第 3 个选项可以在你的右键菜单里添加 &quot;通过 Code 打开&quot; 的选项, 这样子你可以很方便的直接使用右键点击文件或者文件夹或者文件夹的空白处, 然后把他们在 <code>VS Code</code> 中打开进行操作.</p>
<p>第 5 个选项平常不会怎么用到, 但是保持默认选项勾上就可以了, 它可以让你在命令行中用 <code>Code</code> 进行操作</p>
<p>一路下一步, 然后就安装完成, 之后可以选择重启一下电脑让一些配置立即生效, 不过不重启也没关系, 没啥影响.</p>
<h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><p>首先说说平常写代码时候, 一般来说都是至少以一个文件夹作为最小单位来操作 (除非真的是非常临时的一份小脚本, 否则都推荐弄个文件夹舒服, 里面不仅放代码同时也放代码要引用和生成的其他文件).</p>
<p>这个文件夹就是你的项目文件夹, 一个 Project, 之后会在这个基础上开展你后续的 Coding 工作.</p>
<p>所以基本上你要写点啥课程大作业代码的时候, 第一步就是找个地方新建一个文件夹, 然后用 Code 打开. 这里用一个叫 &quot;example&quot; 的文件夹作为示例, 讲解一下 <code>VS Code</code> 的基本使用方法.</p>
<h4 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h4><p>不管你是用通过右键打开的项目文件夹还是从 &quot;文件&quot; 菜单栏打开的, 之后的界面都应该和下面的图长得差不多, 一片空白.</p>
<p><img data-src="/static/image/wast-vscandvs/vJ85wR.png" alt="vJ85wR.png"></p>
<p>然后我们选到左边的长得像方块的图标, 也就是扩展, 开始按照工作需求自定义我们的 <code>VS Code</code>.</p>
<p><img data-src="/static/image/wast-vscandvs/vJGk6g.png" alt="vJGk6g.png"></p>
<p>可以看到这里已经有一个扩展了, 这也是我们下载 <code>VS Code</code> 几乎必装的一个扩展, 中文汉化扩展, 如果没有预装, 则直接搜索对应的扩展名字装上就可以了. <del>英语大佬请无视中文扩展</del>.</p>
<p>装完会提示重新启动 <code>VS Code</code> 加载, 之后的界面就会像我图里那样全中文了.</p>
<p>然后是编程语言扩展, 这也是最基本的东西, 需要用 <code>VS Code</code> 写什么语言的代码就装什么语言的扩展, 一般直接装 Microsoft 官方的或者 Star 最多的就行.</p>
<p>由于 <code>VS Code</code> 之后基本上用来写 <code>python</code>, 因此这里把 <code>python</code> 扩展先装上, 日后有需求可以自行举一反三.</p>
<p><img data-src="/static/image/wast-vscandvs/vJGj3T.png" alt="vJGj3T.png"></p>
<p>安装完成之后可能会弹出来一些 Get Start 页面, 不用管, 不过有时间的话可以稍微翻一翻, 也是一些新手教程.</p>
<h4 id="第一份代码"><a href="#第一份代码" class="headerlink" title="第一份代码"></a>第一份代码</h4><p><img data-src="/static/image/wast-vscandvs/vJJhI1.png" alt="vJJhI1.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sub</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a - b</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mul</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a * b</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">div</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a / b</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    num1 = add(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    num2 = mul(num1, <span class="number">7</span>)</span><br><span class="line">    num3 = sub(num2, num1)</span><br><span class="line">    num4 = div(num3, num1)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Result: <span class="subst">&#123;num4&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>新建一份文件, 然后随便敲一点东西之后, 得到了现在的 <code>main.py</code> 文件. 下面说说对这份文件最简单的运行和调试.</p>
<h5 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h5><p>有很多方法可以运行, 这里只说两种最简单的, 一是靠鼠标或者快捷键, 二是在命令行里敲命令.</p>
<p><img data-src="/static/image/wast-vscandvs/vJYkZj.png" alt="vJYkZj.png"></p>
<p>图内可以看到菜单栏有个运行选项, 点开就是两个, 一个叫 &quot;启动调试&quot; (<code>F5</code>), 另一个是 &quot;以非调试模式运行&quot; (<code>Ctrl + F5</code>).</p>
<p>前者是调试, 后者是单纯的运行, 对于我们来说, 只需要点击后者, 或者直接快捷键 <code>Ctrl + F5</code>, 就可以看到运行效果了.</p>
<p><img data-src="/static/image/wast-vscandvs/vJY3w9.png" alt="vJY3w9.png"></p>
<p>自动弹出了一个终端, 并且成功的打印出了我们的结果. 到这里第一种方法就结束了, 更多细致的功能日后再慢慢探索吧.</p>
<p>然后是第二种方式, 自己在命令行里敲命令, 那么首先需要知道怎么把终端调用出来.</p>
<p><img data-src="/static/image/wast-vscandvs/vJYBeH.png" alt="vJYBeH.png"></p>
<p><img data-src="/static/image/wast-vscandvs/vJYyFI.png" alt="vJYyFI.png"></p>
<p><img data-src="/static/image/wast-vscandvs/vJY4mQ.png" alt="vJY4mQ.png"></p>
<p>如上图新建一个终端, 然后敲入指令 <code>python main.py</code>, 同样输出了我们的运行结果. 可以看到, 新建的终端会自动打开到我们的项目文件夹目录, 所以可以直接访问到里面的内容, 而我们的所有命令, 也都是基于项目文件夹作为根目录来运行的. (这一点很重要, 如果命令行的工作目录和项目文件夹不一致, 可以自己手动 <code>cd</code> 切换一下, 可以免去写代码时带来的一些路径问题)</p>
<h5 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h5><p>这里简单的调试一下这份文件, 打一下断点, 查看一下运行中变量.</p>
<p>所谓断点, 就是你在调试的时候需要让程序停在哪个点, 从而在某个点可以查看程序的运行情况, 快速定位问题来源.</p>
<p>打上断点的方式也很简单, 比如在第 15 行停下, 那么只需要在行号左边点一下就可以了, 这样子当程序运行到第 15 行的时候, 会停下, 且第 15 行<strong>不会执行</strong>, 是即将要执行的语句.</p>
<p><img data-src="/static/image/wast-vscandvs/vJtKht.png" alt="vJtKht.png"></p>
<p>然后, 从运行菜单里选择 &quot;进行调试&quot; 或者快捷键 <code>F5</code>, 会弹出提示让你选择要使用的调试配置 (因为我们没有给这个项目设定自己的调试配置, 所以需要选择一种系统提供的默认调试配置), 这里直接选第一个就行了.</p>
<p><img data-src="/static/image/wast-vscandvs/vJtyB4.png" alt="vJtyB4.png"></p>
<p>不出意外的话, 程序会稳稳的停在第 15 行, 并且左边跳转到了调试面板, 显示了各种调试信息.</p>
<p><img data-src="/static/image/wast-vscandvs/vJtouD.png" alt="vJtouD.png"></p>
<ul>
<li>变量: 显示了各种局部或者全局的变量值.</li>
<li>监视: 可以手动输入一些变量或者表达式来进行单独观察.</li>
<li>调用堆栈: 显示了函数之间的嵌套调用关系.</li>
<li>断点: 显示当前所有的断点信息, 有三种固有断点, 和程序的报错有关.</li>
</ul>
<p>这里可以看到, 左边变量里, 显示了一个局部变量 <code>num1</code> 等于 5, 这和我们的预期是一致的, 并且第 15 行尚未执行, 所以还没有 <code>num2</code> 这个变量.</p>
<p>然后是调试过程中可以使用的基本操作, 可以看到上方多出来一个条, 有各种调试按钮.</p>
<div class="note info"><p>程序执行过程中, 可能会遇到函数调用, 如果我们需要进入这个函数进行调试, 查看这个函数的内部情况, 则需要使用 &quot;单步调试&quot;, 即一步一步执行, 进入函数内部.</p>
<p>而当你在当前函数内部查看完情况之后, 可能函数还剩很多没执行完, 这个之后需要使用 &quot;单步跳出&quot;, 直接快进到把当前函数执行完成.</p>
<p>有的时候你完全不想进入某个函数, 想直接执行一整行, 这种时候可以使用 &quot;单步跳过&quot;.</p>
<p>最后, 如果你这一片代码已经调试完成, 需要直接快进到下一个断点, 使用 &quot;继续&quot; 则会将程序继续执行, 直到再次遇见断点则停下, 或者直接执行到程序结束.</p>
</div>

<p>这些调试按钮配合左侧面板的调试信息, 可以很清晰的知道程序的执行步骤以及每一步的变化情况, 是解决代码 bug 的利器, 闲暇时间可以多尝试几次, 熟悉调试过程和操作.</p>
<h2 id="Visual-Studio"><a href="#Visual-Studio" class="headerlink" title="Visual Studio"></a>Visual Studio</h2><p>第二个推荐的编程工具是 <code>VS</code>, 相比于 <code>VS Code</code>, <code>VS</code> 更加臃肿但是功能更加强大, 如果用习惯了, 在 Windows 平台上写 <code>c</code> 语言之类的课程作业,  将会是无比舒适.</p>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p><code>VS</code> 的安装分成两步, 首先是安装它专属的 Installer, 然后再决定安装具体的 <code>VS</code> 内容.</p>
<p>官方网站是 <span class="exturl" data-url="aHR0cHM6Ly92aXN1YWxzdHVkaW8ubWljcm9zb2Z0LmNvbS8=">https://visualstudio.microsoft.com/<i class="fa fa-external-link-alt"></i></span>, 目前是 2022 的最新版本, 下的时候选择 Community 版本下载, 这个版本是<strong>面向个人免费使用</strong>的, 只需要注册微软的账户就可以授权给个人了.</p>
<p><img data-src="/static/image/wast-vscandvs/vJ5QCq.png" alt="vJ5QCq.png"></p>
<p>这个东西下完之后是 VS 的 Installer, 直接无脑装好然后运行, 会进入如下的选择界面. (找不到就去开始菜单里翻, 它是不会有桌面快捷方式的)</p>
<p><img data-src="/static/image/wast-vscandvs/vJI6S0.png" alt="vJI6S0.png"></p>
<p><img data-src="/static/image/wast-vscandvs/vJIfw4.png" alt="vJIfw4.png"></p>
<p>默认会直接进到第二张图, 如果不是的话按第一张图自己选安装.</p>
<p>对于我们日常写写作业来说, 我们只需要能够写 <code>c</code> 语言就够了, 所以只需勾选下面其中的一个就完全足够使用了, 那就是 &quot;使用 C++ 的桌面开发&quot;. 虽然写的是 <code>c++</code>, 但是其实写 <code>c</code> 也是用这个写的, 只要你创建源文件的时候, 后缀名自己改成 <code>.c</code> 而不是 <code>.cpp</code>, 这样子编译的时候就会换成 <code>c</code> 的编译方式.</p>
<p><img data-src="/static/image/wast-vscandvs/vJIqOO.png" alt="vJIqOO.png"></p>
<p>这一坨子东西装下来还是要一点空间和时间的, 推荐电脑有空闲时间的时候慢慢挂机安装, 安装完之后重启一下电脑, 让一些系统项生效.</p>
<h3 id="基本使用-1"><a href="#基本使用-1" class="headerlink" title="基本使用"></a>基本使用</h3><p>打开装好的 <code>VS</code>, 我们开始用 <code>c</code> 写一个 Hello World 程序<del>程序员绕不过去的新手代码</del>.</p>
<p>首先会跳出来这个界面, 我们直接选择创建新项目.</p>
<p><img data-src="/static/image/wast-vscandvs/vJOeqP.png" alt="vJOeqP.png"></p>
<p>然后是选择项目模板, 模板类型有很多, 但是我们选择最简单的 &quot;空项目&quot;, 这样子可以后续自己手动创建文件, 了解一下具体的项目结构.</p>
<p>然后是设置名称. 这里有两个内容可以自定义, 一个是项目名称, 一个是解决方案名称.</p>
<p>在 <code>VS</code> 里面创建项目时, 顶层结构不是 &quot;项目&quot; 而是 &quot;解决方案&quot;, 这是与 <code>VS Code</code> 不同的一点. 一个 &quot;解决方案&quot; 是一个更大的容器, 里面可以包含很多的 &quot;项目&quot;, 然后每一个 &quot;项目&quot; 是一个个单独的内容, 用不同的文件夹分门别类的区分开来.</p>
<p>这样子的好处就是, 适应性范围更广, 能够很方便的做多个项目之间的互相调用, 比如你可以一个项目用来写测试, 另一个项目是你实际上要写的代码库.</p>
<p>这里我们把 &quot;解决方案&quot; 的名称设为 &quot;example&quot;, 把项目名称设置为 &quot;c_project&quot;. 这样子实际的物理结构就会是一个 <code>example</code> 的总文件夹下面还有一个 <code>c_project</code> 的项目文件夹.</p>
<p><img data-src="/static/image/wast-vscandvs/vJXf00.png" alt="vJXf00.png"></p>
<p>创建好之后大概长下图所示, 解决方案资源管理器位置可以自己调, 我调左边去了, 视图菜单里也可以手动显示出来.</p>
<p><img data-src="/static/image/wast-vscandvs/vJXztO.png" alt="vJXztO.png"></p>
<h4 id="认识解决方案资源管理器"><a href="#认识解决方案资源管理器" class="headerlink" title="认识解决方案资源管理器"></a>认识解决方案资源管理器</h4><p><code>VS</code> 里面的解决方案资源管理器是一个集合了非常多功能的管理器, 需要熟悉一下它提供给我们的基本功能.</p>
<p>管理器的顶层是解决方案, 也就是刚刚我们命名的 <code>example</code> 文件夹, 然后列出来了里面包含的所有项目, 目前只有一个项目, 就是一起创建的 <code>c_project</code>.</p>
<p>目前看到的这个视图是 &quot;解决方案视图&quot;, 是解决方案内的<strong>逻辑结构</strong>而不是在磁盘上的<strong>物理结构</strong>.</p>
<p>那么我们首先尝试创建一份 <code>main.c</code>, 并写几句代码.</p>
<p>右键 &quot;源文件&quot;, 选择 &quot;添加&quot;, 然后选择 &quot;新建项&quot;, 选择源文件, 同时把文件名设为 <code>main.c</code>. 然后键入经典的 Hello world 程序代码.</p>
<p><img data-src="/static/image/wast-vscandvs/vJjO2Q.png" alt="vJjO2Q.png"></p>
<p><img data-src="/static/image/wast-vscandvs/vJviPU.png" alt="vJviPU.png"></p>
<p><img data-src="/static/image/wast-vscandvs/vJvKIK.png" alt="vJvKIK.png"></p>
<p>可以看到左侧已经成功的在源文件项下面多出来了一份 <code>main.c</code>. 但是刚刚说了目前的界面是解决方案的 &quot;逻辑结构&quot;, 所以我们需要切换一下视图, 看看刚刚创建的文件究竟在哪.</p>
<p><img data-src="/static/image/wast-vscandvs/vJv6Ln.png" alt="vJv6Ln.png"></p>
<p>管理器的上方有一个切换视图按钮, 点击之后可以选择是 &quot;解决方案&quot; 还是 &quot;文件夹视图&quot;, 我们直接换到文件夹视图.</p>
<p><img data-src="/static/image/wast-vscandvs/vJv4WF.png" alt="vJv4WF.png"></p>
<p>这个时候就非常清晰了, 顶层文件夹 <code>example</code>, 次级项目文件夹 <code>c_project</code>, 然后在项目文件夹内有一份 <code>main.c</code>.</p>
<p>切回解决方案视图, 现在再看 &quot;源文件&quot; 这一项, 它其实只是人为设置的一个分类结构, 在 <code>VS</code> 里叫 &quot;筛选器&quot;, 可以在不影响物理结构文件实际路径的同时给开发人员一个合适的文件分类方法, 可以右键新建里添加新的自定义筛选器.</p>
<h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h4><p>既然是写 <code>c</code> 语言, 运行前必不可少的步骤就是编译, 那么首先我们要知道, <code>VS</code> 是如何知道哪些文件是需要被纳入编译范围的.</p>
<p>一个最简单的设置方法就是将文件或者文件夹设置是否包含在项目中. 解决方案视图只会显示在项目中的内容. 即使文件实际上在项目文件夹内, 如果不在项目中, 那它也不会纳入 <code>VS</code> 项目的各种判断逻辑中, 比如不会参与编译.</p>
<p><img data-src="/static/image/wast-vscandvs/vJxqXj.png" alt="vJxqXj.png"></p>
<p>这种方式可以很轻松的把文件排除项目. 那么对于添加到项目里, 比如需要添加现有的文件与源代码, 我们需要首先把对应的文件在物理上移到我们的项目文件夹内合适的地方, 然后使用管理器切换到 &quot;所有文件&quot; 视图.</p>
<p><img data-src="/static/image/wast-vscandvs/vJzQjH.png" alt="vJzQjH.png"></p>
<p>如果刚刚把 <code>main.c</code> 排除了, 那么就会像图上那样有个红色符号, 表示这个文件没有纳入项目逻辑考虑范围. 我们可以用右键把它重新包含到项目内, 这样子红色符号就消失了, 解决方案视图里也能重新看到这个文件了.</p>
<p>当确定了那些文件被包含到项目中后, 就可以开始编译了.</p>
<p>有两种方式会进行编译, 一种是直接运行或者调试程序, 如果项目没有被编译, 则会先进行编译, 再运行程序. 另一种就是只编译不运行, 分步骤进行.</p>
<p>我这里还是推荐分步骤进行, 先编译看看是否存在什么警告或者错误, 再进行运行或者调试.</p>
<p>编译的时候有一些基本选项可以调整.</p>
<p><img data-src="/static/image/wast-vscandvs/vtQxRU.png" alt="vtQxRU.png"></p>
<p><code>x86</code> 和 <code>x64</code> 好理解, 指的是编译出来的二进制文件是 32 位程序还是 64 位程序, 一般来说调成 <code>x64</code> 会让程序能更充分利用现在的 64 位处理器性能.</p>
<p>而 <code>Release</code> 与 <code>Debug</code>, 翻译一般叫 &quot;发布&quot; 与 &quot;调试&quot;. 调试版本是适合于调试代码的版本, <code>VS</code> 在编译时会加入很多调试信息进入最终的二进制文件, 能够在调试时充分的获得程序运行的每一步信息. 而 &quot;发布&quot; 则是适合最终运行的优化版本, <code>VS</code> 会在编译时尽可能的减少代码冗余, 对代码结构进行优化, 提高最终程序的运行效率.</p>
<p>所以写代码的时候用 <code>Debug</code> 版本, 而交程序的时候用 <code>Release</code> 版本. (这两个版本的运行效率差异非常大, 如果你觉得代码太慢, 不妨试一下 <code>Release</code> 来尝试提高效率. <del>说不定有奇效</del>)</p>
<p>然后进入编译的正题. 选择菜单栏里的 &quot;生成&quot;, 在这里可以对解决方案和每个项目进行生成操作. 此处 &quot;生成&quot; 不一定指编译, 而是去生成每个项目的目标文件, 对于 <code>c</code> 语言来说就是编译链接操作. </p>
<p>选择生成整个解决方案, 则 <code>VS</code> 会按照项目间的依赖关系依次生成方案内所有的项目. 选择生成某一个项目, 那就是生成单独的一个项目. 每次可以选择 &quot;重新生成&quot; 或者 &quot;生成&quot;, 前者会先进行一步 &quot;清理&quot; 操作, 把上一次生成时产生的所有文件先清除再进行生成.</p>
<p>一般来说, 直接使用快捷键 <code>Ctrl + B</code> 即可, 会生成当前正在操作的项目.</p>
<p><img data-src="/static/image/wast-vscandvs/vtlezD.png" alt="vtlezD.png"></p>
<p><img data-src="/static/image/wast-vscandvs/vtlnQe.png" alt="vtlnQe.png"></p>
<p>运行一下生成, 可以看到下方的输出里显示生成成功, 并且也输出了生成的二进制文件的路径.</p>
<h4 id="运行与调试"><a href="#运行与调试" class="headerlink" title="运行与调试"></a>运行与调试</h4><p>这里就简单说说, 不赘述了, 因为同为微软家的产品, 基本概念和快捷键都是一样的, 具体的操作和前面 <code>VS Code</code> 中说的大同小异, 几乎是一致的. 这里就放一下成功运行截图了.</p>
<p>按下快捷键 <code>Ctrl + F5</code>, <code>VS</code> 就会自动弹出来一个运行黑框了, &quot;Hello world!&quot;</p>
<p><img data-src="/static/image/wast-vscandvs/vtlJW8.png" alt="vtlJW8.png"></p>
<h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>这一篇就打算写这么多了, 第一次写这种新手教程额, 尽可能的按照一个没有接触过编程但是来到了网安学院的大一新生视角来写, 希望能够有所帮助, 快速入门吧. <del>上啊, 卷死他们!</del></p>
]]></content>
      <categories>
        <category>网安本科速通</category>
        <category>新手入门</category>
      </categories>
      <tags>
        <tag>VS Code</tag>
        <tag>Visual Studio Code</tag>
        <tag>Visual Studio</tag>
        <tag>VS</tag>
      </tags>
  </entry>
  <entry>
    <title>IDM 破解版</title>
    <url>//posts/2023/05/17/idm-cracked/</url>
    <content><![CDATA[<p>IDM 破解版, 下载地址: <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pZkNUaDB3Zjdxa2I=">IDM-v6.41.11-Repack.zip<i class="fa fa-external-link-alt"></i></span>.</p>
<p>校验码:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MD5: EC358D55F0B1657A3095568747CC5B27</span><br><span class="line">SHA1: 8F544AA6CA37BA181A6D942441CC65C0B448FE42</span><br><span class="line">SHA2-256: 8A6DE19A91AE4644762D89C507946AB8E7D096B39D14A32B42C2FAACF9C442DD</span><br><span class="line">SHA3-256: 0679F2F0EB14C58149380429E1229AED27012A5ABC46347AE4742E3975C59079</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>下载工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Typora 破解版</title>
    <url>//posts/2023/07/03/typora-cracked/</url>
    <content><![CDATA[<p>Typora v1.3.8 破解版, 下载地址: <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pWmFuNTBuNGF3cGE=">typora-setup-x64.zip<i class="fa fa-external-link-alt"></i></span>.</p>
<p>安装包安装之后, 将压缩包里的 <code>winmm.dll</code> 文件放到程序安装目录下. 可能会报毒, 需要手动添加信任.</p>
<p>校验码:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MD5: 8AA8CCF545DA329B44E56700C9D2F468</span><br><span class="line">SHA1: A10C3549E148C7C8124AF9A46D4D3882AC86214B</span><br><span class="line">SHA2-256: B997A59F563AD71282CFA99E3B1AD0900E7DE870D27576C5A53D1EC98567900E</span><br><span class="line">SHA3-256: 590592CE225A2D5261B4D2EC892E869E61301ABDCC49D6D78A3AA268A38E1C4D</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>下载工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 10 激活工具</title>
    <url>//posts/2023/02/27/win10activation/</url>
    <content><![CDATA[<p>Windows 10 激活工具存档, 下载地址: <span class="exturl" data-url="aHR0cHM6Ly93dy1ybS5sYW56b3V0LmNvbS9pZFJabjBvbTJqdWQ=">W10_Digital_Activation_Program_v1.4.6_Chs.zip<i class="fa fa-external-link-alt"></i></span>.</p>
<p>校验码:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MD5: A7A44635E59CC9C403EBA7873D1B6D0E</span><br><span class="line">SHA1: 13275066B9D3FBFF8F99AA7CDF89D5AC2E94F571</span><br><span class="line">SHA2-256: E44F2F49A0805F3B0B7CB4720B48CFCAEDB3755189ED12CC49F406B425A40296</span><br><span class="line">SHA3-256: 078D7D813914831F4D19757FE98E89F49177C8EC9DEBA4A7FDEEE1083233D890</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>激活工具</tag>
      </tags>
  </entry>
  <entry>
    <title>扩散模型阅读笔记</title>
    <url>//posts/2022/10/29/diffusion-model/</url>
    <content><![CDATA[<p>本文是对知乎的一篇文章<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81NDgxMTI3MTE=">扩散模型 Diffusion Models - 原理篇<i class="fa fa-external-link-alt"></i></span>的摘要性总结.</p>
<span id="more"></span>

<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p><img data-src="/static/image/diffusion-model/x5xJiR.jpg" alt="x5xJiR.jpg"></p>
<p>前向过程为一张图片 $x_0$ 在经过 $T$ 轮高斯噪声叠加后会变成一张近似纯高斯噪声图 $x_T$, 而网络则是学习反向过程中的参数, 能够通过 $x_T$ 一步步还原出 $x_0$.</p>
<h2 id="前向扩散"><a href="#前向扩散" class="headerlink" title="前向扩散"></a>前向扩散</h2><p>设共进行 $T$ 轮扩散, 有 $\beta_1 &lt; \beta_2 &lt; \dots &lt; \beta_T (0 &lt; \beta_i &lt; 1)$ 的方差参数.</p>
<p>设 $q(x_t|x_{t-1})$ 服从高斯分布, 且:</p>
<p>$$<br>x_t(z;x_{t-1},t)=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}z \sim N(\sqrt{1-\beta_t}x_{t-1}, \beta_t)<br>$$</p>
<p>设 $\alpha_t=1-\beta_t,\bar{\alpha}_t=\prod_{i=1}^t\alpha_t$, 则有:</p>
<p>$$<br>x_t(\epsilon_t;x_0,t)=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon_t \sim N(\sqrt{\bar{\alpha}_t}x_0, 1-\bar{\alpha}_t)<br>$$</p>
<p>则给定 $x_0,t$, 以及高斯随机量 $\epsilon_t$, 可以直接得到对应的 $x_t$.</p>
<h2 id="逆向扩散"><a href="#逆向扩散" class="headerlink" title="逆向扩散"></a>逆向扩散</h2><p>假设 $p(x_{t-1}|x_t;\theta)$ 也服从高斯分布, 则有:</p>
<p>$$<br>x_{t-1}(z;x_t,t) = \mu_t(x_t, t;\theta)+\sigma_t(x_t, t;\theta)z \sim N(\mu_t(x_t, t;\theta), \sigma^2_t(x_t, t;\theta))<br>$$</p>
<p>$p(x_{t-1}|x_t;\theta)$ 无法用公式表示, 但是 $q(x_{t-1}|x_t,x_0)$ 可以, 有:</p>
<p>$$<br>\mu_t = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_t)<br>$$</p>
<p>$$<br>\sigma_t = \sqrt{\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t}<br>$$</p>
<p>$$<br>x_{t-1}(z;x_t,\epsilon_t,t) = \mu_t+\sigma_tz \sim N(\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_t), \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t)<br>$$</p>
<p>(该公式不含 $x_0$, 但是需要有 $x_0$ 的前提下得到, 由前向的公式替换掉了, $\epsilon_t$ 与前向中的 $\epsilon_t$ 是同一个值)</p>
<p>其中, $\sigma_t$ 可近似认为等于 $\sqrt{\beta_t}$.</p>
<h2 id="损失计算"><a href="#损失计算" class="headerlink" title="损失计算"></a>损失计算</h2><p>目标是能够让 $q$ 和 $p$ 尽可能的接近, 用 $q$ 去近似 $p$.</p>
<p>损失需要算 $q(x_{t-1}|x_t,x_0)$ 和 $p(x_{t-1}|x_t;\theta)$ 之间的 KL 散度(分布相似程度), 一通计算之后得到:</p>
<p>$$<br>Loss = E((\mu_t(x_t, \epsilon_t, t)-\mu_t(x_t,t;\theta))^2)<br>$$</p>
<p>优化后:</p>
<p>$$<br>Loss = E((\epsilon_t-\epsilon_t(x_t,t;\theta))^2)<br>$$</p>
<p>可以看出来实际推理中, 只有均值中的 $\epsilon_t$ 是未知的, 因此需要一个网络去猜测 $\epsilon_t$, 使得 $q(x_{t-1}|x_t,x_0)$ 可以近似替代 $p(x_{t-1}|x_t;\theta)$, 来还原 $t-1$ 步的数据.</p>
<p>优化后是去拟合加入的噪声数据, 也就是一个网络输入了 $t$ 时刻的加噪图, 能估计出添加的噪声变量 $\epsilon_t=\epsilon_t(x_t,t;\theta)$, 进而使用 $q(x_{t-1}|x_t,x_0)$ 得到 $x_{t-1}$.</p>
<h2 id="一些编程时的步骤"><a href="#一些编程时的步骤" class="headerlink" title="一些编程时的步骤"></a>一些编程时的步骤</h2><h3 id="基本参数"><a href="#基本参数" class="headerlink" title="基本参数"></a>基本参数</h3><ul>
<li><p>$T$</p>
<p>扩散步数, 至少 $100$ 以上.</p>
</li>
<li><p>$\beta_1 &lt; \beta_2 &lt; \dots &lt; \beta_T (0 &lt; \beta_i &lt; 1)$</p>
<p>每一轮扩散的方差, 在满足大小关系的情况下, 尽可能的小, 通常在 $10^{-3}$ 的数量级左右. (应该步骤越多, 方差越精细?)</p>
</li>
</ul>
<h3 id="预计算的值"><a href="#预计算的值" class="headerlink" title="预计算的值"></a>预计算的值</h3><ul>
<li>$\alpha_t=1-\beta_t$</li>
<li>$\bar{\alpha}_t=\prod_{i=1}^t\alpha_t$</li>
</ul>
<h3 id="设计一个神经网络"><a href="#设计一个神经网络" class="headerlink" title="设计一个神经网络"></a>设计一个神经网络</h3><p>输入:</p>
<ul>
<li>$x_t$: 训练集样本经过 $t$ 轮正向扩散后的结果.</li>
<li>$t$: 扩散步数</li>
</ul>
<p>输出:</p>
<ul>
<li>$\epsilon_t(\theta)$: 噪声估计值</li>
</ul>
<h3 id="损失计算方法"><a href="#损失计算方法" class="headerlink" title="损失计算方法"></a>损失计算方法</h3><p>产生一个随机噪声 $\epsilon_t$, 通过网络得到估计值 $\epsilon_t(\theta)$, 计算两者之间的均方差 (MSE损失).</p>
<h3 id="训练步骤"><a href="#训练步骤" class="headerlink" title="训练步骤"></a>训练步骤</h3><p>给定训练集 $X$, 去拟合每个样本 $x$ 在每个步骤 $t$ 时刻的噪声估计.</p>
<h3 id="推理步骤"><a href="#推理步骤" class="headerlink" title="推理步骤"></a>推理步骤</h3><p>给定一个真实样本 $x_t$, 指定其 $t$ 值, 根据网络得到噪声估计 $\epsilon_t(\theta)$, 计算出 $\mu_t$ 和 $\sigma_t$, 采样一个随机标准高斯噪声 $z$, 计算 $x_{t-1} = \mu_t+\sigma_tz$</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>图像生成</tag>
        <tag>扩散模型</tag>
        <tag>Diffusion Model</tag>
      </tags>
  </entry>
  <entry>
    <title>MultiheadAttention 使用方法</title>
    <url>//posts/2024/01/22/multiheadattention/</url>
    <content><![CDATA[<p>记录一下 PyTorch 中多头注意力 <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9nZW5lcmF0ZWQvdG9yY2gubm4uTXVsdGloZWFkQXR0ZW50aW9uLmh0bWw=">MultiheadAttention<i class="fa fa-external-link-alt"></i></span> 的使用方法, 主要是对维度变换的过程梳理.</p>
<span id="more"></span>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 PyTorch 的文档中, 对于 <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9nZW5lcmF0ZWQvdG9yY2gubm4uTXVsdGloZWFkQXR0ZW50aW9uLmh0bWw=">MultiheadAttention<i class="fa fa-external-link-alt"></i></span> 类有着这么几个与维度有关的构造参数, 影响 <code>forward</code> 传入的 <code>query</code>, <code>key</code>, <code>value</code> 的形状:</p>
<blockquote>
<ul>
<li><code>embed_dim</code> – Total dimension of the model.</li>
<li><code>num_heads</code> – Number of parallel attention heads. Note that <code>embed_dim</code> will be split across <code>num_heads</code> (i.e. each head will have dimension <code>embed_dim // num_heads</code>).</li>
<li><code>kdim</code> – Total number of features for keys. Default: <code>None</code> (uses <code>kdim</code>=<code>embed_dim</code>).</li>
<li><code>vdim</code> – Total number of features for values. Default: <code>None</code> (uses <code>vdim</code>=<code>embed_dim</code>).</li>
</ul>
</blockquote>
<p>在使用自注意力的时候, 前向传播只需要填入相同的参数作为 <code>query</code>, <code>key</code>, <code>value</code>, 不用考虑太多, 但是需要使用填入具有不同维度的 <code>query</code>, <code>key</code>, <code>value</code> 时, 则会令一些不熟悉的新手晕头转向.</p>
<h2 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h2><div class="note info"><p>以下输入并不是 <code>MultiheadAttention</code> 的输入, 只是注意力部分的输入.</p>
</div>

<p>设有三个独立的张量 $Q_{B \times L \times d_k}$, $K_{B \times S \times d_k}$, $V_{B \times S \times d_v}$ 为注意力的输入, 其中 $B$ 指批大小, $L$ 指 $Q$ 的序列长, $S$ 指 $K$ 和 $V$ 的序列长, 那么可以知道输入:</p>
<ul>
<li>$Q$, $K$ 的每个元素长度 (特征数) 相同, 而 $V$ 可以具有独立的元素长度.</li>
<li>$Q$ 的序列长度是独立的, 而 $K$ 和 $V$ 的序列长度必须相等, 因为它们的元素成对出现.</li>
</ul>
<p>下一步则是计算注意力, 也就是经典公式:</p>
<p>$$<br>Attention(Q, K, V) = softmax(\frac{QK^\top}{\sqrt{d_k}})V<br>$$</p>
<p>中间的 $QK^\top$ 将会得到一个 $B \times L \times S$ 的张量, 也就是为每个样本生成了一个 $L \times S$ 的矩阵, 而这个矩阵中间的每个元素就是 $Q$ 和 $K$ 中每个元素的内积.</p>
<p><img data-src="/static/image/multiheadattention/attention.jpg" alt="attention"></p>
<p>如上图所示是一个样本的计算过程, 在获取内积结果之后, 对每一行进行 softmax 操作, 目的是得到 $K$ 中每个元素对于 $Q$ 的每个元素的权重, 然后将与 $K$ 匹配的 $V$ 中的值进行加权平均.</p>
<p>对 $Q$ 中的每个元素来说, 相当于是从一个 KV 表中通过对关键字 (<strong>Key</strong>) 的查询 (<strong>Query</strong>), 来获得了对应每一个值 (<strong>Value</strong>) 的权重, 最后对整个表进行加权平均, 得到了查询结果.</p>
<h2 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h2><p>上一节中我们回顾了注意力部分的内容, 而在完整的注意力模型里, 还有多头处理.</p>
<p>现在, 设我们的原始输入 <code>query</code>, <code>key</code>, <code>value</code> 形状分别为 $(B, L, E_q)$, $(B, S, E_k)$, $(B, S, E_v)$, 然后还有一个 $d_{model}$, 模型使用的隐藏层大小, 以及 $h$, 模型使用的注意力头数.</p>
<p>此时, 我们将会有 $h$ 个线性投影矩阵, 记为 $W^Q_i, W^K_i, W^V_i, i = 0, \ldots, h - 1$, 它们的形状分别为 $(E_q, d_k)$, $(E_k, d_k)$, $(E_v, d_v)$.</p>
<p>每一组 $W^*_i$ 都形成一组注意力头, 对输入的 <code>query</code>, <code>key</code>, <code>value</code> 投影出一组 $Q_i, K_i, V_i$, 并计算出不同方面的 $Attention(Q_i, K_i, V_i)$ 注意力结果.</p>
<p>最后将 $h$ 个长度为 $d_v$ 的注意力结果拼接起来, 将拼接后的结果与一个 $W^O_{hd_v \times d_{model}}$ 进行运算, 得到最后的多头注意力输出, 形状为 $(B, L, d_{model})$.</p>
<h2 id="PyTorch-中的参数设置"><a href="#PyTorch-中的参数设置" class="headerlink" title="PyTorch 中的参数设置"></a>PyTorch 中的参数设置</h2><p>在 PyTorch 的实现中:</p>
<ul>
<li>参数 <code>embed_size</code> 对应 $E_q$.</li>
<li>参数 <code>k_dim</code> 对应 $E_k$.</li>
<li>参数 <code>v_dim</code> 对应 $E_v$.</li>
<li>参数 <code>num_heads</code> 对应 $h$.</li>
<li>$d_{model} = E_q$, 也就是限制了输入 <code>query</code> 的维度和模型的输出维度相同.</li>
<li>$d_k = d_{model} / h$, 要求 <code>embed_size</code> 能够整除 <code>num_heads</code>.</li>
<li>$d_v = d_k$, 即输入注意力的 $V_i$ 与 $Q_i, K_i$ 特征数相同, 输出的注意力结果特征数与输入相同.</li>
<li>$hd_v = d_{model}$. 当 $h = 1$ 时, 有 $d_v = d_k = d_{model} = E_q$.</li>
</ul>
<p>可以看出 PyTorch 内部实现隐含了很多处的维度相等, 并不支持所有的细节调整, 但是完成原始论文中的要求还是绰绰有余.</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9kb2kub3JnLzEwLjQ4NTUwL2FyWGl2LjE3MDYuMDM3NjI=">Attention is All you Need<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9qYWxhbW1hci5naXRodWIuaW8vaWxsdXN0cmF0ZWQtdHJhbnNmb3JtZXIv">The Illustrated Transformer<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9nZW5lcmF0ZWQvdG9yY2gubm4uTXVsdGloZWFkQXR0ZW50aW9uLmh0bWw=">torch.nn.MultiheadAttention<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
        <tag>MultiheadAttention</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Simpleperf 三部曲 (一)</title>
    <url>//posts/2024/07/07/simpleperf1/</url>
    <content><![CDATA[<p>本文是对性能分析工具 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvUkVBRE1FLm1k">Simpleperf<i class="fa fa-external-link-alt"></i></span> 使用文档总结, 也可以看作是文档翻译.</p>
<span id="more"></span>

<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>相比与直接使用 Simpleperf, Android Studio 提供了一个基于 simpleperf 的图形化前端, <span class="exturl" data-url="aHR0cHM6Ly9kZXZlbG9wZXIuYW5kcm9pZC5jb20vc3R1ZGlvL3Byb2ZpbGUvY3B1LXByb2ZpbGVy">Inspect CPU activity with CPU Profiler<i class="fa fa-external-link-alt"></i></span> 文档中介绍了如何使用 CPU Profiler 来分析安卓上的应用性能.</p>
<p>Simpleperf 是 Android 的本地 CPU 分析工具. 它可以用来分析 Android 应用程序和运行在 Android 上的本地进程. 它可以分析 Android 上的 Java 和 c++ 代码. Simpleperf 可执行文件可以在 Android &gt;= L 上运行, Python 脚本可以在 Android &gt;= N 上使用.</p>
<p>Simpleperf 包含两个部分: simpleperf 可执行文件和 Python 脚本.</p>
<p>simpleperf 可执行文件类似于 linux-tools-perf, 但在 Android 性能分析环境中具有一些特定功能:</p>
<ul>
<li>在性能分析数据中收集更多信息. 由于常见的工作流程是&quot;在设备上记录, 并在主机上报告&quot;, simpleperf 不仅在性能分析数据中收集样本, 还收集所需的符号, 设备信息和记录时间.</li>
<li>提供新的记录功能.<ul>
<li>在记录基于 dwarf 的调用图时, simpleperf 在将样本写入文件之前展开堆栈. 这是为了节省设备上的存储空间.</li>
<li>支持使用 <code>--trace-offcpu</code> 选项跟踪 CPU 时间和非 CPU 时间.</li>
<li>支持在 Android P 及以上版本上记录 JIT 编译和解释的 Java 代码的调用图.</li>
</ul>
</li>
<li>与 Android 平台紧密相关.<ul>
<li>了解 Android 环境, 例如使用系统属性启用性能分析, 使用 <code>run-as</code> 在应用程序的上下文中进行性能分析.</li>
<li>支持从 <code>.gnu_debugdata</code> 部分读取符号和调试信息, 因为系统库从 Android O 开始使用 <code>.gnu_debugdata</code> 部分构建.</li>
<li>支持分析嵌入在 apk 文件中的共享库.</li>
<li>使用标准的 Android 堆栈展开器, 因此其结果与所有其他 Android 工具一致.</li>
</ul>
</li>
<li>构建用于不同用途的可执行文件和共享库.<ul>
<li>在设备上构建静态可执行文件. 由于静态可执行文件不依赖于任何库, simpleperf 可执行文件可以推送到任何 Android 设备上并用于记录性能分析数据.</li>
<li>在不同的主机上构建可执行文件: Linux, Mac 和 Windows. 这些可执行文件可用于在主机上报告.</li>
<li>在不同的主机上构建报告共享库. 报告库由不同的 Python 脚本使用来解析性能分析数据.</li>
</ul>
</li>
</ul>
<p>有关 simpleperf 可执行文件的详细文档见 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvUkVBRE1FLm1kI2V4ZWN1dGFibGUtY29tbWFuZHMtcmVmZXJlbmNl">executable-commands-reference<i class="fa fa-external-link-alt"></i></span>.</p>
<p>Python 脚本根据其功能分为三个部分:</p>
<ul>
<li>用于记录的脚本, 如 <code>app_profiler.py</code>, <code>run_simpleperf_without_usb_connection.py</code>.</li>
<li>用于报告的脚本, 如 <code>report.py</code>, <code>report_html.py</code>, <code>inferno</code>.</li>
<li>用于解析性能分析数据的脚本, 如 <code>simpleperf_report_lib.py</code>.</li>
</ul>
<p>这些 Python 脚本在 Python &gt;= 3.9 版本上进行了测试. 旧版本可能不受支持. 有关 Python 脚本的详细文档见 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvUkVBRE1FLm1kI3NjcmlwdHMtcmVmZXJlbmNl">scripts-reference<i class="fa fa-external-link-alt"></i></span>.</p>
<h3 id="simpleperf-中的工具"><a href="#simpleperf-中的工具" class="headerlink" title="simpleperf 中的工具"></a>simpleperf 中的工具</h3><p>simpleperf 可执行文件和 Python 脚本位于 NDK 发布版的 simpleperf/ 目录中, 以及 AOSP 的 system/extras/simpleperf/scripts/ 目录中. 它们的功能如下所列.</p>
<ul>
<li><p><code>bin/</code>: 包含可执行文件和共享库.</p>
<ul>
<li><code>bin/android/$&#123;arch&#125;/simpleperf</code>: 用于设备上的静态 simpleperf 可执行文件.</li>
<li><code>bin/$&#123;host&#125;/$&#123;arch&#125;/simpleperf</code>: 用于主机上的 simpleperf 可执行文件, 仅支持报告功能.</li>
<li><code>bin/$&#123;host&#125;/$&#123;arch&#125;/libsimpleperf_report.$&#123;so/dylib/dll&#125;</code>: 用于主机上的报告共享库.</li>
</ul>
</li>
<li><p><code>*.py</code>, <code>inferno</code>, <code>purgatorio</code>: 用于记录和报告的 Python 脚本. 详细信息见 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2Mvc2NyaXB0c19yZWZlcmVuY2UubWQ=">scripts_reference.md<i class="fa fa-external-link-alt"></i></span>.</p>
</li>
</ul>
<h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><h4 id="在不同-Android-版本上的支持"><a href="#在不同-Android-版本上的支持" class="headerlink" title="在不同 Android 版本上的支持"></a>在不同 Android 版本上的支持</h4><p>在 Android &lt; N 上, 内核可能过旧 (&lt; 3.18), 不支持记录基于 DWARF 的调用图等功能. 在 Android M - O 上, 我们只能分析 C++ 代码和完全编译的 Java 代码. 在 Android &gt;= P 上, ART 解释器支持基于 DWARF 的展开, 因此我们可以分析 Java 代码. 在 Android &gt;= Q 上, 我们可以使用设备上的 simpleperf 来分析已发布的 Android 应用, 只需在 AndroidManifest.xml 中添加 <code>&lt;profileable android:shell=&quot;true&quot; /&gt;</code>.</p>
<h4 id="比较基于-DWARF-和基于堆栈帧的调用图"><a href="#比较基于-DWARF-和基于堆栈帧的调用图" class="headerlink" title="比较基于 DWARF 和基于堆栈帧的调用图"></a>比较基于 DWARF 和基于堆栈帧的调用图</h4><p>Simpleperf 支持两种方式记录调用栈. 一个是基于 DWARF 的调用图, 另一个是基于堆栈帧的调用图. 以下是它们的比较:</p>
<p>记录基于 DWARF 的调用图:</p>
<ul>
<li>需要二进制文件中调试信息的支持.</li>
<li>在 ARM 和 ARM64 上表现良好, 对 Java 代码和 C++ 代码都适用.</li>
<li>每个样本只能展开 64K 的堆栈. 因此不总是可能展开到最底部. 然而, 这在 simpleperf 中得到了缓解, 如下一节所述.</li>
<li>比基于堆栈帧的调用图占用更多的 CPU 时间. 因此它的开销更大, 无法以很高的频率采样 (通常 &lt;= 4000 Hz).</li>
</ul>
<p>记录基于堆栈帧的调用图:</p>
<ul>
<li>需要堆栈帧寄存器的支持.</li>
<li>在 ARM 上表现不佳. 因为 ARM 缺少寄存器, 且 ARM 和 THUMB 代码有不同的堆栈帧寄存器. 因此内核无法展开同时包含 ARM 和 THUMB 代码的用户堆栈.</li>
<li>在 Java 代码上也表现不佳. 因为 ART 编译器不保留堆栈帧寄存器, 并且它无法获取解释的 Java 代码的帧.</li>
<li>在分析 ARM64 上的本机程序时表现良好. 一个例子是分析 surfacelinger. 当它表现良好时, 通常会显示完整的火焰图.</li>
<li>比基于 DWARF 的调用图占用更少的 CPU 时间. 因此采样频率可以达到 10000 Hz 或更高.</li>
</ul>
<p>所以, 如果需要在 ARM 上分析代码或分析 Java 代码, 基于 DWARF 的调用图更好. 如果需要在 ARM64 上分析 C++ 代码, 基于堆栈帧的调用图可能更好. 总之, 可以先尝试基于 DWARF 的调用图, 这是使用 <code>-g</code> 时的默认选项. 因为它总能产生合理的结果. 如果效果不够好, 再尝试基于堆栈帧的调用图.</p>
<h4 id="修复基于-DWARF-的破损调用图"><a href="#修复基于-DWARF-的破损调用图" class="headerlink" title="修复基于 DWARF 的破损调用图"></a>修复基于 DWARF 的破损调用图</h4><p>基于 DWARF 的调用图是通过展开线程堆栈生成的. 当记录一个样本时, 内核会转储最多 64KB 的堆栈数据. 通过基于 DWARF 信息展开堆栈, 我们可以得到调用栈.</p>
<p>造成调用栈破损的两个原因:</p>
<ul>
<li>内核每个样本只能转储最多 64KB 的堆栈数据, 但线程可能有更大的堆栈. 在这种情况下, 我们无法展开到线程的起始点.</li>
<li>我们需要包含 DWARF 调用帧信息的二进制文件来展开堆栈帧. 二进制文件应具有以下部分之一: <code>.eh_frame</code>, <code>.debug_frame</code>, <code>.ARM.exidx</code> 或 <code>.gnu_debugdata</code>.</li>
</ul>
<p>为缓解这些问题:</p>
<p>关于缺少堆栈数据的问题:</p>
<p>为缓解这个问题, simpleperf 在记录后会连接调用链 (调用栈). 如果一个线程的两个调用链有包含相同 ip 和 sp 地址的条目, 那么 simpleperf 尝试连接它们以延长调用链. 因此, 通过更长时间的记录和更多样本的连接, 我们可以获得更完整的调用链. 虽然这不能保证获得完整的调用图, 但通常效果很好.</p>
<p>simpleperf 在展开样本前将其存储在缓冲区中. 如果缓冲区空闲空间不足, simpleperf 可能会决定将样本的堆栈数据截断为 1K. 希望通过调用链连接可以恢复这些数据. 但如果大量样本被截断, 许多调用链可能会破损. 我们可以通过记录命令的输出判断样本是否被截断, 例如:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ simpleperf record ...</span><br><span class="line">simpleperf I cmd_record.cpp:809] Samples recorded: 105584 (<span class="built_in">cut</span> 86291). Samples lost: 6501.</span><br><span class="line"></span><br><span class="line">$ simpleperf record ...</span><br><span class="line">simpleperf I cmd_record.cpp:894] Samples recorded: 7,365 (1,857 with truncated stacks).</span><br></pre></td></tr></table></figure>

<p>有两种方法可以避免截断样本. 一种是增加缓冲区大小, 例如 <code>--user-buffer-size 1G</code>. 但 <code>--user-buffer-size</code> 仅在最新的 simpleperf 中可用. 如果该选项不可用, 可以使用 <code>--no-cut-samples</code> 禁止截断样本.</p>
<p>关于缺少 DWARF 调用帧信息的问题:</p>
<p>大多数 C++ 代码生成的二进制文件包含调用帧信息, 位于 <code>.eh_frame</code> 或 <code>.ARM.exidx</code> 部分. 这些部分不会被剥离, 通常足以进行堆栈展开.</p>
<p>对于 C 代码和一小部分编译器确定不会生成异常的 C++ 代码, 调用帧信息生成在 <code>.debug_frame</code> 部分. 通常 <code>.debug_frame</code> 部分会与其他调试部分一起被剥离 (strip). 解决方法之一是在设备上下载未剥离的二进制文件, 如<span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvUkVBRE1FLm1kI2ZpeC1icm9rZW4tY2FsbGNoYWluLXN0b3BwZWQtYXQtYy1mdW5jdGlvbnM=">这里<i class="fa fa-external-link-alt"></i></span>所述.</p>
<p>编译器不会为函数的序言和尾声生成展开指令, 因为它们操作堆栈帧且不会生成异常. 但分析可能会遇到这些指令, 并且无法展开它们. 这通常在帧图中不重要, 但在基于时间的堆栈图表 (如 Android Studio 和 Firefox 分析器中) 中, 偶尔会导致堆栈间隙. 我们可以通过 <code>--remove-gaps</code> 移除堆栈间隙, 默认情况下已启用此选项.</p>
<h4 id="修复在-C-函数中停止的破损调用链"><a href="#修复在-C-函数中停止的破损调用链" class="headerlink" title="修复在 C 函数中停止的破损调用链"></a>修复在 C 函数中停止的破损调用链</h4><p>使用基于 DWARF 的调用图时, simpleperf 在记录期间生成调用链以节省空间. 展开 C 函数所需的调试信息在 <code>.debug_frame</code> 部分, 通常在 apk 中的本机库中被剥离. 为解决此问题, 我们可以在设备上下载未剥离的本机库, 并在记录时要求 simpleperf 使用它们.</p>
<p>直接使用 simpleperf:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在设备上创建 native_libs 目录, 并推送未剥离的库到其中 (不支持嵌套目录). </span></span><br><span class="line">$ adb shell <span class="built_in">mkdir</span> /data/local/tmp/native_libs</span><br><span class="line">$ adb push &lt;unstripped_dir&gt;/*.so /data/local/tmp/native_libs</span><br><span class="line"><span class="comment"># 使用 --symfs 选项运行 simpleperf record. </span></span><br><span class="line">$ adb shell simpleperf record xxx --symfs /data/local/tmp/native_libs</span><br></pre></td></tr></table></figure>

<p>使用 <code>app_profiler.py</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./app_profiler.py -lib &lt;unstripped_dir&gt;</span><br></pre></td></tr></table></figure>

<h4 id="如何解决报告中缺少符号的问题"><a href="#如何解决报告中缺少符号的问题" class="headerlink" title="如何解决报告中缺少符号的问题"></a>如何解决报告中缺少符号的问题</h4><p><code>simpleperf record</code> 命令在设备上的 <code>perf.data</code> 中收集符号. 但如果你在设备上使用的本机库被剥离, 这会导致报告中有很多未知符号. 解决方案是在主机上构建 <code>binary_cache</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 收集 perf.data 中需要的二进制文件到 binary_cache/ 中. </span></span><br><span class="line">$ ./binary_cache_builder.py -lib NATIVE_LIB_DIR,...</span><br></pre></td></tr></table></figure>

<p>传递给 <code>-lib</code> 选项的 NATIVE_LIB_DIR 是包含主机上未剥离本机库的目录. 运行后, 包含符号表的本机库将收集到 binary_cache/ 中供报告使用.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ./report.py --symfs binary_cache</span><br><span class="line"></span><br><span class="line"><span class="comment"># report_html.py 会自动搜索 binary_cache/, 因此不需要传递任何参数. </span></span><br><span class="line">$ ./report_html.py</span><br></pre></td></tr></table></figure>

<h4 id="显示注释的源代码和反汇编"><a href="#显示注释的源代码和反汇编" class="headerlink" title="显示注释的源代码和反汇编"></a>显示注释的源代码和反汇编</h4><p>要在源代码和指令级别显示热点位置, 我们需要显示带有事件计数注释的源代码和反汇编. simpleperf 支持显示 C++ 代码和完全编译的 Java 代码的注释源代码和反汇编. simpleperf 支持两种方法来实现这一点:</p>
<p>通过 <code>report_html.py</code>:</p>
<ul>
<li>生成 perf.data 并将其拉到主机上.</li>
<li>生成包含调试信息的 elf 文件的 binary_cache. 使用 <code>-lib</code> 选项添加带有调试信息的库. 通过 <code>binary_cache_builder.py -i perf.data -lib &lt;dir_of_lib_with_debug_info&gt;</code> 实现.</li>
<li>使用 <code>report_html.py</code> 生成带有注释源代码和反汇编的 <code>report.html</code>, 如<span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2Mvc2NyaXB0c19yZWZlcmVuY2UubWQjcmVwb3J0X2h0bWxfcHk=">此处<i class="fa fa-external-link-alt"></i></span>所述.</li>
</ul>
<p>通过 <code>pprof</code>:</p>
<ul>
<li>如上所述生成 <code>perf.data</code> 和 <code>binary_cache</code>.</li>
<li>使用 <code>pprof_proto_generator.py</code> 生成 pprof 原型文件.</li>
<li>使用 pprof 报告带有注释源代码的函数, 如<span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2Mvc2NyaXB0c19yZWZlcmVuY2UubWQjcHByb2ZfcHJvdG9fZ2VuZXJhdG9yX3B5">此处<i class="fa fa-external-link-alt"></i></span>所述.</li>
</ul>
<h4 id="减少丢失的样本和堆栈被截断的样本"><a href="#减少丢失的样本和堆栈被截断的样本" class="headerlink" title="减少丢失的样本和堆栈被截断的样本"></a>减少丢失的样本和堆栈被截断的样本</h4><p>使用 simpleperf 记录时, 我们可能会看到丢失的样本或堆栈数据被截断的样本. 在将样本保存到文件之前, simpleperf 使用两个缓冲区在内存中缓存样本. 一个是内核缓冲区, 另一个是用户空间缓冲区. 内核将样本放入内核缓冲区. simpleperf 在处理样本之前将样本从内核缓冲区移动到用户空间缓冲区. 如果缓冲区溢出, 我们会丢失样本或得到堆栈数据被截断的样本. 以下是一个示例.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ simpleperf record -a --duration 1 -g --user-buffer-size 100k</span><br><span class="line">simpleperf I cmd_record.cpp:799] Recorded <span class="keyword">for</span> 1.00814 seconds. Start post processing.</span><br><span class="line">simpleperf I cmd_record.cpp:894] Samples recorded: 79 (16 with truncated stacks).</span><br><span class="line">                                 Samples lost: 2,129 (kernelspace: 18, userspace: 2,111).</span><br><span class="line">simpleperf W cmd_record.cpp:911] Lost 18.5567% of samples <span class="keyword">in</span> kernel space, consider increasing</span><br><span class="line">                                 kernel buffer size(-m), or decreasing sample frequency(-f), or</span><br><span class="line">                                 increasing sample period(-c).</span><br><span class="line">simpleperf W cmd_record.cpp:928] Lost/Truncated 97.1233% of samples <span class="keyword">in</span> user space, consider</span><br><span class="line">                                 increasing userspace buffer size(--user-buffer-size), or</span><br><span class="line">                                 decreasing sample frequency(-f), or increasing sample period(-c).</span><br></pre></td></tr></table></figure>

<p>在上述示例中, 我们得到了 79 个样本, 其中 16 个样本的堆栈数据被截断. 我们在内核缓冲区中丢失了 18 个样本, 在用户空间缓冲区中丢失了 2111 个样本.</p>
<p>要减少内核缓冲区中丢失的样本, 我们可以通过 <code>-m</code> 增加内核缓冲区大小. 要减少用户空间缓冲区中丢失的样本或减少堆栈数据被截断的样本, 我们可以通过 <code>--user-buffer-size</code> 增加用户空间缓冲区大小.</p>
<p>我们还可以减少在固定时间段内生成的样本数量, 例如使用 <code>-f</code> 减少采样频率, 减少监控的线程数量, 不同时监控多个 perf 事件.</p>
<h2 id="Android-应用程序分析"><a href="#Android-应用程序分析" class="headerlink" title="Android 应用程序分析"></a>Android 应用程序分析</h2><p>原文见 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvYW5kcm9pZF9hcHBsaWNhdGlvbl9wcm9maWxpbmcubWQ=">Android application profiling<i class="fa fa-external-link-alt"></i></span>.</p>
<p>分析安卓应用程序涉及三个步骤:</p>
<ol>
<li>准备安卓应用程序.</li>
<li>记录性能分析数据.</li>
<li>报告性能分析数据.</li>
</ol>
<h3 id="准备安卓应用"><a href="#准备安卓应用" class="headerlink" title="准备安卓应用"></a>准备安卓应用</h3><p>根据分析情况, 我们可能需要定制构建脚本, 以专门生成用于分析的 apk 文件. 以下是一些建议.</p>
<hr>
<p>如果你想分析应用程序的调试版本:</p>
<p>对于调试版本类型, Android Studio 在 <code>AndroidManifest.xml</code> 中设置 <code>android:debuggable=&quot;true&quot;</code>, 启用 JNI 检查, 并且可能不会优化 C/C++ 代码. 无需任何更改, simpleperf 就可以分析它.</p>
<hr>
<p>如果你想分析应用程序的发布版本:</p>
<p>对于发布版本类型, Android Studio 在 <code>AndroidManifest.xml</code> 中设置 <code>android:debuggable=&quot;false&quot;</code>, 禁用 JNI 检查并优化 C/C++ 代码. 然而, 由于安全限制, 只有设置了 <code>android:debuggable</code> 为 <code>true</code> 的应用程序才能被分析. 因此, simpleperf 只能在以下三种情况下分析发布版本:</p>
<ol>
<li><p>如果你使用的是已 root 的设备, 可以分析任何应用程序.</p>
</li>
<li><p>如果你使用的是 Android &gt;= Q, 可以在 <code>AndroidManifest.xml</code> 中添加 profileableFromShell 标志, 这使得预装的分析工具可以分析发布的应用程序. 在这种情况下, 通过 adb 下载的 simpleperf 将调用系统镜像中预装的 simpleperf 来分析应用程序.</p>
 <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">manifest</span> <span class="attr">...</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">application</span> <span class="attr">...</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">profileable</span> <span class="attr">android:shell</span>=<span class="string">&quot;true&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">application</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>如果你使用的是 Android &gt;= O, 我们可以使用 <code>wrap.sh</code> 来分析发布版本:</p>
<ol>
<li><p>第一步: 在 <code>AndroidManifest.xml</code> 中添加 <code>android:debuggable=&quot;true&quot;</code> 以启用分析.</p>
 <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">manifest</span> <span class="attr">...</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">application</span> <span class="attr">android:debuggable</span>=<span class="string">&quot;true&quot;</span> <span class="attr">...</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>第二步: 在 <code>lib/arch</code> 目录中添加 <code>wrap.sh</code>. <code>wrap.sh</code> 在不传递任何调试标志给 ART 的情况下运行应用程序, 因此应用程序作为发布应用程序运行. 可以通过在 <code>app/build.gradle</code> 中添加以下脚本来实现 <code>wrap.sh</code>.</p>
 <figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">android &#123;</span><br><span class="line">    buildTypes &#123;</span><br><span class="line">        release &#123;</span><br><span class="line">            sourceSets &#123;</span><br><span class="line">                release &#123;</span><br><span class="line">                    resources &#123;</span><br><span class="line">                        srcDir &#123;</span><br><span class="line">                            <span class="string">&quot;wrap_sh_lib_dir&quot;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">task createWrapShLibDir &#123;</span><br><span class="line">    <span class="keyword">for</span> (String <span class="attr">abi :</span> [<span class="string">&quot;armeabi-v7a&quot;</span>, <span class="string">&quot;arm64-v8a&quot;</span>, <span class="string">&quot;x86&quot;</span>, <span class="string">&quot;x86_64&quot;</span>]) &#123;</span><br><span class="line">        <span class="keyword">def</span> dir = <span class="keyword">new</span> File(<span class="string">&quot;app/wrap_sh_lib_dir/lib/&quot;</span> + abi)</span><br><span class="line">        dir.mkdirs()</span><br><span class="line">        <span class="keyword">def</span> wrapFile = <span class="keyword">new</span> File(dir, <span class="string">&quot;wrap.sh&quot;</span>)</span><br><span class="line">        wrapFile.withWriter &#123; writer -&gt;</span><br><span class="line">            writer.write(<span class="string">&#x27;#!/system/bin/sh\n$@\n&#x27;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<hr>
<p>如果你想分析 C/C++ 代码:</p>
<p>Android Studio 会在 apk 中剥离本机库的符号表和调试信息. 因此, 分析结果可能包含未知符号或损坏的调用图. 为了解决这个问题, 我们可以通过 <code>-lib</code> 选项将包含未剥离本机库的目录传递给 <code>app_profiler.py</code>. 通常, 这个目录可以是你的 Android Studio 项目的路径.</p>
<hr>
<p>如果你想分析 Java 代码:</p>
<ul>
<li>在 Android &gt;= P 上, simpleperf 支持分析 Java 代码, 无论是通过解释器执行, 还是通过 JIT 编译, 或者编译成本机指令. 因此, 你不需要做任何事情.</li>
<li>在 Android O 上, simpleperf 支持分析编译成本机指令的 Java 代码, 并且还需要 wrap.sh 来使用编译后的 Java 代码. 要编译 Java 代码, 我们可以传递 --compile_java_code 选项给 app_profiler.py.</li>
<li>在 Android N 上, simpleperf 支持分析编译成本机指令的 Java 代码. 要编译 Java 代码, 我们可以传递 --compile_java_code 选项给 app_profiler.py.</li>
<li>在 Android &lt;= M 上, simpleperf 不支持分析 Java 代码.</li>
</ul>
<p>以下是使用 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kZW1vL1NpbXBsZXBlcmZFeGFtcGxlQ3Bw">SimpleperfExampleCpp<i class="fa fa-external-link-alt"></i></span> 应用程序的示例. 它构建了一个用于分析的 app-debug.apk.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://android.googlesource.com/platform/system/extras</span><br><span class="line">$ <span class="built_in">cd</span> extras/simpleperf/demo</span><br><span class="line"><span class="comment"># 用 Android Studio 打开 SimpleperfExampleCpp 项目, 并成功构建此项目, 否则下面的 `./gradlew` 命令将失败. </span></span><br><span class="line">$ <span class="built_in">cd</span> SimpleperfExampleCpp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 Windows 上, 使用 &quot;gradlew&quot; 而不是 &quot;./gradlew&quot;. </span></span><br><span class="line">$ ./gradlew clean assemble</span><br><span class="line">$ adb install -r app/build/outputs/apk/debug/app-debug.apk</span><br></pre></td></tr></table></figure>

<h3 id="记录和报告分析数据"><a href="#记录和报告分析数据" class="headerlink" title="记录和报告分析数据"></a>记录和报告分析数据</h3><p>我们可以使用 <code>app_profiler.py</code> 来分析安卓应用程序.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换到 simpleperf 脚本的目录. 记录 perf.data. </span></span><br><span class="line"><span class="comment"># -p 选项通过包名选择被分析的应用程序. </span></span><br><span class="line"><span class="comment"># --compile_java_code 选项将 Java 代码编译成本机指令, Android &gt;= P 上不需要这个选项. </span></span><br><span class="line"><span class="comment"># -a 选项选择要分析的 Activity. </span></span><br><span class="line"><span class="comment"># -lib 选项指定查找调试本机库的目录. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp -a .MixActivity -lib path_of_SimpleperfExampleCpp</span><br></pre></td></tr></table></figure>

<p>这将在当前目录中收集 <code>perf.data</code> 作为性能分析数据, 并在 <code>binary_cache/</code> 中存储相关的本机二进制文件.</p>
<p>通常我们在分析时需要使用应用程序, 否则可能不会记录任何样本. 但在这种情况下, MixActivity 启动了一个忙线程, 因此我们在分析时不需要使用应用程序.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在 stdio 界面中报告 perf.data. </span></span><br><span class="line">$ ./report.py</span><br><span class="line">Cmdline: /data/data/simpleperf.example.cpp/simpleperf record ...</span><br><span class="line">Arch: arm64</span><br><span class="line">Event: task-clock:u (<span class="built_in">type</span> 1, config 1)</span><br><span class="line">Samples: 10023</span><br><span class="line">Event count: 10023000000</span><br><span class="line"></span><br><span class="line">Overhead  Command     Pid   Tid   Shared Object              Symbol</span><br><span class="line">27.04%    BusyThread  5703  5729  /system/lib64/libart.so    art::JniMethodStart(art::Thread*)</span><br><span class="line">25.87%    BusyThread  5703  5729  /system/lib64/libc.so      long StrToI&lt;long, ...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p><code>report.py</code> 在 stdio 界面中报告性能分析数据. 如果报告中有许多未知符号, 请检查此处.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在 html 界面中报告 perf.data. </span></span><br><span class="line">$ ./report_html.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加源代码和反汇编. 如果 source_dirs 路径不正确, 请进行更改. </span></span><br><span class="line">$ ./report_html.py --add_source_code --source_dirs path_of_SimpleperfExampleCpp --add_disassembly</span><br></pre></td></tr></table></figure>

<p><code>report_html.py</code> 会在 <code>report.html</code> 中生成报告, 并弹出浏览器标签页显示它.</p>
<h3 id="记录和报告调用图"><a href="#记录和报告调用图" class="headerlink" title="记录和报告调用图"></a>记录和报告调用图</h3><p>我们可以按如下步骤记录和报告调用图.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 记录基于 DWARF 的调用图: 在 -r 选项中添加 &quot;-g&quot;. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp -r <span class="string">&quot;-e task-clock:u -f 1000 --duration 10 -g&quot;</span> -lib path_of_SimpleperfExampleCpp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录基于栈帧的调用图: 在 -r 选项中添加 &quot;--call-graph fp&quot;. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp -r <span class="string">&quot;-e task-clock:u -f 1000 --duration 10 --call-graph fp&quot;</span> \</span><br><span class="line">        -lib path_of_SimpleperfExampleCpp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 stdio 界面中报告调用图. </span></span><br><span class="line">$ ./report.py -g</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 Python Tk 界面中报告调用图. </span></span><br><span class="line">$ ./report.py -g --gui</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 html 界面中报告调用图. </span></span><br><span class="line">$ ./report_html.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 flamegraphs 中报告调用图. </span></span><br><span class="line"><span class="comment"># 在 Windows 上, 使用 inferno.bat 而不是 ./inferno.sh. </span></span><br><span class="line">$ ./inferno.sh -sc</span><br></pre></td></tr></table></figure>

<h3 id="通过网页接口进行报告"><a href="#通过网页接口进行报告" class="headerlink" title="通过网页接口进行报告"></a>通过网页接口进行报告</h3><p>我们可以使用 report_html.py 在网页浏览器中显示性能分析结果. report_html.py 集成了图表统计, 样本表, 火焰图, 源代码注释和反汇编注释. 它是显示报告的推荐方式.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./report_html.py</span><br></pre></td></tr></table></figure>

<h3 id="展示火焰图"><a href="#展示火焰图" class="headerlink" title="展示火焰图"></a>展示火焰图</h3><p>要显示火焰图, 我们需要先记录调用图. 火焰图可以在 report_html.py 的 &quot;Flamegraph&quot; 标签中显示. 我们也可以使用 inferno 直接显示火焰图.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在 Windows 上, 使用 inferno.bat 而不是 ./inferno.sh. </span></span><br><span class="line">$ ./inferno.sh -sc</span><br></pre></td></tr></table></figure>

<p>我们还可以使用 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JyZW5kYW5ncmVnZy9GbGFtZUdyYXBo">FlameGraph<i class="fa fa-external-link-alt"></i></span> 来生成火焰图. 请确保已安装 Perl.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/brendangregg/FlameGraph.git</span><br><span class="line">./report_sample.py --symfs binary_cache &gt; out.perf</span><br><span class="line">FlameGraph/stackcollapse-perf.pl out.perf &gt; out.folded</span><br><span class="line">FlameGraph/flamegraph.pl out.folded &gt; a.svg</span><br></pre></td></tr></table></figure>

<h3 id="在-Android-Studio-中进行报告"><a href="#在-Android-Studio-中进行报告" class="headerlink" title="在 Android Studio 中进行报告"></a>在 Android Studio 中进行报告</h3><p>simpleperf 的 <code>report-sample</code> 命令可以将 <code>perf.data</code> 转换为 Android Studio CPU 分析器接受的 protobuf 格式. 转换可以在设备上或主机上完成. 如果在主机上有更多符号信息, 建议使用 <code>--symdir</code> 选项在主机上进行转换.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ simpleperf report-sample --protobuf --show-callchain -i perf.data -o perf.trace</span><br><span class="line"><span class="comment"># 然后在 Android Studio 中打开 perf.trace 进行查看. </span></span><br></pre></td></tr></table></figure>

<h3 id="去混淆-Java-符号"><a href="#去混淆-Java-符号" class="headerlink" title="去混淆 Java 符号"></a>去混淆 Java 符号</h3><p>Java 符号可能会被 ProGuard 混淆. 要在报告中恢复原始符号, 可以通过 <code>--proguard-mapping-file</code> 将 ProGuard 映射文件传递给 report 脚本或 <code>report-sample</code> 命令.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./report_html.py --proguard-mapping-file proguard_mapping_file.txt</span><br></pre></td></tr></table></figure>

<h3 id="记录-CPU-时间和非-CPU-时间"><a href="#记录-CPU-时间和非-CPU-时间" class="headerlink" title="记录 CPU 时间和非 CPU 时间"></a>记录 CPU 时间和非 CPU 时间</h3><p>我们可以记录 CPU 时间和非 CPU 时间.</p>
<p>首先检查设备是否支持 <code>trace-offcpu</code> 功能.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ./run_simpleperf_on_device.py list --show-features</span><br><span class="line">dwarf-based-call-graph</span><br><span class="line">trace-offcpu</span><br></pre></td></tr></table></figure>

<p>如果支持 trace-offcpu 功能, 它会显示在功能列表中. 然后我们可以尝试使用它.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./app_profiler.py -p simpleperf.example.cpp -a .SleepActivity -r <span class="string">&quot;-g -e task-clock:u -f 1000 --duration 10 --trace-offcpu&quot;</span> -lib path_of_SimpleperfExampleCpp</span><br><span class="line">./report_html.py --add_disassembly --add_source_code --source_dirs path_of_SimpleperfExampleCpp</span><br></pre></td></tr></table></figure>

<h3 id="从启动开始分析"><a href="#从启动开始分析" class="headerlink" title="从启动开始分析"></a>从启动开始分析</h3><p>我们可以从应用程序启动时进行分析.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 开始 simpleperf 录制, 然后启动要分析的 Activity. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp -a .MainActivity</span><br></pre></td></tr></table></figure>

<p>我们也可以在设备上手动启动 Activity.</p>
<ol>
<li><p>确保应用程序没有运行或不是最近的应用程序之一.</p>
</li>
<li><p>开始 simpleperf 录制.</p>
 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./app_profiler.py -p simpleperf.example.cpp</span><br></pre></td></tr></table></figure></li>
<li><p>在设备上手动启动应用程序.</p>
</li>
</ol>
<h3 id="在应用程序代码中控制记录"><a href="#在应用程序代码中控制记录" class="headerlink" title="在应用程序代码中控制记录"></a>在应用程序代码中控制记录</h3><p>Simpleperf 支持从应用程序代码中控制记录. 以下是工作流程:</p>
<ol>
<li>运行 <code>api_profiler.py prepare -p &lt;package_name&gt;</code> 以允许应用程序使用 simpleperf 记录自身. 默认情况下, 权限在设备重启后会被重置. 因此, 我们需要在每次设备重启后运行该脚本. 但是在 Android &gt;= 13 上, 我们可以使用 <code>--days</code> 选项设置权限持续的天数.</li>
<li>在应用程序中链接 simpleperf app_api 代码. 应用程序需要设置为 debuggable 或 profileableFromShell, 如 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvYW5kcm9pZF9hcHBsaWNhdGlvbl9wcm9maWxpbmcubWQjcHJlcGFyZS1hbi1hbmRyb2lkLWFwcGxpY2F0aW9u">Prepare an Android application<i class="fa fa-external-link-alt"></i></span> 所述. 然后, 应用程序可以使用 API 来开始/暂停/恢复/停止记录. 为了开始记录, app_api 会 fork 一个运行 simpleperf 的子进程, 并使用管道文件向子进程发送命令. 记录完成后, 会生成一个分析数据文件.</li>
<li>运行 <code>api_profiler.py collect -p &lt;package_name&gt;</code> 将分析数据文件收集到主机.</li>
</ol>
<p>示例可以在 demo 中的 CppApi 和 JavaApi 找到.</p>
<h3 id="手动解析性能分析数据"><a href="#手动解析性能分析数据" class="headerlink" title="手动解析性能分析数据"></a>手动解析性能分析数据</h3><p>我们也可以通过编写 Python 脚本来手动解析分析数据, 通过使用 <a href="https://android.googlesource.com/platform/system/extras/+/main/simpleperf/doc/scripts_reference.md#simpleperf_report_libpy"><code>simpleperf_report_lib.py</code></a> 库. 示例包括 <code>report_sample.py</code> 和<code>report_html.py</code>.</p>
<h2 id="查看分析结果"><a href="#查看分析结果" class="headerlink" title="查看分析结果"></a>查看分析结果</h2><p>使用 <code>simpleperf record</code> 或 <code>app_profiler.py</code> 后, 我们会得到一个分析数据文件. 该文件包含一个样本列表. 每个样本都有时间戳、线程 ID、调用栈、在此样本中使用的事件（如 cpu-cycles 或 cpu-clock）等. 我们有多种查看分析结果的选择. 我们可以按时间顺序显示样本, 或者显示聚合的火焰图. 我们可以以文本格式显示报告, 或者在一些交互式 UI 中显示报告.</p>
<p>以下是一些推荐的查看分析结果的 UI. Google 开发者可以在 go/gmm-profiling 中找到更多示例.</p>
<ul>
<li>Continuous PProf UI (great flamegraph UI, but only available internally)</li>
<li>Firefox Profiler (great chronological UI)</li>
<li>FlameScope (great jank-finding UI)</li>
<li>Differential FlameGraph</li>
<li>Android Studio Profiler</li>
<li>Simpleperf HTML Report</li>
<li>PProf Interactive Command Line</li>
<li>Simpleperf Report Command Line</li>
<li>Custom Report Interface</li>
</ul>
<h3 id="Android-Studio-Profiler"><a href="#Android-Studio-Profiler" class="headerlink" title="Android Studio Profiler"></a>Android Studio Profiler</h3><p>Android Studio Profiler 支持记录和报告应用进程的分析数据. 它支持几种记录方法, 包括使用 simpleperf 作为后端的方法. 您可以使用 Android Studio Profiler 进行记录和报告.</p>
<p>在 Android Studio 中: Open View -&gt; Tool Windows -&gt; Profiler -&gt; Click + -&gt; Your Device -&gt; Profileable Processes -&gt; Your App</p>
<p>点击 &quot;CPU&quot; 图表</p>
<p>选择 Callstack Sample Recording. 即使您使用 Java, 这也能提供更好的可观察性, 包括 ART、malloc 和内核.</p>
<p>点击 Record, 在设备上运行您的测试, 完成后点击 Stop.</p>
<p>点击一个线程轨迹, 并选择 &quot;Flame Chart&quot; 以在左侧查看按时间顺序排列的图表, 在右侧查看聚合的火焰图:</p>
<p>如果您希望在记录选项上有更多灵活性, 或希望添加 proguard 映射文件, 可以使用 simpleperf 进行记录, 并使用 Android Studio Profiler 进行报告.</p>
<p>我们可以使用 <code>simpleperf report-sample</code> 将 <code>perf.data</code> 转换为 Android Studio Profiler 的跟踪文件.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将 perf.data 转换为 Android Studio Profiler 的 perf.trace 文件. </span></span><br><span class="line"><span class="comment"># 如果在 Mac/Windows 上, 使用相应平台的 simpleperf 主机可执行文件. </span></span><br><span class="line">bin/linux/x86_64/simpleperf report-sample --show-callchain --protobuf -i perf.data -o perf.trace</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 proguard 映射文件将 perf.data 转换为 perf.trace. </span></span><br><span class="line">bin/linux/x86_64/simpleperf report-sample --show-callchain --protobuf -i perf.data -o perf.trace \</span><br><span class="line">    --proguard-mapping-file proguard.map</span><br></pre></td></tr></table></figure>

<p>在 Android Studio 中: 打开 File -&gt; Open -&gt; 选择 perf.trace</p>
<hr>
<p>在原文 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2Mvdmlld190aGVfcHJvZmlsZS5tZA==">View the profile<i class="fa fa-external-link-alt"></i></span> 查看更多 UI 的介绍和用法.</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>Simpleperf</tag>
        <tag>Android</tag>
        <tag>安卓性能分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Simpleperf 三部曲 (二)</title>
    <url>//posts/2024/07/07/simpleperf2/</url>
    <content><![CDATA[<p>本文是对性能分析工具 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvUkVBRE1FLm1k">Simpleperf<i class="fa fa-external-link-alt"></i></span> 使用文档总结, 也可以看作是文档翻译.</p>
<p>本篇原文见 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvZXhlY3V0YWJsZV9jb21tYW5kc19yZWZlcmVuY2UubWQ=">Executable commands reference<i class="fa fa-external-link-alt"></i></span>.</p>
<span id="more"></span>

<h2 id="Simpleperf-是如何工作的"><a href="#Simpleperf-是如何工作的" class="headerlink" title="Simpleperf 是如何工作的"></a>Simpleperf 是如何工作的</h2><p>现代 CPU 有一个名为性能监控单元 (PMU) 的硬件组件. PMU有几个硬件计数器, 用于计数诸如发生了多少CPU周期, 执行了多少指令或发生了多少缓存未命中等事件.</p>
<p>Linux 内核将这些硬件计数器封装成硬件性能事件. 此外, Linux 内核还提供与硬件无关的软件事件和跟踪点事件. Linux 内核通过 <code>perf_event_open</code> 系统调用将所有事件暴露给用户空间, 这个调用被 simpleperf 使用.</p>
<p>Simpleperf 有三个主要命令: <code>stat</code>, <code>record</code> 和 <code>report</code>.</p>
<p><code>stat</code> 命令总结在一段时间内被分析的进程中发生的事件数量. 其工作原理如下:</p>
<ul>
<li>根据用户选项, simpleperf 通过对内核进行系统调用来启用分析.</li>
<li>在分析的进程运行时, 内核启用计数器.</li>
<li>分析结束后, simpleperf 从内核读取计数器, 并报告计数器摘要.</li>
</ul>
<p><code>record</code> 命令在一段时间内记录被分析进程的样本. 其工作原理如下:</p>
<ul>
<li>根据用户选项, simpleperf 通过对内核进行系统调用来启用分析.</li>
<li>Simpleperf 在 simpleperf 和内核之间创建映射缓冲区.</li>
<li>在分析的进程运行时, 内核启用计数器.</li>
<li>每当发生一定数量的事件时, 内核将样本转储到映射缓冲区.</li>
<li>Simpleperf 从映射缓冲区读取样本, 并将分析数据存储在名为<code>perf.data</code>的文件中.</li>
</ul>
<p><code>report</code> 命令读取 <code>perf.data</code> 文件和任何被分析进程使用的共享库, 并输出显示时间花费在哪些地方的报告.</p>
<p>Simpleperf 支持以下几个命令:</p>
<ul>
<li><code>debug-unwind</code> 命令: 调试/测试基于 DWARF 的离线展开, 用于调试 simpleperf.</li>
<li><code>dump</code> 命令: 转储 <code>perf.data</code> 中的内容, 用于调试 simpleperf.</li>
<li><code>help</code> 命令: 打印其他命令的帮助信息.</li>
<li><code>kmem</code> 命令: 收集内核内存分配信息 (将被Python脚本替代) .</li>
<li><code>list</code> 命令: 列出 Android 设备上支持的所有事件类型.</li>
<li><code>record</code> 命令: 分析进程并将分析数据存储在 <code>perf.data</code> 中.</li>
<li><code>report</code> 命令: 报告 <code>perf.data</code> 中的分析数据.</li>
<li><code>report-sample</code> 命令: 报告 <code>perf.data</code> 中的每个样本, 用于支持 simpleperf 在 Android Studio 中的集成.</li>
<li><code>stat</code> 命令: 分析进程并打印计数器摘要.</li>
</ul>
<p>每个命令支持不同的选项, 可以通过帮助信息查看.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 列出所有命令. </span></span><br><span class="line">$ simpleperf --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印 record 命令的帮助信息. </span></span><br><span class="line">$ simpleperf record --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<p>以下描述了最常用的命令, 分别是 list, stat, record 和 report.</p>
<h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><p>这个命令列出了设备上所有可用的事件列表. 不同的设备可能支持不同的事件, 因为它们具有不同的硬件和内核.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ simpleperf list</span><br><span class="line">List of hw-cache events:</span><br><span class="line">  branch-loads</span><br><span class="line">  ...</span><br><span class="line">List of hardware events:</span><br><span class="line">  cpu-cycles</span><br><span class="line">  instructions</span><br><span class="line">  ...</span><br><span class="line">List of software events:</span><br><span class="line">  cpu-clock</span><br><span class="line">  task-clock</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure>

<p>在 ARM/ARM64 架构上, <code>list</code> 命令还显示了一组原始事件列表, 这些事件是设备上 ARM 性能监视器单元 (PMU) 支持的事件. 内核已经将其中的一部分包装成了硬件事件和硬件缓存事件. 例如, <code>raw-cpu-cycles</code> 被包装成了 <code>cpu-cycles</code>, <code>raw-instruction-retired</code> 被包装成了<code>instructions</code>. 原始事件的提供是为了在我们希望使用设备上支持的某些事件时, 但不幸的是内核没有将其包装成硬件事件时使用.</p>
<h2 id="stat"><a href="#stat" class="headerlink" title="stat"></a>stat</h2><p>stat 命令用于获取被分析进程的事件计数器值. 通过传递选项, 我们可以选择使用哪些事件, 监控哪些进程/线程, 监控多长时间以及打印间隔.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Stat using default events (cpu-cycles,instructions,...), and monitor process 7394 for 10 seconds.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -p 7394 --duration 10</span><br><span class="line">Performance counter statistics:</span><br><span class="line"></span><br><span class="line"><span class="comment">#         count  event_name                # count / runtime</span></span><br><span class="line">     16,513,564  cpu-cycles                <span class="comment"># 1.612904 GHz</span></span><br><span class="line">      4,564,133  stalled-cycles-frontend   <span class="comment"># 341.490 M/sec</span></span><br><span class="line">      6,520,383  stalled-cycles-backend    <span class="comment"># 591.666 M/sec</span></span><br><span class="line">      4,900,403  instructions              <span class="comment"># 612.859 M/sec</span></span><br><span class="line">         47,821  branch-misses             <span class="comment"># 6.085 M/sec</span></span><br><span class="line">  25.274251(ms)  task-clock                <span class="comment"># 0.002520 cpus used</span></span><br><span class="line">              4  context-switches          <span class="comment"># 158.264 /sec</span></span><br><span class="line">            466  page-faults               <span class="comment"># 18.438 K/sec</span></span><br><span class="line"></span><br><span class="line">Total <span class="built_in">test</span> time: 10.027923 seconds.</span><br></pre></td></tr></table></figure>

<h3 id="选择要统计的事件"><a href="#选择要统计的事件" class="headerlink" title="选择要统计的事件"></a>选择要统计的事件</h3><p>我们可以通过 <code>-e</code> 选项选择要使用的事件 (event).</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Stat event cpu-cycles.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -e cpu-cycles -p 11904 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Stat event cache-references and cache-misses.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -e cache-references,cache-misses -p 11904 --duration 10</span><br></pre></td></tr></table></figure>

<p>当运行 stat 命令时, 如果硬件事件的数量大于 PMU 可用的硬件计数器数量, 内核会在事件之间共享硬件计数器, 因此每个事件仅在总时间的一部分被监控. 结果, 显示的事件数量小于实际发生的事件数量. 以下是一个示例.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Stat using event cache-references, cache-references:u,....</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -p 7394 -e cache-references,cache-references:u,cache-references:k \</span><br><span class="line">      -e cache-misses,cache-misses:u,cache-misses:k,instructions --duration 1</span><br><span class="line">Performance counter statistics:</span><br><span class="line"></span><br><span class="line"><span class="comment">#   count  event_name           # count / runtime</span></span><br><span class="line">  490,713  cache-references     <span class="comment"># 151.682 M/sec</span></span><br><span class="line">  899,652  cache-references:u   <span class="comment"># 130.152 M/sec</span></span><br><span class="line">  855,218  cache-references:k   <span class="comment"># 111.356 M/sec</span></span><br><span class="line">   61,602  cache-misses         <span class="comment"># 7.710 M/sec</span></span><br><span class="line">   33,282  cache-misses:u       <span class="comment"># 5.050 M/sec</span></span><br><span class="line">   11,662  cache-misses:k       <span class="comment"># 4.478 M/sec</span></span><br><span class="line">        0  instructions         <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">Total <span class="built_in">test</span> time: 1.000867 seconds.</span><br><span class="line">simpleperf W cmd_stat.cpp:946] It seems the number of hardware events are more than the number of</span><br><span class="line">available CPU PMU hardware counters. That will trigger hardware counter</span><br><span class="line">multiplexing. As a result, events are not counted all the time processes</span><br><span class="line">running, and event counts are smaller than what really happens.</span><br><span class="line">Use --print-hw-counter to show available hardware counters.</span><br></pre></td></tr></table></figure>

<p>在上述示例中, 我们监控了 7 个事件. 每个事件仅在总时间的一部分被监控. 因为 <code>cache-references</code> 的数量小于 <code>cache-references:u</code> (仅在用户空间的 <code>cache-references</code>) 和 <code>cache-references:k</code> (仅在内核中的 <code>cache-references</code>) . 指令数为零. 在打印结果后, simpleperf 会检查 CPU 是否有足够的硬件计数器来同时计数硬件事件. 如果没有, 它会打印一个警告.</p>
<p>为了避免硬件计数器复用, 我们可以使用 <code>simpleperf stat --print-hw-counter</code> 来显示每个 CPU 上的可用计数器. 然后不要监控比可用计数器更多的硬件事件.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ simpleperf <span class="built_in">stat</span> --print-hw-counter</span><br><span class="line">There are 2 CPU PMU hardware counters available on cpu 0.</span><br><span class="line">There are 2 CPU PMU hardware counters available on cpu 1.</span><br><span class="line">There are 2 CPU PMU hardware counters available on cpu 2.</span><br><span class="line">There are 2 CPU PMU hardware counters available on cpu 3.</span><br><span class="line">There are 2 CPU PMU hardware counters available on cpu 4.</span><br><span class="line">There are 2 CPU PMU hardware counters available on cpu 5.</span><br><span class="line">There are 2 CPU PMU hardware counters available on cpu 6.</span><br><span class="line">There are 2 CPU PMU hardware counters available on cpu 7.</span><br></pre></td></tr></table></figure>

<p>当发生计数器复用时, 无法保证哪些事件在何时被监控. 如果我们希望确保某些事件始终同时被监控, 我们可以使用 <code>--group</code> 选项.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Stat using event cache-references, cache-references:u,....</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -p 7964 --group cache-references,cache-misses \</span><br><span class="line">      --group cache-references:u,cache-misses:u --group cache-references:k,cache-misses:k \</span><br><span class="line">      --duration 1</span><br><span class="line">Performance counter statistics:</span><br><span class="line"></span><br><span class="line"><span class="comment">#     count  event_name           # count / runtime</span></span><br><span class="line">  2,088,463  cache-references     <span class="comment"># 181.360 M/sec</span></span><br><span class="line">     47,871  cache-misses         <span class="comment"># 2.292164% miss rate</span></span><br><span class="line">  1,277,600  cache-references:u   <span class="comment"># 136.419 M/sec</span></span><br><span class="line">     25,977  cache-misses:u       <span class="comment"># 2.033265% miss rate</span></span><br><span class="line">    326,305  cache-references:k   <span class="comment"># 74.724 M/sec</span></span><br><span class="line">     13,596  cache-misses:k       <span class="comment"># 4.166654% miss rate</span></span><br><span class="line"></span><br><span class="line">Total <span class="built_in">test</span> time: 1.029729 seconds.</span><br><span class="line">simpleperf W cmd_stat.cpp:946] It seems the number of hardware events are more than the number of</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="选择要统计的目标"><a href="#选择要统计的目标" class="headerlink" title="选择要统计的目标"></a>选择要统计的目标</h3><p>我们可以通过 <code>-p</code> 或<code>-t</code> 选项选择要监控的进程或线程. 监控一个进程相当于监控该进程中的所有线程. Simpleperf 还可以派生一个子进程来运行新命令, 然后监控该子进程.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计进程 11904 和 11905.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -p 11904,11905 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计名字里包含 &quot;chrome&quot; 的进程.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -p chrome --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正则表达式统计进程名.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -p <span class="string">&quot;chrome:(privileged|sandboxed)&quot;</span> --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计线程 11904 和 11905.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -t 11904,11905 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启子进程 ls 并进行统计.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计安卓应用, 在非 root 设备上, 只能统计 debuggable</span></span><br><span class="line"><span class="comment"># 或者 profileable from shell 的应用.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> --app simpleperf.example.cpp --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 仅统计应用的某个线程.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> --app simpleperf.example.cpp -t 11904 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 -a 进行系统范围的统计.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -a --duration 10</span><br></pre></td></tr></table></figure>

<h3 id="决定统计的时长"><a href="#决定统计的时长" class="headerlink" title="决定统计的时长"></a>决定统计的时长</h3><p>在监控现有线程时, 我们可以使用 <code>--duration</code> 选项来决定监控的时长. 在监控运行新命令的子进程时, simpleperf 会一直监控直到子进程结束. 在这种情况下, 我们可以随时使用 Ctrl-C 来停止监控.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Stat process 11904 for 10 seconds.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -p 11904 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Stat until the child process running `ls` finishes.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Stop monitoring using Ctrl-C.</span></span><br><span class="line">$ simpleperf <span class="built_in">stat</span> -p 11904 --duration 10</span><br><span class="line">^C</span><br></pre></td></tr></table></figure>

<p>如果您希望编写脚本来控制监控时长, 可以向 simpleperf 发送 <code>SIGINT</code>, <code>SIGTERM</code> 或 <code>SIGHUP</code> 信号来停止监控.</p>
<hr>
<p>更多内容见 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvZXhlY3V0YWJsZV9jb21tYW5kc19yZWZlcmVuY2UubWQjdGhlLXN0YXQtY29tbWFuZA==">The stat command<i class="fa fa-external-link-alt"></i></span>.</p>
<h2 id="record"><a href="#record" class="headerlink" title="record"></a>record</h2><p>record 命令用于转储被分析进程的样本. 每个样本可以包含生成样本的时间, 自上次样本以来的事件数量, 线程的程序计数器, 线程的调用链等信息.</p>
<p>通过传递选项, 我们可以选择使用哪些事件, 监控哪些进程/线程, 转储样本的频率, 监控多长时间, 以及存储样本的位置.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Record on process 7394 for 10 seconds, using default event (cpu-cycles), </span></span><br><span class="line"><span class="comment"># using default sample frequency (4000 samples per second),</span></span><br><span class="line"><span class="comment"># writing records to perf.data.</span></span><br><span class="line">$ simpleperf record -p 7394 --duration 10</span><br><span class="line">simpleperf I cmd_record.cpp:316] Samples recorded: 21430. Samples lost: 0.</span><br></pre></td></tr></table></figure>

<h3 id="选择要记录的事件"><a href="#选择要记录的事件" class="headerlink" title="选择要记录的事件"></a>选择要记录的事件</h3><p>默认情况下, 使用 <code>cpu-cycles</code> 事件来评估消耗的 CPU 周期. 但我们也可以通过 <code>-e</code> 选项使用其他事件.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Record using event instructions.</span></span><br><span class="line">$ simpleperf record -e instructions -p 11904 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record using task-clock, which shows the passed CPU time in nanoseconds.</span></span><br><span class="line">$ simpleperf record -e task-clock -p 11904 --duration 10</span><br></pre></td></tr></table></figure>

<h3 id="选择要记录的目标"><a href="#选择要记录的目标" class="headerlink" title="选择要记录的目标"></a>选择要记录的目标</h3><p><code>record</code> 命令中选择目标的方式类似于 <code>stat</code> 命令.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Record process 11904 and 11905.</span></span><br><span class="line">$ simpleperf record -p 11904,11905 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record processes with name containing &quot;chrome&quot;.</span></span><br><span class="line">$ simpleperf record -p chrome --duration 10</span><br><span class="line"><span class="comment"># Record processes with name containing part matching regex &quot;chrome:(privileged|sandboxed)&quot;.</span></span><br><span class="line">$ simpleperf record -p <span class="string">&quot;chrome:(privileged|sandboxed)&quot;</span> --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record thread 11904 and 11905.</span></span><br><span class="line">$ simpleperf record -t 11904,11905 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record a child process running `ls`.</span></span><br><span class="line">$ simpleperf record <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Record the process of an Android application. On non-root devices, this only works for debuggable</span></span><br><span class="line"><span class="comment"># or profileable from shell apps.</span></span><br><span class="line">$ simpleperf record --app simpleperf.example.cpp --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record only selected thread 11904 in an app.</span></span><br><span class="line">$ simpleperf record --app simpleperf.example.cpp -t 11904 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record system wide.</span></span><br><span class="line">$ simpleperf record -a --duration 10</span><br></pre></td></tr></table></figure>

<h3 id="设置记录频率"><a href="#设置记录频率" class="headerlink" title="设置记录频率"></a>设置记录频率</h3><p>我们可以通过 <code>-f</code> 或 <code>-c</code> 选项设置转储记录的频率. 例如, <code>-f 4000</code> 表示在监控的线程运行时, 每秒钟大约转储 4000 条记录. 如果一个监控的线程在一秒钟内运行了 0.2 秒 (在其他时间它可能被抢占或阻塞) , simpleperf 每秒钟大约转储 4000 * 0.2 / 1.0 = 800 条记录. 另一种方式是使用 <code>-c</code>. 例如, <code>-c 10000</code> 表示每当发生 10000 个事件时转储一条记录.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用采样频率 1000 进行记录: 每秒运行采样 1000 次. </span></span><br><span class="line">$ simpleperf record -f 1000 -p 11904,11905 --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用采样周期 100000 进行记录: 每 100000 个事件采样一次. </span></span><br><span class="line">$ simpleperf record -c 100000 -t 11904,11905 --duration 10</span><br></pre></td></tr></table></figure>

<p>为了避免生成样本花费过多时间, kernel &gt;= 3.10 设置了用于生成样本的最大 CPU 时间百分比 (默认是 25%) , 并在达到该限制时降低允许的最大采样频率. simpleperf 使用 <code>--cpu-percent</code> 选项来调整它, 但这需要 root 权限或运行 Android &gt;= Q.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用采样频率 10000 进行记录, 允许的最大 CPU 使用率为 50%. </span></span><br><span class="line">$ simpleperf record -f 1000 -p 11904,11905 --duration 10 --cpu-percent 50</span><br></pre></td></tr></table></figure>

<h3 id="决定记录的时长"><a href="#决定记录的时长" class="headerlink" title="决定记录的时长"></a>决定记录的时长</h3><p>与 <code>stat</code> 类似, 也可以通过 <code>--duration</code> 来控制记录时长.</p>
<h3 id="设置存储分析数据的路径"><a href="#设置存储分析数据的路径" class="headerlink" title="设置存储分析数据的路径"></a>设置存储分析数据的路径</h3><p>默认情况下, simpleperf 将分析数据存储在当前目录的 <code>perf.data</code> 文件中. 但可以使用 <code>-o</code> 选项更改存储路径.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Write records to data/perf2.data.</span></span><br><span class="line">$ simpleperf record -p 11904 -o data/perf2.data --duration 10</span><br></pre></td></tr></table></figure>

<h3 id="记录调用图"><a href="#记录调用图" class="headerlink" title="记录调用图"></a>记录调用图</h3><p>调用图是显示函数调用关系的树结构. 以下是一个示例.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">main() &#123;</span><br><span class="line">    FunctionOne();</span><br><span class="line">    FunctionTwo();</span><br><span class="line">&#125;</span><br><span class="line">FunctionOne() &#123;</span><br><span class="line">    FunctionTwo();</span><br><span class="line">    FunctionThree();</span><br><span class="line">&#125;</span><br><span class="line">a call graph:</span><br><span class="line">    main-&gt; FunctionOne</span><br><span class="line">       |    |</span><br><span class="line">       |    |-&gt; FunctionTwo</span><br><span class="line">       |    |-&gt; FunctionThree</span><br><span class="line">       |</span><br><span class="line">       |-&gt; FunctionTwo</span><br></pre></td></tr></table></figure>

<p>调用图显示了一个函数如何调用其他函数, 反向调用图则显示一个函数如何被其他函数调用. 要显示调用图, 我们首先需要记录它, 然后再报告它.</p>
<p>有两种记录调用图的方法, 一种是记录基于 dwarf 的调用图, 另一种是记录基于栈帧的调用图. 记录基于 dwarf 的调用图需要本地二进制文件中的调试信息支持. 而记录基于栈帧的调用图则需要栈帧寄存器的支持.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 记录基于 dwarf 的调用图</span></span><br><span class="line">$ simpleperf record -p 11904 -g --duration 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录基于栈帧的调用图</span></span><br><span class="line">$ simpleperf record -p 11904 --call-graph fp --duration 10</span><br></pre></td></tr></table></figure>

<h3 id="记录-CPU-时间和非-CPU-时间"><a href="#记录-CPU-时间和非-CPU-时间" class="headerlink" title="记录 CPU 时间和非 CPU 时间"></a>记录 CPU 时间和非 CPU 时间</h3><p>Simpleperf 是一个 CPU 分析器, 它只在线程运行在 CPU 上时生成样本. 但有时我们想知道线程在 CPU 外的时间是如何花费的 (例如, 被其他线程抢占, 在 IO 中阻塞或等待某些事件) . 为支持这一点, simpleperf 在 <code>record</code> 命令中添加了 <code>--trace-offcpu</code> 选项. 当使用 <code>--trace-offcpu</code> 时, simpleperf 会执行以下操作:</p>
<ol>
<li>仅允许 <code>cpu-clock``/task-clock</code> 事件与 <code>--trace-offcpu</code> 一起使用, 这使得 simpleperf 为 <code>cpu-clock</code> 事件生成 on-cpu 样本.</li>
<li>Simpleperf 还监控 <code>sched:sched_switch</code> 事件, 每次监控的线程从 CPU 上调度时会生成一个 sched_switch 样本.</li>
<li>Simpleperf 还记录上下文切换记录, 因此它知道线程何时被调度回 CPU.</li>
</ol>
<p>simpleperf 为线程收集的样本和上下文切换记录如下所示:</p>
<p><img data-src="data:image/png;base64,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" alt="simpleperf_trace_offcpu_sample_mode"></p>
<p>这里有两种类型的样本:</p>
<ol>
<li>为 cpu-clock 事件生成的 on-cpu 样本. 每个样本中的周期值表示在 CPU 上花费了多少纳秒 (针对该样本的调用链) .</li>
<li>为 sched:sched_switch 事件生成的 off-cpu (sched_switch) 样本. 周期值由 simpleperf 计算为下一个 switch on 记录的时间戳减去当前样本的时间戳. 因此, 每个样本中的周期值表示在 CPU 外花费了多少纳秒 (针对该样本的调用链) .</li>
</ol>
<p>注意: 实际上, switch on 记录和样本可能会丢失. 为了减轻精度损失, 我们计算一个 off-cpu 样本的周期为下一个 switch on 记录或样本的时间戳减去当前样本的时间戳.</p>
<p>通过 Python 脚本报告时, <code>simpleperf_report_lib.py</code> 提供 <code>SetTraceOffCpuMode()</code> 方法来控制如何报告样本:</p>
<ol>
<li>on-cpu 模式: 仅报告 on-cpu 样本.</li>
<li>off-cpu 模式: 仅报告 off-cpu 样本.</li>
<li>on-off-cpu 模式: 报告 on-cpu 和 off-cpu 样本, 可以按事件名称分开.</li>
<li>mixed-on-off-cpu 模式: 在相同事件名称下报告 on-cpu 和 off-cpu 样本.</li>
</ol>
<p>如果未设置, 将使用 mixed-on-off-cpu 模式进行报告.</p>
<p>使用 <code>report_html.py</code>, <code>inferno</code> 和 <code>report_sample.py</code> 时, 可以通过 <code>--trace-offcpu</code> 选项设置报告模式.</p>
<p>以下是一些记录和报告 trace offcpu 配置文件的示例.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check if --trace-offcpu is supported by the kernel (should be available on kernel &gt;= 4.2).</span></span><br><span class="line">$ simpleperf list --show-features</span><br><span class="line">trace-offcpu</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record with --trace-offcpu.</span></span><br><span class="line">$ simpleperf record -g -p 11904 --duration 10 --trace-offcpu -e cpu-clock</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record system wide with --trace-offcpu.</span></span><br><span class="line">$ simpleperf record -a -g --duration 3 --trace-offcpu -e cpu-clock</span><br><span class="line"></span><br><span class="line"><span class="comment"># Record with --trace-offcpu using app_profiler.py.</span></span><br><span class="line">$ ./app_profiler.py -p com.google.samples.apps.sunflower \</span><br><span class="line">    -r <span class="string">&quot;-g -e cpu-clock:u --duration 10 --trace-offcpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Report on-cpu samples.</span></span><br><span class="line">$ ./report_html.py --trace-offcpu on-cpu</span><br><span class="line"><span class="comment"># Report off-cpu samples.</span></span><br><span class="line">$ ./report_html.py --trace-offcpu off-cpu</span><br><span class="line"><span class="comment"># Report on-cpu and off-cpu samples under different event names.</span></span><br><span class="line">$ ./report_html.py --trace-offcpu on-off-cpu</span><br><span class="line"><span class="comment"># Report on-cpu and off-cpu samples under the same event name.</span></span><br><span class="line">$ ./report_html.py --trace-offcpu mixed-on-off-cpu</span><br></pre></td></tr></table></figure>

<h2 id="report"><a href="#report" class="headerlink" title="report"></a>report</h2><p>report 命令用于报告由 record 命令生成的分析数据. 报告包含一个样本条目表, 每个样本条目是报告中的一行. report 命令将属于同一进程, 线程, 库, 函数的样本分组到同一个样本条目中. 然后根据样本条目的事件计数对样本条目进行排序.</p>
<p>通过传递选项, 我们可以决定如何过滤掉不感兴趣的样本, 如何将样本分组到样本条目中, 以及在哪里查找分析数据和二进制文件.</p>
<p>下面是一个示例. 记录被分组为 4 个样本条目, 每个条目是一行. 有几列, 每列显示属于样本条目的一部分信息. 第一列是 Overhead, 显示当前样本条目中事件占总事件的百分比. 由于 perf 事件是 cpu-cycles, overhead 是每个函数使用的 CPU 周期的百分比.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Reports perf.data, using only records sampled in libsudo-game-jni.so, grouping records using</span></span><br><span class="line"><span class="comment"># thread name(comm), process id(pid), thread id(tid), function name(symbol), and showing sample</span></span><br><span class="line"><span class="comment"># count for each row.</span></span><br><span class="line">$ simpleperf report --dsos /data/app/com.example.sudogame-2/lib/arm64/libsudo-game-jni.so \</span><br><span class="line">      --<span class="built_in">sort</span> <span class="built_in">comm</span>,pid,tid,symbol -n</span><br><span class="line">Cmdline: /data/data/com.example.sudogame/simpleperf record -p 7394 --duration 10</span><br><span class="line">Arch: arm64</span><br><span class="line">Event: cpu-cycles (<span class="built_in">type</span> 0, config 0)</span><br><span class="line">Samples: 28235</span><br><span class="line">Event count: 546356211</span><br><span class="line"></span><br><span class="line">Overhead  Sample  Command    Pid   Tid   Symbol</span><br><span class="line">59.25%    16680   sudogame  7394  7394  checkValid(Board const&amp;, int, int)</span><br><span class="line">20.42%    5620    sudogame  7394  7394  canFindSolution_r(Board&amp;, int, int)</span><br><span class="line">13.82%    4088    sudogame  7394  7394  randomBlock_r(Board&amp;, int, int, int, int, int)</span><br><span class="line">6.24%     1756    sudogame  7394  7394  @plt</span><br></pre></td></tr></table></figure>

<h3 id="设置读取分析数据的路径"><a href="#设置读取分析数据的路径" class="headerlink" title="设置读取分析数据的路径"></a>设置读取分析数据的路径</h3><p>默认情况下, report 命令从当前目录的 perf.data 文件中读取分析数据. 但可以使用 <code>-i</code> 选项更改读取路径.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">simpleperf report -i data/perf2.data</span><br></pre></td></tr></table></figure>

<h3 id="设置查找二进制文件的路径"><a href="#设置查找二进制文件的路径" class="headerlink" title="设置查找二进制文件的路径"></a>设置查找二进制文件的路径</h3><p>为了报告函数符号, simpleperf 需要读取被监控进程使用的可执行二进制文件以获取符号表和调试信息. 默认情况下, 路径是记录时被监控进程使用的可执行二进制文件. 然而, 这些二进制文件在报告时可能不存在或不包含符号表和调试信息. 因此, 我们可以使用 <code>--symfs</code> 选项重定向路径.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># In this case, when simpleperf wants to read executable binary /A/b, it reads file in /A/b.</span></span><br><span class="line">$ simpleperf report</span><br><span class="line"></span><br><span class="line"><span class="comment"># In this case, when simpleperf wants to read executable binary /A/b, it prefers file in</span></span><br><span class="line"><span class="comment"># /debug_dir/A/b to file in /A/b.</span></span><br><span class="line">$ simpleperf report --symfs /debug_dir</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read symbols for system libraries built locally. Note that this is not needed since Android O,</span></span><br><span class="line"><span class="comment"># which ships symbols for system libraries on device.</span></span><br><span class="line">$ simpleperf report --symfs <span class="variable">$ANDROID_PRODUCT_OUT</span>/symbols</span><br></pre></td></tr></table></figure>

<h3 id="报告调用图"><a href="#报告调用图" class="headerlink" title="报告调用图"></a>报告调用图</h3><p>要报告调用图, 请确保分析数据是带有调用图记录的, 如 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvZXhlY3V0YWJsZV9jb21tYW5kc19yZWZlcmVuY2UubWQjcmVjb3JkLWNhbGwtZ3JhcGhz">Record call graphs<i class="fa fa-external-link-alt"></i></span> 所示.</p>
<hr>
<p>更多详细内容见 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvZXhlY3V0YWJsZV9jb21tYW5kc19yZWZlcmVuY2UubWQjdGhlLXJlY29yZC1jb21tYW5k">The record command<i class="fa fa-external-link-alt"></i></span>.</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>Simpleperf</tag>
        <tag>Android</tag>
        <tag>安卓性能分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Simpleperf 三部曲 (三)</title>
    <url>//posts/2024/07/07/simpleperf3/</url>
    <content><![CDATA[<p>本文是对性能分析工具 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2MvUkVBRE1FLm1k">Simpleperf<i class="fa fa-external-link-alt"></i></span> 使用文档总结, 也可以看作是文档翻译.</p>
<p>本篇原文见 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL21haW4vc2ltcGxlcGVyZi9kb2Mvc2NyaXB0c19yZWZlcmVuY2UubWQ=">Scripts reference<i class="fa fa-external-link-alt"></i></span>.</p>
<span id="more"></span>

<h2 id="记录分析数据"><a href="#记录分析数据" class="headerlink" title="记录分析数据"></a>记录分析数据</h2><h3 id="app-profiler-py"><a href="#app-profiler-py" class="headerlink" title="app_profiler.py"></a>app_profiler.py</h3><p><code>app_profiler.py</code> 用于记录 Android 应用程序和本地可执行文件的分析数据.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 记录一个 Android 应用程序. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录包含编译成本地指令的 Java 代码的 Android 应用程序. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp --compile_java_code</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录一个 Android 应用程序的 Activity 启动. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp -a .SleepActivity</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录一个本地进程. </span></span><br><span class="line">$ ./app_profiler.py -np surfaceflinger</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据 pid 记录一个本地进程. </span></span><br><span class="line">$ ./app_profiler.py --pid 11324</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录一个命令. </span></span><br><span class="line">$ ./app_profiler.py -cmd \</span><br><span class="line">    <span class="string">&quot;dex2oat --dex-file=/data/local/tmp/app-debug.apk --oat-file=/data/local/tmp/a.oat&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录一个 Android 应用程序, 并使用 -r 向 record 命令发送自定义选项. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp \</span><br><span class="line">    -r <span class="string">&quot;-e cpu-clock -g --duration 30&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录 CPU 时间和非 CPU 时间. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp \</span><br><span class="line">    -r <span class="string">&quot;-e task-clock -g -f 1000 --duration 10 --trace-offcpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将分析数据保存到自定义文件 (如 perf_custom.data) 而不是 perf.data. </span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp -o perf_custom.data</span><br></pre></td></tr></table></figure>

<h3 id="从应用程序启动时进行分析"><a href="#从应用程序启动时进行分析" class="headerlink" title="从应用程序启动时进行分析"></a>从应用程序启动时进行分析</h3><p>有时我们想分析应用程序的启动时间. 为支持这一点, 我们在 record 命令中添加了 --app 选项. --app 选项设置要分析的 Android 应用程序的包名. 如果应用程序尚未运行, record 命令将以 1 毫秒的间隔轮询应用程序进程. 因此, 要从应用程序启动时开始分析, 我们可以先使用 --app 启动 record 命令, 然后再启动应用程序. 下面是一个示例.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ./run_simpleperf_on_device.py record --app simpleperf.example.cpp \</span><br><span class="line">    -g --duration 1 -o /data/local/tmp/perf.data</span><br><span class="line"><span class="comment"># Start the app manually or using the `am` command.</span></span><br></pre></td></tr></table></figure>

<p>为了方便使用, app_profiler.py 支持使用 <code>-a</code> 选项在记录开始后启动一个 Activity.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./app_profiler.py -p simpleperf.example.cpp -a .MainActivity</span><br></pre></td></tr></table></figure>

<h3 id="binary-cache-builder-py"><a href="#binary-cache-builder-py" class="headerlink" title="binary_cache_builder.py"></a>binary_cache_builder.py</h3><p><code>binary_cache</code> 目录是一个保存分析数据文件所需二进制文件的目录. 这些二进制文件应为未剥离版本, 包含调试信息和符号表. report 脚本使用 <code>binary_cache</code> 目录读取二进制文件的符号, <code>report_html.py</code> 也使用该目录生成带注释的源代码和反汇编代码.</p>
<p>默认情况下, <code>app_profiler.py</code> 在记录后构建 <code>binary_cache</code> 目录. 但我们也可以使用 <code>binary_cache_builder.py</code> 为现有的分析数据文件构建 <code>binary_cache</code>. 这在您直接使用 <code>simpleperf record</code> 进行系统范围的分析或在未连接 USB 线缆的情况下记录数据时非常有用.</p>
<p><code>binary_cache_builder.py</code> 可以从 Android 设备中拉取二进制文件, 或在主机上的目录中查找二进制文件 (通过 -lib 选项) .</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Generate binary_cache for perf.data, by pulling binaries from the device.</span></span><br><span class="line">$ ./binary_cache_builder.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate binary_cache, by pulling binaries from the device and finding binaries in</span></span><br><span class="line"><span class="comment"># SimpleperfExampleCpp.</span></span><br><span class="line">$ ./binary_cache_builder.py -lib path_of_SimpleperfExampleCpp</span><br></pre></td></tr></table></figure>

<h3 id="run-simpleperf-on-device-py"><a href="#run-simpleperf-on-device-py" class="headerlink" title="run_simpleperf_on_device.py"></a>run_simpleperf_on_device.py</h3><p>这个脚本将 simpleperf 可执行文件推送到设备上, 并在设备上运行 simpleperf 命令. 它比手动运行 adb 命令更方便.</p>
<h2 id="查看分析数据"><a href="#查看分析数据" class="headerlink" title="查看分析数据"></a>查看分析数据</h2><p>本节中的脚本用于查看分析结果或将分析数据转换为外部 UI 使用的格式. 有关推荐的 UI, 请参见 view_the_profile.md.</p>
<h3 id="report-py"><a href="#report-py" class="headerlink" title="report.py"></a>report.py</h3><p><code>report.py</code> 是主机上 report 命令的包装器. 它接受 report 命令的所有选项.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 报告调用图</span></span><br><span class="line">$ ./report.py -g</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在由 Python Tk 实现的 GUI 窗口中报告调用图</span></span><br><span class="line">$ ./report.py -g --gui</span><br></pre></td></tr></table></figure>

<h3 id="report-html-py"><a href="#report-html-py" class="headerlink" title="report_html.py"></a>report_html.py</h3><p><code>report_html.py</code> 根据分析数据生成 <code>report.html</code>. 然后 <code>report.html</code> 可以在不依赖其他文件的情况下显示分析结果. 因此, 它可以在本地浏览器中显示或传输到其他机器上. 根据使用的命令行选项, <code>report.html</code> 的内容可以包括: 图表统计, 样本表, 火焰图, 每个函数的注释源代码, 每个函数的注释反汇编.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 基于 perf.data 生成图表统计, 样本表和火焰图. </span></span><br><span class="line">$ ./report_html.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加源代码. </span></span><br><span class="line">$ ./report_html.py --add_source_code --source_dirs path_of_SimpleperfExampleCpp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加反汇编. </span></span><br><span class="line">$ ./report_html.py --add_disassembly</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为所有二进制文件添加反汇编可能会花费很多时间. 因此, 我们可以选择仅为选定的二进制文件添加反汇编. </span></span><br><span class="line">$ ./report_html.py --add_disassembly --binary_filter libgame.so</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为属于包名为 com.example.myapp 的应用程序的二进制文件添加反汇编和源代码. </span></span><br><span class="line">$ ./report_html.py --add_source_code --add_disassembly --binary_filter com.example.myapp</span><br><span class="line"></span><br><span class="line"><span class="comment"># report_html.py 接受多个记录数据文件. </span></span><br><span class="line">$ ./report_html.py -i perf1.data perf2.data</span><br></pre></td></tr></table></figure>

<p>下面是为 SimpleperfExampleCpp 生成 html 分析结果的示例.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./app_profiler.py -p simpleperf.example.cpp</span><br><span class="line">./report_html.py --add_source_code --source_dirs path_of_SimpleperfExampleCpp --add_disassembly</span><br></pre></td></tr></table></figure>

<p>在浏览器中打开生成的 report.html 后, 有几个标签页:</p>
<p>第一个标签页是 &quot;Chart Statistics&quot;. 您可以点击饼图以显示每个进程, 线程, 库和函数所消耗的时间.</p>
<p>第二个标签页是 &quot;Sample Table&quot;. 它显示每个函数所花费的时间. 通过点击表格中的一行, 我们可以跳转到一个名为&quot;Function&quot;的新标签页.</p>
<p>第三个标签页是 &quot;Flamegraph&quot;. 它显示了由 inferno 生成的图表.</p>
<p>第四个标签页是 &quot;Function&quot;. 只有当用户点击 &quot;Sample Table&quot; 标签页中的一行时才会出现. 它显示一个函数的信息, 包括:</p>
<ul>
<li>显示该函数调用的函数的火焰图.</li>
<li>显示调用该函数的函数的火焰图.</li>
<li>该函数的注释源代码. 只有在该函数有源代码文件时才会出现.</li>
<li>该函数的注释反汇编. 只有在包含该函数的二进制文件存在时才会出现.</li>
</ul>
<h3 id="inferno"><a href="#inferno" class="headerlink" title="inferno"></a>inferno</h3><p>inferno 是一个用于在 HTML 文件中生成火焰图的工具.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 基于 perf.data 生成火焰图. </span></span><br><span class="line"><span class="comment"># 在 Windows 上, 使用 inferno.bat 代替 ./inferno.sh. </span></span><br><span class="line">$ ./inferno.sh -sc --record_file perf.data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录一个本地程序并生成火焰图. </span></span><br><span class="line">$ ./inferno.sh -np surfaceflinger</span><br></pre></td></tr></table></figure>

<h3 id="purgatorio"><a href="#purgatorio" class="headerlink" title="purgatorio"></a>purgatorio</h3><p>purgatorio 是一个可视化工具, 用于按时间顺序显示样本.</p>
<h3 id="pprof-proto-generator-py"><a href="#pprof-proto-generator-py" class="headerlink" title="pprof_proto_generator.py"></a>pprof_proto_generator.py</h3><p>它将分析数据文件转换为 pprof.proto 格式, 该格式由 pprof 使用.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将当前目录中的 perf.data 转换为 pprof.proto 格式. </span></span><br><span class="line">$ ./pprof_proto_generator.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以 PDF 格式显示报告. </span></span><br><span class="line">$ pprof -pdf pprof.profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以 HTML 格式显示报告. 要显示反汇编, 添加 --tools 选项, 如: </span></span><br><span class="line"><span class="comment"># --tools=objdump:&lt;ndk_path&gt;/toolchains/llvm/prebuilt/linux-x86_64/aarch64-linux-android/bin</span></span><br><span class="line"><span class="comment"># 要显示注释源代码或反汇编, 在视图菜单中选择 `top`, 点击一个函数并选择 `source` 或 `disassemble`. </span></span><br><span class="line">$ pprof -http=:8080 pprof.profile</span><br></pre></td></tr></table></figure>

<h3 id="gecko-profile-generator-py"><a href="#gecko-profile-generator-py" class="headerlink" title="gecko_profile_generator.py"></a>gecko_profile_generator.py</h3><p>将 perf.data 转换为 Gecko Profile 格式, 该格式可被 <span class="exturl" data-url="aHR0cHM6Ly9wcm9maWxlci5maXJlZm94LmNvbS8=">https://profiler.firefox.com/<i class="fa fa-external-link-alt"></i></span> 读取.</p>
<p>Firefox Profiler 是一个功能强大的通用分析器 UI, 可以在任何浏览器 (不仅仅是 Firefox) 本地运行, 具有:</p>
<ul>
<li>每线程轨迹</li>
<li>火焰图</li>
<li>搜索, 聚焦于特定的堆栈</li>
<li>时间序列视图, 以时间戳顺序查看样本</li>
<li>按线程和持续时间过滤</li>
</ul>
<p>使用方法:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 记录应用程序的分析数据</span></span><br><span class="line">$ ./app_profiler.py -p simpleperf.example.cpp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换并压缩. </span></span><br><span class="line">$ ./gecko_profile_generator.py -i perf.data | gzip &gt; gecko-profile.json.gz</span><br></pre></td></tr></table></figure>

<p>然后在 <span class="exturl" data-url="aHR0cHM6Ly9wcm9maWxlci5maXJlZm94LmNvbS8=">https://profiler.firefox.com/<i class="fa fa-external-link-alt"></i></span> 中打开 gecko-profile.json.gz.</p>
<h3 id="report-sample-py"><a href="#report-sample-py" class="headerlink" title="report_sample.py"></a>report_sample.py</h3><p>report_sample.py 将分析数据文件转换为 linux-perf-tool 输出的 perf 脚本文本格式.</p>
<p>这种格式可以导入到:</p>
<ul>
<li>FlameGraph</li>
<li>Flamescope</li>
<li>Firefox Profiler, 但更推荐使用 gecko_profile_generator.py.</li>
<li>Speedscope</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将分析数据记录到 perf.data</span></span><br><span class="line">$ ./app_profiler.py &lt;args&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将当前目录中的 perf.data 转换为 FlameGraph 使用的格式. </span></span><br><span class="line">$ ./report_sample.py --symfs binary_cache &gt;out.perf</span><br><span class="line"></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/brendangregg/FlameGraph.git</span><br><span class="line">$ FlameGraph/stackcollapse-perf.pl out.perf &gt;out.folded</span><br><span class="line">$ FlameGraph/flamegraph.pl out.folded &gt;a.svg</span><br></pre></td></tr></table></figure>

<h3 id="stackcollapse-py"><a href="#stackcollapse-py" class="headerlink" title="stackcollapse.py"></a>stackcollapse.py</h3><p>stackcollapse.py 将分析数据文件 (perf.data) 转换为 Brendan Gregg 的  &quot;折叠堆栈&quot;  格式.</p>
<p>折叠堆栈是以分号分隔的堆栈帧 (从根到叶) , 后跟在该堆栈中采样的事件计数的行, 例如:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BusyThread;__start_thread;__pthread_start(void*);java.lang.Thread.run 17889729</span><br></pre></td></tr></table></figure>

<p>所有相似的堆栈都被聚合, 样本时间戳不被使用.</p>
<p>折叠堆栈格式可被以下工具读取:</p>
<ul>
<li>The FlameGraph toolkit</li>
<li>Inferno (FlameGraph 的 Rust 移植版)</li>
<li>Speedscope</li>
</ul>
<p>示例:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将分析数据记录到 perf.data</span></span><br><span class="line">$ ./app_profiler.py &lt;args&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为折叠堆栈格式</span></span><br><span class="line">$ ./stackcollapse.py --kernel --jit | gzip &gt; profile.folded.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 FlameGraph 可视化 Java 堆栈和纳秒时间</span></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/brendangregg/FlameGraph.git</span><br><span class="line">$ gunzip -c profile.folded.gz \</span><br><span class="line">    | FlameGraph/flamegraph.pl --color=java --countname=ns \</span><br><span class="line">    &gt; profile.svg</span><br></pre></td></tr></table></figure>

<h2 id="一些工具库"><a href="#一些工具库" class="headerlink" title="一些工具库"></a>一些工具库</h2><h3 id="simpleperf-report-lib-py"><a href="#simpleperf-report-lib-py" class="headerlink" title="simpleperf_report_lib.py"></a>simpleperf_report_lib.py</h3><p>simpleperf_report_lib.py 是一个用于解析由 record 命令生成的分析数据文件的 Python 库. 内部它使用 libsimpleperf_report.so 来完成工作. 通常, 对于每个分析数据文件, 我们创建一个 ReportLib 实例, 传递文件路径 (通过 SetRecordFile) . 然后我们可以通过 GetNextSample() 读取所有样本. 对于每个样本, 我们可以读取其事件信息 (通过 GetEventOfCurrentSample) , 符号信息 (通过 GetSymbolOfCurrentSample) 和调用链信息 (通过 GetCallChainOfCurrentSample) . 我们还可以获取一些全局信息, 如记录选项 (通过 GetRecordCmd) , 设备架构 (通过 GetArch) 和元信息字符串 (通过 MetaInfo) .</p>
<p>使用 simpleperf_report_lib.py 的示例可以在 report_sample.py, report_html.py, pprof_proto_generator.py 和 inferno/inferno.py 中找到.</p>
<h3 id="ipc-py"><a href="#ipc-py" class="headerlink" title="ipc.py"></a>ipc.py</h3><p>ipc.py 捕获系统在指定持续时间内的每周期指令数 (IPC) .</p>
<p>示例:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./ipc.py</span><br><span class="line">./ipc.py 2 20          <span class="comment"># 设置间隔为2秒, 总持续时间为20秒</span></span><br><span class="line">./ipc.py -p 284 -C 4   <span class="comment"># 仅在核4上分析PID 284</span></span><br><span class="line">./ipc.py -c <span class="string">&#x27;sleep 5&#x27;</span>  <span class="comment"># 仅分析运行的命令</span></span><br></pre></td></tr></table></figure>

<p>结果如下所示:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">K_CYCLES   K_INSTR      IPC</span><br><span class="line">36840      14138       0.38</span><br><span class="line">70701      27743       0.39</span><br><span class="line">104562     41350       0.40</span><br><span class="line">138264     54916       0.40</span><br></pre></td></tr></table></figure>

<h3 id="sample-filter-py"><a href="#sample-filter-py" class="headerlink" title="sample_filter.py"></a>sample_filter.py</h3><p>sample_filter.py 根据 <span class="exturl" data-url="aHR0cHM6Ly9hbmRyb2lkLmdvb2dsZXNvdXJjZS5jb20vcGxhdGZvcm0vc3lzdGVtL2V4dHJhcy8rL3JlZnMvaGVhZHMvbWFpbi9zaW1wbGVwZXJmL2RvYy9zYW1wbGVfZmlsdGVyLm1k">sample_filter.md<i class="fa fa-external-link-alt"></i></span> 中的文档生成样本过滤器文件. 运行报告脚本时, 可以通过 <code>--filter-file</code> 选项传递过滤器文件.</p>
<p>例如, 它可以用于将一个大型记录文件拆分为多个报告文件.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sample_filter.py -i perf.data --split-time-range 2 -o sample_filter</span><br><span class="line">$ gecko_profile_generator.py -i perf.data --filter-file sample_filter_part1 \</span><br><span class="line">    | gzip &gt;profile-part1.json.gz</span><br><span class="line">$ gecko_profile_generator.py -i perf.data --filter-file sample_filter_part2 \</span><br><span class="line">    | gzip &gt;profile-part2.json.gz</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>Simpleperf</tag>
        <tag>Android</tag>
        <tag>安卓性能分析</tag>
      </tags>
  </entry>
  <entry>
    <title>SM9 文档阅读笔记</title>
    <url>//posts/2023/12/15/sm9/</url>
    <content><![CDATA[<p>本文记录自己在学习实现 SM9 中遇到的问题和个人理解. 由于实现之前没有系统学习过 SM9 涉及的相关数学知识, 因此踩了许多坑, 特此记录.</p>
<p>主要是一些关键性数学概念的理解, 以及一些简单的优化技巧.</p>
<span id="more"></span>

<h2 id="扩域运算"><a href="#扩域运算" class="headerlink" title="扩域运算"></a>扩域运算</h2><p>在 SM9 中, 按如下方式进行扩域运算:</p>
<p>$F_{q^{12}}$ 的 $1\text{-}2\text{-}4\text{-}12$ 塔式扩张:</p>
<p>$$<br>\begin{align*}<br>  &amp; F_{q^{2}}[u] = F_{q}[u]/(u^2 - \alpha), &amp;&amp; \alpha = -2 \\<br>  &amp; F_{q^{4}}[v] = F_{q^{2}}[v]/(v^2 - \xi), &amp;&amp; \xi = u \\<br>  &amp; F_{q^{12}}[w] = F_{q^{4}}[w]/(w^3 - v), &amp;&amp; v^2 = \xi<br>\end{align*}<br>$$</p>
<p>其中, 第一次的 2 次扩张约化多项式为: $x^2 - \alpha, \alpha=-2$;</p>
<p>第二次进行 2 次扩张的约化多项式为: $x^2 - u, u^2 = \alpha, u = \sqrt{-2}$;</p>
<p>第三次进行 3 次扩张的约化多项式为: $x^3-v, v^2=u, v = \sqrt{\sqrt{-2}}$.</p>
<p>$u$ 属于 $F_{q^{2}}$, 表示为 $(1, 0)$.</p>
<p>$v$ 属于 $F_{q^{4}}$, 表示为 $(0, 1, 0, 0)$, 也可以用 $F_{q^{2}}$ 元素表示为 $((0, 1), (0, 0))$.</p>
<p>扩域这个概念可以类比中学学过的 &quot;复数&quot;, $ai + b$, 将实数域扩展到了复数域, 这里面的 $i$ 是 $\sqrt{-1}$.</p>
<p>扩展后的域元素可以用扩展前的域元素来进行表示, 这里面 $a$ 和 $b$ 都是实数域, 而 $ai + b$ 则是复数域.</p>
<p>因此 SM9 中将 $F_{q}$ 的元素最高扩展到了 $F_{q^{12}}$ 上, 也就是从原本的 1 项变成了 12 项. 并且需要注意扩域元素的书写方式.</p>
<p>例如 $F_{q^{4}}$ 上我们需要按 $F_{q^{2 \times 2}}$ 来理解, 也就是在 $F_{q^{2}}$ 上进行了 1 次 2 次扩张, 这样扩域后的元素用 $F_{q^{2}}$ 上的元素表示, <strong>而不是</strong>简单的用 $F_{q}$ 进行表示, 两者之间需要进行转换.</p>
<p>具体来说可以根据扩域元素 $u$, $v$ 和 $w$ 来进行转换计算, 在 SM9 中扩域元素使用多项式进行表示, 三者之间存在如下关系.</p>
<p>$$<br>\begin{align*}<br>  \alpha = u^2 = (v^2)^2 = ((w^3)^2)^2<br>\end{align*}<br>$$</p>
<p>因此有:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  w &amp;= \alpha^\frac{1}{12} \\<br>  v &amp;= \alpha^\frac{1}{6} = w^2 \\<br>  u &amp;= \alpha^\frac{1}{2} = w^6<br>\end{align*}<br>\right.<br>$$</p>
<p>所以塔式扩张下一个 $F_{q^{12}}$ 上的域元素 $X_{F_{q^{12}}}$ 可以被表示为:</p>
<p>$$<br>\begin{align*}<br>  X &amp;= Aw^2 + Bw + C \\<br>  ~ &amp;= (a_1v + a_0)w^2 + (b_1v + b_0)w + (c_1v + c_0) \\<br>  ~ &amp;= ((a_{11}u + a_{10})v + (a_{01}u + a_{00}))w^2 + ((b_{11}u + b_{10})v + (b_{01}u + b_{00}))w + ((c_{11}u + c_{10})v + (c_{01}u + c_{00})) \\<br>  ~ &amp;= a_{11}uvw^2 + a_{10}vw^2 + a_{01}uw^2 + a_{00}w^2 + b_{11}uvw + b_{10}vw + b_{01}uw + b_{00}w + c_{11}uv + c_{10}v + c_{01}u + c_{00} \\<br>  ~ &amp;= a_{11}w^{11} + a_{10}w^5 + a_{01}w^8 + a_{00}w^2 + b_{11}w^{10} + b_{10}w^4 + b_{01}w^7 + b_{00}w + c_{11}w^9 + c_{10}w^3 + c_{01}w^6 + c_{00} \\<br>  ~ &amp;= (((a_{11}, a_{10}), (a_{01}, a_{00})), ((b_{11}, b_{10}), (b_{01}, b_{00})), ((c_{11}, c_{10}), (c_{01}, c_{00}))) \\<br>  ~ &amp;= (a_{11}, b_{11}, c_{11}, a_{01}, b_{01}, c_{01}, a_{10}, b_{10}, c_{10}, a_{00}, b_{00}, c_{00})<br>\end{align*}<br>$$</p>
<p>幂次与系数转换关系如下:</p>
<p>$$<br>\begin{align*}<br>&amp;(  &amp;11&amp;, &amp;10&amp;,    &amp;9&amp;,  &amp;8&amp;,      &amp;7&amp;,  &amp;6&amp;,    &amp;5&amp;,  &amp;4&amp;,      &amp;3&amp;,  &amp;2&amp;,    &amp;1&amp;,  &amp;0&amp;  &amp;) \\<br>&amp;(((&amp;11&amp;,  &amp;5&amp;), ( &amp;8&amp;,  &amp;2&amp;)), ((&amp;10&amp;,  &amp;4&amp;), ( &amp;7&amp;,  &amp;1&amp;)), (( &amp;9&amp;,  &amp;3&amp;), ( &amp;6&amp;,  &amp;0&amp;))&amp;)<br>\end{align*}<br>$$</p>
<p>在这种情况下, 如果采用第二种方式表示扩域元素, 在需要将低维元素直接扩展成高维元素时, 低维元素保留在右侧, 左侧部分置零.</p>
<h2 id="BN-曲线上-R-ate-对的计算"><a href="#BN-曲线上-R-ate-对的计算" class="headerlink" title="BN 曲线上 R-ate 对的计算"></a>BN 曲线上 R-ate 对的计算</h2><h3 id="涉及的群"><a href="#涉及的群" class="headerlink" title="涉及的群"></a>涉及的群</h3><p>SM9 的双线性对涉及三个群的运算, $\mathbb{G}_1$, $\mathbb{G}_2$ 和 $\mathbb{G}_T$.</p>
<p>其中 $\mathbb{G}_1$, $\mathbb{G}_2$ 分别是 $F_{q}$, $F_{q^2}$ <strong>椭圆曲线上的点群</strong>, 而 $\mathbb{G}_T$ 是 $F_{q^{12}}$ 上的<strong>域元素群</strong>.</p>
<h3 id="扭曲线"><a href="#扭曲线" class="headerlink" title="扭曲线"></a>扭曲线</h3><p>R-ate 对的计算为 $f = R_a(P, Q)$, 其中 $P \in E(F_{q}), Q \in E&#39;(F_{q^2}), f \in F_{q^{12}}$.</p>
<p>这里输入的 $Q$ 原本应该是 $E(F_{q^{12}})$ 上的元素, 但是 BN 曲线存在一条扭曲线 $E&#39;(F_{q^2})$, 能够将原本需要在 $F_{q^{12}}$ 上进行的椭圆曲线点运算转换到 $F_{q^2}$ 上的椭圆曲线进行, 从而降低计算量.</p>
<p>转换函数与扭曲线参数 $\beta$ 有关, 记为 $\phi: E&#39; \rightarrow E: (x, y) \mapsto (\frac{x}{\beta^{\frac{1}{3}}}, \frac{y}{\beta^{\frac{1}{2}}})$.</p>
<p>所以, 在 R-ate 对的计算过程中, 对于需要 $Q$ 的运算中, <strong>只有椭圆曲线上的点运算是直接使用 $Q$ 进行计算的</strong>, 其余计算都需要先将 $Q$ 使用 $\phi$ 函数转换到 $E(F_{q^{12}})$ 上再进行计算.</p>
<h3 id="R-ate-计算"><a href="#R-ate-计算" class="headerlink" title="R-ate 计算"></a>R-ate 计算</h3><p>除了对 $Q$ 进行点运算时在 $F_{q^2}$ 上进行, 其余的计算都在 $F_{q^{12}}$ 上进行.</p>
<p>例如计算 $g$ 函数时, 正确的做法是计算 $g_{\phi(T), \phi(T)}(P&#39;)$ 和 $g_{\phi(T), \phi(Q)}(P&#39;)$, 其中 $P&#39;$ 是将 $P$ 直接扩展到 $E(F_{q^{12}})$ 的点.</p>
<p>以及后面计算 Frobenius 自同态的 $\pi_q$ 和 $\pi_{q^2}$ 时, 需要进行转换计算 $Q_1 = \phi^{-1}(\pi_q(\phi(Q)))$ 和 $Q_2 = \phi^{-1}(\pi_{q^2}(\phi(Q)))$.</p>
<h2 id="Frobenius-优化"><a href="#Frobenius-优化" class="headerlink" title="Frobenius 优化"></a>Frobenius 优化</h2><p>Frobenius 运算定义为: $\pi_q(x, y) = (x^q, y^q)$, 其中 $x, y$ 可以是扩域上的元素.</p>
<p>设 $x = a_nx^n + a_{n-1}x^{n-1} + \cdots + a_1$, 则:</p>
<p>$$<br>\begin{align*}<br>  x^q &amp;= (a_nx_n + a_{n-1}x_{n-1} + \cdots + a_1)^q \\<br>  ~ &amp;= \sum{(C_{q}^{i}C_{q-i}^{j}C_{q-i-j}^{k} \cdots )(a_nx_n)^i(a_{n-1}x_{n-1})^j(a_{n-2}x_{n-2})^k \cdots}<br>\end{align*}<br>$$</p>
<p>当 $q$ 为素数时, 由费马小定理可以知道 $a^{q} \equiv a \mod q$, 且当 $(C_{q}^{i}C_{q-i}^{j}C_{q-i-j}^{k} \cdots )$ 不为 1 时必为 $q$ 的倍数 (被 $q$ 整除).</p>
<p>所以在进行模 $q$ 运算后, $x^q = a_nx_n^q + a_{n-1}x_{n-1}^q + \cdots + a_1$.</p>
<p>可以看出来 Frobenius 运算就是在原有的系数上乘上了一个对应元素的 $q$ 次方, 在扩域元素确定的情况下, 这些值是可以被提前计算出来的, 因此将会被简化成 $n$ 次扩域乘法和 $n - 1$ 次扩域加法.</p>
<p>进一步, 由文献 <span class="exturl" data-url="aHR0cHM6Ly9kb2kub3JnLzEwLjExMDkvSUNDU0QuMjAxOS44ODQyOTA4">Simplification and Hardware Parallel Design of Frobenius Mapping Algorithm Based on SM9<i class="fa fa-external-link-alt"></i></span> 可以得到针对 SM9 参数的特定优化策略, 即每一项前面仅仅是乘了一个常数, 所以可以将常数值全部进行预计算从而提高后续计算速度, 此时只需要 $n - 1$ 次 $F_{q}$ 上的乘法就能完成运算.</p>
<h2 id="FinalExp-优化"><a href="#FinalExp-优化" class="headerlink" title="FinalExp 优化"></a>FinalExp 优化</h2><p>在 R-ate 对计算的最后, 有一步 $f = f^{\frac{q^{12} - 1}{r}}$.</p>
<p>这是一步在 $F_{q^{12}}$ 上的指数运算, 并且指数非常大, 常规运算时间开销非常夸张. 由文献 <span class="exturl" data-url="aHR0cHM6Ly9kb2kub3JnLzEwLjEwMDcvOTc4LTMtNjQyLTAzMjk4LTFfNg==">On the Final Exponentiation for Calculating Pairings on Ordinary Elliptic Curves<i class="fa fa-external-link-alt"></i></span> 可以得到对 BN 曲线的特定优化:</p>
<p>$$<br>\frac{q^{12} - 1}{r} = (q^6 - 1)(q^2 + 1)(\frac{q^4 - q^2 + 1}{r})<br>$$</p>
<p>前半部分的 $(q^6 - 1)(q^2 + 1)$ 称为 &quot;简单部分&quot;, 因为可以通过 Frobenius 和模逆运算快速得到结果 (并且 $q^6$ 可以仅通过共轭和取负得到结果).</p>
<p>后半部分的 $\frac{q^4 - q^2 + 1}{r}$ 称为 &quot;困难部分&quot;, 文献中根据 BN 曲线 $q$ 和 $r$ 关于 $t$ 的表达式继续分解得到:</p>
<p>$$<br>\frac{q^4 - q^2 + 1}{r} = \lambda_3q^3 + \lambda_2q^2 + \lambda_1q + \lambda<br>$$</p>
<p>其中:</p>
<p>$$<br>\left\{<br>\begin{align*}<br>  \lambda_3 &amp;= 1 \\<br>  \lambda_2 &amp;= 6t^2 + 1 \\<br>  \lambda_1 &amp;= -36t^3 - 18t^2 - 12t + 1 \\<br>  \lambda_0 &amp;= -36t^3 - 30t^2 - 18t - 2<br>\end{align*}<br>\right.<br>$$</p>
<p>因此困难部分的指数可以表示为:</p>
<p>$$<br>\begin{align*}<br>  \frac{q^4 - q^2 + 1}{r} = (6t^2q^2 + q^3 + q^2 + q) - (36(t^3 + t^3q) + 30t^2 + 18(t^2q + t) + 12tq + 2)<br>\end{align*}<br>$$</p>
<p>括号内只需要依次算出和 $t, q$ 有关的 $f$ 指数运算结果即可, 并且 $q$ 可以用 Frobenius 运算得到, 最后负号的内容一起求一次逆就行.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>花了一点篇幅记录了一下自己在实现 SM9 算法中遇到的问题和解决过程, 给自己补充了很多基础的密码学知识, 很多内容对于领域内人来说是基础中的基础, 但是初见还是容易让人晕头转向.</p>
<p>关于 SM9 的优化方法还有很多, 这里只简单提了一些, 自己实现的时候也是尽可能的加进去能看懂的优化方法了<del>毕竟没专门研究这方面, 不能一上来就挑战地狱难度副本</del>.</p>
<p>实现过程中也参考了开源的国密库 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2d1YW56aGkvR21TU0w=">GmSSL<i class="fa fa-external-link-alt"></i></span>, 毕竟调试的时候没有标准答案真的很痛苦.</p>
<p>最后放上自己实现的国密算法库 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3d3LXJtL2dtYWxn">gmalg<i class="fa fa-external-link-alt"></i></span>, 一个不依赖第三方库纯 Python 实现的国密算法库, 就不考虑性能了, 主要是学习国密算法原理<del>能用就行</del>.</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>SM9</tag>
        <tag>双线性对</tag>
        <tag>R-ate</tag>
        <tag>Frobenius</tag>
        <tag>FinalExp</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer 的训练与推理</title>
    <url>//posts/2023/08/29/transformer/</url>
    <content><![CDATA[<p>本文是对 Transformer 训练和预测过程的一些细节理解记录, 基于 <span class="exturl" data-url="aHR0cHM6Ly9qYWxhbW1hci5naXRodWIuaW8vaWxsdXN0cmF0ZWQtdHJhbnNmb3JtZXIv">The Illustrated Transformer<i class="fa fa-external-link-alt"></i></span>, 本文内符号也沿用此文.</p>
<p>主要是对于 Decoder 部分训练和预测时的区别以及并行化原理的总结.</p>
<span id="more"></span>

<h2 id="数据流动回顾"><a href="#数据流动回顾" class="headerlink" title="数据流动回顾"></a>数据流动回顾</h2><p><img data-src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png" alt="framework"></p>
<p>这张图是一个简略的 Transformer 整体框架图.</p>
<p>对于 Encoder 部分, 输入是 <code>(B, T, E)</code> 的形状, 其中 <code>B</code> 是批大小, <code>T</code> 是最大句长, <code>E</code> 是词向量长度; 输出形状和输入相同, 也是 <code>(B, T, E)</code>, 并且这同一份数据对应接下来 Decoder 其中一层注意力的 <code>Key</code> 和 <code>Value</code> 输入.</p>
<p>而对于 Decoder 部分, 同样设输入形状是 <code>(B, T, E)</code>, 那么它的输出形状也是和输入形状一样为 <code>(B, T, E)</code>.</p>
<p>最后的 Liner 和 Softmax 则是将 Decoder 的 <code>(B, T, E)</code> 映射到词典大小的概率矩阵 <code>(B, T, vocab_size)</code>.</p>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>Encoder 部分很简单, 在训练和预测上没有什么理解上的问题, 主要是 Decoder 部分是如何做到并行化的.</p>
<p>前面说到, 对于 Decoder 而言, 输入和输出的形状都是一样的 <code>(B, T, E)</code>, 那么首先要知道的是, 此处的并行化, 是在训练时将不同时间步的输出并行化了.</p>
<p>对于 <code>t</code> 个时间步的输入 $[x_0, x_1, \ldots, x_{t-1}]$, Decoder 的输出是 $[y_1, y_2, \ldots, y_t]$, 而它们的对应关系如下所示:</p>
<p>$$<br>\begin{bmatrix}<br>  x_0 &amp; ~ &amp; ~ &amp; ~ \\<br>  x_0 &amp; x_1 &amp; ~ &amp; ~ \\<br>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>  x_0 &amp; x_1 &amp; \ldots &amp; x_{t-1}<br>\end{bmatrix} \Rightarrow \begin{bmatrix}<br>  y_1 \\<br>  y_2 \\<br>  \vdots \\<br>  y_t<br>\end{bmatrix}<br>$$</p>
<p>而实现这种并行的关键是 Masked-Attension, 这个网上有很多举例, 简单来说就是对于 $y_i$, 通过 Mask 让它只包含了 $[x_0, x_1, \ldots, x_{i-1}]$ 的信息.</p>
<p>最后把这 <code>t</code> 个时刻的不同长度的输入序列 &quot;叠&quot; 在一起, 得到了等长的依次排在一起的不同时刻的输出.</p>
<h2 id="预测过程"><a href="#预测过程" class="headerlink" title="预测过程"></a>预测过程</h2><p>通过前面的训练过程可以知道, 从原理上来说, 虽然 Decoder 的输入和输出形状相同, 但是每个时间步的输入序列只有一个输出符号, 也就是预测出来的下一个输入符号, 因此 Decoder 在预测时, 是串行的循环过程, 直到出现终止符.</p>
<p><img data-src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" alt="decoder"></p>
<p>那么来看这张图, 预测时, Decoder 一开始的输入 <code>(B, T, E)</code> 里面, 只有第一个符号是有效的, 并且是开始符, 随后进行预测, 得到了输出数据 <code>(B, T, E)</code>, 但是只需要取输出的第一个符号, 并且也只有这个符号有效, 它将作为下一个要拼在输入序列后面的第二个符号.</p>
<p>随后重复上述步骤, 对于 <code>t</code> 时刻的操作, 输入的 <code>(B, T, E)</code> 内只有前 <code>t</code> 个符号有效, 而得到输出序列 <code>(B, T, E)</code> 后也只有前 <code>t</code> 个符号有效, 并且第 <code>t</code> 个符号就是下一个要接在输入序列后的预测符号, 而前 <code>t - 1</code> 个符号可以忽略不要, 因为它就是之前已经使用过的已经放在输入序列里的符号 (因为第 <code>i</code> 个输出符号只受前 <code>i - 1</code> 个输入符号的影响, 因此输入序列变长也不影响曾经的输出符号结果, 只有最后的第 <code>t</code> 个输出符号是新内容).</p>
<p>循环整个过程, 直到遇见终止符, 就可以解码出完整的预测结果.</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9qYWxhbW1hci5naXRodWIuaW8vaWxsdXN0cmF0ZWQtdHJhbnNmb3JtZXIv">The Illustrated Transformer<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>Transformer</tag>
      </tags>
  </entry>
</search>
